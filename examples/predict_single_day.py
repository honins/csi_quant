#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å•æ—¥ç›¸å¯¹ä½ç‚¹é¢„æµ‹è„šæœ¬
å…è®¸ç”¨æˆ·è¾“å…¥æ—¥æœŸï¼Œé¢„æµ‹è¯¥æ—¥æœŸæ˜¯å¦ä¸ºç›¸å¯¹ä½ç‚¹ï¼Œå¹¶éªŒè¯ç»“æœã€‚
æ”¯æŒä½¿ç”¨å·²è®­ç»ƒå¥½çš„AIæ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚
"""

import sys
import os
import logging
import json
from datetime import datetime

# å‡è®¾é¡¹ç›®æ ¹ç›®å½•åœ¨sys.pathä¸­ï¼Œæˆ–è€…æ‰‹åŠ¨æ·»åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.data.data_module import DataModule
from src.strategy.strategy_module import StrategyModule
from src.ai.ai_optimizer_improved import AIOptimizerImproved as AIOptimizer
from src.utils.utils import load_config
from src.prediction.prediction_utils import setup_logging, predict_and_validate
from src.utils.trade_date import is_trading_day

def save_prediction_results(prediction_result, predict_date_str, config, market_data=None, technical_indicators=None, model_analysis=None, detailed_analysis=None):
    """
    ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ–‡ä»¶
    
    Args:
        prediction_result: é¢„æµ‹ç»“æœå¯¹è±¡
        predict_date_str: é¢„æµ‹æ—¥æœŸå­—ç¬¦ä¸²
        config: é…ç½®ä¿¡æ¯
        market_data: å¸‚åœºæ•°æ®å­—å…¸
        technical_indicators: æŠ€æœ¯æŒ‡æ ‡å­—å…¸
        model_analysis: æ¨¡å‹åˆ†æç»“æœå­—å…¸
        detailed_analysis: è¯¦ç»†åˆ†ææ•°æ®å­—å…¸
    """
    try:
        # ç¡®ä¿resultsç›®å½•åŠå…¶å­ç›®å½•å­˜åœ¨
        results_path = config.get('results', {}).get('save_path', 'results')
        
        # åˆ›å»ºå­ç›®å½•ç»“æ„
        single_predictions_dir = os.path.join(results_path, 'single_predictions')
        reports_dir = os.path.join(results_path, 'reports')
        history_dir = os.path.join(results_path, 'history')
        
        for directory in [results_path, single_predictions_dir, reports_dir, history_dir]:
            if not os.path.exists(directory):
                os.makedirs(directory)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # å‡†å¤‡å®Œæ•´çš„ç»“æœæ•°æ®
        full_results = {
            'timestamp': timestamp,
            'prediction_date': predict_date_str,
            'prediction_time': datetime.now().isoformat(),
            'model_info': {
                'model_file': model_analysis.get('model_file', '') if model_analysis else '',
                'model_age_hours': model_analysis.get('model_age_hours', 0) if model_analysis else 0,
                'feature_count': model_analysis.get('feature_count', 0) if model_analysis else 0,
                'model_type': model_analysis.get('model_type', '') if model_analysis else ''
            },
            'market_data': market_data or {},
            'technical_indicators': technical_indicators or {},
            'prediction_results': {
                'is_predicted_low_point': prediction_result.predicted_low_point if prediction_result else False,
                'confidence': prediction_result.confidence if prediction_result else 0.0,
                'actual_low_point': prediction_result.actual_low_point if prediction_result else None,
                'prediction_correct': prediction_result.prediction_correct if prediction_result else None,
                'future_max_rise': prediction_result.future_max_rise if prediction_result else None,
                'days_to_rise': prediction_result.days_to_rise if prediction_result else None,
                'predict_price': prediction_result.predict_price if prediction_result else None
            },
            'model_analysis': model_analysis or {}
        }
        
        # ä¿å­˜JSONæ ¼å¼ç»“æœåˆ°å•ç‹¬é¢„æµ‹ç›®å½•
        json_filename = f'prediction_{predict_date_str}_{timestamp}.json'
        json_path = os.path.join(single_predictions_dir, json_filename)
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(full_results, f, indent=2, ensure_ascii=False, default=str)
        
        # ä¿å­˜å¯è¯»MarkdownæŠ¥å‘Šåˆ°æŠ¥å‘Šç›®å½•
        md_filename = f'report_{predict_date_str}_{timestamp}.md'
        md_path = os.path.join(reports_dir, md_filename)
        
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write("# ğŸ“‹ å•æ—¥ç›¸å¯¹ä½ç‚¹é¢„æµ‹æŠ¥å‘Š\n\n")
            f.write(f"## ğŸ“Š åŸºæœ¬ä¿¡æ¯\n\n")
            f.write(f"- **ğŸ¯ é¢„æµ‹æ—¥æœŸ**: {predict_date_str}\n")
            f.write(f"- **ğŸ• ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
            f.write(f"- **ğŸ“Š æŠ¥å‘Šç¼–å·**: `{timestamp}`\n\n")
            
            # æ¨¡å‹ä¿¡æ¯
            if model_analysis:
                f.write("## ğŸ¤– æ¨¡å‹ä¿¡æ¯\n\n")
                f.write("| é¡¹ç›® | å€¼ |\n")
                f.write("| --- | --- |\n")
                f.write(f"| æ¨¡å‹æ–‡ä»¶ | `{model_analysis.get('model_file', 'N/A')}` |\n")
                f.write(f"| æ¨¡å‹ç±»å‹ | {model_analysis.get('model_type', 'N/A')} |\n")
                f.write(f"| ç‰¹å¾ç»´åº¦ | {model_analysis.get('feature_count', 'N/A')} |\n")
                f.write(f"| æ¨¡å‹å¹´é¾„ | {model_analysis.get('model_age_description', 'N/A')} |\n\n")
            
            # å¸‚åœºæ•°æ®
            if market_data:
                f.write("## ğŸ“Š å¸‚åœºæ•°æ®\n\n")
                f.write("| æŒ‡æ ‡ | æ•°å€¼ |\n")
                f.write("| --- | --- |\n")
                f.write(f"| æ”¶ç›˜ä»· | **{market_data.get('close_price', 'N/A')}** |\n")
                f.write(f"| æ¶¨è·Œå¹… | {market_data.get('price_change', 'N/A')} |\n")
                f.write(f"| æˆäº¤é‡å˜åŒ– | {market_data.get('volume_change', 'N/A')} |\n")
                f.write(f"| æ³¢åŠ¨ç‡ | {market_data.get('volatility', 'N/A')} |\n\n")
            
            # æŠ€æœ¯æŒ‡æ ‡
            if technical_indicators:
                f.write("## ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡\n\n")
                f.write("| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |\n")
                f.write("| --- | --- | --- |\n")
                f.write(f"| RSI(14) | {technical_indicators.get('rsi', 'N/A')} | {technical_indicators.get('rsi_status', '')} |\n")
                f.write(f"| MACD | {technical_indicators.get('macd', 'N/A')} | {technical_indicators.get('macd_trend', '')} |\n")
                f.write(f"| MACDä¿¡å· | {technical_indicators.get('signal', 'N/A')} | - |\n")
                f.write(f"| MACDæŸ±çŠ¶ | {technical_indicators.get('hist', 'N/A')} | - |\n")
                f.write(f"| å¸ƒæ—å¸¦ä½ç½® | {technical_indicators.get('bb_position', 'N/A')} | {technical_indicators.get('bb_status', '')} |\n\n")
                
                # è¯¦ç»†çš„å¸ƒæ—å¸¦åˆ†æ
                if technical_indicators.get('bb_upper') and technical_indicators.get('bb_lower'):
                    f.write("### ğŸ“ å¸ƒæ—å¸¦è¯¦ç»†åˆ†æ\n\n")
                    f.write(f"- **ä¸Šè½¨**: {technical_indicators.get('bb_upper', 'N/A')}\n")
                    f.write(f"- **ä¸‹è½¨**: {technical_indicators.get('bb_lower', 'N/A')}\n")
                    f.write(f"- **ç›¸å¯¹ä½ç½®**: {technical_indicators.get('bb_position', 'N/A')}\n")
                    f.write(f"- **å¸‚åœºçŠ¶æ€**: {technical_indicators.get('bb_status', 'N/A')}\n\n")
            
            # ç‰¹å¾é‡è¦æ€§åˆ†æ
            if model_analysis and model_analysis.get('feature_importance'):
                f.write("## ğŸ”¬ ç‰¹å¾é‡è¦æ€§åˆ†æ\n\n")
                f.write("| æ’å | ç‰¹å¾åç§° | é‡è¦æ€§ |\n")
                f.write("| --- | --- | --- |\n")
                feature_importance = model_analysis.get('feature_importance', {})
                for i, (feature, importance) in enumerate(list(feature_importance.items())[:10]):
                    f.write(f"| {i+1} | {feature} | {importance:.4f} |\n")
                f.write("\n")
            
            # è¯¦ç»†åˆ†æç« èŠ‚
            if detailed_analysis:
                # å‡çº¿åˆ†æ
                if detailed_analysis.get('ma_analysis'):
                    f.write("## ğŸ“Š å‡çº¿è¯¦ç»†åˆ†æ\n\n")
                    ma_analysis = detailed_analysis['ma_analysis']
                    f.write("| å‡çº¿ | æ•°å€¼ | è·ç¦» | è¶‹åŠ¿ |\n")
                    f.write("| --- | --- | --- | --- |\n")
                    for ma_info in ma_analysis:
                        trend_icon = "ğŸ“ˆ" if ma_info['distance'] > 0 else "ğŸ“‰" if ma_info['distance'] < -1 else "â–"
                        f.write(f"| {ma_info['name']} | {ma_info['value']:.2f} | {ma_info['distance']:+.2f}% | {trend_icon} |\n")
                    f.write("\n")
                
                # AIæ¨¡å‹å†³ç­–åˆ†æ
                if detailed_analysis.get('ai_decision'):
                    f.write("## ğŸ¤– AIæ¨¡å‹å†³ç­–åˆ†æ\n\n")
                    ai_decision = detailed_analysis['ai_decision']
                    f.write(f"### é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ\n")
                    f.write(f"- **éä½ç‚¹æ¦‚ç‡**: {ai_decision.get('non_low_prob', 0):.4f} ({ai_decision.get('non_low_prob', 0):.2%})\n")
                    f.write(f"- **ä½ç‚¹æ¦‚ç‡**: {ai_decision.get('low_prob', 0):.4f} ({ai_decision.get('low_prob', 0):.2%})\n")
                    f.write(f"- **ç½®ä¿¡åº¦è¯„çº§**: {ai_decision.get('confidence_level', 'N/A')}\n\n")
                
                # å†³ç­–ä¾æ®åˆ†æ
                if detailed_analysis.get('decision_basis'):
                    f.write("## ğŸ§  å†³ç­–ä¾æ®åˆ†æ\n\n")
                    decision_basis = detailed_analysis['decision_basis']
                    for basis in decision_basis:
                        icon = "âœ…" if basis['support'] == 'strong' else "âš¡" if basis['support'] == 'partial' else "âŒ"
                        f.write(f"- {icon} **{basis['indicator']}**: {basis['description']}\n")
                    f.write("\n")
            
            # é¢„æµ‹ç»“æœ
            f.write("## ğŸ¯ é¢„æµ‹ç»“æœ\n\n")
            if prediction_result:
                result_text = "**æ˜¯ç›¸å¯¹ä½ç‚¹** âœ…" if prediction_result.predicted_low_point else "**ä¸æ˜¯ç›¸å¯¹ä½ç‚¹** âŒ"
                f.write(f"### AIé¢„æµ‹\n{result_text}\n\n")
                f.write(f"**ç½®ä¿¡åº¦**: `{prediction_result.confidence:.4f}` ({prediction_result.confidence:.2%})\n\n")
                
                if prediction_result.actual_low_point is not None:
                    actual_text = "**æ˜¯ç›¸å¯¹ä½ç‚¹** âœ…" if prediction_result.actual_low_point else "**ä¸æ˜¯ç›¸å¯¹ä½ç‚¹** âŒ"
                    f.write(f"### éªŒè¯ç»“æœ\n")
                    f.write(f"- **å®é™…ç»“æœ**: {actual_text}\n")
                    
                    if prediction_result.prediction_correct is not None:
                        correct_text = "**æ­£ç¡®** âœ…" if prediction_result.prediction_correct else "**é”™è¯¯** âŒ"
                        f.write(f"- **é¢„æµ‹å‡†ç¡®æ€§**: {correct_text}\n")
                    
                    if prediction_result.future_max_rise is not None:
                        f.write(f"- **æœªæ¥æœ€å¤§æ¶¨å¹…**: `{prediction_result.future_max_rise:.2%}`\n")
                    
                    if prediction_result.days_to_rise is not None and prediction_result.days_to_rise > 0:
                        rise_threshold = config.get('strategy', {}).get('rise_threshold', 0.04)
                        f.write(f"- **è¾¾åˆ°{rise_threshold:.1%}æ¶¨å¹…ç”¨æ—¶**: {prediction_result.days_to_rise}å¤©\n")
                    
                    f.write("\n")
                else:
                    f.write("> âš ï¸ æ— æ³•è·å–éªŒè¯æ•°æ®\n\n")
            else:
                f.write("> âŒ é¢„æµ‹å¤±è´¥\n\n")
            
            f.write("---\n")
            f.write("*ğŸ“ æŠ¥å‘Šç»“æŸ*\n")
        
        # æ›´æ–°é¢„æµ‹å†å²è®°å½•ï¼ˆä¿å­˜åœ¨historyå­ç›®å½•ï¼‰
        update_prediction_history(predict_date_str, full_results, history_dir)
        
        logging.getLogger("SingleDayPredictor").info(f"ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜:")
        logging.getLogger("SingleDayPredictor").info(f"   ğŸ“„ JSONæ•°æ®: {os.path.relpath(json_path)}")
        logging.getLogger("SingleDayPredictor").info(f"   ğŸ“‹ MarkdownæŠ¥å‘Š: {os.path.relpath(md_path)}")
        logging.getLogger("SingleDayPredictor").info(f"   ğŸ“Š å†å²è®°å½•: {os.path.relpath(os.path.join(history_dir, 'prediction_history.json'))}")
        
        return json_path, md_path
        
    except Exception as e:
        logging.getLogger("SingleDayPredictor").error(f"âŒ ä¿å­˜é¢„æµ‹ç»“æœå¤±è´¥: {e}")
        return None, None

def update_prediction_history(predict_date_str, results_data, history_dir):
    """
    æ›´æ–°é¢„æµ‹å†å²è®°å½•
    
    Args:
        predict_date_str: é¢„æµ‹æ—¥æœŸå­—ç¬¦ä¸²
        results_data: ç»“æœæ•°æ®
        history_dir: å†å²è®°å½•ä¿å­˜ç›®å½•
    """
    try:
        history_file = os.path.join(history_dir, 'prediction_history.json')
        
        # è¯»å–ç°æœ‰å†å²è®°å½•
        history = []
        if os.path.exists(history_file):
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            except:
                history = []
        
        # æ·»åŠ æ–°è®°å½•
        history_entry = {
            'date': predict_date_str,
            'timestamp': results_data['timestamp'],
            'prediction_time': results_data['prediction_time'],
            'predicted_low_point': results_data['prediction_results']['is_predicted_low_point'],
            'confidence': results_data['prediction_results']['confidence'],
            'actual_low_point': results_data['prediction_results']['actual_low_point'],
            'prediction_correct': results_data['prediction_results']['prediction_correct'],
            'model_file': results_data['model_info']['model_file']
        }
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ—¥æœŸçš„è®°å½•ï¼Œå¦‚æœå­˜åœ¨åˆ™æ›¿æ¢
        existing_index = None
        for i, entry in enumerate(history):
            if entry.get('date') == predict_date_str:
                existing_index = i
                break
        
        if existing_index is not None:
            history[existing_index] = history_entry
        else:
            history.append(history_entry)
        
        # æŒ‰æ—¥æœŸæ’åº
        history.sort(key=lambda x: x['date'], reverse=True)
        
        # ä¿å­˜å†å²è®°å½•
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2, ensure_ascii=False, default=str)
            
    except Exception as e:
        logging.getLogger("SingleDayPredictor").error(f"âŒ æ›´æ–°é¢„æµ‹å†å²è®°å½•å¤±è´¥: {e}")

def predict_single_day(predict_date_str: str, use_trained_model: bool = True):
    """
    é¢„æµ‹å•æ—¥ç›¸å¯¹ä½ç‚¹
    
    Args:
        predict_date_str: é¢„æµ‹æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
        use_trained_model: æ˜¯å¦ä½¿ç”¨å·²è®­ç»ƒå¥½çš„æ¨¡å‹ (é»˜è®¤True)
    
    Returns:
        bool: é¢„æµ‹æ˜¯å¦æˆåŠŸ
    """
    setup_logging()
    logger = logging.getLogger("SingleDayPredictor")

    try:
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'system.yaml')
        config = load_config(config_path=config_path)
        
        # åˆå§‹åŒ–æ¨¡å—
        data_module = DataModule(config)
        strategy_module = StrategyModule(config)
        ai_optimizer = AIOptimizer(config)

        predict_date = datetime.strptime(predict_date_str, "%Y-%m-%d")
        if not is_trading_day(predict_date.date()):
            logger.warning(f"{predict_date_str} ä¸æ˜¯Aè‚¡äº¤æ˜“æ—¥ï¼Œè·³è¿‡é¢„æµ‹ã€‚")
            return False
            
        logger.info(f"å¼€å§‹é¢„æµ‹æ—¥æœŸ: {predict_date.strftime('%Y-%m-%d')} æ˜¯å¦ä¸ºç›¸å¯¹ä½ç‚¹")
        
        if use_trained_model:
            logger.info("ä½¿ç”¨å·²è®­ç»ƒå¥½çš„AIæ¨¡å‹è¿›è¡Œé¢„æµ‹...")
            # å°è¯•åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹
            if not ai_optimizer._load_model():
                logger.error("âŒ æœªæ‰¾åˆ°å·²è®­ç»ƒçš„æ¨¡å‹ï¼")
                logger.error("ğŸ’¡ è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤è®­ç»ƒæ¨¡å‹ï¼š")
                logger.error("   python run.py ai -m optimize  # AIä¼˜åŒ–+è®­ç»ƒ")
                logger.error("   python run.py ai -m full      # å®Œæ•´é‡è®­ç»ƒ")
                return False

        if use_trained_model:
            # ä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹
            result = predict_with_trained_model(
                predict_date=predict_date,
                data_module=data_module,
                strategy_module=strategy_module,
                ai_optimizer=ai_optimizer,
                config=config,
                logger=logger
            )
        else:
            # ä½¿ç”¨åŸæœ‰æ–¹æ³•ï¼ˆé‡æ–°è®­ç»ƒæ¨¡å‹ï¼‰
            logger.info("é‡æ–°è®­ç»ƒAIæ¨¡å‹...")
            result = predict_and_validate(
                predict_date=predict_date,
                data_module=data_module,
                strategy_module=strategy_module,
                ai_optimizer=ai_optimizer,
                config=config,
                logger=logger
            )

        if result is None:
            logger.error("é¢„æµ‹å’ŒéªŒè¯è¿‡ç¨‹å¤±è´¥")
            return False

        if result.prediction_correct is not None:
            if result.prediction_correct:
                logger.info("âœ… é¢„æµ‹ä¸å®é™…ç›¸ç¬¦ï¼")
            else:
                logger.warning("âŒ é¢„æµ‹ä¸å®é™…ä¸ç¬¦ï¼")
        return True
        
    except Exception as e:
        logger.error(f"å•æ—¥é¢„æµ‹è„šæœ¬è¿è¡Œå¤±è´¥: {e}")
        return False

def predict_with_trained_model(
    predict_date: datetime,
    data_module,
    strategy_module,
    ai_optimizer,
    config,
    logger
):
    """
    ä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹
    
    Args:
        predict_date: é¢„æµ‹æ—¥æœŸ
        data_module: æ•°æ®æ¨¡å—å®ä¾‹
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        ai_optimizer: AIä¼˜åŒ–å™¨å®ä¾‹ï¼ˆå·²åŠ è½½æ¨¡å‹ï¼‰
        config: é…ç½®ä¿¡æ¯
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        PredictionResult: é¢„æµ‹ç»“æœ
    """
    from src.prediction.prediction_utils import PredictionResult
    from datetime import timedelta
    import os
    
    try:
        # è¾“å‡ºæ¨¡å‹ä¿¡æ¯
        logger.info("="*80)
        logger.info("ğŸ“‹ æ¨¡å‹ä¿¡æ¯ä¸ä¾æ®åˆ†æ")
        logger.info("="*80)
        
        # åˆå§‹åŒ–æ•°æ®æ”¶é›†å­—å…¸
        market_data = {}
        technical_indicators = {}
        model_analysis = {}
        detailed_analysis = {}
        
        # 1. æ£€æŸ¥å¹¶è¾“å‡ºæ¨¡å‹ç‰ˆæœ¬ä¿¡æ¯
        latest_model_path = os.path.join(ai_optimizer.models_dir, 'latest_improved_model.txt')
        if os.path.exists(latest_model_path):
            with open(latest_model_path, 'r') as f:
                model_path = f.read().strip()
                
                # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
                if not os.path.isabs(model_path):
                    # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆä»å½“å‰æ–‡ä»¶ä½ç½®å‘ä¸Šä¸¤çº§ï¼šexamples/predict_single_day.py -> é¡¹ç›®æ ¹ç›®å½•ï¼‰
                    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                    model_path = os.path.join(project_root, model_path)
                
                model_file = os.path.basename(model_path)
                model_analysis['model_file'] = model_file
                # ä»æ–‡ä»¶åæå–æ—¶é—´æˆ³
                if 'model_' in model_file:
                        timestamp_str = model_file.replace('model_', '').replace('.pkl', '')
                        try:
                            from datetime import datetime
                            model_time = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                            logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_file}")
                            logger.info(f"ğŸ• è®­ç»ƒæ—¶é—´: {model_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
                            
                            # è®¡ç®—æ¨¡å‹å¹´é¾„
                            model_age = datetime.now() - model_time
                            model_analysis['model_time'] = model_time.isoformat()
                            model_analysis['model_age_hours'] = (model_age.total_seconds() / 3600)
                            
                            if model_age.days == 0:
                                age_description = f"{model_age.seconds // 3600}å°æ—¶{(model_age.seconds % 3600) // 60}åˆ†é’Ÿ (éå¸¸æ–°é²œ)"
                                logger.info(f"ğŸ“… æ¨¡å‹å¹´é¾„: {age_description}")
                            else:
                                age_description = f"{model_age.days}å¤© {'(è¾ƒæ–°)' if model_age.days < 7 else '(éœ€è€ƒè™‘æ›´æ–°)' if model_age.days < 30 else '(å»ºè®®é‡æ–°è®­ç»ƒ)'}"
                                logger.info(f"ğŸ“… æ¨¡å‹å¹´é¾„: {age_description}")
                            
                            model_analysis['model_age_description'] = age_description
                        except:
                            logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_file}")
        
        # 2. è·å–ç‰¹å¾é‡è¦æ€§
        feature_importance = ai_optimizer.get_feature_importance()
        if feature_importance:
            logger.info("\nğŸ“Š ç‰¹å¾é‡è¦æ€§æ’åº (Top 10):")
            for i, (feature, importance) in enumerate(list(feature_importance.items())[:10]):
                logger.info(f"   {i+1:2d}. {feature:<20}: {importance:.4f}")
            model_analysis['feature_importance'] = feature_importance
        
        logger.info("\n" + "="*80)
        logger.info("ğŸ” é¢„æµ‹è¿‡ç¨‹è¯¦ç»†åˆ†æ")
        logger.info("="*80)
        
        # 1. è·å–é¢„æµ‹æ‰€éœ€çš„å†å²æ•°æ®ï¼ˆç”¨äºç‰¹å¾æå–ï¼‰
        history_days_needed = config["data"]["history_days"]
        start_date_for_prediction = predict_date - timedelta(days=history_days_needed)
        
        logger.info(f"ğŸ“ˆ æ•°æ®è·å–èŒƒå›´: {start_date_for_prediction.strftime('%Y-%m-%d')} è‡³ {predict_date.strftime('%Y-%m-%d')}")
        prediction_data = data_module.get_history_data(
            start_date=start_date_for_prediction.strftime('%Y-%m-%d'),
            end_date=predict_date.strftime('%Y-%m-%d')
        )
        
        if prediction_data.empty:
            logger.error("âŒ é¢„æµ‹æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹ã€‚")
            return None

        # é¢„å¤„ç†æ•°æ®
        prediction_data = data_module.preprocess_data(prediction_data)
        logger.info(f"âœ… æˆåŠŸè·å–å¹¶é¢„å¤„ç† {len(prediction_data)} æ¡å†å²æ•°æ®")
        
        # è·å–å½“å¤©çš„å…·ä½“æ•°æ®
        predict_day_data = prediction_data.iloc[-1:].copy()
        current_row = predict_day_data.iloc[0]
        
        # æ”¶é›†å¸‚åœºæ•°æ®
        market_data.update({
            'close_price': f"{current_row.get('close', 'N/A'):.2f}",
            'price_change': f"{current_row.get('price_change', 0):.2%}",
            'volume_change': f"{current_row.get('volume_change', 0):.2%}",
            'volatility': f"{current_row.get('volatility', 0):.4f}"
        })
        
        # è¾“å‡ºå½“æ—¥å…³é”®å¸‚åœºæ•°æ®
        logger.info(f"\nğŸ“Š {predict_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} å…³é”®å¸‚åœºæ•°æ®:")
        logger.info(f"   æ”¶ç›˜ä»·: {market_data['close_price']}")
        logger.info(f"   æ¶¨è·Œå¹…: {market_data['price_change']}")
        logger.info(f"   æˆäº¤é‡å˜åŒ–: {market_data['volume_change']}")
        logger.info(f"   æ³¢åŠ¨ç‡: {market_data['volatility']}")
        
        # æ”¶é›†æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        rsi_val = current_row.get('rsi', 50)
        rsi_status = '[è¶…å–]' if rsi_val < 30 else '[åå¼±]' if rsi_val < 40 else '[ä¸­æ€§]' if rsi_val < 60 else '[åå¼º]'
        macd_trend = '[é‡‘å‰è¶‹åŠ¿]' if current_row.get('hist', 0) > 0 else '[æ­»å‰è¶‹åŠ¿]'
        
        technical_indicators.update({
            'rsi': f"{rsi_val:.2f}",
            'rsi_status': rsi_status,
            'macd': f"{current_row.get('macd', 'N/A'):.4f}",
            'signal': f"{current_row.get('signal', 'N/A'):.4f}",
            'hist': f"{current_row.get('hist', 'N/A'):.4f}",
            'macd_trend': macd_trend
        })
        
        # è¾“å‡ºæŠ€æœ¯æŒ‡æ ‡
        logger.info(f"\nğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡åˆ†æ:")
        logger.info(f"   RSI(14): {technical_indicators['rsi']} {rsi_status}")
        logger.info(f"   MACD: {technical_indicators['macd']}")
        logger.info(f"   MACDä¿¡å·: {technical_indicators['signal']}")
        logger.info(f"   MACDæŸ±çŠ¶: {technical_indicators['hist']} {macd_trend}")
        
        # è¾“å‡ºå‡çº¿æƒ…å†µ
        ma5 = current_row.get('ma5', 0)
        ma10 = current_row.get('ma10', 0)
        ma20 = current_row.get('ma20', 0)
        ma60 = current_row.get('ma60', 0)
        close_price = current_row.get('close', 0)
        
        # æ”¶é›†å‡çº¿åˆ†ææ•°æ®
        ma_analysis = [
            {'name': 'MA5', 'value': ma5, 'distance': ((close_price - ma5) / ma5 * 100) if ma5 > 0 else 0},
            {'name': 'MA10', 'value': ma10, 'distance': ((close_price - ma10) / ma10 * 100) if ma10 > 0 else 0},
            {'name': 'MA20', 'value': ma20, 'distance': ((close_price - ma20) / ma20 * 100) if ma20 > 0 else 0},
            {'name': 'MA60', 'value': ma60, 'distance': ((close_price - ma60) / ma60 * 100) if ma60 > 0 else 0}
        ]
        detailed_analysis['ma_analysis'] = ma_analysis
        
        logger.info(f"\nğŸ“Š å‡çº¿åˆ†æ:")
        logger.info(f"   MA5:  {ma5:.2f} (è·ç¦»: {((close_price - ma5) / ma5 * 100):+.2f}%)")
        logger.info(f"   MA10: {ma10:.2f} (è·ç¦»: {((close_price - ma10) / ma10 * 100):+.2f}%)")
        logger.info(f"   MA20: {ma20:.2f} (è·ç¦»: {((close_price - ma20) / ma20 * 100):+.2f}%)")
        logger.info(f"   MA60: {ma60:.2f} (è·ç¦»: {((close_price - ma60) / ma60 * 100):+.2f}%)")
        
        # å¸ƒæ—å¸¦åˆ†æ
        bb_upper = current_row.get('bb_upper', 0)
        bb_lower = current_row.get('bb_lower', 0)
        if bb_upper > 0 and bb_lower > 0:
            bb_position = (close_price - bb_lower) / (bb_upper - bb_lower)
            bb_status = '[è¶…å–åŒºåŸŸ]' if bb_position < 0.2 else '[åå¼±åŒºåŸŸ]' if bb_position < 0.4 else '[ä¸­æ€§åŒºåŸŸ]' if bb_position < 0.6 else '[åå¼ºåŒºåŸŸ]' if bb_position < 0.8 else '[è¶…ä¹°åŒºåŸŸ]'
            
            technical_indicators.update({
                'bb_upper': f"{bb_upper:.2f}",
                'bb_lower': f"{bb_lower:.2f}",
                'bb_position': f"{bb_position:.2%}",
                'bb_status': bb_status
            })
            
            logger.info(f"\nğŸ“ å¸ƒæ—å¸¦åˆ†æ:")
            logger.info(f"   ä¸Šè½¨: {bb_upper:.2f}")
            logger.info(f"   ä¸‹è½¨: {bb_lower:.2f}")
            logger.info(f"   ä½ç½®: {bb_position:.2%} {bb_status}")
        
        # 2. ä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹
        logger.info(f"\nğŸ”® AIæ¨¡å‹é¢„æµ‹åˆ†æ:")
        prediction_result = ai_optimizer.predict_low_point(predict_day_data)
        
        # æ£€æŸ¥é¢„æµ‹ç»“æœæ˜¯å¦åŒ…å«é”™è¯¯
        if prediction_result is None or prediction_result.get("error"):
            error_msg = prediction_result.get("error", "é¢„æµ‹å¤±è´¥") if prediction_result else "é¢„æµ‹è¿”å›None"
            logger.error(f"âŒ AIæ¨¡å‹é¢„æµ‹å¤±è´¥: {error_msg}")
            return None
        
        is_predicted_low_point = prediction_result.get("is_low_point")
        confidence = prediction_result.get("confidence")
        # final_confidence å·²åºŸå¼ƒï¼Œç»Ÿä¸€ä½¿ç”¨ confidence
        prediction_proba = prediction_result.get("prediction_proba", [])
        
        # æ”¶é›†æ¨¡å‹åˆ†ææ•°æ®
        model_analysis.update({
            'model_type': prediction_result.get('model_type', ''),
            'feature_count': prediction_result.get('feature_count', 0),
            'prediction_proba': prediction_proba
        })
        
        # è¾“å‡ºé¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
        if len(prediction_proba) >= 2:
            logger.info(f"   éä½ç‚¹æ¦‚ç‡: {prediction_proba[0]:.4f} ({prediction_proba[0]:.2%})")
            logger.info(f"   ä½ç‚¹æ¦‚ç‡:   {prediction_proba[1]:.4f} ({prediction_proba[1]:.2%})")
        
        # ç½®ä¿¡åº¦è¯„çº§
        confidence_level = "æä½" if confidence < 0.3 else "è¾ƒä½" if confidence < 0.5 else "ä¸­ç­‰" if confidence < 0.7 else "è¾ƒé«˜" if confidence < 0.85 else "å¾ˆé«˜"
        logger.info(f"   ç½®ä¿¡åº¦è¯„çº§: {confidence_level} ({confidence:.2%})")
        
        # æ”¶é›†AIå†³ç­–åˆ†ææ•°æ®
        ai_decision = {
            'non_low_prob': prediction_proba[0] if len(prediction_proba) >= 2 else 0,
            'low_prob': prediction_proba[1] if len(prediction_proba) >= 2 else 0,
            'confidence_level': confidence_level,
            'confidence_value': confidence
        }
        detailed_analysis['ai_decision'] = ai_decision
        
        # é¢„æµ‹ç»“æœæ€»ç»“
        logger.info(f"\nğŸ¯ AIé¢„æµ‹ç»“æœ: \033[1;{'32' if is_predicted_low_point else '31'}m{predict_date.strftime('%Y-%m-%d')} {'æ˜¯' if is_predicted_low_point else 'ä¸æ˜¯'} ç›¸å¯¹ä½ç‚¹\033[0m")
        logger.info(f"   æ•´ä½“ç½®ä¿¡åº¦: \033[1m{confidence:.4f}\033[0m ({confidence:.2%})")
        
        # å†³ç­–ä¾æ®åˆ†æ
        logger.info(f"\nğŸ§  å†³ç­–ä¾æ®åˆ†æ:")
        
        # æ”¶é›†å†³ç­–ä¾æ®æ•°æ®
        decision_basis = []
        
        # RSIä¾æ®
        rsi_val = current_row.get('rsi', 50)
        if rsi_val < 30:
            logger.info(f"   âœ… RSIè¶…å– ({rsi_val:.1f} < 30) - æ”¯æŒä½ç‚¹åˆ¤æ–­")
            decision_basis.append({
                'indicator': 'RSI',
                'description': f'RSIè¶…å– ({rsi_val:.1f} < 30) - æ”¯æŒä½ç‚¹åˆ¤æ–­',
                'support': 'strong'
            })
        elif rsi_val < 40:
            logger.info(f"   âš¡ RSIåå¼± ({rsi_val:.1f} < 40) - éƒ¨åˆ†æ”¯æŒä½ç‚¹åˆ¤æ–­")
            decision_basis.append({
                'indicator': 'RSI',
                'description': f'RSIåå¼± ({rsi_val:.1f} < 40) - éƒ¨åˆ†æ”¯æŒä½ç‚¹åˆ¤æ–­',
                'support': 'partial'
            })
        else:
            logger.info(f"   âŒ RSIéè¶…å– ({rsi_val:.1f} â‰¥ 40) - ä¸æ”¯æŒä½ç‚¹åˆ¤æ–­")
            decision_basis.append({
                'indicator': 'RSI',
                'description': f'RSIéè¶…å– ({rsi_val:.1f} â‰¥ 40) - ä¸æ”¯æŒä½ç‚¹åˆ¤æ–­',
                'support': 'none'
            })
        
        # MACDä¾æ®
        macd_val = current_row.get('macd', 0)
        hist_val = current_row.get('hist', 0)
        if macd_val < 0 and hist_val > current_row.get('hist_prev', hist_val - 0.001):
            logger.info(f"   âœ… MACDè´Ÿå€¼ä½†æŸ±çŠ¶çº¿æ”¹å–„ - æ”¯æŒåè½¬ä¿¡å·")
            decision_basis.append({
                'indicator': 'MACD',
                'description': 'MACDè´Ÿå€¼ä½†æŸ±çŠ¶çº¿æ”¹å–„ - æ”¯æŒåè½¬ä¿¡å·',
                'support': 'strong'
            })
        elif macd_val < 0:
            logger.info(f"   âš¡ MACDä¸ºè´Ÿ ({macd_val:.4f}) - è¶‹åŠ¿åå¼±")
            decision_basis.append({
                'indicator': 'MACD',
                'description': f'MACDä¸ºè´Ÿ ({macd_val:.4f}) - è¶‹åŠ¿åå¼±',
                'support': 'partial'
            })
        else:
            logger.info(f"   âŒ MACDä¸ºæ­£ ({macd_val:.4f}) - è¶‹åŠ¿å‘ä¸Š")
            decision_basis.append({
                'indicator': 'MACD',
                'description': f'MACDä¸ºæ­£ ({macd_val:.4f}) - è¶‹åŠ¿å‘ä¸Š',
                'support': 'none'
            })
        
        # å‡çº¿ä¾æ®  
        ma_below_count = sum([close_price < ma5, close_price < ma10, close_price < ma20, close_price < ma60])
        if ma_below_count >= 3:
            logger.info(f"   âœ… ä»·æ ¼ä½äº{ma_below_count}/4æ¡å‡çº¿ - å¼ºçƒˆæ”¯æŒä½ç‚¹")
            decision_basis.append({
                'indicator': 'å‡çº¿',
                'description': f'ä»·æ ¼ä½äº{ma_below_count}/4æ¡å‡çº¿ - å¼ºçƒˆæ”¯æŒä½ç‚¹',
                'support': 'strong'
            })
        elif ma_below_count >= 2:
            logger.info(f"   âš¡ ä»·æ ¼ä½äº{ma_below_count}/4æ¡å‡çº¿ - éƒ¨åˆ†æ”¯æŒä½ç‚¹")
            decision_basis.append({
                'indicator': 'å‡çº¿',
                'description': f'ä»·æ ¼ä½äº{ma_below_count}/4æ¡å‡çº¿ - éƒ¨åˆ†æ”¯æŒä½ç‚¹',
                'support': 'partial'
            })
        else:
            logger.info(f"   âŒ ä»·æ ¼é«˜äºå¤šæ•°å‡çº¿ ({4-ma_below_count}/4æ¡) - ä¸æ”¯æŒä½ç‚¹")
            decision_basis.append({
                'indicator': 'å‡çº¿',
                'description': f'ä»·æ ¼é«˜äºå¤šæ•°å‡çº¿ ({4-ma_below_count}/4æ¡) - ä¸æ”¯æŒä½ç‚¹',
                'support': 'none'
            })
        
        # å¸ƒæ—å¸¦ä¾æ®
        if bb_upper > 0 and bb_lower > 0:
            if close_price <= bb_lower * 1.02:  # æ¥è¿‘ä¸‹è½¨
                logger.info(f"   âœ… ä»·æ ¼æ¥è¿‘å¸ƒæ—å¸¦ä¸‹è½¨ - æ”¯æŒä½ç‚¹åˆ¤æ–­")
                decision_basis.append({
                    'indicator': 'å¸ƒæ—å¸¦',
                    'description': 'ä»·æ ¼æ¥è¿‘å¸ƒæ—å¸¦ä¸‹è½¨ - æ”¯æŒä½ç‚¹åˆ¤æ–­',
                    'support': 'strong'
                })
            elif bb_position < 0.3:
                logger.info(f"   âš¡ ä»·æ ¼åœ¨å¸ƒæ—å¸¦ä¸‹æ–¹åŒºåŸŸ - éƒ¨åˆ†æ”¯æŒä½ç‚¹")
                decision_basis.append({
                    'indicator': 'å¸ƒæ—å¸¦',
                    'description': 'ä»·æ ¼åœ¨å¸ƒæ—å¸¦ä¸‹æ–¹åŒºåŸŸ - éƒ¨åˆ†æ”¯æŒä½ç‚¹',
                    'support': 'partial'
                })
            else:
                logger.info(f"   âŒ ä»·æ ¼è¿œç¦»å¸ƒæ—å¸¦ä¸‹è½¨ - ä¸æ”¯æŒä½ç‚¹åˆ¤æ–­")
                decision_basis.append({
                    'indicator': 'å¸ƒæ—å¸¦',
                    'description': 'ä»·æ ¼è¿œç¦»å¸ƒæ—å¸¦ä¸‹è½¨ - ä¸æ”¯æŒä½ç‚¹åˆ¤æ–­',
                    'support': 'none'
                })
        
        # æˆäº¤é‡ä¾æ®
        volume_change = current_row.get('volume_change', 0)
        if volume_change > 0.4:  # æ”¾é‡ä¸‹è·Œ
            logger.info(f"   âœ… æˆäº¤é‡æ”¾å¤§ ({volume_change:+.1%}) - å¯èƒ½ææ…Œæ€§æŠ›å”®")
            decision_basis.append({
                'indicator': 'æˆäº¤é‡',
                'description': f'æˆäº¤é‡æ”¾å¤§ ({volume_change:+.1%}) - å¯èƒ½ææ…Œæ€§æŠ›å”®',
                'support': 'strong'
            })
        elif volume_change < -0.2:  # ç¼©é‡ä¸‹è·Œ
            logger.info(f"   âš¡ æˆäº¤é‡èç¼© ({volume_change:+.1%}) - æŠ›å‹å‡è½»")
            decision_basis.append({
                'indicator': 'æˆäº¤é‡',
                'description': f'æˆäº¤é‡èç¼© ({volume_change:+.1%}) - æŠ›å‹å‡è½»',
                'support': 'partial'
            })
        else:
            logger.info(f"   â– æˆäº¤é‡å˜åŒ–é€‚ä¸­ ({volume_change:+.1%}) - ä¸­æ€§ä¿¡å·")
            decision_basis.append({
                'indicator': 'æˆäº¤é‡',
                'description': f'æˆäº¤é‡å˜åŒ–é€‚ä¸­ ({volume_change:+.1%}) - ä¸­æ€§ä¿¡å·',
                'support': 'none'
            })
        
        # ä¿å­˜å†³ç­–ä¾æ®æ•°æ®
        detailed_analysis['decision_basis'] = decision_basis

        # 3. éªŒè¯é¢„æµ‹ç»“æœï¼ˆå¦‚æœéœ€è¦ï¼‰
        logger.info(f"\n" + "="*80)
        logger.info("ğŸ“Š å†å²éªŒè¯åˆ†æ")
        logger.info("="*80)
        
        end_date_for_validation = predict_date + timedelta(days=config["default_strategy"]["max_days"] + 10)
        start_date_for_validation = predict_date - timedelta(days=config["default_strategy"]["max_days"] + 10)
        
        validation_data = data_module.get_history_data(
            start_date=start_date_for_validation.strftime('%Y-%m-%d'),
            end_date=end_date_for_validation.strftime('%Y-%m-%d')
        )

        if validation_data.empty:
            logger.warning("âš ï¸  éªŒè¯æ•°æ®ä¸ºç©ºï¼Œæ— æ³•éªŒè¯é¢„æµ‹ç»“æœã€‚")
            prediction_result_obj = PredictionResult(
                date=predict_date,
                predicted_low_point=is_predicted_low_point,
                actual_low_point=None,
                confidence=confidence,
                future_max_rise=None,
                days_to_rise=None,
                prediction_correct=None,
                predict_price=None
            )
            
            # ä¿å­˜ç»“æœ
            save_prediction_results(
                prediction_result_obj,
                predict_date.strftime('%Y-%m-%d'),
                config,
                market_data,
                technical_indicators,
                model_analysis,
                detailed_analysis
            )
            
            return prediction_result_obj

        # é¢„å¤„ç†éªŒè¯æ•°æ®
        full_validation_set = data_module.preprocess_data(validation_data)
        predict_date_data = full_validation_set[full_validation_set['date'] == predict_date]
        
        if predict_date_data.empty:
            logger.warning(f"âš ï¸  æ— æ³•åœ¨éªŒè¯æ•°æ®ä¸­æ‰¾åˆ° {predict_date.strftime('%Y-%m-%d')} çš„è®°å½•ï¼Œæ— æ³•éªŒè¯é¢„æµ‹ç»“æœã€‚")
            prediction_result_obj = PredictionResult(
                date=predict_date,
                predicted_low_point=is_predicted_low_point,
                actual_low_point=None,
                confidence=confidence,
                final_confidence=final_confidence,
                future_max_rise=None,
                days_to_rise=None,
                prediction_correct=None,
                predict_price=None
            )
            
            # ä¿å­˜ç»“æœ
            save_prediction_results(
                prediction_result_obj,
                predict_date.strftime('%Y-%m-%d'),
                config,
                market_data,
                technical_indicators,
                model_analysis,
                detailed_analysis
            )
            
            return prediction_result_obj

        predict_price = predict_date_data.iloc[0]['close']
        future_data = full_validation_set[full_validation_set['date'] > predict_date]
        
        if future_data.empty:
            logger.warning(f"âš ï¸  æ— æ³•è·å– {predict_date.strftime('%Y-%m-%d')} ä¹‹åçš„æ•°æ®ï¼Œæ— æ³•éªŒè¯é¢„æµ‹ç»“æœã€‚")
            prediction_result_obj = PredictionResult(
                date=predict_date,
                predicted_low_point=is_predicted_low_point,
                actual_low_point=None,
                confidence=confidence,
                final_confidence=final_confidence,
                future_max_rise=None,
                days_to_rise=None,
                prediction_correct=None,
                predict_price=predict_price
            )
            
            # ä¿å­˜ç»“æœ
            save_prediction_results(
                prediction_result_obj,
                predict_date.strftime('%Y-%m-%d'),
                config,
                market_data,
                technical_indicators,
                model_analysis,
                detailed_analysis
            )
            
            return prediction_result_obj

        # è·å–é¢„æµ‹æ—¥çš„index
        predict_index = predict_date_data.iloc[0]['index']
        max_rise = 0.0
        days_to_rise = 0
        rise_threshold = config["default_strategy"]["rise_threshold"]
        max_days = config["default_strategy"]["max_days"]
        
        logger.info(f"ğŸ“ˆ æœªæ¥{max_days}å¤©è¡¨ç°è¿½è¸ª:")
        logger.info(f"   é¢„æµ‹æ—¥ä»·æ ¼: {predict_price:.2f}")
        logger.info(f"   ç›®æ ‡æ¶¨å¹…: {rise_threshold:.1%}")
        
        # è®¡ç®—æœªæ¥æœ€å¤§æ¶¨å¹…å’Œè¾¾åˆ°ç›®æ ‡æ¶¨å¹…æ‰€éœ€å¤©æ•°
        daily_performance = []
        for i, row in future_data.iterrows():
            rise_rate = (row['close'] - predict_price) / predict_price
            days_elapsed = row['index'] - predict_index
            
            if days_elapsed <= max_days:
                daily_performance.append({
                    'day': days_elapsed,
                    'date': row['date'],
                    'price': row['close'],
                    'rise': rise_rate
                })
            
            if rise_rate > max_rise:
                max_rise = rise_rate
                
            if rise_rate >= rise_threshold and days_to_rise == 0:
                days_to_rise = days_elapsed

        # æ˜¾ç¤ºå‰å‡ å¤©çš„è¯¦ç»†è¡¨ç°
        for i, perf in enumerate(daily_performance[:min(10, len(daily_performance))]):
            status = "âœ…è¾¾æ ‡" if perf['rise'] >= rise_threshold else "ğŸ“ˆä¸Šæ¶¨" if perf['rise'] > 0 else "ğŸ“‰ä¸‹è·Œ"
            logger.info(f"   ç¬¬{perf['day']}å¤© ({perf['date']}): {perf['price']:.2f} ({perf['rise']:+.2%}) {status}")

        actual_is_low_point = max_rise >= rise_threshold

        logger.info(f"\nğŸ“‹ éªŒè¯ç»“æœæ€»ç»“:")
        logger.info(f"   å®é™…æ˜¯å¦ä¸ºç›¸å¯¹ä½ç‚¹: {'âœ… æ˜¯' if actual_is_low_point else 'âŒ å¦'}")
        logger.info(f"   æœªæ¥{max_days}å¤©æœ€å¤§æ¶¨å¹…: {max_rise:.2%}")
        if days_to_rise > 0:
            logger.info(f"   è¾¾åˆ°{rise_threshold:.1%}æ¶¨å¹…ç”¨æ—¶: {days_to_rise}å¤©")
        else:
            logger.info(f"   æœªåœ¨{max_days}å¤©å†…è¾¾åˆ°{rise_threshold:.1%}æ¶¨å¹…")
        
        # é¢„æµ‹å‡†ç¡®æ€§åˆ†æ
        prediction_correct = is_predicted_low_point == actual_is_low_point
        logger.info(f"\nğŸ¯ é¢„æµ‹å‡†ç¡®æ€§: {'âœ… æ­£ç¡®' if prediction_correct else 'âŒ é”™è¯¯'}")
        
        if prediction_correct:
            if is_predicted_low_point:
                logger.info(f"   ğŸ‰ æˆåŠŸè¯†åˆ«å‡ºç›¸å¯¹ä½ç‚¹ï¼æœªæ¥æœ€å¤§æ”¶ç›Š{max_rise:.2%}")
            else:
                logger.info(f"   âœ… æ­£ç¡®é¿å¼€éä½ç‚¹ï¼Œé¿å…äº†å¯èƒ½çš„æŸå¤±")
        else:
            if is_predicted_low_point and not actual_is_low_point:
                logger.info(f"   âš ï¸  è¯¯åˆ¤ä¸ºä½ç‚¹ï¼ˆå‡é˜³æ€§ï¼‰ï¼Œå¯èƒ½å¯¼è‡´è¿‡æ—©å…¥åœº")
            else:
                logger.info(f"   ğŸ˜” é”™è¿‡çœŸæ­£çš„ä½ç‚¹ï¼ˆå‡é˜´æ€§ï¼‰ï¼Œé”™å¤±äº†{max_rise:.2%}çš„æ”¶ç›Šæœºä¼š")

        logger.info("="*80)

        prediction_result_obj = PredictionResult(
            date=predict_date,
            predicted_low_point=is_predicted_low_point,
            actual_low_point=actual_is_low_point,
            confidence=confidence,
            future_max_rise=max_rise,
            days_to_rise=days_to_rise,
            prediction_correct=prediction_correct,
            predict_price=predict_price
        )
        
        # ä¿å­˜ç»“æœ
        save_prediction_results(
            prediction_result_obj,
            predict_date.strftime('%Y-%m-%d'),
            config,
            market_data,
            technical_indicators,
            model_analysis,
            detailed_analysis
        )

        return prediction_result_obj

    except Exception as e:
        logger.error(f"âŒ ä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python predict_single_day.py <YYYY-MM-DD> [--retrain]")
        print("ç¤ºä¾‹: python predict_single_day.py 2024-06-01")
        print("ç¤ºä¾‹: python predict_single_day.py 2024-06-01 --retrain")
        sys.exit(1)
    
    predict_date_str = sys.argv[1]
    use_trained_model = "--retrain" not in sys.argv
    
    if use_trained_model:
        print("ğŸ”® ä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹...")
    else:
        print("ğŸ”„ é‡æ–°è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹...")
    
    success = predict_single_day(predict_date_str, use_trained_model)
    sys.exit(0 if success else 1)


