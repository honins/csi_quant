#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
AIé¢„æµ‹æ¨¡å‹æ»šåŠ¨å›æµ‹è„šæœ¬

è¯¥è„šæœ¬å®ç°AIé¢„æµ‹æ¨¡å‹çš„æ»šåŠ¨å›æµ‹ï¼Œæ¨¡æ‹Ÿæ¨¡å‹åœ¨ä¸åŒæ—¶é—´ç‚¹è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹ï¼Œ
å¹¶ç»Ÿè®¡é¢„æµ‹çš„æˆåŠŸç‡ï¼Œä»¥æ›´çœŸå®åœ°è¯„ä¼°æ¨¡å‹çš„é•¿æœŸè¡¨ç°ã€‚
"""

import sys
import os
import logging
# from matplotlib import font_manager
import pandas as pd
from datetime import datetime, timedelta
# import matplotlib.pyplot as plt
# plt.rcParams['axes.unicode_minus'] = False    # æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
# import matplotlib.dates as mdates
import numpy as np
from sklearn.calibration import calibration_curve
from sklearn.metrics import brier_score_loss, log_loss

# å‡è®¾é¡¹ç›®æ ¹ç›®å½•åœ¨sys.pathä¸­ï¼Œæˆ–è€…æ‰‹åŠ¨æ·»åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.data.data_module import DataModule
from src.strategy.strategy_module import StrategyModule
from src.ai.ai_optimizer_improved import AIOptimizerImproved as AIOptimizer
from src.utils.utils import load_config, resolve_confidence_param
from src.prediction.prediction_utils import setup_logging, predict_and_validate
from src.utils.trade_date import is_trading_day

def run_rolling_backtest(start_date_str: str, end_date_str: str, training_window_days: int = 365, 
                         reuse_model: bool = True, retrain_interval_days: int = None,
                         generate_report: bool = True, report_dir: str = None):
    setup_logging()
    logger = logging.getLogger("RollingBacktest")

    try:
        # ä½¿ç”¨æ ‡å‡†é…ç½®åŠ è½½å™¨ï¼ˆè‡ªåŠ¨åˆå¹¶æ‰€æœ‰é…ç½®æ–‡ä»¶ï¼‰
        from src.utils.config_loader import load_config as load_config_improved
        config = load_config_improved()
        
        # åº”ç”¨è®­ç»ƒç­–ç•¥é…ç½®
        if retrain_interval_days is not None:
            config.setdefault('ai', {})['retrain_interval_days'] = retrain_interval_days
        config.setdefault('ai', {})['enable_model_reuse'] = reuse_model
        
        # åˆå§‹åŒ–æ¨¡å—
        data_module = DataModule(config)
        strategy_module = StrategyModule(config)
        # ä½¿ç”¨AIä¼˜åŒ–å™¨
        from src.ai.ai_optimizer_improved import AIOptimizerImproved
        ai_optimizer = AIOptimizerImproved(config)

        # ğŸ”’ ç¦æ­¢å›æµ‹è¿‡ç¨‹ä¸­è‡ªåŠ¨è®­ç»ƒæ¨¡å‹ï¼Œåªå…è®¸ä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹
        if not ai_optimizer._load_model():
            logger.error("âŒ æœªæ‰¾åˆ°å·²è®­ç»ƒçš„æ¨¡å‹ï¼")
            logger.error("ğŸ’¡ è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤è®­ç»ƒæ¨¡å‹ï¼š")
            logger.error("   python run.py ai -m optimize  # AIä¼˜åŒ–+è®­ç»ƒ")
            logger.error("   python run.py ai -m full      # å®Œæ•´é‡è®­ç»ƒ")
            return {
                'success': False,
                'error': 'æœªæ‰¾åˆ°å·²è®­ç»ƒæ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒï¼'
            }

        start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
        end_date = datetime.strptime(end_date_str, "%Y-%m-%d")

        results = []
        current_date = start_date
        training_count = 0  # è®°å½•å®é™…è®­ç»ƒæ¬¡æ•°

        # é¢„å…ˆè·å–æ‰€æœ‰å¯ç”¨äº¤æ˜“æ—¥
        all_data = data_module.get_history_data(start_date=start_date, end_date=end_date)
        all_data = data_module.preprocess_data(all_data)
        available_dates = set(pd.to_datetime(all_data['date']).dt.date)
        
        # æ–°å¢ï¼šæ§åˆ¶å‰Nå¤©çš„è¯¦ç»†æ—¥å¿—è¾“å‡ºï¼ˆé»˜è®¤å‰5å¤©ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
        try:
            first_n_days = int(os.environ.get('RB_FIRST_N_DAYS', '5'))
        except Exception:
            first_n_days = 5
        detailed_days_counter = 0
        
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸš€ æ»šåŠ¨å›æµ‹é…ç½®")
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“… å›æµ‹æœŸé—´: {start_date_str} è‡³ {end_date_str}")
        logger.info(f"ğŸ¤– åªä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹: å¯ç”¨")
        logger.info(f"ğŸ“Š å¯ç”¨äº¤æ˜“æ—¥: {len(available_dates)} å¤©")
        logger.info(f"ğŸ“ å°†è¾“å‡ºå‰ {first_n_days} å¤©çš„è¯¦ç»†é¢„æµ‹æ—¥å¿—ï¼ˆconfidence ä¸ final_confidence åˆ†å¸ƒï¼‰")
        logger.info(f"{'='*60}")

        while current_date <= end_date:
            # æ–°å¢ï¼šåˆ¤æ–­è¯¥æ—¥æœŸæ˜¯å¦åœ¨äº¤æ˜“æ•°æ®æºä¸­
            if current_date.date() not in available_dates:
                current_date += timedelta(days=1)
                continue
            if not is_trading_day(current_date.date()):
                current_date += timedelta(days=1)
                continue

            logger.info(f"\n--- æ»šåŠ¨å›æµ‹æ—¥æœŸ: {current_date.strftime('%Y-%m-%d')} ---")

            # åªç”¨å·²è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹å’ŒéªŒè¯
            result = predict_and_validate(
                predict_date=current_date,
                data_module=data_module,
                strategy_module=strategy_module,
                ai_optimizer=ai_optimizer,
                config=config,
                logger=logger,
                force_retrain=False,  # ç¦æ­¢è‡ªåŠ¨è®­ç»ƒ
                only_use_trained_model=True  # ç¦æ­¢ä»»ä½•è®­ç»ƒå’Œä¿å­˜
            )

            # å‰Nå¤©è¯¦ç»†æ—¥å¿—ï¼šè¾“å‡º confidence å’Œ final_confidence åŠé˜ˆå€¼
            if result is not None and getattr(result, 'date', None) is not None and detailed_days_counter < first_n_days:
                try:
                    # å›ºå®šé˜ˆå€¼ï¼šä»é…ç½®è¯»å–
                    final_threshold = resolve_confidence_param(config, 'final_threshold', 0.5)
                    logger.info("[è¯¦ç»†æ—¥å¿—-é˜ˆå€¼ä¸ç½®ä¿¡åº¦]")
                    logger.info(f"  é˜ˆå€¼(final_threshold): {final_threshold:.4f}")
                    logger.info(f"  confidence: {getattr(result, 'confidence', None):.4f}  | final_confidence: {getattr(result, 'final_confidence', None):.4f}")
                    logger.info(f"  é¢„æµ‹ç»“æœ: {'æ˜¯ä½ç‚¹' if getattr(result, 'predicted_low_point', False) else 'éä½ç‚¹'}  | å®é™…: {('æ˜¯ä½ç‚¹' if getattr(result, 'actual_low_point', False) else 'é/æœªçŸ¥')}  | æ˜¯å¦æ­£ç¡®: {getattr(result, 'prediction_correct', None)}")
                except Exception as e:
                    logger.warning(f"è¾“å‡ºè¯¦ç»†æ—¥å¿—æ—¶å‡ºé”™: {e}")
                detailed_days_counter += 1

            # ç»Ÿè®¡è®­ç»ƒæ¬¡æ•°ï¼ˆç†è®ºä¸Šåº”ä¸º0ï¼‰
            if hasattr(ai_optimizer, '_last_training_date') and ai_optimizer._last_training_date == current_date:
                training_count += 1

            if result is not None and getattr(result, 'date', None) is not None:
                results.append(result)

            current_date += timedelta(days=1) # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªæ—¥æœŸ

        # ç»Ÿè®¡å’Œå¯è§†åŒ–ç»“æœ
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“Š å›æµ‹æ•ˆç‡ç»Ÿè®¡")
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ¯ æ€»å›æµ‹å¤©æ•°: {len(results)}")
        logger.info(f"ğŸ”„ å®é™…è®­ç»ƒæ¬¡æ•°: {training_count}")
        logger.info(f"âš¡ æ•ˆç‡æå‡: {((len(results) - training_count) / len(results) * 100):.1f}%")
        logger.info(f"{'='*60}")
        
        results_df = pd.DataFrame([vars(r) for r in results])
        if 'date' not in results_df.columns:
            logger.error(f"ç»“æœDataFrameç¼ºå°‘dateåˆ—ï¼Œå®é™…åˆ—: {results_df.columns.tolist()}")
            raise ValueError("ç»“æœDataFrameç¼ºå°‘dateåˆ—")
        # ç¡®ä¿dateä¸ºdatetimeç±»å‹
        results_df['date'] = pd.to_datetime(results_df['date'])
        results_df.set_index('date', inplace=True)
        # ç¡®ä¿prediction_correctä¸ºboolç±»å‹ - ä¿®å¤FutureWarning
        results_df['prediction_correct'] = results_df['prediction_correct'].fillna(False).infer_objects(copy=False).astype(bool)

        # è¿‡æ»¤æ‰æ— æ³•éªŒè¯çš„è¡Œ
        results_df_validated = results_df.dropna(subset=['prediction_correct'])

        if not results_df_validated.empty:
            total_predictions = len(results_df_validated)
            correct_predictions = results_df_validated['prediction_correct'].sum()
            success_rate = (correct_predictions / total_predictions) if total_predictions > 0 else 0

            logger.info("\n--- æ»šåŠ¨å›æµ‹ç»Ÿè®¡ç»“æœ ---")
            logger.info(f"æ€»é¢„æµ‹æ—¥æœŸæ•° (å¯éªŒè¯): {total_predictions}")
            logger.info(f"æ­£ç¡®é¢„æµ‹æ•°: {correct_predictions}")
            logger.info(f"é¢„æµ‹æˆåŠŸç‡: {success_rate:.2%}")

            # ========== åˆ†ç±»æŒ‡æ ‡ï¼ˆPrecision / Recall / F1 / Specificity / Balanced Accuracyï¼‰==========
            # ä»…ä½¿ç”¨å¯éªŒè¯çš„æ•°æ®è¡Œè®¡ç®—æ··æ·†çŸ©é˜µ
            y_pred = results_df_validated['predicted_low_point'].astype(bool)
            y_true = results_df_validated['actual_low_point'].astype(bool)

            tp = int(((y_pred == True) & (y_true == True)).sum())
            fp = int(((y_pred == True) & (y_true == False)).sum())
            tn = int(((y_pred == False) & (y_true == False)).sum())
            fn = int(((y_pred == False) & (y_true == True)).sum())

            pred_pos = tp + fp
            pred_neg = tn + fn
            actual_pos = tp + fn
            actual_neg = tn + fp

            success_rate = (tp + tn) / max((tp + tn + fp + fn), 1)
            precision = tp / max((tp + fp), 1) if (tp + fp) > 0 else 0.0
            recall = tp / max((tp + fn), 1) if (tp + fn) > 0 else 0.0
            specificity = tn / max((tn + fp), 1) if (tn + fp) > 0 else 0.0
            balanced_acc = (recall + specificity) / 2.0
            f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0
            
            # ç»Ÿä¸€ä½¿ç”¨â€œå¯éªŒè¯æ ·æœ¬æ•°â€
            total_predictions_validated = int((tp + tn + fp + fn))
        
            # æ–°å¢ï¼šå…ˆåˆå§‹åŒ–æ¦‚ç‡æ ¡å‡†ç›¸å…³å˜é‡ï¼Œé¿å…ä¸Šæ–¹è¯Šæ–­å¼‚å¸¸æ—¶æœªå®šä¹‰
            brier_value = None
            logloss_value = None
            ece_value = None
            calib_bin_rows = []
            reliability_points = []
        
            # æ–°å¢ï¼šç½®ä¿¡åº¦åˆ†å¸ƒè¯Šæ–­ï¼ˆconfidence ä¸ final_confidenceï¼‰
            try:
                final_series = results_df['final_confidence'].astype(float).dropna()
                conf_series = results_df['confidence'].astype(float).dropna()

                def _safe_stat(s: pd.Series):
                    if s.empty:
                        return {
                            'mean': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0,
                            'q10': 0.0, 'q25': 0.0, 'q50': 0.0, 'q75': 0.0, 'q90': 0.0
                        }
                    qs = s.quantile([0.1, 0.25, 0.5, 0.75, 0.9])
                    return {
                        'mean': float(s.mean()),
                        'std': float(s.std(ddof=0)),
                        'min': float(s.min()),
                        'max': float(s.max()),
                        'q10': float(qs.loc[0.1]),
                        'q25': float(qs.loc[0.25]),
                        'q50': float(qs.loc[0.5]),
                        'q75': float(qs.loc[0.75]),
                        'q90': float(qs.loc[0.9]),
                    }

                conf_stat = _safe_stat(conf_series)
                final_stat = _safe_stat(final_series)

                # ç›´æ–¹åˆ†å¸ƒï¼ˆfinal_confidenceï¼‰ï¼šå«é˜ˆå€¼é™„è¿‘çš„ç»†åˆ†
                final_threshold = resolve_confidence_param(config, 'final_threshold', 0.5)
                bins = [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]
                bin_labels = ["[0.0,0.2)", "[0.2,0.4)", "[0.4,0.5)", "[0.5,0.6)", "[0.6,0.8)", "[0.8,1.0]"]
                bin_counts = {lbl: 0 for lbl in bin_labels}
                if len(final_series) > 0:
                    counts, _ = np.histogram(final_series, bins=bins)
                    for i, lbl in enumerate(bin_labels):
                        bin_counts[lbl] = int(counts[i])
                bin_perc = {k: (v / len(final_series) * 100 if len(final_series) > 0 else 0.0) for k, v in bin_counts.items()}

                # ç°åŒº
                gray_width = 0.05
                gray_lower = max(0.0, final_threshold - gray_width)
                gray_upper = min(1.0, final_threshold + gray_width)
                gray_mask = (results_df['final_confidence'] >= gray_lower) & (results_df['final_confidence'] <= gray_upper)
                gray_df = results_df[gray_mask]
                gray_total = len(gray_df)
                gray_pos = int((gray_df['predicted_low_point'] == True).sum()) if gray_total > 0 else 0
                gray_correct = int((gray_df['prediction_correct'] == True).sum()) if gray_total > 0 else 0

                # ç›¸å…³æ€§ï¼šfinal_confidence ä¸ future_max_riseã€prediction_correct
                corr_final_rise = 0.0
                corr_final_correct = 0.0
                try:
                    tmp = results_df[['final_confidence', 'future_max_rise']].dropna()
                    if not tmp.empty and tmp['final_confidence'].nunique() > 1 and tmp['future_max_rise'].nunique() > 1:
                        corr_final_rise = float(tmp['final_confidence'].corr(tmp['future_max_rise']))
                except Exception:
                    pass
                try:
                    tmp2 = results_df[['final_confidence', 'prediction_correct']].dropna()
                    if not tmp2.empty and tmp2['final_confidence'].nunique() > 1 and tmp2['prediction_correct'].nunique() > 1:
                        corr_final_correct = float(tmp2['final_confidence'].corr(tmp2['prediction_correct'].astype(float)))
                except Exception:
                    pass

                logger.info("\n--- ç½®ä¿¡åº¦åˆ†å¸ƒè¯Šæ–­ ---")
                logger.info(f"final_confidence: mean={final_stat['mean']:.4f}, std={final_stat['std']:.4f}, min={final_stat['min']:.4f}, max={final_stat['max']:.4f}")
                logger.info(f"quantiles(10/25/50/75/90): {final_stat['q10']:.4f}/{final_stat['q25']:.4f}/{final_stat['q50']:.4f}/{final_stat['q75']:.4f}/{final_stat['q90']:.4f}")
                logger.info(f"confidence: mean={conf_stat['mean']:.4f}, std={conf_stat['std']:.4f}, min={conf_stat['min']:.4f}, max={conf_stat['max']:.4f}")
                logger.info(f"åˆ†ç®±(final_confidence)ï¼š" + ", ".join([f"{lbl}: {bin_counts[lbl]} ({bin_perc[lbl]:.2f}%)" for lbl in bin_labels]))
                logger.info(f"é˜ˆå€¼(final_threshold)={final_threshold:.2f}ï¼Œç°åŒº[{gray_lower:.2f}, {gray_upper:.2f}] è¦†ç›–: {gray_total} æ¡ï¼Œå æ¯” {(gray_total/len(results_df)*100 if len(results_df)>0 else 0):.2f}%ï¼›ç°åŒºä¸­é¢„æµ‹æ­£ç±» {gray_pos} æ¡ï¼Œæ­£ç¡® {gray_correct} æ¡")
                logger.info(f"ç›¸å…³æ€§ï¼šfinal_confidence vs future_max_rise = {corr_final_rise:.3f}ï¼Œfinal_confidence vs prediction_correct = {corr_final_correct:.3f}")
            except Exception as e:
                logger.warning(f"ç½®ä¿¡åº¦åˆ†å¸ƒè¯Šæ–­å¤±è´¥: {e}")

            # æ–°å¢ï¼šæ¦‚ç‡æ ¡å‡†è¯„ä¼°ï¼ˆBrier / LogLoss / ECE & å¯é æ€§è¡¨ï¼‰
            try:
                if not results_df_validated.empty and 'final_confidence' in results_df_validated.columns and 'actual_low_point' in results_df_validated.columns:
                    y_true_arr = results_df_validated['actual_low_point'].astype(int).values
                    y_prob_arr = results_df_validated['final_confidence'].astype(float).values
                    mask = ~np.isnan(y_prob_arr)
                    y_true_f = y_true_arr[mask]
                    y_prob_f = np.clip(y_prob_arr[mask], 1e-6, 1 - 1e-6)

                    if y_true_f.size > 0 and np.unique(y_true_f).size > 1:
                        brier_value = float(brier_score_loss(y_true_f, y_prob_f))
                        logloss_value = float(log_loss(y_true_f, y_prob_f))

                        # è®¡ç®— ECE ä¸å¯é æ€§è¡¨ï¼ˆ10 ç­‰å®½åˆ†ç®±ï¼‰
                        n_bins = 10
                        bins = np.linspace(0.0, 1.0, n_bins + 1)
                        # å°† 1.0 æ”¾å…¥æœ€åä¸€ä¸ªç®±
                        bin_ids = np.digitize(y_prob_f, bins, right=True) - 1
                        bin_ids = np.clip(bin_ids, 0, n_bins - 1)

                        calib_bin_rows = []
                        reliability_points = []
                        ece_sum = 0.0
                        total_cnt = y_prob_f.size
                        for k in range(n_bins):
                            lo, hi = bins[k], bins[k+1]
                            idx = (bin_ids == k)
                            cnt = int(idx.sum())
                            if cnt > 0:
                                avg_conf = float(y_prob_f[idx].mean())
                                acc = float(y_true_f[idx].mean())
                                gap = abs(acc - avg_conf)
                                weight = cnt / max(total_cnt, 1)
                                ece_sum += weight * gap
                                # åŒºé—´å³å¼€ï¼ˆæœ€åä¸€æ®µå³é—­ï¼‰
                                right_bracket = ')' if k < n_bins - 1 else ']'
                                calib_bin_rows.append({
                                    'range': f"[{lo:.1f},{hi:.1f}{right_bracket}",
                                    'count': cnt,
                                    'avg_conf': avg_conf,
                                    'acc': acc,
                                    'gap': gap,
                                })
                                reliability_points.append({'mean_pred': avg_conf, 'frac_pos': acc})
                        ece_value = float(ece_sum)
                        logger.info(f"æ¦‚ç‡æ ¡å‡†è¯„ä¼°ï¼šBrier={brier_value:.4f}, LogLoss={logloss_value:.4f}, ECE(10)={ece_value:.4f}")
                    else:
                        logger.info("æ¦‚ç‡æ ¡å‡†è¯„ä¼°ï¼šç±»åˆ«å•ä¸€æˆ–æ ·æœ¬ä¸è¶³ï¼Œè·³è¿‡ Brier/LogLoss/ECE è®¡ç®—")
                else:
                    logger.info("æ¦‚ç‡æ ¡å‡†è¯„ä¼°ï¼šç»“æœä¸ºç©ºæˆ–ç¼ºå°‘å¿…è¦åˆ—ï¼Œè·³è¿‡è®¡ç®—")
            except Exception as e:
                logger.warning(f"æ¦‚ç‡æ ¡å‡†è¯„ä¼°å¤±è´¥: {e}")

            # è·å–ç­–ç•¥å‚æ•°
            rise_threshold = config.get('strategy', {}).get('rise_threshold', 0.04)
            max_days = config.get('strategy', {}).get('max_days', 20)
            confidence_weights = config.get('strategy', {}).get('confidence_weights', {})
            rsi_oversold = confidence_weights.get('rsi_oversold_threshold', 30)
            rsi_low = confidence_weights.get('rsi_low_threshold', 40)
            # ä»å¤šä¸ªå€™é€‰ä½ç½®æ¨æ–­ final_thresholdï¼ˆç”¨äºæŠ¥å‘Šå±•ç¤ºï¼‰
            final_threshold = resolve_confidence_param(config, 'final_threshold', 0.5)

            # ç”ŸæˆæŠ¥å‘Š
            report_path = None
            if generate_report:
                # ç¡®ä¿æŠ¥å‘Šç›®å½•
                base_results_dir = os.path.join(os.path.dirname(__file__), '..', 'results')
                reports_dir = report_dir or os.path.join(base_results_dir, 'reports')
                if not os.path.exists(reports_dir):
                    os.makedirs(reports_dir)
                report_path = os.path.join(reports_dir, f"report_rolling_backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md")

                # é€‰å–å…³é”®ä¿¡å·ï¼ˆé¢„æµ‹ä¸ºæ­£ç±»ï¼‰æŒ‰æœ€ç»ˆç½®ä¿¡åº¦æ’åº
                pos_signals = []
                try:
                    pos_df = results_df_validated[results_df_validated['predicted_low_point'] == True].copy()
                    pos_df = pos_df.sort_values(by=['final_confidence', 'confidence'], ascending=False)
                    for idx, (dt, row) in enumerate(pos_df.head(15).iterrows(), start=1):
                        pos_signals.append({
                            'index': idx,
                            'date': dt.strftime('%Y-%m-%d'),
                            'predicted': 'æ˜¯' if row.get('predicted_low_point') else 'å¦',
                            'actual': 'æ˜¯' if row.get('actual_low_point') else 'å¦',
                            'confidence': row.get('confidence', 0),
                            'final_confidence': row.get('final_confidence', 0),
                            'future_max_rise': row.get('future_max_rise', 0),
                            'actual': 'æ˜¯' if row.get('actual_low_point') else 'å¦',
                            'max_rise': f"{float(row.get('future_max_rise', 0)):.2%}" if not pd.isna(row.get('future_max_rise')) else "N/A",
                            'days_to_rise': f"{int(row.get('days_to_rise', 0))}" if not pd.isna(row.get('days_to_rise')) else "N/A",
                            'predict_price': row.get('predict_price') if row.get('predict_price') is not None else 'N/A',
                            'correct': 'âœ…' if row.get('prediction_correct') else 'âŒ'
                        })
                except Exception as e:
                    pos_signals = [{'error': f"ç”Ÿæˆæ ·ä¾‹è¡Œæ—¶å‡ºç°å¼‚å¸¸: {e}"}]

                # æ–°å¢ï¼šå…¨åŒºé—´ Top-Nï¼ˆæŒ‰ final_confidence é™åºï¼ŒåŒ…å«æœªè¾¾é˜ˆå€¼ï¼‰
                top_all_signals = []
                try:
                    all_df = results_df.copy()
                    all_df = all_df.sort_values(by=['final_confidence', 'confidence'], ascending=False)
                    for idx, (dt, row) in enumerate(all_df.head(15).iterrows(), start=1):
                        top_all_signals.append({
                            'index': idx,
                            'date': dt.strftime('%Y-%m-%d'),
                            'predicted': 'æ˜¯' if row.get('predicted_low_point') else 'å¦',
                            'actual': 'æ˜¯' if row.get('actual_low_point') else 'å¦',
                            'confidence': row.get('confidence', 0),
                            'final_confidence': row.get('final_confidence', 0),
                            'future_max_rise': row.get('future_max_rise', 0),
                            'days_to_rise': int(row.get('days_to_rise') or 0) if row.get('days_to_rise') is not None else 0,
                            'predict_price': row.get('predict_price') if row.get('predict_price') is not None else 'N/A',
                            'correct': ('âœ…' if row.get('prediction_correct') else ('âŒ' if row.get('prediction_correct') is not None else 'N/A'))
                        })
                except Exception as e:
                    top_all_signals = [{'error': f"ç”ŸæˆTop-Næ—¶å‡ºç°å¼‚å¸¸: {e}"}]

                # ç”Ÿæˆé¢„æµ‹åˆ†å¸ƒè¡¨æ ¼ï¼ˆç±»ä¼¼åŸå›¾è¡¨çš„æ•°æ®å±•ç¤ºï¼‰
                correct_dates = results_df_validated[results_df_validated['prediction_correct'] == True]
                incorrect_dates = results_df_validated[results_df_validated['prediction_correct'] == False]
                
                # æŒ‰æœˆä»½ç»Ÿè®¡é¢„æµ‹åˆ†å¸ƒï¼ˆæ›¿ä»£åŸå›¾è¡¨çš„æ—¶é—´è½´ä¿¡æ¯ï¼‰
                monthly_stats = []
                try:
                    monthly_groups = results_df_validated.groupby(results_df_validated.index.to_period('M'))
                    for period, group in monthly_groups:
                        month_total = len(group)
                        month_correct = group['prediction_correct'].sum()
                        month_pos_pred = (group['predicted_low_point'] == True).sum()
                        month_pos_actual = (group['actual_low_point'] == True).sum()
                        monthly_stats.append({
                            'month': str(period),
                            'total': month_total,
                            'correct': month_correct,
                            'success_rate': month_correct / month_total if month_total > 0 else 0,
                            'pred_positive': month_pos_pred,
                            'actual_positive': month_pos_actual
                        })
                except Exception as e:
                    monthly_stats = [{'error': f"æœˆåº¦ç»Ÿè®¡å¼‚å¸¸: {e}"}]

                # æ„å»ºå®Œæ•´æŠ¥å‘Š
                report_lines = []
                report_lines.append(f"# AIæ»šåŠ¨å›æµ‹æŠ¥å‘Š")
                report_lines.append("")
                report_lines.append(f"## åŸºæœ¬ä¿¡æ¯")
                report_lines.append(f"- **å›æµ‹æœŸé—´**: {start_date_str} è‡³ {end_date_str}")
                report_lines.append(f"- **ä½¿ç”¨æ¨¡å‹**: å·²è®­ç»ƒæ¨¡å‹ï¼ˆç¦æ­¢å›æµ‹è®­ç»ƒï¼‰")
                report_lines.append(f"- **ç­–ç•¥å‚æ•°**: rise_threshold={resolve_confidence_param(config, 'rise_threshold', 0.04):.1%}, max_days={config.get('strategy', {}).get('max_days', 20)}")
                report_lines.append(f"- **ç½®ä¿¡åº¦é˜ˆå€¼(final_threshold)**: {final_threshold:.2f}")
                report_lines.append(f"- **è®­ç»ƒæ•ˆç‡**: {training_count}/{len(results)} (èŠ‚çœ {((len(results) - training_count) / len(results) * 100):.1f}%)")
                report_lines.append("")
                
                report_lines.append("## æ€»ä½“æŒ‡æ ‡")
                report_lines.append(f"- **æ€»é¢„æµ‹æ—¥æœŸæ•°(å¯éªŒè¯)**: {total_predictions_validated}")
                report_lines.append(f"- **æ­£ç¡®é¢„æµ‹æ•°**: {correct_predictions}")
                report_lines.append(f"- **å‡†ç¡®ç‡(Accuracy)**: {success_rate:.2%}")
                report_lines.append(f"- **Precision**: {precision:.2%}")
                report_lines.append(f"- **Recall**: {recall:.2%}")
                report_lines.append(f"- **F1 Score**: {(2*precision*recall/max(precision+recall, 1e-12)):.2%}")
                report_lines.append(f"- **Specificity**: {specificity:.2%}")
                report_lines.append(f"- **Balanced Accuracy**: {balanced_acc:.2%}")
                report_lines.append("")

                # æ–°å¢ï¼šç½®ä¿¡åº¦åˆ†å¸ƒè¯Šæ–­ï¼ˆå†™å…¥æŠ¥å‘Šï¼‰
                try:
                    report_lines.append("## ç½®ä¿¡åº¦åˆ†å¸ƒè¯Šæ–­")
                    report_lines.append(f"- final_confidence: å‡å€¼={final_stat['mean']:.4f}, æ ‡å‡†å·®={final_stat['std']:.4f}, æœ€å°={final_stat['min']:.4f}, æœ€å¤§={final_stat['max']:.4f}")
                    report_lines.append(f"- åˆ†ä½æ•°(10/25/50/75/90): {final_stat['q10']:.4f} / {final_stat['q25']:.4f} / {final_stat['q50']:.4f} / {final_stat['q75']:.4f} / {final_stat['q90']:.4f}")
                    report_lines.append(f"- confidence: å‡å€¼={conf_stat['mean']:.4f}, æ ‡å‡†å·®={conf_stat['std']:.4f}, æœ€å°={conf_stat['min']:.4f}, æœ€å¤§={conf_stat['max']:.4f}")
                    report_lines.append("")
                    report_lines.append("### final_confidence ç›´æ–¹åˆ†å¸ƒ")
                    report_lines.append("| åŒºé—´ | æ•°é‡ | å æ¯” |")
                    report_lines.append("|------|------|------|")
                    for lbl in bin_labels:
                        report_lines.append(f"| {lbl} | {int(bin_counts[lbl])} | {bin_perc[lbl]:.2f}% |")
                    report_lines.append("")
                    report_lines.append(f"- é˜ˆå€¼={final_threshold:.2f}ï¼Œç°åŒº[{gray_lower:.2f}, {gray_upper:.2f}] è¦†ç›–: {gray_total} æ¡ï¼Œå æ¯” {(gray_total/len(results_df)*100 if len(results_df)>0 else 0):.2f}%ï¼›ç°åŒºä¸­é¢„æµ‹æ­£ç±» {gray_pos} æ¡ï¼Œæ­£ç¡® {gray_correct} æ¡")
                    report_lines.append(f"- ç›¸å…³æ€§ï¼šfinal_confidence vs future_max_rise = {corr_final_rise:.3f}ï¼Œfinal_confidence vs prediction_correct = {corr_final_correct:.3f}")
                    report_lines.append("")
                except Exception as e:
                    report_lines.append(f"(ç½®ä¿¡åº¦åˆ†å¸ƒè¯Šæ–­ç”Ÿæˆå¤±è´¥: {e})")
                    report_lines.append("")

                report_lines.append("## æ¦‚ç‡æ ¡å‡†è¯„ä¼°")
                if brier_value is not None:
                    report_lines.append(f"- Brier Score: {brier_value:.4f}ï¼ˆè¶Šä½è¶Šå¥½ï¼‰")
                else:
                    report_lines.append(f"- Brier Score: N/A")
                if logloss_value is not None:
                    report_lines.append(f"- Log Loss: {logloss_value:.4f}ï¼ˆè¶Šä½è¶Šå¥½ï¼‰")
                else:
                    report_lines.append(f"- Log Loss: N/A")
                if ece_value is not None:
                    report_lines.append(f"- ECE(10 bins): {ece_value:.4f}ï¼ˆè¶Šä½è¶Šå¥½ï¼‰")
                    report_lines.append("")
                    report_lines.append("### å¯é æ€§è¡¨ï¼ˆåˆ†ç®±ç»Ÿè®¡ï¼‰")
                    report_lines.append("| ç½®ä¿¡åº¦åŒºé—´ | æ•°é‡ | å¹³å‡ç½®ä¿¡åº¦ | å®é™…æ­£ç‡ | åå·® |")
                    report_lines.append("|------------|------|------------|----------|------|")
                    for row in calib_bin_rows:
                        report_lines.append(f"| {row['range']} | {row['count']} | {row['avg_conf']:.3f} | {row['acc']:.3f} | {row['gap']:.3f} |")
                if len(reliability_points) > 0:
                    report_lines.append("")
                    report_lines.append("- å¯é æ€§æ›²çº¿ç‚¹(mean_pred â†’ frac_pos)ï¼š" + ", ".join([f"{pt['mean_pred']:.2f}â†’{pt['frac_pos']:.2f}" for pt in reliability_points]))
                else:
                    report_lines.append(f"- ECE(10 bins): N/A")
                report_lines.append("")

                report_lines.append("## é¢„æµ‹åˆ†å¸ƒä¸æ··æ·†çŸ©é˜µ")
                report_lines.append(f"- **é¢„æµ‹ä¸ºä½ç‚¹(æ­£ç±»)**: {pred_pos} ({(pred_pos/max(total_predictions_validated,1)*100):.2f}%)")
                report_lines.append(f"- **é¢„æµ‹ä¸ºéä½ç‚¹(è´Ÿç±»)**: {pred_neg} ({(pred_neg/max(total_predictions_validated,1)*100):.2f}%)")
                report_lines.append(f"- **å®é™…ä¸ºä½ç‚¹(æ­£ç±»)**: {actual_pos} ({(actual_pos/max(total_predictions_validated,1)*100):.2f}%)")
                report_lines.append(f"- **å®é™…ä¸ºéä½ç‚¹(è´Ÿç±»)**: {actual_neg} ({(actual_neg/max(total_predictions_validated,1)*100):.2f}%)")
                report_lines.append("")
                report_lines.append("### æ··æ·†çŸ©é˜µ")
                report_lines.append("|       | é¢„æµ‹æ­£ç±» | é¢„æµ‹è´Ÿç±» |")
                report_lines.append("|-------|---------|---------|")
                report_lines.append(f"| **å®é™…æ­£ç±»** | TP: {tp} | FN: {fn} |")
                report_lines.append(f"| **å®é™…è´Ÿç±»** | FP: {fp} | TN: {tn} |")
                report_lines.append("")

                # æœˆåº¦ç»Ÿè®¡ï¼ˆæŒ‰ç´¢å¼•æ—¥æœŸåˆ†ç»„ï¼‰
                month_group = results_df_validated.groupby(results_df_validated.index.to_period('M').astype(str))
                month_stats = []
                for month, group in month_group:
                    total = len(group)
                    month_correct = group['prediction_correct'].sum()
                    month_success_rate = month_correct / total if total > 0 else 0.0
                    month_pred_pos = (group['predicted_low_point'] == True).sum()
                    month_pos_actual = (group['actual_low_point'] == True).sum()
                    month_stats.append({
                        'month': month,
                        'total': int(total),
                        'correct': int(month_correct),
                        'success_rate': float(month_success_rate),
                        'pred_positive': int(month_pred_pos),
                        'actual_positive': int(month_pos_actual)
                    })

                report_lines.append("## æœˆåº¦é¢„æµ‹åˆ†å¸ƒ")
                report_lines.append("| æœˆä»½ | æ€»é¢„æµ‹ | æ­£ç¡®æ•° | æˆåŠŸç‡ | é¢„æµ‹æ­£ç±» | å®é™…æ­£ç±» |")
                report_lines.append("|------|--------|--------|--------|----------|----------|")
                for stat in month_stats:
                    report_lines.append(f"| {stat['month']} | {stat['total']} | {stat['correct']} | {stat['success_rate']:.1%} | {stat['pred_positive']} | {stat['actual_positive']} |")
                report_lines.append("")

                report_lines.append("## æ¯æ—¥é¢„æµ‹æ˜ç»†")
                report_lines.append("| æ—¥æœŸ | é¢„æµ‹ä»·æ ¼ | é¢„æµ‹ç»“æœ | ç½®ä¿¡åº¦ | æœ€ç»ˆç½®ä¿¡åº¦ | å®é™…ç»“æœ | æœªæ¥æœ€å¤§æ¶¨å¹… | è¾¾æ ‡ç”¨æ—¶(å¤©) | é¢„æµ‹æ­£ç¡® |")
                report_lines.append("|------|----------|----------|--------|------------|----------|-------------|-------------|----------|")
                for dt, row in results_df.iterrows():
                    date_str = pd.to_datetime(dt).strftime('%Y-%m-%d') if not pd.isna(dt) else ''
                    predict_price = f"{row.get('predict_price', '')}"
                    predicted = "æ˜¯" if row.get('predicted_low_point') else "å¦"
                    confidence = f"{row.get('confidence', 0):.2f}"
                    final_confidence = f"{row.get('final_confidence', 0):.2f}"
                    actual = "æ˜¯" if row.get('actual_low_point') else "å¦"
                    max_rise = f"{float(row.get('future_max_rise', 0)):.2%}" if not pd.isna(row.get('future_max_rise')) else "N/A"
                    days_to_rise = f"{int(row.get('days_to_rise', 0))}" if not pd.isna(row.get('days_to_rise')) else "N/A"
                    prediction_correct = "æ˜¯" if row.get('prediction_correct') else "å¦"
                    if pd.isna(row.get('actual_low_point')):
                        actual = 'æ•°æ®ä¸è¶³'
                    if pd.isna(row.get('prediction_correct')):
                        prediction_correct = 'æ•°æ®ä¸è¶³'
                    report_lines.append(f"| {date_str} | {predict_price} | {predicted} | {confidence} | {final_confidence} | {actual} | {max_rise} | {days_to_rise} | {prediction_correct} |")
                report_lines.append("")

                report_lines.append(f"**ç­–ç•¥å‚æ•°**: æ¶¨å¹…é˜ˆå€¼={resolve_confidence_param(config, 'rise_threshold', 0.04):.1%}, æœ€å¤§è§‚å¯Ÿå¤©æ•°={config.get('strategy', {}).get('max_days', 20)}, RSIè¶…å–={config.get('strategy', {}).get('rsi_oversold', 30)}, RSIåä½={config.get('strategy', {}).get('rsi_low', 40)}, ç½®ä¿¡åº¦é˜ˆå€¼={final_threshold:.2f}")
                report_lines.append("")

                report_lines.append("## å…³é”®ä¿¡å·è¯¦æƒ…ï¼ˆæŒ‰æœ€ç»ˆç½®ä¿¡åº¦é™åºï¼Œæœ€å¤š15æ¡ï¼‰")
                report_lines.append("| åºå· | æ—¥æœŸ | é¢„æµ‹ | å®é™… | ç½®ä¿¡åº¦ | æœ€ç»ˆç½®ä¿¡åº¦ | æœªæ¥æœ€å¤§æ¶¨å¹… | ç”¨æ—¶å¤©æ•° | é¢„æµ‹ä»· | ç»“æœ |")
                report_lines.append("|------|------|------|------|--------|------------|-------------|----------|---------|------|")
                if len(pos_signals) > 0:
                    for signal in pos_signals:
                        report_lines.append(f"| {signal['index']} | {signal['date']} | {signal['predicted']} | {signal['actual']} | {signal['confidence']:.2f} | {signal['final_confidence']:.2f} | {signal['future_max_rise']:.2%} | {signal['days_to_rise']} | {signal['predict_price']} | {signal['correct']} |")
                else:
                    report_lines.append("- (æœ¬æ¬¡æ— æ­£ç±»ä¿¡å·æˆ–æ— æ³•ç”Ÿæˆæ ·ä¾‹)")
                report_lines.append("")

                # æ–°å¢ï¼šå…¨åŒºé—´ Top-N final_confidenceï¼ˆåŒ…å«æœªè¾¾é˜ˆå€¼ï¼‰
                report_lines.append("## å…¨åŒºé—´ Top-N final_confidenceï¼ˆåŒ…å«æœªè¾¾é˜ˆå€¼ï¼‰")
                report_lines.append("| åºå· | æ—¥æœŸ | é¢„æµ‹ | å®é™… | ç½®ä¿¡åº¦ | æœ€ç»ˆç½®ä¿¡åº¦ | æœªæ¥æœ€å¤§æ¶¨å¹… | ç”¨æ—¶å¤©æ•° | é¢„æµ‹ä»· | ç»“æœ |")
                report_lines.append("|------|------|------|------|--------|------------|-------------|----------|---------|------|")
                if len(top_all_signals) > 0:
                    for signal in top_all_signals:
                        report_lines.append(f"| {signal['index']} | {signal['date']} | {signal['predicted']} | {signal['actual']} | {signal['confidence']:.2f} | {signal['final_confidence']:.2f} | {signal['future_max_rise']:.2%} | {signal['days_to_rise']} | {signal['predict_price']} | {signal['correct']} |")
                else:
                    report_lines.append("- (æ— æ³•ç”ŸæˆTop-Nåˆ—è¡¨)")
                report_lines.append("")

                report_lines.append("## ç­–ç•¥å‚æ•°è¯¦æƒ…")
                report_lines.append(f"- **æ¶¨å¹…é˜ˆå€¼**: {resolve_confidence_param(config, 'rise_threshold', 0.04):.1%}")
                report_lines.append(f"- **æœ€å¤§è§‚å¯Ÿå¤©æ•°**: {config.get('strategy', {}).get('max_days', 20)}")
                report_lines.append(f"- **RSIè¶…å–é˜ˆå€¼**: {config.get('strategy', {}).get('rsi_oversold', 30)}")
                report_lines.append(f"- **RSIåä½é˜ˆå€¼**: {config.get('strategy', {}).get('rsi_low', 40)}")
                report_lines.append(f"- **æœ€ç»ˆç½®ä¿¡åº¦é˜ˆå€¼**: {final_threshold:.2f}")
                report_lines.append("")

                report_lines.append("> **å…è´£å£°æ˜**: æœ¬æŠ¥å‘Šç”±è„šæœ¬è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ç”¨äºç­–ç•¥ä¸æ¨¡å‹è¯„ä¼°ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚")

                with open(report_path, 'w', encoding='utf-8') as f:
                    f.write("\n".join(report_lines))
                logger.info(f"ğŸ“„ å›æµ‹æŠ¥å‘Šå·²ç”Ÿæˆ: {os.path.relpath(report_path)}")

            # è¿”å›è®¡ç®—å¥½çš„æŒ‡æ ‡ï¼ˆä¾›ç½‘æ ¼æµ‹è¯•/æŠ¥å‘Šä½¿ç”¨ï¼‰
            return {
                'success': True,
                'metrics': {
                    'total_predictions': total_predictions,
                    'correct_predictions': int(correct_predictions),
                    'success_rate': success_rate,
                    'pred_positive': pred_pos,
                    'precision': precision,
                    'recall': recall,
                    'f1': f1,
                    'specificity': specificity,
                    'balanced_accuracy': balanced_acc
                },
                'report_path': report_path
            }
        else:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„é¢„æµ‹ç»“æœç”¨äºç»Ÿè®¡åˆ†æ")
            return {
                'success': False,
                'error': 'æ²¡æœ‰æœ‰æ•ˆçš„é¢„æµ‹ç»“æœ'
            }

    except Exception as e:
        logger.error(f"æ»šåŠ¨å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return {
            'success': False,
            'error': str(e)
        }


def run_rolling_backtest_with_return(start_date_str: str, end_date_str: str, training_window_days: int = 365, 
                                     reuse_model: bool = True, retrain_interval_days: int = None,
                                     generate_report: bool = True, report_dir: str = None):
    """
    å¸¦è¿”å›å€¼çš„æ»šåŠ¨å›æµ‹å‡½æ•°ï¼ˆä¾›ç½‘æ ¼æµ‹è¯•/æŠ¥å‘Šä½¿ç”¨ï¼‰
    
    Args:
        start_date_str: å¼€å§‹æ—¥æœŸå­—ç¬¦ä¸²
        end_date_str: ç»“æŸæ—¥æœŸå­—ç¬¦ä¸²
        training_window_days: è®­ç»ƒçª—å£å¤©æ•°
        reuse_model: æ˜¯å¦é‡ç”¨æ¨¡å‹
        retrain_interval_days: é‡è®­ç»ƒé—´éš”å¤©æ•°
        generate_report: æ˜¯å¦ç”ŸæˆæŠ¥å‘Šæ–‡æ¡£ï¼ˆMarkdownï¼‰
        report_dir: æŠ¥å‘Šè¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        dict: åŒ…å« success æ ‡å¿—å’Œ metrics çš„ç»“æœå­—å…¸
    """
    return run_rolling_backtest(start_date_str, end_date_str, training_window_days, reuse_model, retrain_interval_days,
                                generate_report=generate_report, report_dir=report_dir)

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("ç”¨æ³•: python run_rolling_backtest.py <start_date> <end_date>")
        print("ç¤ºä¾‹: python run_rolling_backtest.py 2023-01-01 2023-03-31")
        sys.exit(1)
    
    start_date = sys.argv[1]
    end_date = sys.argv[2]
    run_rolling_backtest(start_date, end_date)


