#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥pklæ–‡ä»¶ä¸­çš„å®é™…å‚æ•°
"""

import os
import sys
import pickle
import numpy as np
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def check_pkl_parameters():
    """æ£€æŸ¥pklæ–‡ä»¶ä¸­çš„å®é™…å‚æ•°"""
    print("ğŸ” æ£€æŸ¥pklæ–‡ä»¶ä¸­çš„å®é™…å‚æ•°")
    print("=" * 50)
    
    try:
        # è¯»å–æœ€æ–°æ¨¡å‹è·¯å¾„
        latest_model_path = "models/latest_improved_model.txt"
        if os.path.exists(latest_model_path):
            with open(latest_model_path, 'r') as f:
                model_path = f.read().strip()
        else:
            # å¦‚æœæ²¡æœ‰latestæ–‡ä»¶ï¼Œä½¿ç”¨æœ€æ–°çš„pklæ–‡ä»¶
            models_dir = "models"
            pkl_files = [f for f in os.listdir(models_dir) if f.endswith('.pkl')]
            if pkl_files:
                pkl_files.sort(reverse=True)  # æŒ‰æ–‡ä»¶åæ’åºï¼Œæœ€æ–°çš„åœ¨å‰é¢
                model_path = os.path.join(models_dir, pkl_files[0])
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°pklæ–‡ä»¶")
                return False
        
        print(f"ğŸ“ æ£€æŸ¥æ¨¡å‹æ–‡ä»¶: {model_path}")
        
        # åŠ è½½pklæ–‡ä»¶
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)
        
        print("\nğŸ“‹ pklæ–‡ä»¶å†…å®¹ç»“æ„:")
        print("-" * 30)
        for key, value in model_data.items():
            if key == 'model':
                print(f"   {key}: {type(value).__name__}")
                if hasattr(value, 'named_steps'):
                    print(f"       Pipelineæ­¥éª¤: {list(value.named_steps.keys())}")
                    if 'classifier' in value.named_steps:
                        classifier = value.named_steps['classifier']
                        print(f"       åˆ†ç±»å™¨ç±»å‹: {type(classifier).__name__}")
                        if hasattr(classifier, 'n_estimators'):
                            print(f"       å†³ç­–æ ‘æ•°é‡: {classifier.n_estimators}")
                        if hasattr(classifier, 'max_depth'):
                            print(f"       æœ€å¤§æ·±åº¦: {classifier.max_depth}")
            elif key == 'feature_names':
                print(f"   {key}: {len(value)} ä¸ªç‰¹å¾")
                print(f"      ç‰¹å¾åˆ—è¡¨: {value}")
            elif key == 'incremental_count':
                print(f"   {key}: {value}")
            elif key == 'scaler':
                print(f"   {key}: {type(value).__name__}")
            else:
                print(f"   {key}: {type(value).__name__}")
        
        print("\nğŸ¯ ç‰¹å¾åˆ†æ:")
        print("-" * 30)
        if 'feature_names' in model_data:
            feature_names = model_data['feature_names']
            print(f"ç‰¹å¾æ€»æ•°: {len(feature_names)}")
            
            # åˆ†ç±»ç‰¹å¾
            trend_features = [f for f in feature_names if 'trend' in f]
            volume_features = [f for f in feature_names if 'volume' in f]
            ma_features = [f for f in feature_names if 'ma' in f and f != 'macd']
            price_features = [f for f in feature_names if 'price' in f]
            technical_features = [f for f in feature_names if f in ['rsi', 'macd', 'signal', 'hist', 'bb_upper', 'bb_lower']]
            distance_features = [f for f in feature_names if 'dist_' in f]
            
            print(f"è¶‹åŠ¿ç‰¹å¾ ({len(trend_features)}): {trend_features}")
            print(f"æˆäº¤é‡ç‰¹å¾ ({len(volume_features)}): {volume_features}")
            print(f"å‡çº¿ç‰¹å¾ ({len(ma_features)}): {ma_features}")
            print(f"ä»·æ ¼ç‰¹å¾ ({len(price_features)}): {price_features}")
            print(f"æŠ€æœ¯æŒ‡æ ‡ ({len(technical_features)}): {technical_features}")
            print(f"è·ç¦»ç‰¹å¾ ({len(distance_features)}): {distance_features}")
        
        print("\nğŸ¤– æ¨¡å‹ä¿¡æ¯:")
        print("-" * 30)
        if 'model' in model_data:
            model = model_data['model']
            if hasattr(model, 'named_steps') and 'classifier' in model.named_steps:
                classifier = model.named_steps['classifier']
                print(f"æ¨¡å‹ç±»å‹: {type(classifier).__name__}")
                if hasattr(classifier, 'n_estimators'):
                    print(f"å†³ç­–æ ‘æ•°é‡: {classifier.n_estimators}")
                if hasattr(classifier, 'max_depth'):
                    print(f"æœ€å¤§æ·±åº¦: {classifier.max_depth}")
                if hasattr(classifier, 'min_samples_split'):
                    print(f"æœ€å°åˆ†å‰²æ ·æœ¬æ•°: {classifier.min_samples_split}")
                if hasattr(classifier, 'min_samples_leaf'):
                    print(f"æœ€å°å¶å­èŠ‚ç‚¹æ ·æœ¬æ•°: {classifier.min_samples_leaf}")
                if hasattr(classifier, 'class_weight'):
                    print(f"ç±»åˆ«æƒé‡: {classifier.class_weight}")
        
        print("\nğŸ“Š æ–‡ä»¶å¤§å°ä¿¡æ¯:")
        print("-" * 30)
        file_size = os.path.getsize(model_path)
        print(f"æ–‡ä»¶å¤§å°: {file_size / 1024:.1f} KB")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

def compare_with_optimization_params():
    """å¯¹æ¯”pklæ–‡ä»¶å‚æ•°ä¸ä¼˜åŒ–å‚æ•°"""
    print("\nğŸ”„ å¯¹æ¯”pklæ–‡ä»¶å‚æ•°ä¸ä¼˜åŒ–å‚æ•°")
    print("=" * 50)
    
    try:
        # ä»é…ç½®æ–‡ä»¶è¯»å–ä¼˜åŒ–å‚æ•°èŒƒå›´
        import yaml
        with open('config/strategy.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        strategy_ranges = config.get('strategy_ranges', {})
        optimization_ranges = config.get('optimization_ranges', {})
        
        print("ğŸ“‹ é…ç½®æ–‡ä»¶ä¸­çš„ä¼˜åŒ–å‚æ•°:")
        print("-" * 30)
        
        print("ğŸ”§ strategy_ranges (åŸºç¡€å‚æ•°):")
        for param_name, param_config in strategy_ranges.items():
            if param_name not in ['rise_threshold', 'max_days']:
                print(f"   {param_name}: {param_config.get('min', 'N/A')} - {param_config.get('max', 'N/A')}")
        
        print("\nğŸ¤– optimization_ranges (AIä¼˜åŒ–å‚æ•°):")
        for param_name, param_config in optimization_ranges.items():
            print(f"   {param_name}: {param_config.get('min', 'N/A')} - {param_config.get('max', 'N/A')}")
        
        print(f"\nğŸ“Š æ€»ç»“:")
        print(f"   ä¼˜åŒ–å‚æ•°æ€»æ•°: {len(strategy_ranges) + len(optimization_ranges) - 2} (å‡å»å›ºå®šå‚æ•°)")
        print(f"   pklæ–‡ä»¶ç‰¹å¾æ•°: æ ¹æ®å®é™…åŠ è½½çš„æ¨¡å‹ç¡®å®š")
        print(f"   å‚æ•°ç±»å‹: ç­–ç•¥å‚æ•°(å½±å“æ ‡ç­¾ç”Ÿæˆ) vs æ¨¡å‹ç‰¹å¾(ç”¨äºAIé¢„æµ‹)")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¯¹æ¯”å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    try:
        # æ£€æŸ¥pklæ–‡ä»¶å‚æ•°
        success1 = check_pkl_parameters()
        
        # å¯¹æ¯”ä¼˜åŒ–å‚æ•°
        success2 = compare_with_optimization_params()
        
        # æ€»ç»“
        print("\nğŸ“Š æ€»ç»“:")
        print("=" * 30)
        print(f"pklæ–‡ä»¶æ£€æŸ¥: {'âœ… æˆåŠŸ' if success1 else 'âŒ å¤±è´¥'}")
        print(f"å‚æ•°å¯¹æ¯”: {'âœ… æˆåŠŸ' if success2 else 'âŒ å¤±è´¥'}")
        
        if success1 and success2:
            print("\nğŸ’¡ è¯´æ˜:")
            print("1. pklæ–‡ä»¶åŒ…å«AIæ¨¡å‹å’Œç‰¹å¾ä¿¡æ¯ï¼Œç”¨äºé¢„æµ‹")
            print("2. ä¼˜åŒ–å‚æ•°å½±å“æ ‡ç­¾ç”Ÿæˆï¼Œç”¨äºè®­ç»ƒ")
            print("3. ä¸¤è€…æ˜¯ä¸åŒçš„æ¦‚å¿µï¼šæ¨¡å‹ç‰¹å¾ vs ç­–ç•¥å‚æ•°")
        
    except Exception as e:
        print(f"âŒ ä¸»å‡½æ•°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 