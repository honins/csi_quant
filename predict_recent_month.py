#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€è¿‘ä¸€ä¸ªæœˆé¢„æµ‹è„šæœ¬
æ‰¹é‡é¢„æµ‹æœ€è¿‘ä¸€ä¸ªæœˆçš„äº¤æ˜“æ—¥æ•°æ®
"""

import sys
import os
import logging
import pandas as pd
import json
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from src.data.data_module import DataModule
from src.strategy.strategy_module import StrategyModule
from src.ai.ai_optimizer_improved import AIOptimizerImproved as AIOptimizer
from src.utils.utils import load_config
from src.prediction.prediction_utils import setup_logging, PredictionResult, predict_and_validate

# è®¾ç½®æ—¥å¿—
setup_logging()
logger = logging.getLogger("RecentMonthPredictor")

def get_recent_trading_days(data_file, days=30):
    """è·å–æœ€è¿‘çš„äº¤æ˜“æ—¥"""
    try:
        df = pd.read_csv(data_file)
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')
        
        # è·å–æœ€è¿‘çš„äº¤æ˜“æ—¥
        recent_days = df.tail(days)['date'].dt.strftime('%Y-%m-%d').tolist()
        return recent_days
    except Exception as e:
        logger.error(f"è·å–äº¤æ˜“æ—¥å¤±è´¥: {e}")
        return []

def predict_single_date(predict_date_str, config, data_module, strategy_module, ai_optimizer):
    """é¢„æµ‹å•ä¸ªæ—¥æœŸï¼ˆåŒ…å«éªŒè¯ï¼‰"""
    try:
        predict_date = datetime.strptime(predict_date_str, '%Y-%m-%d')
        
        # ä½¿ç”¨ç»Ÿä¸€çš„é¢„æµ‹+éªŒè¯æµç¨‹ï¼ˆä¸åœ¨æ­¤å¤„è®­ç»ƒï¼Œä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹ï¼‰
        pr: PredictionResult = predict_and_validate(
            predict_date=predict_date,
            data_module=data_module,
            strategy_module=strategy_module,
            ai_optimizer=ai_optimizer,
            config=config,
            logger=logger,
            force_retrain=False,
            only_use_trained_model=True
        )
        
        # ç»„è£…å­—å…¸ç»“æœï¼Œä¾¿äºåç»­ç”ŸæˆæŠ¥å‘Š/CSV
        return {
            'date': predict_date_str,
            'predicted_low_point': bool(pr.predicted_low_point) if pr.predicted_low_point is not None else False,
            'actual_low_point': pr.actual_low_point,
            'prediction_correct': pr.prediction_correct,
            'confidence': float(pr.confidence) if pr.confidence is not None else 0.0,
            'predict_price': pr.predict_price,
            'used_threshold': pr.used_threshold
        }
    except Exception as e:
        logger.error(f"é¢„æµ‹ {predict_date_str} å¤±è´¥: {e}")
        return None

def generate_prediction_report(results, start_date, end_date, config):
    """ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š"""
    try:
        # åˆ›å»ºæŠ¥å‘Šç›®å½•
        base_results_dir = os.path.join(project_root, 'results')
        reports_dir = os.path.join(base_results_dir, 'reports')
        csv_dir = os.path.join(base_results_dir, 'csv')
        os.makedirs(reports_dir, exist_ok=True)
        os.makedirs(csv_dir, exist_ok=True)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        report_filename = f'report_recent_month_prediction_{timestamp}.md'
        report_path = os.path.join(reports_dir, report_filename)
        
        # CSVæ–‡ä»¶è·¯å¾„
        csv_filename = f'recent_month_prediction_{timestamp}.csv'
        csv_path = os.path.join(csv_dir, csv_filename)
        
        # ç»Ÿè®¡æ•°æ®
        total_predictions = len(results)
        low_point_predictions = sum(1 for r in results if r['predicted_low_point'])
        high_confidence_predictions = sum(1 for r in results if r['confidence'] > 0.5)
        avg_confidence = sum(r['confidence'] for r in results) / total_predictions if total_predictions > 0 else 0
        
        # ç½®ä¿¡åº¦åˆ†å¸ƒç»Ÿè®¡
        confidences = [r['confidence'] for r in results]
        confidence_stats = {
            'mean': sum(confidences) / len(confidences) if confidences else 0,
            'min': min(confidences) if confidences else 0,
            'max': max(confidences) if confidences else 0,
            'std': (sum((x - avg_confidence) ** 2 for x in confidences) / len(confidences)) ** 0.5 if confidences else 0
        }
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        report_lines = []
        report_lines.append("# ğŸ“ˆ æœ€è¿‘ä¸€ä¸ªæœˆé¢„æµ‹æŠ¥å‘Š")
        report_lines.append("")
        report_lines.append("## ğŸ“Š åŸºæœ¬ä¿¡æ¯")
        report_lines.append(f"- **é¢„æµ‹æœŸé—´**: {start_date} è‡³ {end_date}")
        report_lines.append(f"- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        report_lines.append(f"- **æŠ¥å‘Šç¼–å·**: `{timestamp}`")
        report_lines.append(f"- **ä½¿ç”¨æ¨¡å‹**: AIä¼˜åŒ–æ¨¡å‹")
        report_lines.append("")
        
        report_lines.append("## ğŸ¯ é¢„æµ‹æ±‡æ€»")
        report_lines.append(f"- **æ€»é¢„æµ‹å¤©æ•°**: {total_predictions}")
        report_lines.append(f"- **é¢„æµ‹ä¸ºç›¸å¯¹ä½ç‚¹**: {low_point_predictions} å¤© ({low_point_predictions/total_predictions*100:.1f}%)")
        report_lines.append(f"- **é«˜ç½®ä¿¡åº¦é¢„æµ‹**: {high_confidence_predictions} å¤© ({high_confidence_predictions/total_predictions*100:.1f}%)")
        report_lines.append(f"- **å¹³å‡ç½®ä¿¡åº¦**: {avg_confidence:.4f}")
        report_lines.append("")
        
        report_lines.append("## ğŸ“ˆ ç½®ä¿¡åº¦åˆ†æ")
        report_lines.append(f"- **ç½®ä¿¡åº¦å‡å€¼**: {confidence_stats['mean']:.4f}")
        report_lines.append(f"- **ç½®ä¿¡åº¦æ ‡å‡†å·®**: {confidence_stats['std']:.4f}")
        report_lines.append(f"- **æœ€ä½ç½®ä¿¡åº¦**: {confidence_stats['min']:.4f}")
        report_lines.append(f"- **æœ€é«˜ç½®ä¿¡åº¦**: {confidence_stats['max']:.4f}")
        report_lines.append("")
        
        # é¢„æµ‹è¯¦æƒ…
        if low_point_predictions > 0:
            report_lines.append("## ğŸ¯ é¢„æµ‹çš„ç›¸å¯¹ä½ç‚¹")
            report_lines.append("| æ—¥æœŸ | ç½®ä¿¡åº¦ | å¤‡æ³¨ |")
            report_lines.append("| --- | --- | --- |")
            for r in results:
                if r['predicted_low_point']:
                    report_lines.append(f"| {r['date']} | {r['confidence']:.4f} | é¢„æµ‹ä¸ºç›¸å¯¹ä½ç‚¹ |")
            report_lines.append("")
        else:
            report_lines.append("## ğŸ“Š é¢„æµ‹ç»“æœ")
            report_lines.append("**æœ€è¿‘ä¸€ä¸ªæœˆæœªå‘ç°æ˜æ˜¾çš„ç›¸å¯¹ä½ç‚¹**")
            report_lines.append("")
        
        # ç½®ä¿¡åº¦æœ€é«˜çš„é¢„æµ‹
        sorted_results = sorted(results, key=lambda x: x['confidence'], reverse=True)
        report_lines.append("## ğŸ” ç½®ä¿¡åº¦æœ€é«˜çš„é¢„æµ‹")
        report_lines.append("| æ’å | æ—¥æœŸ | é¢„æµ‹ç»“æœ | ç½®ä¿¡åº¦ |")
        report_lines.append("| --- | --- | --- | --- |")
        for i, r in enumerate(sorted_results[:10], 1):
            prediction_text = "ç›¸å¯¹ä½ç‚¹" if r['predicted_low_point'] else "éç›¸å¯¹ä½ç‚¹"
            report_lines.append(f"| {i} | {r['date']} | {prediction_text} | {r['confidence']:.4f} |")
        report_lines.append("")
        
        # æ¯æ—¥é¢„æµ‹æ˜ç»† - ä½¿ç”¨ä¸å†å²å›æµ‹æŠ¥å‘Šä¸€è‡´çš„å­—æ®µæ ¼å¼
        report_lines.append("## æ¯æ—¥é¢„æµ‹æ˜ç»†")
        report_lines.append("| æ—¥æœŸ | é¢„æµ‹ä»·æ ¼ | é¢„æµ‹ç»“æœ | ç½®ä¿¡åº¦ | é˜ˆå€¼(used) | å®é™…ç»“æœ | è¶‹åŠ¿ | æœªæ¥æœ€å¤§æ¶¨å¹… | è¾¾æ ‡ç”¨æ—¶(å¤©) | é¢„æµ‹æ­£ç¡® |")
        report_lines.append("|------|----------|----------|--------|------------|----------|------|-------------|-------------|----------|")
        for r in results:
            prediction_text = "æ˜¯" if r['predicted_low_point'] else "å¦"
            predict_price = r.get('predict_price', 'N/A')
            used_thr = r.get('used_threshold')
            used_thr = used_thr if isinstance(used_thr, (int, float)) else 0.50
            actual_text = "æ˜¯" if r.get('actual_low_point') else "å¦" if r.get('actual_low_point') is not None else "æ•°æ®ä¸è¶³"
            prediction_success_text = "æ˜¯" if r.get('prediction_correct') else "å¦" if r.get('prediction_correct') is not None else "å¦"
            max_rise_text = "å¾…éªŒè¯"  # æ­¤è„šæœ¬åœºæ™¯ä¸ç»Ÿè®¡è¯¥å€¼
            days_to_target_text = "å¾…éªŒè¯"  # æ­¤è„šæœ¬åœºæ™¯ä¸ç»Ÿè®¡è¯¥å€¼
            trend_text = "å¾…éªŒè¯"  # æš‚ä¸å±•ç¤ºç­–ç•¥è¶‹åŠ¿
            report_lines.append(f"| {r['date']} | {predict_price} | {prediction_text} | {r['confidence']:.2f} | {used_thr:.2f} | {actual_text} | {trend_text} | {max_rise_text} | {days_to_target_text} | {prediction_success_text} |")
        report_lines.append("")
        
        report_lines.append("> **å…è´£å£°æ˜**: æœ¬æŠ¥å‘Šç”±AIæ¨¡å‹è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…ã€‚")
        
        # å†™å…¥MarkdownæŠ¥å‘Š
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(report_lines))
        
        logger.info(f"ğŸ“„ é¢„æµ‹æŠ¥å‘Šå·²ç”Ÿæˆ: {os.path.relpath(report_path)}")
        
        # ç”ŸæˆCSVæ–‡ä»¶
        csv_data = []
        for r in results:
            csv_data.append({
                'æ—¥æœŸ': r['date'],
                'é¢„æµ‹ä¸ºä½ç‚¹': r['predicted_low_point'],
                'ç½®ä¿¡åº¦': r['confidence'],
                'é¢„æµ‹ç»“æœ': 'ç›¸å¯¹ä½ç‚¹' if r['predicted_low_point'] else 'éç›¸å¯¹ä½ç‚¹',
                'ç½®ä¿¡åº¦ç­‰çº§': 'é«˜' if r['confidence'] > 0.5 else 'ä¸­' if r['confidence'] > 0.3 else 'ä½',
                'å®é™…ç»“æœ': 'æ˜¯' if r.get('actual_low_point') else 'å¦',
                'é¢„æµ‹æˆåŠŸ': 'æ˜¯' if (r.get('prediction_correct') is True) else 'å¦'
            })
        
        csv_df = pd.DataFrame(csv_data)
        csv_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        logger.info(f"ğŸ§¾ é¢„æµ‹æ˜ç»†å·²å¯¼å‡ºCSV: {os.path.relpath(csv_path)}")
        
        return {
            'report_path': report_path,
            'csv_path': csv_path,
            'total_predictions': total_predictions,
            'low_point_predictions': low_point_predictions,
            'high_confidence_predictions': high_confidence_predictions,
            'avg_confidence': avg_confidence
        }
        
    except Exception as e:
        logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("å¼€å§‹æœ€è¿‘ä¸€ä¸ªæœˆé¢„æµ‹...")
        
        # åŠ è½½é…ç½®
        config_path = os.path.join(os.path.dirname(__file__), 'config', 'system.yaml')
        config = load_config(config_path=config_path)
        
        # åˆå§‹åŒ–æ¨¡å—
        data_module = DataModule(config)
        strategy_module = StrategyModule(config)
        ai_optimizer = AIOptimizer(config)
        
        # å°è¯•é¢„åŠ è½½å·²ä¿å­˜æ¨¡å‹ï¼Œé¿å…ä»…ç”¨å·²è®­ç»ƒæ¨¡å‹æ—¶æå‰è¿”å›
        try:
            if getattr(ai_optimizer, 'model', None) is None:
                loaded = ai_optimizer._load_model()
                logger.info(f"é¢„åŠ è½½æ¨¡å‹: {'æˆåŠŸ' if loaded else 'å¤±è´¥'}")
        except Exception as _e:
            logger.warning(f"é¢„åŠ è½½æ¨¡å‹å¼‚å¸¸: {_e}")
        
        # è·å–æœ€è¿‘30ä¸ªäº¤æ˜“æ—¥
        data_file = "data/SHSE.000905_1d.csv"
        recent_days = get_recent_trading_days(data_file, 30)
        
        if not recent_days:
            logger.error("æ— æ³•è·å–æœ€è¿‘çš„äº¤æ˜“æ—¥")
            return False
            
        logger.info(f"å°†é¢„æµ‹æœ€è¿‘ {len(recent_days)} ä¸ªäº¤æ˜“æ—¥")
        
        # æ‰¹é‡é¢„æµ‹
        results = []
        for i, date_str in enumerate(recent_days, 1):
            logger.info(f"é¢„æµ‹è¿›åº¦: {i}/{len(recent_days)} - {date_str}")
            
            result = predict_single_date(date_str, config, data_module, strategy_module, ai_optimizer)
            if result:
                results.append(result)
                
                # è¾“å‡ºé¢„æµ‹ç»“æœ
                is_low = "æ˜¯" if result['predicted_low_point'] else "å¦"
                confidence = result['confidence'] * 100
                actual_text = "æ˜¯" if result.get('actual_low_point') else "å¦" if result.get('actual_low_point') is not None else "æ•°æ®ä¸è¶³"
                success_text = "æ˜¯" if (result.get('prediction_correct') is True) else "å¦"
                logger.info(f"  ğŸ“… {date_str}: {is_low}ç›¸å¯¹ä½ç‚¹ (ç½®ä¿¡åº¦: {confidence:.2f}%) ï½œ å®é™…: {actual_text} ï½œ é¢„æµ‹æˆåŠŸ: {success_text}")
            else:
                logger.warning(f"  âŒ {date_str}: é¢„æµ‹å¤±è´¥")
        
        # æ±‡æ€»ç»“æœ
        if results:
            logger.info("\n" + "="*60)
            logger.info("ğŸ“Š æœ€è¿‘ä¸€ä¸ªæœˆé¢„æµ‹æ±‡æ€»")
            logger.info("="*60)
            
            low_points = [r for r in results if r['predicted_low_point']]
            high_confidence = [r for r in results if r['confidence'] > 0.5]
            
            logger.info(f"æ€»é¢„æµ‹å¤©æ•°: {len(results)}")
            logger.info(f"é¢„æµ‹ä¸ºç›¸å¯¹ä½ç‚¹: {len(low_points)} å¤©")
            logger.info(f"é«˜ç½®ä¿¡åº¦é¢„æµ‹: {len(high_confidence)} å¤©")
            
            if low_points:
                logger.info("\nğŸ¯ é¢„æµ‹çš„ç›¸å¯¹ä½ç‚¹æ—¥æœŸ:")
                for lp in low_points:
                    logger.info(f"  ğŸ“… {lp['date']}: ç½®ä¿¡åº¦ {lp['confidence']*100:.2f}%")
            else:
                logger.info("\nğŸ“ˆ æœ€è¿‘ä¸€ä¸ªæœˆæœªå‘ç°æ˜æ˜¾çš„ç›¸å¯¹ä½ç‚¹")
                
            # æ˜¾ç¤ºæœ€é«˜ç½®ä¿¡åº¦çš„å‡ ä¸ªé¢„æµ‹
            sorted_results = sorted(results, key=lambda x: x['confidence'], reverse=True)
            logger.info("\nğŸ” ç½®ä¿¡åº¦æœ€é«˜çš„5ä¸ªé¢„æµ‹:")
            for i, r in enumerate(sorted_results[:5], 1):
                is_low = "ç›¸å¯¹ä½ç‚¹" if r['predicted_low_point'] else "éä½ç‚¹"
                logger.info(f"  {i}. {r['date']}: {is_low} (ç½®ä¿¡åº¦: {r['confidence']*100:.2f}%)")
            
            # ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š
            logger.info("\nğŸ“„ æ­£åœ¨ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š...")
            start_date_str = recent_days[0] if recent_days else ""
            end_date_str = recent_days[-1] if recent_days else ""
            report_info = generate_prediction_report(results, start_date_str, end_date_str, config)
            
            if report_info:
                logger.info("\nğŸ“‹ æŠ¥å‘Šç”Ÿæˆå®Œæˆ:")
                logger.info(f"  ğŸ“„ MarkdownæŠ¥å‘Š: {os.path.relpath(report_info['report_path'])}")
                logger.info(f"  ğŸ§¾ CSVæ˜ç»†: {os.path.relpath(report_info['csv_path'])}")
                logger.info(f"  ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: {report_info['total_predictions']}å¤©é¢„æµ‹, {report_info['low_point_predictions']}ä¸ªä½ç‚¹, å¹³å‡ç½®ä¿¡åº¦{report_info['avg_confidence']:.4f}")
            else:
                logger.warning("âš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
                
        else:
            logger.error("æ²¡æœ‰æˆåŠŸçš„é¢„æµ‹ç»“æœ")
            return False
            
        logger.info("\nâœ… æœ€è¿‘ä¸€ä¸ªæœˆé¢„æµ‹å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"é¢„æµ‹è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)