# ç­–ç•¥ä¼˜åŒ–æµç¨‹ä»‹ç»

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»é¡¹ç›®ä¸­ç­–ç•¥å‚æ•°ä¼˜åŒ–çš„å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬ä¼˜åŒ–ç®—æ³•ã€å‚æ•°èŒƒå›´ã€è¯„ä¼°æ ‡å‡†ç­‰ã€‚

## ä¼˜åŒ–æµç¨‹æ¦‚è¿°

ç­–ç•¥ä¼˜åŒ–æ˜¯ä¸€ä¸ªç³»ç»Ÿæ€§çš„è¿‡ç¨‹ï¼Œé€šè¿‡å¤šç§ç®—æ³•å¯»æ‰¾æœ€ä¼˜çš„ç­–ç•¥å‚æ•°ç»„åˆï¼Œä»¥æé«˜ç›¸å¯¹ä½ç‚¹è¯†åˆ«çš„å‡†ç¡®æ€§å’Œç›ˆåˆ©èƒ½åŠ›ã€‚

## ç­–ç•¥ä¼˜åŒ–æµç¨‹å›¾

```mermaid
flowchart TD
    A[å¼€å§‹ç­–ç•¥ä¼˜åŒ–] --> B[æ•°æ®å‡†å¤‡é˜¶æ®µ]
    
    B --> B1[åŠ è½½å†å²æ•°æ®<br/>2018-2024å¹´æ•°æ®]
    B --> B2[æ•°æ®é¢„å¤„ç†<br/>æ¸…æ´—ã€æ ¼å¼åŒ–]
    B --> B3[è®¡ç®—æŠ€æœ¯æŒ‡æ ‡<br/>MA, RSI, MACDç­‰]
    B --> B4[æ•°æ®åˆ†å‰²<br/>è®­ç»ƒé›†65% éªŒè¯é›†20% æµ‹è¯•é›†15%]
    
    B1 --> C[å‚æ•°ç©ºé—´å®šä¹‰]
    B2 --> C
    B3 --> C
    B4 --> C
    
    C --> C1[ç½®ä¿¡åº¦æƒé‡èŒƒå›´<br/>ma_all_below: 0.2-0.4]
    C --> C2[æŠ€æœ¯æŒ‡æ ‡å‚æ•°èŒƒå›´<br/>rsi_threshold: 25-35]
    C --> C3[é£é™©æ§åˆ¶å‚æ•°èŒƒå›´<br/>final_threshold: 0.4-0.7]
    
    C1 --> D{é€‰æ‹©ä¼˜åŒ–ç®—æ³•}
    C2 --> D
    C3 --> D
    
    D -->|ä¸»è¦| E[è´å¶æ–¯ä¼˜åŒ–]
    D -->|è¾…åŠ©| F[é—ä¼ ç®—æ³•]
    D -->|å±€éƒ¨| G[å¢é‡ä¼˜åŒ–]
    
    E --> E1[é«˜æ–¯è¿‡ç¨‹å»ºæ¨¡]
    E --> E2[é‡‡é›†å‡½æ•°ä¼˜åŒ–<br/>Expected Improvement]
    E --> E3[å…¨å±€æœç´¢<br/>100æ¬¡è¯„ä¼°]
    
    F --> F1[ç§ç¾¤åˆå§‹åŒ–<br/>20ä¸ªä¸ªä½“]
    F --> F2[é€‚åº”åº¦è¯„ä¼°]
    F --> F3[é€‰æ‹©äº¤å‰å˜å¼‚<br/>10ä»£è¿›åŒ–]
    
    G --> G1[åŠ è½½å†å²æœ€ä¼˜]
    G --> G2[é‚»åŸŸæœç´¢]
    G --> G3[å±€éƒ¨ç²¾è°ƒ]
    
    E1 --> H[ç›®æ ‡å‡½æ•°è¯„ä¼°]
    E2 --> H
    E3 --> H
    F1 --> H
    F2 --> H
    F3 --> H
    G1 --> H
    G2 --> H
    G3 --> H
    
    H --> H1[å‚æ•°é…ç½®æ›´æ–°]
    H --> H2[å›æµ‹æ‰§è¡Œ<br/>åœ¨è®­ç»ƒé›†ä¸Š]
    H --> H3[æŒ‡æ ‡è®¡ç®—<br/>æˆåŠŸç‡ã€å¹³å‡æ¶¨å¹…]
    H --> H4[ç»¼åˆè¯„åˆ†<br/>åŠ æƒç»¼åˆå¾—åˆ†]
    
    H1 --> I{æ”¶æ•›åˆ¤æ–­}
    H2 --> I
    H3 --> I
    H4 --> I
    
    I -->|æœªæ”¶æ•›| J[ç»§ç»­ä¼˜åŒ–]
    I -->|å·²æ”¶æ•›| K[ç»“æœéªŒè¯]
    
    J --> H
    
    K --> K1[éªŒè¯é›†æµ‹è¯•<br/>é˜²æ­¢è¿‡æ‹Ÿåˆ]
    K --> K2[ç¨³å®šæ€§æµ‹è¯•<br/>BootstrapéªŒè¯]
    K --> K3[æ€§èƒ½å¯¹æ¯”<br/>ä¼˜åŒ–å‰åå¯¹æ¯”]
    
    K1 --> L{éªŒè¯é€šè¿‡?}
    K2 --> L
    K3 --> L
    
    L -->|é€šè¿‡| M[åº”ç”¨ä¼˜åŒ–ç»“æœ]
    L -->|å¤±è´¥| N[è°ƒæ•´ç­–ç•¥é‡æ–°ä¼˜åŒ–]
    
    N --> C
    
    M --> M1[å¤‡ä»½åŸé…ç½®]
    M --> M2[æ›´æ–°é…ç½®æ–‡ä»¶<br/>config.yaml]
    M --> M3[å…¨å±€ç”Ÿæ•ˆ<br/>æ‰€æœ‰æ¨¡å—è‡ªåŠ¨ä½¿ç”¨]
    M --> M4[æ€§èƒ½ç›‘æ§<br/>æŒç»­è·Ÿè¸ªæ•ˆæœ]
    
    M1 --> O[ä¼˜åŒ–å®Œæˆ]
    M2 --> O
    M3 --> O
    M4 --> O
    
    O --> O1[ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š]
    O --> O2[ä¿å­˜ä¼˜åŒ–å†å²]
    O --> O3[è®¾ç½®ä¸‹æ¬¡ä¼˜åŒ–è®¡åˆ’]
    
    style A fill:#e3f2fd
    style O fill:#c8e6c9
    style H fill:#fff3e0
    style L fill:#f3e5f5
    style N fill:#ffebee
```

### æµç¨‹å›¾è¯´æ˜

ç­–ç•¥ä¼˜åŒ–æµç¨‹åˆ†ä¸º**6ä¸ªæ ¸å¿ƒé˜¶æ®µ**ï¼š

1. **æ•°æ®å‡†å¤‡é˜¶æ®µ**ï¼š
   - åŠ è½½2018-2024å¹´å†å²æ•°æ®
   - è¿›è¡Œæ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ–
   - è®¡ç®—æ‰€éœ€çš„æŠ€æœ¯æŒ‡æ ‡
   - æŒ‰65%/20%/15%æ¯”ä¾‹åˆ†å‰²è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†

2. **å‚æ•°ç©ºé—´å®šä¹‰**ï¼š
   - è®¾ç½®ç½®ä¿¡åº¦æƒé‡å‚æ•°èŒƒå›´
   - å®šä¹‰æŠ€æœ¯æŒ‡æ ‡å‚æ•°è¾¹ç•Œ
   - ç¡®å®šé£é™©æ§åˆ¶å‚æ•°èŒƒå›´

3. **ä¼˜åŒ–ç®—æ³•é€‰æ‹©**ï¼š
   - **è´å¶æ–¯ä¼˜åŒ–**ï¼šä¸»è¦ç®—æ³•ï¼Œé€‚åˆå…¨å±€æœç´¢
   - **é—ä¼ ç®—æ³•**ï¼šè¾…åŠ©ç®—æ³•ï¼Œå¢å¼ºå¤šæ ·æ€§
   - **å¢é‡ä¼˜åŒ–**ï¼šå±€éƒ¨ä¼˜åŒ–ï¼Œç²¾ç»†è°ƒå‚

4. **è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹**ï¼š
   - å‚æ•°é…ç½®æ›´æ–°
   - å›æµ‹æ‰§è¡Œå’ŒæŒ‡æ ‡è®¡ç®—
   - ç»¼åˆè¯„åˆ†å’Œæ”¶æ•›åˆ¤æ–­

5. **ç»“æœéªŒè¯**ï¼š
   - éªŒè¯é›†æµ‹è¯•é˜²æ­¢è¿‡æ‹Ÿåˆ
   - BootstrapéªŒè¯æµ‹è¯•ç¨³å®šæ€§
   - ä¸åŸå‚æ•°è¿›è¡Œæ€§èƒ½å¯¹æ¯”

6. **åº”ç”¨ä¸ç›‘æ§**ï¼š
   - å¤‡ä»½åŸé…ç½®å¹¶æ›´æ–°æ–°å‚æ•°
   - å…¨å±€ç”Ÿæ•ˆåˆ°æ‰€æœ‰æ¨¡å—
   - æŒç»­ç›‘æ§ä¼˜åŒ–æ•ˆæœ

**å…³é”®å†³ç­–ç‚¹**ï¼š
- **æ”¶æ•›åˆ¤æ–­**ï¼šå†³å®šæ˜¯å¦ç»§ç»­ä¼˜åŒ–è¿­ä»£
- **éªŒè¯é€šè¿‡**ï¼šç¡®å®šä¼˜åŒ–ç»“æœæ˜¯å¦å¯ç”¨

**é¢œè‰²è¯´æ˜**ï¼š
- ğŸ”µ è“è‰²ï¼šå¼€å§‹é˜¶æ®µ
- ğŸŸ¢ ç»¿è‰²ï¼šæˆåŠŸå®Œæˆ
- ğŸŸ  æ©™è‰²ï¼šæ ¸å¿ƒè®¡ç®—è¿‡ç¨‹
- ğŸŸ£ ç´«è‰²ï¼šéªŒè¯å†³ç­–ç‚¹
- ğŸ”´ çº¢è‰²ï¼šå¤±è´¥éœ€é‡æ–°ä¼˜åŒ–

### ä¼˜åŒ–ç›®æ ‡
- **æœ€å¤§åŒ–æˆåŠŸç‡**ï¼šæé«˜ç›¸å¯¹ä½ç‚¹è¯†åˆ«çš„å‡†ç¡®æ€§
- **ä¼˜åŒ–å¹³å‡æ¶¨å¹…**ï¼šç¡®ä¿é¢„æµ‹æˆåŠŸåçš„ç›ˆåˆ©å¹…åº¦
- **ç¼©çŸ­è¾¾æ ‡å¤©æ•°**ï¼šæé«˜èµ„é‡‘ä½¿ç”¨æ•ˆç‡
- **æ§åˆ¶é£é™©æ°´å¹³**ï¼šå¹³è¡¡æ”¶ç›Šä¸é£é™©

### ä¼˜åŒ–ç»´åº¦
- **æŠ€æœ¯æŒ‡æ ‡å‚æ•°**ï¼šMAå‘¨æœŸã€RSIé˜ˆå€¼ã€MACDå‚æ•°ç­‰
- **ç½®ä¿¡åº¦æƒé‡**ï¼šå„æŒ‡æ ‡åœ¨æœ€ç»ˆå†³ç­–ä¸­çš„æƒé‡
- **é£é™©æ§åˆ¶å‚æ•°**ï¼šæœ€å°ç½®ä¿¡åº¦ã€å†·å´æœŸç­‰
- **AIæ¨¡å‹å‚æ•°**ï¼šè®­ç»ƒå‚æ•°ã€ç‰¹å¾æƒé‡ç­‰

## ä¼˜åŒ–ç®—æ³•ä»‹ç»

### 1. è´å¶æ–¯ä¼˜åŒ–ï¼ˆä¸»è¦ç®—æ³•ï¼‰

#### ç®—æ³•åŸç†
è´å¶æ–¯ä¼˜åŒ–åŸºäºé«˜æ–¯è¿‡ç¨‹ï¼Œé€šè¿‡å»ºç«‹ç›®æ ‡å‡½æ•°çš„æ¦‚ç‡æ¨¡å‹æ¥æŒ‡å¯¼å‚æ•°æœç´¢ï¼Œèƒ½å¤Ÿåœ¨è¾ƒå°‘çš„è¯„ä¼°æ¬¡æ•°ä¸‹æ‰¾åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚

#### å®ç°æµç¨‹
```python
def bayesian_optimization():
    # 1. åˆå§‹åŒ–é«˜æ–¯è¿‡ç¨‹
    gp = GaussianProcessRegressor()
    
    # 2. éšæœºé‡‡æ ·åˆå§‹ç‚¹
    initial_points = random_sample(param_ranges, n_initial=20)
    
    # 3. è¯„ä¼°åˆå§‹ç‚¹
    initial_scores = [evaluate(point) for point in initial_points]
    
    # 4. è¿­ä»£ä¼˜åŒ–
    for i in range(n_calls):
        # 4.1 æ›´æ–°é«˜æ–¯è¿‡ç¨‹
        gp.fit(evaluated_points, scores)
        
        # 4.2 é‡‡é›†å‡½æ•°é€‰æ‹©ä¸‹ä¸€ä¸ªç‚¹
        next_point = acquisition_function(gp, param_ranges)
        
        # 4.3 è¯„ä¼°æ–°ç‚¹
        score = evaluate(next_point)
        
        # 4.4 æ›´æ–°å†å²
        evaluated_points.append(next_point)
        scores.append(score)
    
    return best_point, best_score
```

#### é…ç½®å‚æ•°
```yaml
bayesian_optimization:
  n_calls: 100              # æœ€å¤§è¯„ä¼°æ¬¡æ•°
  n_initial_points: 20      # åˆå§‹éšæœºç‚¹æ•°é‡
  acq_func: "EI"           # é‡‡é›†å‡½æ•°ï¼ˆExpected Improvementï¼‰
  xi: 0.01                 # æ¢ç´¢å‚æ•°
  kappa: 1.96              # UCBå‚æ•°
```

### 2. é—ä¼ ç®—æ³•ï¼ˆè¾…åŠ©ç®—æ³•ï¼‰

#### ç®—æ³•æµç¨‹
```python
def genetic_algorithm():
    # 1. åˆå§‹åŒ–ç§ç¾¤
    population = initialize_population(population_size)
    
    for generation in range(max_generations):
        # 2. è¯„ä¼°é€‚åº”åº¦
        fitness_scores = [evaluate(individual) for individual in population]
        
        # 3. é€‰æ‹©æ“ä½œï¼ˆé”¦æ ‡èµ›é€‰æ‹©ï¼‰
        parents = tournament_selection(population, fitness_scores)
        
        # 4. äº¤å‰æ“ä½œ
        offspring = crossover(parents, crossover_rate)
        
        # 5. å˜å¼‚æ“ä½œ
        offspring = mutate(offspring, mutation_rate)
        
        # 6. ç²¾è‹±ä¿ç•™
        population = elite_replacement(population, offspring, fitness_scores)
    
    return best_individual
```

#### é…ç½®å‚æ•°
```yaml
genetic_algorithm:
  population_size: 20       # ç§ç¾¤å¤§å°
  generations: 10           # è¿›åŒ–ä»£æ•°
  crossover_rate: 0.8       # äº¤å‰æ¦‚ç‡
  mutation_rate: 0.1        # å˜å¼‚æ¦‚ç‡
  elite_ratio: 0.1          # ç²¾è‹±ä¿ç•™æ¯”ä¾‹
```

### 3. å¢é‡ä¼˜åŒ–ç®—æ³•

#### ç®—æ³•ç‰¹ç‚¹
åŸºäºå†å²æœ€ä¼˜ç»“æœè¿›è¡Œå±€éƒ¨æœç´¢ï¼Œé¿å…é‡å¤æœç´¢å·²çŸ¥çš„æ¬¡ä¼˜åŒºåŸŸã€‚

#### å®ç°æœºåˆ¶
```python
def incremental_optimization():
    # 1. åŠ è½½å†å²æœ€ä¼˜å‚æ•°
    best_params = load_historical_best()
    
    # 2. ç”Ÿæˆé‚»åŸŸå€™é€‰å‚æ•°
    candidates = generate_neighbors(best_params, neighbor_radius=0.1)
    
    # 3. æ”¶ç¼©æœç´¢èŒƒå›´
    contracted_ranges = contract_ranges(original_ranges, factor=0.5)
    
    # 4. åœ¨æ”¶ç¼©èŒƒå›´å†…æœç´¢
    optimized_params = search_in_ranges(contracted_ranges)
    
    return optimized_params
```

## å‚æ•°ä¼˜åŒ–èŒƒå›´

### ç½®ä¿¡åº¦æƒé‡å‚æ•°
```yaml
confidence_weights:
  # ç§»åŠ¨å¹³å‡çº¿æƒé‡
  ma_all_below: [0.2, 0.4]          # ä»·æ ¼è·Œç ´æ‰€æœ‰å‡çº¿
  ma_partial_below: [0.1, 0.3]      # ä»·æ ¼è·Œç ´éƒ¨åˆ†å‡çº¿
  
  # æŠ€æœ¯æŒ‡æ ‡æƒé‡
  rsi_oversold: [0.2, 0.4]          # RSIè¶…å–
  rsi_low: [0.1, 0.3]               # RSIåä½
  macd_negative: [0.05, 0.15]       # MACDè´Ÿå€¼
  bb_lower_near: [0.15, 0.25]       # å¸ƒæ—å¸¦ä¸‹è½¨
  
  # ä»·æ ¼åŠ¨é‡æƒé‡
  recent_decline: [0.1, 0.3]        # è¿‘æœŸä¸‹è·Œ
  volume_panic_bonus: [0.05, 0.15]  # ææ…Œæ€§æŠ›å”®
  volume_surge_bonus: [0.02, 0.08]  # æ¸©å’Œæ”¾é‡
  
  # AIä¼˜åŒ–å‚æ•°
  dynamic_confidence_adjustment: [0.05, 0.25]  # åŠ¨æ€è°ƒæ•´
  market_sentiment_weight: [0.08, 0.25]        # å¸‚åœºæƒ…ç»ª
  trend_strength_weight: [0.06, 0.20]          # è¶‹åŠ¿å¼ºåº¦
  volume_weight: [0.15, 0.35]                  # æˆäº¤é‡æƒé‡
  price_momentum_weight: [0.12, 0.30]          # ä»·æ ¼åŠ¨é‡æƒé‡
```

### æŠ€æœ¯æŒ‡æ ‡å‚æ•°
```yaml
technical_indicators:
  # ç§»åŠ¨å¹³å‡çº¿
  ma_periods: [[5,10,20,60], [5,10,20,50], [5,15,30,60]]
  
  # RSIå‚æ•°
  rsi_period: [10, 20]              # RSIè®¡ç®—å‘¨æœŸ
  rsi_oversold_threshold: [25, 35]  # è¶…å–é˜ˆå€¼
  rsi_low_threshold: [35, 45]       # åä½é˜ˆå€¼
  
  # MACDå‚æ•°
  macd_fast: [10, 15]               # å¿«çº¿å‘¨æœŸ
  macd_slow: [24, 30]               # æ…¢çº¿å‘¨æœŸ
  macd_signal: [7, 12]              # ä¿¡å·çº¿å‘¨æœŸ
  
  # å¸ƒæ—å¸¦å‚æ•°
  bb_period: [15, 25]               # è®¡ç®—å‘¨æœŸ
  bb_std: [1.5, 2.5]                # æ ‡å‡†å·®å€æ•°
```

### é£é™©æ§åˆ¶å‚æ•°
```yaml
risk_control:
  final_threshold: [0.4, 0.7]      # æœ€ç»ˆç½®ä¿¡åº¦é˜ˆå€¼
  min_confidence: [0.5, 0.8]       # æœ€å°ç½®ä¿¡åº¦è¦æ±‚
  max_daily_signals: [1, 5]        # æ¯æ—¥æœ€å¤§ä¿¡å·æ•°
  cooldown_days: [3, 10]           # ä¿¡å·å†·å´æœŸ
```

## è¯„ä¼°ä½“ç³»

### ä¸»è¦è¯„ä¼°æŒ‡æ ‡

#### 1. æˆåŠŸç‡ï¼ˆSuccess Rateï¼‰
```python
success_rate = successful_predictions / total_predictions

# æˆåŠŸæ ‡å‡†ï¼šé¢„æµ‹ä¸ºç›¸å¯¹ä½ç‚¹ä¸”æœªæ¥20å¤©å†…æ¶¨å¹…â‰¥4%
```

#### 2. å¹³å‡æ¶¨å¹…ï¼ˆAverage Riseï¼‰
```python
average_rise = sum(future_max_rises) / len(predictions)

# è®¡ç®—æ‰€æœ‰é¢„æµ‹ç‚¹æœªæ¥æœ€å¤§æ¶¨å¹…çš„å¹³å‡å€¼
```

#### 3. å¹³å‡å¤©æ•°ï¼ˆAverage Daysï¼‰
```python
average_days = sum(days_to_target) / len(successful_predictions)

# è¾¾åˆ°ç›®æ ‡æ¶¨å¹…æ‰€éœ€çš„å¹³å‡å¤©æ•°
```

#### 4. é£é™©è°ƒæ•´æ”¶ç›Šï¼ˆRisk-Adjusted Returnï¼‰
```python
risk_adjusted_return = (average_rise - risk_free_rate) / volatility
```

### ç»¼åˆè¯„åˆ†ç®—æ³•
```python
def calculate_composite_score(success_rate, avg_rise, avg_days, risk_metrics):
    # æƒé‡é…ç½®
    weights = {
        'success': 0.4,    # æˆåŠŸç‡æƒé‡
        'rise': 0.3,       # æ¶¨å¹…æƒé‡
        'speed': 0.2,      # é€Ÿåº¦æƒé‡
        'risk': 0.1        # é£é™©æƒé‡
    }
    
    # æ ‡å‡†åŒ–å¤„ç†
    success_score = success_rate * weights['success']
    rise_score = min(avg_rise / 0.1, 1.0) * weights['rise']  # ä»¥10%ä¸ºåŸºå‡†
    speed_score = min(10.0 / avg_days, 1.0) * weights['speed']  # ä»¥10å¤©ä¸ºåŸºå‡†
    risk_score = (1 - risk_metrics['volatility']) * weights['risk']
    
    total_score = success_score + rise_score + speed_score + risk_score
    return total_score
```

## ä¼˜åŒ–æ‰§è¡Œæµç¨‹

### 1. æ•°æ®å‡†å¤‡
```python
def prepare_optimization_data():
    # 1.1 åŠ è½½å†å²æ•°æ®
    data = load_historical_data(start_date, end_date)
    
    # 1.2 æ•°æ®é¢„å¤„ç†
    data = preprocess_data(data)
    
    # 1.3 è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    data = calculate_technical_indicators(data)
    
    # 1.4 æ•°æ®åˆ†å‰²ï¼ˆä¸¥æ ¼æ—¶é—´åºåˆ—åˆ†å‰²ï¼‰
    train_data, val_data, test_data = split_data(data, ratios=[0.65, 0.20, 0.15])
    
    return train_data, val_data, test_data
```

### 2. å‚æ•°ç©ºé—´å®šä¹‰
```python
def define_parameter_space():
    param_space = {
        # ç½®ä¿¡åº¦æƒé‡å‚æ•°
        'ma_all_below': Real(0.2, 0.4),
        'rsi_oversold': Real(0.2, 0.4),
        'bb_lower_near': Real(0.15, 0.25),
        
        # æŠ€æœ¯æŒ‡æ ‡å‚æ•°
        'rsi_oversold_threshold': Integer(25, 35),
        'bb_period': Integer(15, 25),
        
        # é£é™©æ§åˆ¶å‚æ•°
        'final_threshold': Real(0.4, 0.7),
        'cooldown_days': Integer(3, 10)
    }
    return param_space
```

### 3. ç›®æ ‡å‡½æ•°å®šä¹‰
```python
def objective_function(params):
    # 3.1 æ›´æ–°ç­–ç•¥å‚æ•°
    strategy_module.update_params(params)
    
    # 3.2 è¿è¡Œå›æµ‹
    backtest_results = strategy_module.backtest(train_data)
    
    # 3.3 è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    evaluation = strategy_module.evaluate_strategy(backtest_results)
    
    # 3.4 è®¡ç®—ç»¼åˆå¾—åˆ†
    score = calculate_composite_score(
        evaluation['success_rate'],
        evaluation['avg_rise'], 
        evaluation['avg_days'],
        evaluation['risk_metrics']
    )
    
    # 3.5 è¿”å›è´Ÿæ•°ï¼ˆå› ä¸ºä¼˜åŒ–å™¨å¯»æ‰¾æœ€å°å€¼ï¼‰
    return -score
```

### 4. ä¼˜åŒ–æ‰§è¡Œ
```python
def execute_optimization():
    # 4.1 é€‰æ‹©ä¼˜åŒ–ç®—æ³•
    if config['optimization']['use_bayesian']:
        optimizer = BayesianOptimizer()
    elif config['optimization']['use_genetic']:
        optimizer = GeneticOptimizer()
    else:
        optimizer = IncrementalOptimizer()
    
    # 4.2 æ‰§è¡Œä¼˜åŒ–
    result = optimizer.minimize(
        func=objective_function,
        dimensions=param_space,
        n_calls=100,
        random_state=42
    )
    
    # 4.3 è·å–æœ€ä¼˜å‚æ•°
    best_params = dict(zip(param_names, result.x))
    best_score = -result.fun
    
    return best_params, best_score
```

### 5. ç»“æœéªŒè¯
```python
def validate_optimization_results(best_params):
    # 5.1 åœ¨éªŒè¯é›†ä¸Šæµ‹è¯•
    strategy_module.update_params(best_params)
    val_results = strategy_module.backtest(val_data)
    val_evaluation = strategy_module.evaluate_strategy(val_results)
    
    # 5.2 è¿‡æ‹Ÿåˆæ£€æµ‹
    overfitting_ratio = train_score / val_score
    if overfitting_ratio > 1.2:
        print("è­¦å‘Šï¼šå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ")
    
    # 5.3 ç¨³å®šæ€§æµ‹è¯•
    stability_test = run_bootstrap_validation(best_params, n_iterations=100)
    
    return val_evaluation, stability_test
```

## å¢é‡ä¼˜åŒ–æœºåˆ¶

### å†å²è®°å½•ç®¡ç†
```python
class OptimizationHistory:
    def __init__(self):
        self.history = []
        self.best_params = None
        self.best_score = -np.inf
    
    def add_result(self, params, score, metrics):
        self.history.append({
            'params': params,
            'score': score,
            'metrics': metrics,
            'timestamp': datetime.now()
        })
        
        if score > self.best_score:
            self.best_score = score
            self.best_params = params
    
    def get_convergence_trend(self):
        scores = [h['score'] for h in self.history[-50:]]
        return np.polyfit(range(len(scores)), scores, 1)[0]
```

### æ”¶æ•›åˆ¤æ–­
```python
def check_convergence(history, patience=20, min_improvement=0.001):
    if len(history.history) < patience:
        return False
    
    recent_scores = [h['score'] for h in history.history[-patience:]]
    max_recent = max(recent_scores)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ”¹è¿›
    improvement = max_recent - recent_scores[0]
    
    return improvement < min_improvement
```

## ä¼˜åŒ–ç»“æœåº”ç”¨

### 1. å‚æ•°ä¿å­˜
```python
def save_optimized_params(best_params, config_path):
    # 1.1 å¤‡ä»½åŸé…ç½®
    backup_config(config_path)
    
    # 1.2 æ›´æ–°é…ç½®æ–‡ä»¶
    config = load_config(config_path)
    config['strategy']['confidence_weights'].update(best_params)
    
    # 1.3 ä¿å­˜é…ç½®
    save_config(config, config_path)
    
    # 1.4 éªŒè¯ä¿å­˜ç»“æœ
    verify_config_update(config_path, best_params)
```

### 2. å…¨å±€ç”Ÿæ•ˆ
ä¼˜åŒ–åçš„å‚æ•°ä¼šè‡ªåŠ¨åœ¨ä»¥ä¸‹åœºæ™¯ä¸­ç”Ÿæ•ˆï¼š
- å•æ—¥é¢„æµ‹ï¼ˆ`python run.py s`ï¼‰
- æ»šåŠ¨å›æµ‹ï¼ˆ`python run.py r`ï¼‰
- äº¤æ˜“æœºå™¨äººï¼ˆ`python run.py bot`ï¼‰
- AIè®­ç»ƒï¼ˆ`python run.py ai`ï¼‰

### 3. æ€§èƒ½å¯¹æ¯”
```python
def compare_performance(original_params, optimized_params):
    # 3.1 ä½¿ç”¨åŸå‚æ•°å›æµ‹
    original_results = backtest_with_params(original_params)
    
    # 3.2 ä½¿ç”¨ä¼˜åŒ–å‚æ•°å›æµ‹
    optimized_results = backtest_with_params(optimized_params)
    
    # 3.3 è®¡ç®—æ”¹è¿›å¹…åº¦
    improvements = {
        'success_rate': (optimized_results['success_rate'] - 
                        original_results['success_rate']) / original_results['success_rate'],
        'avg_rise': (optimized_results['avg_rise'] - 
                    original_results['avg_rise']) / original_results['avg_rise'],
        'composite_score': (optimized_results['score'] - 
                           original_results['score']) / original_results['score']
    }
    
    return improvements
```

## ä¼˜åŒ–ç­–ç•¥å»ºè®®

### 1. æ¸è¿›å¼ä¼˜åŒ–
- å…ˆä¼˜åŒ–ä¸»è¦å‚æ•°ï¼ˆç½®ä¿¡åº¦æƒé‡ï¼‰
- å†ä¼˜åŒ–æ¬¡è¦å‚æ•°ï¼ˆæŠ€æœ¯æŒ‡æ ‡å‚æ•°ï¼‰
- æœ€åå¾®è°ƒé£é™©æ§åˆ¶å‚æ•°

### 2. å¤šè½®ä¼˜åŒ–
```python
def multi_round_optimization():
    # ç¬¬ä¸€è½®ï¼šç²—ç³™æœç´¢
    round1_result = optimize_with_wide_ranges(n_calls=50)
    
    # ç¬¬äºŒè½®ï¼šç²¾ç»†æœç´¢
    narrow_ranges = narrow_search_space(round1_result, factor=0.3)
    round2_result = optimize_with_ranges(narrow_ranges, n_calls=50)
    
    # ç¬¬ä¸‰è½®ï¼šå±€éƒ¨ä¼˜åŒ–
    final_result = local_optimization(round2_result)
    
    return final_result
```

### 3. äº¤å‰éªŒè¯
```python
def cross_validation_optimization(data, n_folds=5):
    fold_results = []
    
    for i in range(n_folds):
        # åˆ›å»ºæŠ˜å 
        train_fold, val_fold = create_fold(data, i, n_folds)
        
        # ä¼˜åŒ–å‚æ•°
        best_params = optimize_on_fold(train_fold)
        
        # éªŒè¯ç»“æœ
        val_score = validate_on_fold(val_fold, best_params)
        fold_results.append((best_params, val_score))
    
    # é€‰æ‹©æœ€ç¨³å®šçš„å‚æ•°
    return select_most_stable_params(fold_results)
```

## å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### 1. ä¼˜åŒ–æ”¶æ•›æ…¢
**åŸå› **ï¼šå‚æ•°ç©ºé—´å¤ªå¤§ï¼Œæœç´¢æ•ˆç‡ä½
**è§£å†³**ï¼š
- å‡å°‘åŒæ—¶ä¼˜åŒ–çš„å‚æ•°æ•°é‡
- ä½¿ç”¨å…ˆéªŒçŸ¥è¯†ç¼©å°æœç´¢èŒƒå›´
- é‡‡ç”¨åˆ†å±‚ä¼˜åŒ–ç­–ç•¥

### 2. è¿‡æ‹Ÿåˆé—®é¢˜
**åŸå› **ï¼šåœ¨è®­ç»ƒé›†ä¸Šè¿‡åº¦ä¼˜åŒ–
**è§£å†³**ï¼š
- ä½¿ç”¨ä¸¥æ ¼çš„æ•°æ®åˆ†å‰²
- å¢åŠ æ­£åˆ™åŒ–çº¦æŸ
- å®šæœŸåœ¨éªŒè¯é›†ä¸Šæ£€æŸ¥

### 3. å‚æ•°ä¸ç¨³å®š
**åŸå› **ï¼šä¼˜åŒ–ç»“æœå¯¹åˆå§‹å€¼æ•æ„Ÿ
**è§£å†³**ï¼š
- å¤šæ¬¡è¿è¡Œå–å¹³å‡å€¼
- ä½¿ç”¨é›†æˆæ–¹æ³•
- å¢åŠ ä¼˜åŒ–è½®æ•°

### 4. è®¡ç®—æ—¶é—´è¿‡é•¿
**åŸå› **ï¼šè¯„ä¼°å‡½æ•°å¤æ‚ï¼Œä¼˜åŒ–æ¬¡æ•°å¤š
**è§£å†³**ï¼š
- ä½¿ç”¨å¹¶è¡Œè®¡ç®—
- å‡å°‘å›æµ‹æ•°æ®é‡
- é‡‡ç”¨è¿‘ä¼¼è¯„ä¼°æ–¹æ³•

## æ€»ç»“

ç­–ç•¥ä¼˜åŒ–æ˜¯ä¸€ä¸ªå¤æ‚çš„ç³»ç»Ÿå·¥ç¨‹ï¼Œéœ€è¦ç»¼åˆè€ƒè™‘ç®—æ³•é€‰æ‹©ã€å‚æ•°èŒƒå›´ã€è¯„ä¼°æ ‡å‡†ç­‰å¤šä¸ªæ–¹é¢ã€‚é€šè¿‡åˆç†çš„ä¼˜åŒ–æµç¨‹ï¼Œå¯ä»¥æ˜¾è‘—æå‡ç­–ç•¥çš„è¡¨ç°ã€‚å»ºè®®ä»ç®€å•å‚æ•°å¼€å§‹ï¼Œé€æ­¥æ‰©å±•åˆ°å¤æ‚å‚æ•°ï¼Œæ³¨æ„é¿å…è¿‡æ‹Ÿåˆï¼Œç¡®ä¿ä¼˜åŒ–ç»“æœçš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ 