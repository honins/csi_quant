#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å¢å¼ºç‰ˆæ—¥å¸¸äº¤æ˜“æµç¨‹è‡ªåŠ¨åŒ–æœºå™¨äºº
æ”¯æŒæ— äººå€¼å®ˆã€å¸¸é©»è¿è¡Œã€è‡ªåŠ¨æ•°æ®æ›´æ–°ã€æ€§èƒ½ç›‘æ§ã€æ•°æ®å¤‡ä»½ç­‰åŠŸèƒ½
"""

import sys
import os
import json
import argparse
import schedule
import time
import logging
import threading
import subprocess
import psutil
import signal
import shutil
import git
import pandas as pd
import platform
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from pathlib import Path
from dataclasses import dataclass
from contextlib import contextmanager
import tempfile
import uuid

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.data.data_module import DataModule
from src.strategy.strategy_module import StrategyModule
from src.ai.ai_optimizer_improved import AIOptimizerImproved
from src.utils.utils import load_config, setup_logging
from src.notification.notification_module import NotificationModule

@dataclass
class SystemMetrics:
    """ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
    cpu_percent: float
    memory_percent: float
    disk_usage: float
    process_count: int
    timestamp: datetime

class EnhancedDailyTradingBot:
    """å¢å¼ºç‰ˆæ—¥å¸¸äº¤æ˜“æµç¨‹è‡ªåŠ¨åŒ–æœºå™¨äºº"""
    
    def __init__(self, config_path: Optional[str] = None, daemon_mode: bool = False):
        """åˆå§‹åŒ–å¢å¼ºç‰ˆäº¤æ˜“æœºå™¨äºº"""
        
        # å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼æ ‡å¿—
        self.daemon_mode = daemon_mode
        self.running = True
        self.restart_flag = False
        
        # çº¿ç¨‹é”
        self._metrics_lock = threading.Lock()
        self._state_lock = threading.Lock()
        
        # å¹³å°æ£€æµ‹
        self.is_windows = platform.system() == 'Windows'
        
        # åŠ è½½é…ç½®
        if not config_path:
            config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'config_core.yaml')
        
        try:
            self.config = load_config(config_path=config_path)
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤é…ç½®æ–‡ä»¶
            fallback_config = os.path.join(os.path.dirname(__file__), '..', 'config', 'config.yaml')
            if os.path.exists(fallback_config):
                self.config = load_config(config_path=fallback_config)
            else:
                raise RuntimeError(f"æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–æ¨¡å—
        try:
            self.data_module = DataModule(self.config)
            self.strategy_module = StrategyModule(self.config)
            self.ai_improved = AIOptimizerImproved(self.config)
            self.notification_manager = NotificationModule(self.config)
        except Exception as e:
            self.logger.error(f"æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
        
        # è®¾ç½®å·¥ä½œç›®å½•
        self.work_dir = Path(os.path.dirname(__file__)).parent
        self.results_dir = self.work_dir / 'results' / 'daily_trading'
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # å¤‡ä»½ç›®å½•
        self.backup_dir = self.work_dir / 'results' / 'backup'
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        # çŠ¶æ€å’Œå†å²æ–‡ä»¶
        self.state_file = self.results_dir / 'bot_state.json'
        self.history_file = self.results_dir / 'trading_history.json'
        self.metrics_file = self.results_dir / 'performance_metrics.json'
        self.pid_file = self.results_dir / 'bot.pid'
        
        # åŠ è½½çŠ¶æ€
        self.state = self.load_state()
        
        # æ€§èƒ½ç›‘æ§
        self.metrics_history = []
        self.last_health_check = datetime.now()
        
        # Gitä»“åº“ï¼ˆç”¨äºæ•°æ®æäº¤ï¼‰
        try:
            self.git_repo = git.Repo(self.work_dir)
            self.logger.info("Gitä»“åº“åˆå§‹åŒ–æˆåŠŸ")
        except git.exc.GitError as e:
            self.git_repo = None
            self.logger.warning(f"Gitä»“åº“åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œæ•°æ®æäº¤åŠŸèƒ½å°†è¢«ç¦ç”¨")
        except Exception as e:
            self.git_repo = None
            self.logger.warning(f"Gitä»“åº“åˆå§‹åŒ–å¼‚å¸¸: {e}ï¼Œæ•°æ®æäº¤åŠŸèƒ½å°†è¢«ç¦ç”¨")
        
        # è®¾ç½®ä¿¡å·å¤„ç†å™¨ï¼ˆå®ˆæŠ¤è¿›ç¨‹ï¼‰
        if self.daemon_mode:
            self._setup_signal_handlers()
        
        self.logger.info("å¢å¼ºç‰ˆæ—¥å¸¸äº¤æ˜“æœºå™¨äººåˆå§‹åŒ–å®Œæˆ")
    
    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰"""
        try:
            signal.signal(signal.SIGTERM, self._signal_handler)
            signal.signal(signal.SIGINT, self._signal_handler)
            
            # SIGUSR1ä»…åœ¨éWindowsç³»ç»Ÿä¸­å¯ç”¨
            if not self.is_windows:
                signal.signal(signal.SIGUSR1, self._restart_handler)
                self.logger.info("ä¿¡å·å¤„ç†å™¨è®¾ç½®å®Œæˆï¼ˆåŒ…å«SIGUSR1ï¼‰")
            else:
                self.logger.info("ä¿¡å·å¤„ç†å™¨è®¾ç½®å®Œæˆï¼ˆWindowsæ¨¡å¼ï¼Œè·³è¿‡SIGUSR1ï¼‰")
                
        except Exception as e:
            self.logger.warning(f"ä¿¡å·å¤„ç†å™¨è®¾ç½®å¤±è´¥: {e}")
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨"""
        self.logger.info(f"æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡é€€å‡º...")
        self.running = False
    
    def _restart_handler(self, signum, frame):
        """é‡å¯ä¿¡å·å¤„ç†å™¨ï¼ˆä»…é™éWindowsç³»ç»Ÿï¼‰"""
        self.logger.info("æ¥æ”¶åˆ°é‡å¯ä¿¡å·...")
        self.restart_flag = True
        self.running = False
    
    def setup_logging(self):
        """è®¾ç½®å¢å¼ºç‰ˆæ—¥å¿—"""
        log_dir = os.path.join(os.path.dirname(__file__), '..', 'logs')
        os.makedirs(log_dir, exist_ok=True)
        
        # ä¸»æ—¥å¿—æ–‡ä»¶
        main_log = os.path.join(log_dir, 'enhanced_trading_bot.log')
        
        # åˆ›å»ºæ—¥å¿—æ ¼å¼å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
        )
        
        # ä¸»æ—¥å¿—å¤„ç†å™¨
        main_handler = logging.FileHandler(main_log, encoding='utf-8')
        main_handler.setFormatter(formatter)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        
        # é…ç½®æ ¹æ—¥å¿—å™¨
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.INFO)
        root_logger.addHandler(main_handler)
        
        # å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ä¸‹ä¸è¾“å‡ºåˆ°æ§åˆ¶å°
        if not self.daemon_mode:
            root_logger.addHandler(console_handler)
    
    def write_pid_file(self):
        """å†™å…¥PIDæ–‡ä»¶"""
        try:
            with open(self.pid_file, 'w', encoding='utf-8') as f:
                f.write(str(os.getpid()))
        except Exception as e:
            self.logger.error(f"å†™å…¥PIDæ–‡ä»¶å¤±è´¥: {e}")
    
    def remove_pid_file(self):
        """åˆ é™¤PIDæ–‡ä»¶"""
        try:
            if self.pid_file.exists():
                os.remove(self.pid_file)
        except Exception as e:
            self.logger.error(f"åˆ é™¤PIDæ–‡ä»¶å¤±è´¥: {e}")
    
    def load_state(self) -> Dict[str, Any]:
        """åŠ è½½æœºå™¨äººçŠ¶æ€ï¼ˆå‘åå…¼å®¹ï¼‰"""
        # é»˜è®¤çŠ¶æ€
        default_state = {
            'last_training_date': None,
            'last_prediction_date': None,
            'last_data_fetch': None,
            'last_backup': None,
            'consecutive_errors': 0,
            'total_predictions': 0,
            'successful_predictions': 0,
            'training_count': 0,
            'data_fetch_count': 0,
            'backup_count': 0,
            'start_date': datetime.now().strftime('%Y-%m-%d'),
            'uptime_start': datetime.now().isoformat()
        }
        
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    existing_state = json.load(f)
                
                # åˆå¹¶ç°æœ‰çŠ¶æ€å’Œé»˜è®¤çŠ¶æ€ï¼ˆç°æœ‰çŠ¶æ€ä¼˜å…ˆï¼‰
                merged_state = default_state.copy()
                merged_state.update(existing_state)
                
                # ç¡®ä¿æ–°å­—æ®µå­˜åœ¨
                if 'uptime_start' not in merged_state:
                    merged_state['uptime_start'] = datetime.now().isoformat()
                if 'data_fetch_count' not in merged_state:
                    merged_state['data_fetch_count'] = 0
                if 'backup_count' not in merged_state:
                    merged_state['backup_count'] = 0
                if 'last_data_fetch' not in merged_state:
                    merged_state['last_data_fetch'] = None
                if 'last_backup' not in merged_state:
                    merged_state['last_backup'] = None
                
                return merged_state
            except (json.JSONDecodeError, IOError) as e:
                self.logger.warning(f"åŠ è½½çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
        
        return default_state
    
    def save_state(self):
        """ä¿å­˜æœºå™¨äººçŠ¶æ€ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self._state_lock:
            try:
                # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ç¡®ä¿åŸå­å†™å…¥
                temp_file = self.state_file.with_suffix('.tmp')
                with open(temp_file, 'w', encoding='utf-8') as f:
                    json.dump(self.state, f, indent=2, ensure_ascii=False)
                
                # åŸå­æ›¿æ¢
                if self.is_windows:
                    # Windowséœ€è¦å…ˆåˆ é™¤ç›®æ ‡æ–‡ä»¶
                    if self.state_file.exists():
                        os.remove(self.state_file)
                temp_file.replace(self.state_file)
                
            except Exception as e:
                self.logger.error(f"ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_file.exists():
                    os.remove(temp_file)
    
    def collect_performance_metrics(self) -> SystemMetrics:
        """æ”¶é›†ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œè·¨å¹³å°å…¼å®¹ï¼‰"""
        try:
            # è·å–ç£ç›˜ä½¿ç”¨ç‡ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰
            if self.is_windows:
                # Windowsä½¿ç”¨Cç›˜
                disk_path = 'C:\\'
            else:
                # Unix/Linuxä½¿ç”¨æ ¹ç›®å½•
                disk_path = '/'
            
            try:
                disk_usage = psutil.disk_usage(disk_path).percent
            except Exception as e:
                self.logger.warning(f"æ— æ³•è·å–ç£ç›˜ä½¿ç”¨ç‡: {e}")
                disk_usage = 0.0
            
            metrics = SystemMetrics(
                cpu_percent=psutil.cpu_percent(interval=1),
                memory_percent=psutil.virtual_memory().percent,
                disk_usage=disk_usage,
                process_count=len(psutil.pids()),
                timestamp=datetime.now()
            )
            
            # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°å†å²è®°å½•
            with self._metrics_lock:
                self.metrics_history.append(metrics)
                
                # åªä¿ç•™æœ€è¿‘24å°æ—¶çš„è®°å½•
                cutoff_time = datetime.now() - timedelta(hours=24)
                self.metrics_history = [
                    m for m in self.metrics_history 
                    if m.timestamp > cutoff_time
                ]
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            self.save_metrics_to_file()
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"æ”¶é›†æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
            return SystemMetrics(0, 0, 0, 0, datetime.now())
    
    def save_metrics_to_file(self):
        """ä¿å­˜æ€§èƒ½æŒ‡æ ‡åˆ°æ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        try:
            with self._metrics_lock:
                metrics_data = []
                for metric in self.metrics_history[-100:]:  # åªä¿å­˜æœ€è¿‘100æ¡
                    metrics_data.append({
                        'timestamp': metric.timestamp.isoformat(),
                        'cpu_percent': metric.cpu_percent,
                        'memory_percent': metric.memory_percent,
                        'disk_usage': metric.disk_usage,
                        'process_count': metric.process_count
                    })
            
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ç¡®ä¿åŸå­å†™å…¥
            temp_file = self.metrics_file.with_suffix('.tmp')
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(metrics_data, f, indent=2, ensure_ascii=False)
            
            # åŸå­æ›¿æ¢
            if self.is_windows:
                if self.metrics_file.exists():
                    os.remove(self.metrics_file)
            temp_file.replace(self.metrics_file)
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file.exists():
                os.remove(temp_file)
    
    def auto_fetch_and_commit_data(self) -> Dict[str, Any]:
        """è‡ªåŠ¨æ‹‰å–æœ€æ–°æ•°æ®å¹¶æäº¤"""
        try:
            self.logger.info("ğŸ”„ å¼€å§‹è‡ªåŠ¨æ•°æ®æ‹‰å–å’Œæäº¤æµç¨‹...")
            
            result = {
                'success': False,
                'timestamp': datetime.now().isoformat(),
                'fetch_success': False,
                'commit_success': False,
                'data_updated': False,
                'error': None
            }
            
            # æ­¥éª¤1: æ‹‰å–æœ€æ–°æ•°æ®
            self.logger.info("ğŸ“¥ æ‹‰å–æœ€æ–°æ•°æ®...")
            try:
                from src.data.data_fetch import main as fetch_main
                fetch_result = fetch_main()
                
                if isinstance(fetch_result, dict):
                    result['fetch_success'] = fetch_result.get('code') == 200
                    result['data_updated'] = fetch_result.get('updated', False)
                else:
                    result['fetch_success'] = bool(fetch_result)
                    result['data_updated'] = True
                
                if result['fetch_success']:
                    self.logger.info("âœ… æ•°æ®æ‹‰å–æˆåŠŸ")
                    with self._state_lock:
                        self.state['data_fetch_count'] += 1
                        self.state['last_data_fetch'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                else:
                    self.logger.error("âŒ æ•°æ®æ‹‰å–å¤±è´¥")
                    return result
                    
            except Exception as e:
                self.logger.error(f"æ•°æ®æ‹‰å–å¼‚å¸¸: {e}")
                result['error'] = f"æ•°æ®æ‹‰å–å¤±è´¥: {str(e)}"
                return result
            
            # æ­¥éª¤2: æ•°æ®è´¨é‡æ£€æŸ¥
            self.logger.info("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥...")
            quality_check = self.check_data_quality()
            
            if not quality_check['success']:
                self.logger.warning(f"æ•°æ®è´¨é‡æ£€æŸ¥æœªé€šè¿‡: {quality_check['error']}")
                # è´¨é‡æ£€æŸ¥å¤±è´¥ä¸å½±å“æ•´ä½“æµç¨‹ï¼Œä½†ä¼šè®°å½•è­¦å‘Š
            
            # æ­¥éª¤3: Gitæäº¤ï¼ˆå¦‚æœæœ‰æ›´æ–°çš„æ•°æ®ï¼‰
            if result['data_updated'] and self.git_repo:
                self.logger.info("ğŸ“¤ æäº¤æ•°æ®åˆ°Gitä»“åº“...")
                try:
                    # æ·»åŠ æ•°æ®æ–‡ä»¶
                    data_dir = self.work_dir / 'data'
                    if data_dir.exists():
                        self.git_repo.index.add([str(data_dir)])
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å˜æ›´
                    if self.git_repo.is_dirty():
                        commit_message = f"è‡ªåŠ¨æ•°æ®æ›´æ–° - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                        self.git_repo.index.commit(commit_message)
                        self.logger.info("âœ… æ•°æ®å·²æäº¤åˆ°Gitä»“åº“")
                        result['commit_success'] = True
                    else:
                        self.logger.info("â„¹ï¸ æ²¡æœ‰æ•°æ®å˜æ›´ï¼Œè·³è¿‡Gitæäº¤")
                        result['commit_success'] = True
                        
                except git.exc.GitError as e:
                    self.logger.error(f"Gitæäº¤å¤±è´¥: {e}")
                    result['error'] = f"Gitæäº¤å¤±è´¥: {str(e)}"
                except Exception as e:
                    self.logger.error(f"Gitæäº¤å¼‚å¸¸: {e}")
                    result['error'] = f"Gitæäº¤å¼‚å¸¸: {str(e)}"
            else:
                result['commit_success'] = True  # æ²¡æœ‰Gitæˆ–æ²¡æœ‰æ›´æ–°æ—¶è®¤ä¸ºæˆåŠŸ
            
            result['success'] = result['fetch_success'] and result['commit_success']
            
            if result['success']:
                self.logger.info("âœ… è‡ªåŠ¨æ•°æ®æ‹‰å–å’Œæäº¤æµç¨‹å®Œæˆ")
            else:
                self.logger.error("âŒ è‡ªåŠ¨æ•°æ®æ‹‰å–å’Œæäº¤æµç¨‹å¤±è´¥")
            
            return result
            
        except Exception as e:
            self.logger.error(f"è‡ªåŠ¨æ•°æ®æ‹‰å–å’Œæäº¤å¼‚å¸¸: {e}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def check_data_quality(self) -> Dict[str, Any]:
        """æ•°æ®è´¨é‡æ£€æŸ¥"""
        try:
            # è·å–æœ€æ–°æ•°æ®
            latest_data = self.data_module.get_latest_data()
            
            if latest_data is None or latest_data.empty:
                return {
                    'success': False,
                    'error': 'æ— æœ€æ–°æ•°æ®'
                }
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            required_fields = ['date', 'open', 'high', 'low', 'close', 'volume']
            missing_fields = []
            
            for field in required_fields:
                if field not in latest_data or pd.isna(latest_data[field]):
                    missing_fields.append(field)
            
            if missing_fields:
                return {
                    'success': False,
                    'error': f'ç¼ºå¤±å­—æ®µ: {", ".join(missing_fields)}'
                }
            
            # æ£€æŸ¥æ•°æ®åˆç†æ€§
            if latest_data['high'] < latest_data['low']:
                return {
                    'success': False,
                    'error': 'æœ€é«˜ä»·å°äºæœ€ä½ä»·'
                }
            
            if latest_data['close'] <= 0 or latest_data['volume'] < 0:
                return {
                    'success': False,
                    'error': 'ä»·æ ¼æˆ–æˆäº¤é‡æ•°æ®å¼‚å¸¸'
                }
            
            return {
                'success': True,
                'latest_date': latest_data['date'],
                'data_points': len(latest_data) if hasattr(latest_data, '__len__') else 1
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def check_system_health(self) -> Dict[str, Any]:
        """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
        try:
            current_metrics = self.collect_performance_metrics()
            
            health_status = {
                'timestamp': datetime.now().isoformat(),
                'overall_healthy': True,
                'warnings': [],
                'errors': [],
                'metrics': {
                    'cpu_percent': current_metrics.cpu_percent,
                    'memory_percent': current_metrics.memory_percent,
                    'disk_usage': current_metrics.disk_usage,
                    'process_count': current_metrics.process_count
                }
            }
            
            # CPUæ£€æŸ¥
            if current_metrics.cpu_percent > 80:
                health_status['errors'].append(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {current_metrics.cpu_percent:.1f}%")
                health_status['overall_healthy'] = False
            elif current_metrics.cpu_percent > 60:
                health_status['warnings'].append(f"CPUä½¿ç”¨ç‡è¾ƒé«˜: {current_metrics.cpu_percent:.1f}%")
            
            # å†…å­˜æ£€æŸ¥
            if current_metrics.memory_percent > 85:
                health_status['errors'].append(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {current_metrics.memory_percent:.1f}%")
                health_status['overall_healthy'] = False
            elif current_metrics.memory_percent > 70:
                health_status['warnings'].append(f"å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜: {current_metrics.memory_percent:.1f}%")
            
            # ç£ç›˜æ£€æŸ¥
            if current_metrics.disk_usage > 90:
                health_status['errors'].append(f"ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {current_metrics.disk_usage:.1f}%")
                health_status['overall_healthy'] = False
            elif current_metrics.disk_usage > 80:
                health_status['warnings'].append(f"ç£ç›˜ä½¿ç”¨ç‡è¾ƒé«˜: {current_metrics.disk_usage:.1f}%")
            
            # è¿ç»­é”™è¯¯æ£€æŸ¥
            if self.state['consecutive_errors'] >= 5:
                health_status['errors'].append(f"è¿ç»­é”™è¯¯æ¬¡æ•°è¿‡å¤š: {self.state['consecutive_errors']}")
                health_status['overall_healthy'] = False
            elif self.state['consecutive_errors'] >= 3:
                health_status['warnings'].append(f"è¿ç»­é”™è¯¯æ¬¡æ•°è¾ƒå¤š: {self.state['consecutive_errors']}")
            
            # æ•°æ®æ–°é²œåº¦æ£€æŸ¥
            if self.state['last_data_fetch']:
                last_fetch = datetime.fromisoformat(self.state['last_data_fetch'].replace(' ', 'T'))
                hours_since_fetch = (datetime.now() - last_fetch).total_seconds() / 3600
                
                if hours_since_fetch > 48:
                    health_status['errors'].append(f"æ•°æ®æ›´æ–°æ»å: {hours_since_fetch:.1f}å°æ—¶")
                    health_status['overall_healthy'] = False
                elif hours_since_fetch > 24:
                    health_status['warnings'].append(f"æ•°æ®æ›´æ–°è¾ƒæ™š: {hours_since_fetch:.1f}å°æ—¶")
            
            # å‘é€å‘Šè­¦ï¼ˆå¦‚æœæœ‰ä¸¥é‡é—®é¢˜ï¼‰
            if health_status['errors']:
                self.send_health_alert(health_status)
            
            self.last_health_check = datetime.now()
            return health_status
            
        except Exception as e:
            self.logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'overall_healthy': False,
                'errors': [f"å¥åº·æ£€æŸ¥å¼‚å¸¸: {str(e)}"],
                'warnings': [],
                'metrics': {}
            }
    
    def send_health_alert(self, health_status: Dict[str, Any]):
        """å‘é€å¥åº·å‘Šè­¦"""
        try:
            alert_message = f"""
âš ï¸ ç³»ç»Ÿå¥åº·å‘Šè­¦

æ—¶é—´: {health_status['timestamp']}
çŠ¶æ€: {'å¥åº·' if health_status['overall_healthy'] else 'å¼‚å¸¸'}

é”™è¯¯ä¿¡æ¯:
{chr(10).join(['âŒ ' + error for error in health_status['errors']])}

è­¦å‘Šä¿¡æ¯:
{chr(10).join(['âš ï¸ ' + warning for warning in health_status['warnings']])}

ç³»ç»ŸæŒ‡æ ‡:
- CPU: {health_status['metrics'].get('cpu_percent', 0):.1f}%
- å†…å­˜: {health_status['metrics'].get('memory_percent', 0):.1f}%
- ç£ç›˜: {health_status['metrics'].get('disk_usage', 0):.1f}%
"""
            
            # ä½¿ç”¨é€šçŸ¥æ¨¡å—å‘é€å‘Šè­¦
            self.notification_manager._send_console_notification({
                'subject': 'ğŸš¨ ç³»ç»Ÿå¥åº·å‘Šè­¦',
                'body': alert_message
            })
            
            self.logger.warning("å·²å‘é€ç³»ç»Ÿå¥åº·å‘Šè­¦")
            
        except Exception as e:
            self.logger.error(f"å‘é€å¥åº·å‘Šè­¦å¤±è´¥: {e}")
    
    def auto_backup_data(self) -> Dict[str, Any]:
        """è‡ªåŠ¨æ•°æ®å¤‡ä»½"""
        try:
            self.logger.info("ğŸ’¾ å¼€å§‹è‡ªåŠ¨æ•°æ®å¤‡ä»½...")
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_subdir = self.backup_dir / f'backup_{timestamp}'
            backup_subdir.mkdir(exist_ok=True)
            
            result = {
                'success': False,
                'timestamp': datetime.now().isoformat(),
                'backup_path': str(backup_subdir),
                'backed_up_items': [],
                'total_size': 0,
                'error': None
            }
            
            # å¤‡ä»½é‡è¦ç›®å½•å’Œæ–‡ä»¶
            backup_targets = [
                ('data', self.work_dir / 'data'),
                ('models', self.work_dir / 'models'),
                ('results', self.work_dir / 'results'),
                ('config', self.work_dir / 'config'),
                ('logs', self.work_dir / 'logs')
            ]
            
            for name, source_path in backup_targets:
                if source_path.exists():
                    target_path = backup_subdir / name
                    
                    try:
                        if source_path.is_dir():
                            shutil.copytree(source_path, target_path, ignore_dangling_symlinks=True)
                        else:
                            shutil.copy2(source_path, target_path)
                        
                        # è®¡ç®—å¤§å°
                        if target_path.is_dir():
                            size = sum(f.stat().st_size for f in target_path.rglob('*') if f.is_file())
                        else:
                            size = target_path.stat().st_size
                        
                        result['backed_up_items'].append({
                            'name': name,
                            'size': size,
                            'path': str(target_path)
                        })
                        result['total_size'] += size
                        
                        self.logger.info(f"âœ… å·²å¤‡ä»½: {name} ({size/1024/1024:.1f}MB)")
                        
                    except Exception as e:
                        self.logger.error(f"å¤‡ä»½ {name} å¤±è´¥: {e}")
                        continue
            
            # åˆ›å»ºå¤‡ä»½æ¸…å•
            manifest = {
                'backup_time': timestamp,
                'total_items': len(result['backed_up_items']),
                'total_size': result['total_size'],
                'items': result['backed_up_items'],
                'created_by': 'EnhancedDailyTradingBot'
            }
            
            manifest_file = backup_subdir / 'backup_manifest.json'
            with open(manifest_file, 'w', encoding='utf-8') as f:
                json.dump(manifest, f, indent=2, ensure_ascii=False)
            
            # æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™æœ€è¿‘10ä¸ªï¼‰
            self.cleanup_old_backups(keep_count=10)
            
            result['success'] = True
            self.state['backup_count'] += 1
            self.state['last_backup'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            self.logger.info(f"âœ… æ•°æ®å¤‡ä»½å®Œæˆ: {result['total_size']/1024/1024:.1f}MBï¼Œå…±{len(result['backed_up_items'])}é¡¹")
            
            return result
            
        except Exception as e:
            self.logger.error(f"è‡ªåŠ¨æ•°æ®å¤‡ä»½å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def cleanup_old_backups(self, keep_count: int = 10):
        """æ¸…ç†æ—§å¤‡ä»½"""
        try:
            backup_dirs = [d for d in self.backup_dir.iterdir() if d.is_dir() and d.name.startswith('backup_')]
            backup_dirs.sort(key=lambda x: x.name, reverse=True)
            
            # åˆ é™¤è¶…å‡ºä¿ç•™æ•°é‡çš„å¤‡ä»½
            for old_backup in backup_dirs[keep_count:]:
                shutil.rmtree(old_backup)
                self.logger.info(f"å·²åˆ é™¤æ—§å¤‡ä»½: {old_backup.name}")
                
        except Exception as e:
            self.logger.error(f"æ¸…ç†æ—§å¤‡ä»½å¤±è´¥: {e}")
    
    def restore_from_backup(self, backup_timestamp: str) -> Dict[str, Any]:
        """ä»å¤‡ä»½æ¢å¤æ•°æ®"""
        try:
            backup_path = self.backup_dir / f'backup_{backup_timestamp}'
            
            if not backup_path.exists():
                return {
                    'success': False,
                    'error': f'å¤‡ä»½ä¸å­˜åœ¨: {backup_timestamp}'
                }
            
            # è¯»å–å¤‡ä»½æ¸…å•
            manifest_file = backup_path / 'backup_manifest.json'
            if manifest_file.exists():
                with open(manifest_file, 'r', encoding='utf-8') as f:
                    manifest = json.load(f)
                self.logger.info(f"æ¢å¤å¤‡ä»½: {manifest['backup_time']}ï¼Œå…±{manifest['total_items']}é¡¹")
            
            # æ¢å¤ä¸»è¦ç›®å½•
            restore_targets = ['data', 'models', 'config']
            restored_items = []
            
            for target in restore_targets:
                source = backup_path / target
                dest = self.work_dir / target
                
                if source.exists():
                    # å¤‡ä»½å½“å‰ç‰ˆæœ¬
                    if dest.exists():
                        backup_current = dest.with_suffix(f'.backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}')
                        if dest.is_dir():
                            shutil.copytree(dest, backup_current)
                        else:
                            shutil.copy2(dest, backup_current)
                    
                    # æ¢å¤æ•°æ®
                    if dest.exists():
                        if dest.is_dir():
                            shutil.rmtree(dest)
                        else:
                            dest.unlink()
                    
                    if source.is_dir():
                        shutil.copytree(source, dest)
                    else:
                        shutil.copy2(source, dest)
                    
                    restored_items.append(target)
                    self.logger.info(f"âœ… å·²æ¢å¤: {target}")
            
            return {
                'success': True,
                'restored_items': restored_items,
                'backup_timestamp': backup_timestamp
            }
            
        except Exception as e:
            self.logger.error(f"æ•°æ®æ¢å¤å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def daily_workflow(self) -> Dict[str, Any]:
        """æ‰§è¡Œå¢å¼ºç‰ˆæ—¥å¸¸å·¥ä½œæµç¨‹"""
        today = datetime.now().strftime('%Y-%m-%d')
        workflow_result = {
            'date': today,
            'timestamp': datetime.now().isoformat(),
            'success': False,
            'steps': {},
            'errors': []
        }
        
        try:
            self.logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œå¢å¼ºç‰ˆæ—¥å¸¸äº¤æ˜“æµç¨‹: {today}")
            
            # æ­¥éª¤1: ç³»ç»Ÿå¥åº·æ£€æŸ¥
            self.logger.info("ğŸ¥ æ­¥éª¤1: ç³»ç»Ÿå¥åº·æ£€æŸ¥")
            health_result = self.check_system_health()
            workflow_result['steps']['health_check'] = health_result
            
            if not health_result['overall_healthy']:
                self.logger.warning("ç³»ç»Ÿå¥åº·çŠ¶æ€å¼‚å¸¸ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
            
            # æ­¥éª¤2: è‡ªåŠ¨æ•°æ®æ‹‰å–å’Œæäº¤
            self.logger.info("ğŸ“¡ æ­¥éª¤2: è‡ªåŠ¨æ•°æ®æ‹‰å–å’Œæäº¤")
            data_fetch_result = self.auto_fetch_and_commit_data()
            workflow_result['steps']['data_fetch'] = data_fetch_result
            
            if not data_fetch_result['success']:
                workflow_result['errors'].append("æ•°æ®æ‹‰å–å’Œæäº¤å¤±è´¥")
                # æ•°æ®æ‹‰å–å¤±è´¥ä¸ä¸­æ–­æµç¨‹ï¼Œä½¿ç”¨ç°æœ‰æ•°æ®ç»§ç»­
            
            # æ­¥éª¤3: æ•°æ®æ£€æŸ¥å’Œæ›´æ–°
            self.logger.info("ğŸ“Š æ­¥éª¤3: æ£€æŸ¥æ•°æ®çŠ¶æ€")
            data_result = self.check_and_update_data()
            workflow_result['steps']['data_check'] = data_result
            
            if not data_result['success']:
                workflow_result['errors'].append("æ•°æ®æ£€æŸ¥å¤±è´¥")
                return workflow_result
            
            # æ­¥éª¤4: å¢é‡è®­ç»ƒ
            self.logger.info("ğŸ¤– æ­¥éª¤4: æ‰§è¡Œå¢é‡è®­ç»ƒ")
            training_result = self.execute_incremental_training(today)
            workflow_result['steps']['training'] = training_result
            
            if training_result['success']:
                self.state['training_count'] += 1
                self.state['last_training_date'] = today
            
            # æ­¥éª¤5: é¢„æµ‹æ‰§è¡Œ
            self.logger.info("ğŸ”® æ­¥éª¤5: æ‰§è¡Œé¢„æµ‹")
            prediction_result = self.execute_prediction(today)
            workflow_result['steps']['prediction'] = prediction_result
            
            if prediction_result['success']:
                self.state['total_predictions'] += 1
                self.state['last_prediction_date'] = today
            
            # æ­¥éª¤6: äº¤æ˜“ä¿¡å·ç”Ÿæˆ
            self.logger.info("ğŸ“ˆ æ­¥éª¤6: ç”Ÿæˆäº¤æ˜“ä¿¡å·")
            signal_result = self.generate_trading_signal(prediction_result)
            workflow_result['steps']['signal'] = signal_result
            
            # æ­¥éª¤7: ç»“æœè®°å½•
            self.logger.info("ğŸ“ æ­¥éª¤7: è®°å½•ç»“æœ")
            record_result = self.record_results(workflow_result)
            workflow_result['steps']['record'] = record_result
            
            # æ­¥éª¤8: å‘é€é€šçŸ¥
            self.logger.info("ğŸ“¨ æ­¥éª¤8: å‘é€é€šçŸ¥")
            notification_result = self.send_notifications(workflow_result)
            workflow_result['steps']['notification'] = notification_result
            
            # æ­¥éª¤9: è‡ªåŠ¨å¤‡ä»½ï¼ˆæ¯å‘¨æ‰§è¡Œä¸€æ¬¡ï¼‰
            if datetime.now().weekday() == 6:  # å‘¨æ—¥æ‰§è¡Œå¤‡ä»½
                self.logger.info("ğŸ’¾ æ­¥éª¤9: è‡ªåŠ¨æ•°æ®å¤‡ä»½")
                backup_result = self.auto_backup_data()
                workflow_result['steps']['backup'] = backup_result
            
            # æ£€æŸ¥æ•´ä½“æˆåŠŸçŠ¶æ€
            workflow_result['success'] = all([
                data_result['success'],
                training_result['success'] or training_result.get('skipped', False),
                prediction_result['success'],
                signal_result['success']
            ])
            
            if workflow_result['success']:
                self.state['consecutive_errors'] = 0
                self.state['successful_predictions'] += 1
                self.logger.info("âœ… å¢å¼ºç‰ˆæ—¥å¸¸äº¤æ˜“æµç¨‹æ‰§è¡ŒæˆåŠŸ")
            else:
                self.state['consecutive_errors'] += 1
                self.logger.error("âŒ å¢å¼ºç‰ˆæ—¥å¸¸äº¤æ˜“æµç¨‹æ‰§è¡Œå¤±è´¥")
            
        except Exception as e:
            self.logger.error(f"æ—¥å¸¸å·¥ä½œæµç¨‹å¼‚å¸¸: {e}")
            workflow_result['errors'].append(f"å·¥ä½œæµç¨‹å¼‚å¸¸: {str(e)}")
            self.state['consecutive_errors'] += 1
        
        finally:
            self.save_state()
        
        return workflow_result
    
    def check_and_update_data(self) -> Dict[str, Any]:
        """æ£€æŸ¥å’Œæ›´æ–°æ•°æ®"""
        try:
            today = datetime.now().strftime('%Y-%m-%d')
            
            # æ£€æŸ¥æœ€æ–°æ•°æ®æ—¥æœŸ
            latest_data = self.data_module.get_latest_data()
            
            if latest_data is None or latest_data.empty:
                return {
                    'success': False,
                    'error': 'æ— æ³•è·å–æœ€æ–°æ•°æ®',
                    'latest_date': None
                }
            
            # latest_data æ˜¯ pd.Series
            if latest_data is not None:
                latest_date = latest_data['date']
                if isinstance(latest_date, str):
                    latest_date = datetime.strptime(latest_date, '%Y-%m-%d').strftime('%Y-%m-%d')
                else:
                    latest_date = latest_date.strftime('%Y-%m-%d')
            else:
                latest_date = None
            
            # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿæ–°
            if latest_date:
                days_behind = (datetime.now() - datetime.strptime(latest_date, '%Y-%m-%d')).days
                data_fresh = days_behind <= 1
            else:
                days_behind = 999
                data_fresh = False
            
            return {
                'success': True,
                'latest_date': latest_date,
                'days_behind': days_behind,
                'data_fresh': data_fresh,
                'records_count': 1 if latest_data is not None else 0
            }
            
        except Exception as e:
            self.logger.error(f"æ•°æ®æ£€æŸ¥å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def execute_incremental_training(self, target_date: str) -> Dict[str, Any]:
        """æ‰§è¡Œå¢é‡è®­ç»ƒ"""
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è®­ç»ƒ
            if self.state['last_training_date'] == target_date:
                self.logger.info("ä»Šæ—¥å·²å®Œæˆè®­ç»ƒï¼Œè·³è¿‡")
                return {
                    'success': True,
                    'skipped': True,
                    'reason': 'ä»Šæ—¥å·²è®­ç»ƒ'
                }
            
            # è·å–è®­ç»ƒæ•°æ®
            end_dt = datetime.strptime(target_date, '%Y-%m-%d')
            start_dt = end_dt - timedelta(days=30)  # è·å–æœ€è¿‘30å¤©æ•°æ®
            
            training_data = self.data_module.get_history_data(
                start_dt.strftime('%Y-%m-%d'),
                target_date
            )
            
            if training_data.empty:
                return {
                    'success': False,
                    'error': 'æ— æ³•è·å–è®­ç»ƒæ•°æ®'
                }
            
            # é¢„å¤„ç†æ•°æ®
            training_data = self.data_module.preprocess_data(training_data)
            
            # æ‰§è¡Œå¢é‡è®­ç»ƒ
            train_result = self.ai_improved.incremental_train(training_data, self.strategy_module)
            
            return {
                'success': train_result['success'],
                'method': train_result.get('method', 'unknown'),
                'update_count': train_result.get('update_count', 0),
                'new_samples': train_result.get('new_samples', 0),
                'error': train_result.get('error', None)
            }
            
        except Exception as e:
            self.logger.error(f"å¢é‡è®­ç»ƒå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def execute_prediction(self, target_date: str) -> Dict[str, Any]:
        """æ‰§è¡Œé¢„æµ‹"""
        try:
            # è·å–é¢„æµ‹æ•°æ®
            end_dt = datetime.strptime(target_date, '%Y-%m-%d')
            start_dt = end_dt - timedelta(days=100)  # ä½¿ç”¨æœ€è¿‘100å¤©æ•°æ®
            
            prediction_data = self.data_module.get_history_data(
                start_dt.strftime('%Y-%m-%d'),
                target_date
            )
            
            if prediction_data.empty:
                return {
                    'success': False,
                    'error': 'æ— æ³•è·å–é¢„æµ‹æ•°æ®'
                }
            
            # é¢„å¤„ç†æ•°æ®
            prediction_data = self.data_module.preprocess_data(prediction_data)
            
            # æ‰§è¡Œé¢„æµ‹
            pred_result = self.ai_improved.predict_low_point(prediction_data, target_date)
            
            return {
                'success': True,
                'is_low_point': pred_result.get('is_low_point', False),
                'confidence': pred_result.get('confidence', 0.0),
                'final_confidence': pred_result.get('final_confidence', 0.0),
                'model_type': pred_result.get('model_type', 'unknown')
            }
            
        except Exception as e:
            self.logger.error(f"é¢„æµ‹æ‰§è¡Œå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def generate_trading_signal(self, prediction_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
        try:
            if not prediction_result['success']:
                return {
                    'success': False,
                    'error': 'é¢„æµ‹å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆä¿¡å·'
                }
            
            is_low_point = prediction_result['is_low_point']
            confidence = prediction_result['final_confidence']
            
            # ä¿¡å·ç”Ÿæˆé€»è¾‘
            signal = {
                'action': 'HOLD',  # é»˜è®¤æŒæœ‰
                'strength': 0,     # ä¿¡å·å¼ºåº¦ (0-5)
                'reason': '',
                'risk_level': 'MEDIUM'
            }
            
            if is_low_point:
                if confidence >= 0.8:
                    signal.update({
                        'action': 'BUY_STRONG',
                        'strength': 5,
                        'reason': f'å¼ºçƒˆä¹°å…¥ä¿¡å· (ç½®ä¿¡åº¦: {confidence:.3f})',
                        'risk_level': 'LOW'
                    })
                elif confidence >= 0.6:
                    signal.update({
                        'action': 'BUY',
                        'strength': 4,
                        'reason': f'ä¹°å…¥ä¿¡å· (ç½®ä¿¡åº¦: {confidence:.3f})',
                        'risk_level': 'LOW'
                    })
                elif confidence >= 0.4:
                    signal.update({
                        'action': 'BUY_WEAK',
                        'strength': 2,
                        'reason': f'å¼±ä¹°å…¥ä¿¡å· (ç½®ä¿¡åº¦: {confidence:.3f})',
                        'risk_level': 'MEDIUM'
                    })
                else:
                    signal.update({
                        'action': 'WATCH',
                        'strength': 1,
                        'reason': f'è§‚æœ› (ç½®ä¿¡åº¦è¾ƒä½: {confidence:.3f})',
                        'risk_level': 'HIGH'
                    })
            else:
                if confidence < 0.2:
                    signal.update({
                        'action': 'HOLD',
                        'strength': 1,
                        'reason': f'ç»§ç»­æŒæœ‰ (éä½ç‚¹ï¼Œç½®ä¿¡åº¦: {confidence:.3f})',
                        'risk_level': 'MEDIUM'
                    })
                else:
                    signal.update({
                        'action': 'WAIT',
                        'strength': 0,
                        'reason': f'ç­‰å¾…æœºä¼š (éä½ç‚¹ï¼Œç½®ä¿¡åº¦: {confidence:.3f})',
                        'risk_level': 'MEDIUM'
                    })
            
            return {
                'success': True,
                'signal': signal,
                'confidence': confidence,
                'is_low_point': is_low_point
            }
            
        except Exception as e:
            self.logger.error(f"ä¿¡å·ç”Ÿæˆå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def record_results(self, workflow_result: Dict[str, Any]) -> Dict[str, Any]:
        """è®°å½•ç»“æœ"""
        try:
            # åŠ è½½å†å²è®°å½•
            history = []
            if self.history_file.exists():
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            
            # æ·»åŠ æ–°è®°å½•
            history.append(workflow_result)
            
            # åªä¿ç•™æœ€è¿‘100å¤©çš„è®°å½•
            history = history[-100:]
            
            # ä¿å­˜è®°å½•
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, indent=2, ensure_ascii=False)
            
            # ç”Ÿæˆæ—¥æŠ¥å‘Š
            report_result = self.generate_daily_report(workflow_result)
            
            return {
                'success': True,
                'history_records': len(history),
                'report_generated': report_result['success']
            }
            
        except Exception as e:
            self.logger.error(f"ç»“æœè®°å½•å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def generate_daily_report(self, workflow_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ—¥æŠ¥å‘Š"""
        try:
            date = workflow_result['date']
            report_file = self.results_dir / f'daily_report_{date}.md'
            
            # æå–å…³é”®ä¿¡æ¯
            prediction = workflow_result['steps'].get('prediction', {})
            signal = workflow_result['steps'].get('signal', {})
            training = workflow_result['steps'].get('training', {})
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            report_content = f"""# æ—¥å¸¸äº¤æ˜“æŠ¥å‘Š - {date}

## ğŸ“Š æ‰§è¡Œæ‘˜è¦
- **æ‰§è¡Œæ—¶é—´**: {workflow_result['timestamp']}
- **æ•´ä½“çŠ¶æ€**: {'âœ… æˆåŠŸ' if workflow_result['success'] else 'âŒ å¤±è´¥'}
- **è¿ç»­æˆåŠŸ**: {self.state['total_predictions'] - self.state['consecutive_errors']} å¤©

## ğŸ¤– AIé¢„æµ‹ç»“æœ
- **é¢„æµ‹ç»“æœ**: {'ğŸ“ˆ ç›¸å¯¹ä½ç‚¹' if prediction.get('is_low_point', False) else 'ğŸ“‰ éç›¸å¯¹ä½ç‚¹'}
- **åŸå§‹ç½®ä¿¡åº¦**: {prediction.get('confidence', 0):.4f}
                - **æœ€ç»ˆç½®ä¿¡åº¦**: {prediction.get('final_confidence', 0):.4f}
- **æ¨¡å‹ç±»å‹**: {prediction.get('model_type', 'N/A')}

## ğŸ“ˆ äº¤æ˜“ä¿¡å·
- **å»ºè®®æ“ä½œ**: {signal.get('signal', {}).get('action', 'N/A')}
- **ä¿¡å·å¼ºåº¦**: {signal.get('signal', {}).get('strength', 0)}/5
- **é£é™©ç­‰çº§**: {signal.get('signal', {}).get('risk_level', 'N/A')}
- **æ“ä½œç†ç”±**: {signal.get('signal', {}).get('reason', 'N/A')}

## ğŸ”„ æ¨¡å‹è®­ç»ƒ
- **è®­ç»ƒçŠ¶æ€**: {'âœ… æˆåŠŸ' if training.get('success', False) else ('â­ï¸ è·³è¿‡' if training.get('skipped', False) else 'âŒ å¤±è´¥')}
- **è®­ç»ƒæ–¹å¼**: {training.get('method', 'N/A')}
- **æ›´æ–°æ¬¡æ•°**: {training.get('update_count', 'N/A')}
- **æ–°å¢æ ·æœ¬**: {training.get('new_samples', 'N/A')}

## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯
- **æ€»é¢„æµ‹æ¬¡æ•°**: {self.state['total_predictions']}
- **æˆåŠŸé¢„æµ‹æ¬¡æ•°**: {self.state['successful_predictions']}
- **è®­ç»ƒæ‰§è¡Œæ¬¡æ•°**: {self.state['training_count']}
- **è¿ç»­é”™è¯¯æ¬¡æ•°**: {self.state['consecutive_errors']}
- **è¿è¡Œå¤©æ•°**: {(datetime.now() - datetime.strptime(self.state['start_date'], '%Y-%m-%d')).days + 1}

## âš ï¸ æ³¨æ„äº‹é¡¹
"""
            
            # æ·»åŠ é”™è¯¯ä¿¡æ¯
            if workflow_result['errors']:
                report_content += "\n### é”™è¯¯ä¿¡æ¯:\n"
                for error in workflow_result['errors']:
                    report_content += f"- âŒ {error}\n"
            
            # æ·»åŠ å»ºè®®
            report_content += "\n### ğŸ’¡ å»ºè®®:\n"
            confidence = prediction.get('final_confidence', 0)
            if confidence >= 0.6:
                report_content += "- ç½®ä¿¡åº¦è¾ƒé«˜ï¼Œå¯è€ƒè™‘é€‚å½“åŠ ä»“\n"
            elif confidence >= 0.4:
                report_content += "- ç½®ä¿¡åº¦ä¸­ç­‰ï¼Œå»ºè®®è°¨æ…æ“ä½œ\n"
            else:
                report_content += "- ç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®è§‚æœ›ç­‰å¾…\n"
            
            if self.state['consecutive_errors'] >= 3:
                report_content += "- âš ï¸ è¿ç»­é”™è¯¯è¾ƒå¤šï¼Œå»ºè®®æ£€æŸ¥ç³»ç»ŸçŠ¶æ€\n"
            
            # ä¿å­˜æŠ¥å‘Š
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            return {
                'success': True,
                'report_file': str(report_file)
            }
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ—¥æŠ¥å‘Šå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def send_notifications(self, workflow_result: Dict[str, Any]) -> Dict[str, Any]:
        """å‘é€é€šçŸ¥"""
        try:
            # æ„å»ºé€šçŸ¥æ¶ˆæ¯
            date = workflow_result['date']
            prediction = workflow_result['steps'].get('prediction', {})
            signal = workflow_result['steps'].get('signal', {})
            
            # åŸºç¡€ä¿¡æ¯
            status_emoji = "âœ…" if workflow_result['success'] else "âŒ"
            prediction_emoji = "ğŸ“ˆ" if prediction.get('is_low_point', False) else "ğŸ“‰"
            
            subject = f"{status_emoji} äº¤æ˜“ä¿¡å· {date}"
            
            message = f"""
{status_emoji} æ—¥å¸¸äº¤æ˜“æµç¨‹æ‰§è¡Œå®Œæˆ

ğŸ“… æ—¥æœŸ: {date}
{prediction_emoji} é¢„æµ‹: {'ç›¸å¯¹ä½ç‚¹' if prediction.get('is_low_point', False) else 'éç›¸å¯¹ä½ç‚¹'}
ğŸ¯ ç½®ä¿¡åº¦: {prediction.get('final_confidence', 0):.3f}
ğŸ“ˆ å»ºè®®: {signal.get('signal', {}).get('action', 'N/A')}
â­ å¼ºåº¦: {signal.get('signal', {}).get('strength', 0)}/5

ğŸ“Š ç»Ÿè®¡: æ€»è®¡{self.state['total_predictions']}æ¬¡é¢„æµ‹ï¼ŒæˆåŠŸ{self.state['successful_predictions']}æ¬¡
"""
            
            # å‘é€é€šçŸ¥
            try:
                # æ„å»ºé€šçŸ¥ç»“æœæ ¼å¼ï¼Œç¬¦åˆNotificationModuleçš„API
                notification_result = {
                    'is_low_point': prediction.get('is_low_point', False),
                    'date': date,
                    'confidence': prediction.get('final_confidence', 0),
                    'price': 0,  # è¿™é‡Œå¯ä»¥ä»æ•°æ®ä¸­è·å–ä»·æ ¼
                    'reasons': [signal.get('signal', {}).get('reason', 'æœªçŸ¥åŸå› ')]
                }
                
                # å§‹ç»ˆå‘é€é€šçŸ¥ï¼ˆåŒ…æ‹¬éä½ç‚¹çš„æ—¥å¸¸æ€»ç»“ï¼‰
                if prediction.get('is_low_point', False):
                    # å‘é€ä½ç‚¹é€šçŸ¥
                    success = self.notification_manager.send_low_point_notification(notification_result)
                else:
                    # å‘é€æ§åˆ¶å°é€šçŸ¥ä½œä¸ºæ—¥å¸¸æ€»ç»“
                    self.notification_manager._send_console_notification({
                        'subject': subject,
                        'body': message
                    })
                    success = True
                
                return {'success': success}
            except Exception as e:
                self.logger.warning(f"é€šçŸ¥å‘é€å¤±è´¥: {e}")
                return {'success': False, 'error': str(e)}
            
        except Exception as e:
            self.logger.error(f"é€šçŸ¥å¤„ç†å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def get_status_report(self) -> Dict[str, Any]:
        """è·å–çŠ¶æ€æŠ¥å‘Š"""
        return {
            'bot_state': self.state.copy(),
            'last_run': datetime.now().isoformat(),
            'config_loaded': bool(self.config),
            'modules_status': {
                'data_module': bool(self.data_module),
                'ai_module': bool(self.ai_improved),
                'strategy_module': bool(self.strategy_module)
            }
        }
    
    def run_daemon_mode(self):
        """è¿è¡Œå®ˆæŠ¤è¿›ç¨‹æ¨¡å¼"""
        self.logger.info("ğŸ›¡ï¸ å¯åŠ¨å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼...")
        
        # å†™å…¥PIDæ–‡ä»¶
        self.write_pid_file()
        
        try:
            # è®¾ç½®å®šæ—¶ä»»åŠ¡
            self.setup_scheduled_tasks()
            
            self.logger.info("â° å®šæ—¶ä»»åŠ¡å·²è®¾ç½®ï¼Œè¿›å…¥å®ˆæŠ¤è¿›ç¨‹å¾ªç¯...")
            
            while self.running:
                try:
                    # æ‰§è¡Œå®šæ—¶ä»»åŠ¡
                    schedule.run_pending()
                    
                    # æ¯30åˆ†é’Ÿè¿›è¡Œä¸€æ¬¡å¥åº·æ£€æŸ¥
                    if (datetime.now() - self.last_health_check).total_seconds() > 1800:
                        threading.Thread(target=self.check_system_health, daemon=True).start()
                    
                    # çŸ­æš‚ä¼‘çœ 
                    time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                    
                except Exception as e:
                    self.logger.error(f"å®ˆæŠ¤è¿›ç¨‹å¾ªç¯å¼‚å¸¸: {e}")
                    time.sleep(300)  # å¼‚å¸¸æ—¶ç­‰å¾…5åˆ†é’Ÿåç»§ç»­
            
            self.logger.info("å®ˆæŠ¤è¿›ç¨‹æ­£å¸¸é€€å‡º")
            
        except KeyboardInterrupt:
            self.logger.info("æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢å®ˆæŠ¤è¿›ç¨‹...")
        except Exception as e:
            self.logger.error(f"å®ˆæŠ¤è¿›ç¨‹å¼‚å¸¸: {e}")
        finally:
            self.cleanup_daemon()
            
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯
        if self.restart_flag:
            self.logger.info("é‡å¯å®ˆæŠ¤è¿›ç¨‹...")
            os.execv(sys.executable, [sys.executable] + sys.argv)
    
    def setup_scheduled_tasks(self):
        """è®¾ç½®å®šæ—¶ä»»åŠ¡"""
        # æ¸…é™¤ç°æœ‰ä»»åŠ¡
        schedule.clear()
        
        # æ¯å¤©15:05è‡ªåŠ¨æ‹‰å–æ•°æ®å¹¶æäº¤
        schedule.every().day.at("15:05").do(self._scheduled_data_fetch)
        
        # æ¯å¤©09:30æ‰§è¡Œæ—¥å¸¸äº¤æ˜“æµç¨‹
        schedule.every().day.at("09:30").do(self._scheduled_daily_workflow)
        
        # æ¯å¤©01:00æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥
        schedule.every().day.at("01:00").do(self._scheduled_health_check)
        
        # æ¯å‘¨æ—¥02:00æ‰§è¡Œæ•°æ®å¤‡ä»½
        schedule.every().sunday.at("02:00").do(self._scheduled_backup)
        
        # æ¯å°æ—¶æ”¶é›†æ€§èƒ½æŒ‡æ ‡
        schedule.every().hour.do(self._scheduled_metrics_collection)
        
        self.logger.info("âœ… å®šæ—¶ä»»åŠ¡è®¾ç½®å®Œæˆ:")
        self.logger.info("   - 15:05 è‡ªåŠ¨æ•°æ®æ‹‰å–å’Œæäº¤")
        self.logger.info("   - 09:30 æ—¥å¸¸äº¤æ˜“æµç¨‹")
        self.logger.info("   - 01:00 ç³»ç»Ÿå¥åº·æ£€æŸ¥")
        self.logger.info("   - å‘¨æ—¥02:00 æ•°æ®å¤‡ä»½")
        self.logger.info("   - æ¯å°æ—¶æ€§èƒ½æŒ‡æ ‡æ”¶é›†")
    
    def _scheduled_data_fetch(self):
        """å®šæ—¶æ•°æ®æ‹‰å–ä»»åŠ¡"""
        try:
            self.logger.info("â° æ‰§è¡Œå®šæ—¶æ•°æ®æ‹‰å–ä»»åŠ¡...")
            result = self.auto_fetch_and_commit_data()
            if result['success']:
                self.logger.info("âœ… å®šæ—¶æ•°æ®æ‹‰å–ä»»åŠ¡å®Œæˆ")
            else:
                self.logger.error(f"âŒ å®šæ—¶æ•°æ®æ‹‰å–ä»»åŠ¡å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        except Exception as e:
            self.logger.error(f"å®šæ—¶æ•°æ®æ‹‰å–ä»»åŠ¡å¼‚å¸¸: {e}")
    
    def _scheduled_daily_workflow(self):
        """å®šæ—¶æ—¥å¸¸äº¤æ˜“æµç¨‹ä»»åŠ¡"""
        try:
            self.logger.info("â° æ‰§è¡Œå®šæ—¶æ—¥å¸¸äº¤æ˜“æµç¨‹...")
            result = self.daily_workflow()
            if result['success']:
                self.logger.info("âœ… å®šæ—¶æ—¥å¸¸äº¤æ˜“æµç¨‹å®Œæˆ")
            else:
                self.logger.error("âŒ å®šæ—¶æ—¥å¸¸äº¤æ˜“æµç¨‹å¤±è´¥")
        except Exception as e:
            self.logger.error(f"å®šæ—¶æ—¥å¸¸äº¤æ˜“æµç¨‹å¼‚å¸¸: {e}")
    
    def _scheduled_health_check(self):
        """å®šæ—¶å¥åº·æ£€æŸ¥ä»»åŠ¡"""
        try:
            self.logger.info("â° æ‰§è¡Œå®šæ—¶å¥åº·æ£€æŸ¥...")
            result = self.check_system_health()
            if result['overall_healthy']:
                self.logger.info("âœ… ç³»ç»Ÿå¥åº·çŠ¶æ€è‰¯å¥½")
            else:
                self.logger.warning("âš ï¸ ç³»ç»Ÿå¥åº·çŠ¶æ€å¼‚å¸¸")
        except Exception as e:
            self.logger.error(f"å®šæ—¶å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
    
    def _scheduled_backup(self):
        """å®šæ—¶å¤‡ä»½ä»»åŠ¡"""
        try:
            self.logger.info("â° æ‰§è¡Œå®šæ—¶å¤‡ä»½ä»»åŠ¡...")
            result = self.auto_backup_data()
            if result['success']:
                self.logger.info("âœ… å®šæ—¶å¤‡ä»½ä»»åŠ¡å®Œæˆ")
            else:
                self.logger.error(f"âŒ å®šæ—¶å¤‡ä»½ä»»åŠ¡å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        except Exception as e:
            self.logger.error(f"å®šæ—¶å¤‡ä»½ä»»åŠ¡å¼‚å¸¸: {e}")
    
    def _scheduled_metrics_collection(self):
        """å®šæ—¶æ€§èƒ½æŒ‡æ ‡æ”¶é›†ä»»åŠ¡"""
        try:
            metrics = self.collect_performance_metrics()
            self.logger.debug(f"æ€§èƒ½æŒ‡æ ‡æ”¶é›†å®Œæˆ: CPU {metrics.cpu_percent:.1f}%, å†…å­˜ {metrics.memory_percent:.1f}%")
        except Exception as e:
            self.logger.error(f"æ€§èƒ½æŒ‡æ ‡æ”¶é›†å¼‚å¸¸: {e}")
    
    def cleanup_daemon(self):
        """æ¸…ç†å®ˆæŠ¤è¿›ç¨‹èµ„æº"""
        try:
            self.remove_pid_file()
            self.logger.info("å®ˆæŠ¤è¿›ç¨‹èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            self.logger.error(f"å®ˆæŠ¤è¿›ç¨‹èµ„æºæ¸…ç†å¤±è´¥: {e}")
    
    def run_scheduled(self):
        """è¿è¡Œå®šæ—¶ä»»åŠ¡ï¼ˆå…¼å®¹åŸæœ‰æ¥å£ï¼‰"""
        if self.daemon_mode:
            self.run_daemon_mode()
        else:
            self.logger.info("å¯åŠ¨ç®€å•å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨")
            
            # è®¾ç½®åŸºæœ¬å®šæ—¶ä»»åŠ¡
            schedule.every().day.at("09:30").do(self.daily_workflow)
            schedule.every().day.at("15:05").do(self.auto_fetch_and_commit_data)
            
            self.logger.info("å®šæ—¶ä»»åŠ¡å·²è®¾ç½®: æ¯å¤©09:30æ‰§è¡Œæ—¥å¸¸äº¤æ˜“æµç¨‹ï¼Œ15:05è‡ªåŠ¨æ‹‰å–æ•°æ®")
            
            try:
                while True:
                    schedule.run_pending()
                    time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            except KeyboardInterrupt:
                self.logger.info("æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºå®šæ—¶ä»»åŠ¡")
            except Exception as e:
                self.logger.error(f"å®šæ—¶ä»»åŠ¡å¼‚å¸¸: {e}")


def main():
    """å¢å¼ºç‰ˆä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¢å¼ºç‰ˆæ—¥å¸¸äº¤æ˜“æµç¨‹è‡ªåŠ¨åŒ–æœºå™¨äºº')
    parser.add_argument('--mode', choices=['run', 'schedule', 'daemon', 'status', 'backup', 'restore', 'health'], 
                       default='run', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--date', help='æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--daemon', action='store_true', help='å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼')
    parser.add_argument('--backup-timestamp', help='å¤‡ä»½æ—¶é—´æˆ³ (ç”¨äºæ¢å¤)')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–å¢å¼ºç‰ˆæœºå™¨äºº
        bot = EnhancedDailyTradingBot(args.config, daemon_mode=args.daemon or args.mode == 'daemon')
        
        if args.mode == 'run':
            # å•æ¬¡æ‰§è¡Œ
            print("ğŸš€ æ‰§è¡Œå•æ¬¡å¢å¼ºç‰ˆæ—¥å¸¸äº¤æ˜“æµç¨‹...")
            result = bot.daily_workflow()
            
            print("\n" + "="*60)
            print("ğŸ“‹ æ‰§è¡Œç»“æœ:")
            print(f"çŠ¶æ€: {'âœ… æˆåŠŸ' if result['success'] else 'âŒ å¤±è´¥'}")
            print(f"æ—¥æœŸ: {result['date']}")
            print(f"æ‰§è¡Œæ—¶é—´: {result['timestamp']}")
            
            # å¥åº·æ£€æŸ¥ç»“æœ
            if result['steps'].get('health_check'):
                health = result['steps']['health_check']
                print(f"ç³»ç»Ÿå¥åº·: {'âœ… æ­£å¸¸' if health['overall_healthy'] else 'âš ï¸ å¼‚å¸¸'}")
                if health['warnings']:
                    print(f"è­¦å‘Š: {len(health['warnings'])}é¡¹")
                if health['errors']:
                    print(f"é”™è¯¯: {len(health['errors'])}é¡¹")
            
            # æ•°æ®æ‹‰å–ç»“æœ
            if result['steps'].get('data_fetch'):
                fetch = result['steps']['data_fetch']
                print(f"æ•°æ®æ‹‰å–: {'âœ… æˆåŠŸ' if fetch['success'] else 'âŒ å¤±è´¥'}")
                if fetch.get('data_updated'):
                    print("   ğŸ“¡ æ•°æ®å·²æ›´æ–°")
                if fetch.get('commit_success'):
                    print("   ğŸ“¤ å·²æäº¤åˆ°Git")
            
            # é¢„æµ‹ç»“æœ
            if result['steps'].get('prediction', {}).get('success'):
                pred = result['steps']['prediction']
                print(f"é¢„æµ‹: {'ğŸ“ˆ ç›¸å¯¹ä½ç‚¹' if pred['is_low_point'] else 'ğŸ“‰ éç›¸å¯¹ä½ç‚¹'}")
                print(f"ç½®ä¿¡åº¦: {pred['final_confidence']:.3f}")
            
            # äº¤æ˜“ä¿¡å·
            if result['steps'].get('signal', {}).get('success'):
                signal = result['steps']['signal']['signal']
                print(f"å»ºè®®: {signal['action']} (å¼ºåº¦: {signal['strength']}/5)")
                print(f"é£é™©: {signal['risk_level']}")
            
            # å¤‡ä»½ç»“æœ
            if result['steps'].get('backup'):
                backup = result['steps']['backup']
                if backup['success']:
                    print(f"å¤‡ä»½: âœ… å®Œæˆ ({backup['total_size']/1024/1024:.1f}MB)")
            
            # é”™è¯¯ä¿¡æ¯
            if result['errors']:
                print("é”™è¯¯:")
                for error in result['errors']:
                    print(f"  âŒ {error}")
            
            print("="*60)
            
        elif args.mode == 'schedule':
            # ç®€å•å®šæ—¶æ‰§è¡Œ
            print("â° å¯åŠ¨ç®€å•å®šæ—¶ä»»åŠ¡æ¨¡å¼...")
            bot.run_scheduled()
            
        elif args.mode == 'daemon':
            # å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼
            print("ğŸ›¡ï¸ å¯åŠ¨å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼...")
            bot.run_daemon_mode()
            
        elif args.mode == 'status':
            # çŠ¶æ€æŸ¥è¯¢
            status = bot.get_status_report()
            print("\n" + "="*60)
            print("ğŸ“Š å¢å¼ºç‰ˆæœºå™¨äººçŠ¶æ€æŠ¥å‘Š")
            print("="*60)
            
            # åŸºæœ¬çŠ¶æ€
            print(f"æ€»é¢„æµ‹æ¬¡æ•°: {status['bot_state']['total_predictions']}")
            print(f"æˆåŠŸæ¬¡æ•°: {status['bot_state']['successful_predictions']}")
            print(f"è®­ç»ƒæ¬¡æ•°: {status['bot_state']['training_count']}")
            print(f"æ•°æ®æ‹‰å–æ¬¡æ•°: {status['bot_state']['data_fetch_count']}")
            print(f"å¤‡ä»½æ¬¡æ•°: {status['bot_state']['backup_count']}")
            
            # æœ€åæ‰§è¡Œæ—¶é—´
            print(f"\næœ€åæ‰§è¡Œæ—¶é—´:")
            print(f"  è®­ç»ƒ: {status['bot_state']['last_training_date'] or 'æ— '}")
            print(f"  é¢„æµ‹: {status['bot_state']['last_prediction_date'] or 'æ— '}")
            print(f"  æ•°æ®æ‹‰å–: {status['bot_state']['last_data_fetch'] or 'æ— '}")
            print(f"  å¤‡ä»½: {status['bot_state']['last_backup'] or 'æ— '}")
            
            # ç³»ç»ŸçŠ¶æ€
            print(f"\nç³»ç»ŸçŠ¶æ€:")
            print(f"  è¿ç»­é”™è¯¯: {status['bot_state']['consecutive_errors']}")
            print(f"  è¿è¡Œæ—¶é•¿: {status['bot_state']['uptime_start']}")
            
            # æ¨¡å—çŠ¶æ€
            modules = status['modules_status']
            print(f"\næ¨¡å—çŠ¶æ€:")
            print(f"  æ•°æ®æ¨¡å—: {'âœ…' if modules['data_module'] else 'âŒ'}")
            print(f"  AIæ¨¡å—: {'âœ…' if modules['ai_module'] else 'âŒ'}")
            print(f"  ç­–ç•¥æ¨¡å—: {'âœ…' if modules['strategy_module'] else 'âŒ'}")
            
            # å¥åº·æ£€æŸ¥
            health = bot.check_system_health()
            print(f"\nç³»ç»Ÿå¥åº·æ£€æŸ¥:")
            print(f"  æ•´ä½“çŠ¶æ€: {'âœ… å¥åº·' if health['overall_healthy'] else 'âš ï¸ å¼‚å¸¸'}")
            print(f"  CPUä½¿ç”¨ç‡: {health['metrics']['cpu_percent']:.1f}%")
            print(f"  å†…å­˜ä½¿ç”¨ç‡: {health['metrics']['memory_percent']:.1f}%")
            print(f"  ç£ç›˜ä½¿ç”¨ç‡: {health['metrics']['disk_usage']:.1f}%")
            
            if health['warnings']:
                print(f"\nâš ï¸ è­¦å‘Š ({len(health['warnings'])}é¡¹):")
                for warning in health['warnings']:
                    print(f"  - {warning}")
            
            if health['errors']:
                print(f"\nâŒ é”™è¯¯ ({len(health['errors'])}é¡¹):")
                for error in health['errors']:
                    print(f"  - {error}")
            
            if not health['warnings'] and not health['errors']:
                print("\nâœ… æœªå‘ç°é—®é¢˜")
        
        elif args.mode == 'backup':
            # æ‰‹åŠ¨å¤‡ä»½
            print("ğŸ’¾ æ‰§è¡Œæ‰‹åŠ¨æ•°æ®å¤‡ä»½...")
            result = bot.auto_backup_data()
            
            if result['success']:
                print(f"âœ… å¤‡ä»½å®Œæˆ!")
                print(f"å¤‡ä»½è·¯å¾„: {result['backup_path']}")
                print(f"å¤‡ä»½å¤§å°: {result['total_size']/1024/1024:.1f}MB")
                print(f"å¤‡ä»½é¡¹ç›®: {len(result['backed_up_items'])}ä¸ª")
                
                for item in result['backed_up_items']:
                    print(f"  - {item['name']}: {item['size']/1024/1024:.1f}MB")
            else:
                print(f"âŒ å¤‡ä»½å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
        elif args.mode == 'restore':
            # æ•°æ®æ¢å¤
            if not args.backup_timestamp:
                print("âŒ æ¢å¤æ¨¡å¼éœ€è¦æŒ‡å®šå¤‡ä»½æ—¶é—´æˆ³: --backup-timestamp YYYYMMDD_HHMMSS")
                return 1
            
            print(f"ğŸ”„ ä»å¤‡ä»½æ¢å¤æ•°æ®: {args.backup_timestamp}")
            result = bot.restore_from_backup(args.backup_timestamp)
            
            if result['success']:
                print(f"âœ… æ¢å¤å®Œæˆ!")
                print(f"æ¢å¤é¡¹ç›®: {', '.join(result['restored_items'])}")
            else:
                print(f"âŒ æ¢å¤å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
        elif args.mode == 'health':
            # å¥åº·æ£€æŸ¥
            print("ğŸ¥ æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥...")
            health = bot.check_system_health()
            
            print(f"\nç³»ç»Ÿå¥åº·çŠ¶æ€: {'âœ… å¥åº·' if health['overall_healthy'] else 'âš ï¸ å¼‚å¸¸'}")
            print(f"æ£€æŸ¥æ—¶é—´: {health['timestamp']}")
            
            print(f"\nğŸ“Š ç³»ç»ŸæŒ‡æ ‡:")
            print(f"  CPUä½¿ç”¨ç‡: {health['metrics']['cpu_percent']:.1f}%")
            print(f"  å†…å­˜ä½¿ç”¨ç‡: {health['metrics']['memory_percent']:.1f}%")
            print(f"  ç£ç›˜ä½¿ç”¨ç‡: {health['metrics']['disk_usage']:.1f}%")
            print(f"  è¿›ç¨‹æ•°é‡: {health['metrics']['process_count']}")
            
            if health['warnings']:
                print(f"\nâš ï¸ è­¦å‘Š ({len(health['warnings'])}é¡¹):")
                for warning in health['warnings']:
                    print(f"  - {warning}")
            
            if health['errors']:
                print(f"\nâŒ é”™è¯¯ ({len(health['errors'])}é¡¹):")
                for error in health['errors']:
                    print(f"  - {error}")
            
            if not health['warnings'] and not health['errors']:
                print("\nâœ… æœªå‘ç°é—®é¢˜")
        
        return 0
        
    except Exception as e:
        print(f"âŒ å¢å¼ºç‰ˆæœºå™¨äººæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main()) 