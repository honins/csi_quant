#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ä¸¥æ ¼æ•°æ®åˆ†å‰²åŠŸèƒ½æµ‹è¯•
éªŒè¯æ•°æ®åˆ†å‰²ã€è¿‡æ‹Ÿåˆé˜²æŠ¤ã€æ—©åœæœºåˆ¶ç­‰åŠŸèƒ½
"""

import sys
import os
import pandas as pd
import numpy as np

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from utils.utils import setup_logging, load_config
from data.data_module import DataModule
from strategy.strategy_module import StrategyModule
from ai.ai_optimizer import AIOptimizer, EarlyStopping

def test_strict_data_split():
    """æµ‹è¯•ä¸¥æ ¼æ•°æ®åˆ†å‰²åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ä¸¥æ ¼æ•°æ®åˆ†å‰²åŠŸèƒ½...")
    
    # è®¾ç½®æ—¥å¿—
    setup_logging('INFO')
    
    # åŠ è½½é…ç½®
    config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'config.yaml')
    config = load_config(config_path)
    
    try:
        # 1. åˆå§‹åŒ–AIä¼˜åŒ–å™¨
        ai_optimizer = AIOptimizer(config)
        
        # 2. åˆ›å»ºæµ‹è¯•æ•°æ®
        dates = pd.date_range('2020-01-01', periods=1000, freq='D')
        test_data = pd.DataFrame({
            'date': dates,
            'open': np.random.randn(1000).cumsum() + 100,
            'high': np.random.randn(1000).cumsum() + 105,
            'low': np.random.randn(1000).cumsum() + 95,
            'close': np.random.randn(1000).cumsum() + 100,
            'volume': np.random.randint(1000000, 10000000, 1000)
        })
        test_data.reset_index(drop=True, inplace=True)
        
        print(f"   åˆ›å»ºæµ‹è¯•æ•°æ®: {len(test_data)} æ¡è®°å½•")
        
        # 3. æµ‹è¯•æ•°æ®åˆ†å‰²
        data_splits = ai_optimizer.strict_data_split(test_data, preserve_test_set=True)
        train_data = data_splits['train']
        validation_data = data_splits['validation']
        test_data_split = data_splits['test']
        
        print(f"   æ•°æ®åˆ†å‰²ç»“æœ:")
        print(f"     - è®­ç»ƒé›†: {len(train_data)} æ¡")
        print(f"     - éªŒè¯é›†: {len(validation_data)} æ¡")
        print(f"     - æµ‹è¯•é›†: {len(test_data_split)} æ¡")
        
        # 4. éªŒè¯åˆ†å‰²æ¯”ä¾‹
        total_size = len(test_data)
        train_ratio = len(train_data) / total_size
        val_ratio = len(validation_data) / total_size
        test_ratio = len(test_data_split) / total_size
        
        expected_train_ratio = ai_optimizer.train_ratio
        expected_val_ratio = ai_optimizer.validation_ratio
        expected_test_ratio = ai_optimizer.test_ratio
        
        assert abs(train_ratio - expected_train_ratio) < 0.02, f"è®­ç»ƒé›†æ¯”ä¾‹ä¸ç¬¦åˆé¢„æœŸ: {train_ratio:.2%} vs {expected_train_ratio:.2%}"
        assert abs(val_ratio - expected_val_ratio) < 0.02, f"éªŒè¯é›†æ¯”ä¾‹ä¸ç¬¦åˆé¢„æœŸ: {val_ratio:.2%} vs {expected_val_ratio:.2%}"
        assert abs(test_ratio - expected_test_ratio) < 0.02, f"æµ‹è¯•é›†æ¯”ä¾‹ä¸ç¬¦åˆé¢„æœŸ: {test_ratio:.2%} vs {expected_test_ratio:.2%}"
        
        print(f"   âœ… æ•°æ®åˆ†å‰²æ¯”ä¾‹éªŒè¯é€šè¿‡")
        
        # 5. éªŒè¯æ•°æ®æ— é‡å 
        train_indices = set(train_data.index)
        val_indices = set(validation_data.index)
        test_indices = set(test_data_split.index)
        
        assert len(train_indices & val_indices) == 0, "è®­ç»ƒé›†å’ŒéªŒè¯é›†æœ‰é‡å "
        assert len(train_indices & test_indices) == 0, "è®­ç»ƒé›†å’Œæµ‹è¯•é›†æœ‰é‡å "
        assert len(val_indices & test_indices) == 0, "éªŒè¯é›†å’Œæµ‹è¯•é›†æœ‰é‡å "
        
        print(f"   âœ… æ•°æ®æ— é‡å éªŒè¯é€šè¿‡")
        
        # 6. æµ‹è¯•æµ‹è¯•é›†ä¿æŠ¤æœºåˆ¶
        data_splits_2 = ai_optimizer.strict_data_split(test_data, preserve_test_set=True)
        test_data_split_2 = data_splits_2['test']
        
        assert test_data_split.equals(test_data_split_2), "æµ‹è¯•é›†ä¿æŠ¤æœºåˆ¶å¤±æ•ˆ"
        print(f"   âœ… æµ‹è¯•é›†ä¿æŠ¤æœºåˆ¶éªŒè¯é€šè¿‡")
        
        print("âœ… ä¸¥æ ¼æ•°æ®åˆ†å‰²åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ ä¸¥æ ¼æ•°æ®åˆ†å‰²åŠŸèƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_early_stopping():
    """æµ‹è¯•æ—©åœæœºåˆ¶"""
    print("ğŸ§ª æµ‹è¯•æ—©åœæœºåˆ¶...")
    
    try:
        # åˆ›å»ºæ—©åœå®ä¾‹
        early_stopping = EarlyStopping(patience=5, min_delta=0.01)
        
        # æ¨¡æ‹Ÿå¾—åˆ†åºåˆ—
        scores = [0.5, 0.55, 0.6, 0.62, 0.61, 0.61, 0.60, 0.59, 0.58, 0.57]
        
        should_stop = False
        stop_iteration = -1
        
        for i, score in enumerate(scores):
            if early_stopping(score):
                should_stop = True
                stop_iteration = i
                break
        
        assert should_stop, "æ—©åœæœºåˆ¶æœªè§¦å‘"
        assert stop_iteration > 0, "æ—©åœè§¦å‘æ—¶æœºä¸æ­£ç¡®"
        
        print(f"   âœ… æ—©åœæœºåˆ¶åœ¨ç¬¬ {stop_iteration + 1} æ¬¡è¿­ä»£è§¦å‘")
        print("âœ… æ—©åœæœºåˆ¶æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ—©åœæœºåˆ¶æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_data_leakage_detection():
    """æµ‹è¯•æ•°æ®æ³„éœ²æ£€æµ‹"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®æ³„éœ²æ£€æµ‹...")
    
    try:
        # è®¾ç½®æ—¥å¿—
        setup_logging('INFO')
        
        # åŠ è½½é…ç½®
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'config.yaml')
        config = load_config(config_path)
        
        # åˆ›å»ºAIä¼˜åŒ–å™¨
        ai_optimizer = AIOptimizer(config)
        data_module = DataModule(config)
        strategy_module = StrategyModule(config)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        dates = pd.date_range('2020-01-01', periods=500, freq='D')
        test_data = pd.DataFrame({
            'date': dates,
            'open': np.random.randn(500).cumsum() + 100,
            'high': np.random.randn(500).cumsum() + 105,
            'low': np.random.randn(500).cumsum() + 95,
            'close': np.random.randn(500).cumsum() + 100,
            'volume': np.random.randint(1000000, 10000000, 500)
        })
        test_data.reset_index(drop=True, inplace=True)
        
        # æ·»åŠ å¿…è¦çš„æŠ€æœ¯æŒ‡æ ‡åˆ—
        test_data['ma_5'] = test_data['close'].rolling(5).mean()
        test_data['ma_10'] = test_data['close'].rolling(10).mean()
        test_data['ma_20'] = test_data['close'].rolling(20).mean()
        test_data['ma_60'] = test_data['close'].rolling(60).mean()
        test_data['bb_upper'] = test_data['close'].rolling(20).mean() + 2 * test_data['close'].rolling(20).std()
        test_data['bb_lower'] = test_data['close'].rolling(20).mean() - 2 * test_data['close'].rolling(20).std()
        test_data['rsi'] = 50 + np.random.randn(500) * 10  # ç®€åŒ–çš„RSI
        test_data['macd'] = np.random.randn(500) * 0.1
        test_data['macd_signal'] = test_data['macd'].rolling(9).mean()
        
        # å…ˆè¿›è¡Œæ•°æ®åˆ†å‰²
        data_splits = ai_optimizer.strict_data_split(test_data, preserve_test_set=True)
        train_data = data_splits['train']
        
        # æµ‹è¯•æ­£å¸¸æƒ…å†µï¼ˆåº”è¯¥é€šè¿‡ï¼‰
        try:
            result = ai_optimizer.optimize_strategy_parameters_on_train_only(strategy_module, train_data)
            print(f"   âœ… æ­£å¸¸è®­ç»ƒæ•°æ®ä¼˜åŒ–é€šè¿‡")
        except Exception as e:
            print(f"   âŒ æ­£å¸¸è®­ç»ƒæ•°æ®ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return False
        
        # æµ‹è¯•æ•°æ®æ³„éœ²æƒ…å†µï¼ˆåº”è¯¥è¢«æ£€æµ‹åˆ°ï¼‰
        # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿå°†æµ‹è¯•é›†æ•°æ®æ··å…¥è®­ç»ƒæ•°æ®çš„æƒ…å†µ
        test_data_leak = data_splits['test']
        contaminated_train_data = pd.concat([train_data, test_data_leak.head(10)]).reset_index(drop=True)
        
        try:
            result = ai_optimizer.optimize_strategy_parameters_on_train_only(strategy_module, contaminated_train_data)
            print(f"   âš ï¸ æ•°æ®æ³„éœ²æœªè¢«æ£€æµ‹åˆ°ï¼ˆå¯èƒ½æ˜¯æµ‹è¯•ç¯å¢ƒé™åˆ¶ï¼‰")
        except ValueError as e:
            if "æ•°æ®æ³„éœ²" in str(e):
                print(f"   âœ… æ•°æ®æ³„éœ²è¢«æˆåŠŸæ£€æµ‹åˆ°: {str(e)}")
            else:
                print(f"   âŒ æ£€æµ‹åˆ°é”™è¯¯ä½†ä¸æ˜¯æ•°æ®æ³„éœ²: {str(e)}")
                return False
        except Exception as e:
            print(f"   âŒ æ•°æ®æ³„éœ²æ£€æµ‹æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
        
        print("âœ… æ•°æ®æ³„éœ²æ£€æµ‹æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®æ³„éœ²æ£€æµ‹æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 60)
    print("ä¸¥æ ¼æ•°æ®åˆ†å‰²åŠŸèƒ½æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    
    tests = [
        ("ä¸¥æ ¼æ•°æ®åˆ†å‰²", test_strict_data_split),
        ("æ—©åœæœºåˆ¶", test_early_stopping),
        ("æ•°æ®æ³„éœ²æ£€æµ‹", test_data_leakage_detection),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ§ª è¿è¡Œæµ‹è¯•: {test_name}")
        try:
            if test_func():
                passed += 1
                print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
            else:
                print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å‡ºé”™: {str(e)}")
    
    print("\n" + "=" * 60)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡ ({passed/total:.1%})")
    print("=" * 60)
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¸¥æ ¼æ•°æ®åˆ†å‰²åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
        return False

def main():
    """ä¸»å‡½æ•°"""
    success = run_all_tests()
    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main() 