#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å‚æ•°ä¼˜åŒ–å™¨æ¨¡å—
ä¸“é—¨è´Ÿè´£ç­–ç•¥å‚æ•°çš„ä¼˜åŒ–ï¼Œä»åŸAIä¼˜åŒ–å™¨ä¸­åˆ†ç¦»å‡ºæ¥

åŠŸèƒ½ï¼š
- ç­–ç•¥å‚æ•°æœç´¢å’Œä¼˜åŒ–
- ç½‘æ ¼æœç´¢å’Œéšæœºæœç´¢
- çœŸæ­£çš„è´å¶æ–¯ä¼˜åŒ–ï¼ˆä½¿ç”¨scikit-optimizeï¼‰
- å‚æ•°èŒƒå›´ç®¡ç†
- è¯„åˆ†å‡½æ•°è®¡ç®—
- ä¼˜åŒ–ç»“æœä¿å­˜
"""

import logging
import time
import json
from datetime import datetime
from typing import Dict, Any, List, Tuple, Optional
import numpy as np
from itertools import product

# è´å¶æ–¯ä¼˜åŒ–ç›¸å…³å¯¼å…¥
try:
    from skopt import gp_minimize
    from skopt.space import Real, Integer
    from skopt.utils import use_named_args
    BAYESIAN_AVAILABLE = True
except ImportError:
    BAYESIAN_AVAILABLE = False

from ..utils.base_module import AIModule
from ..utils.common import (
    PerformanceMonitor, DataValidator, MathUtils,
    safe_execute, error_context, FileManager
)


class ParameterOptimizer(AIModule):
    """
    å‚æ•°ä¼˜åŒ–å™¨
    
    ä¸“é—¨è´Ÿè´£ç­–ç•¥å‚æ•°çš„æœç´¢å’Œä¼˜åŒ–
    """
    
    def _initialize_module(self):
        """åˆå§‹åŒ–å‚æ•°ä¼˜åŒ–å™¨"""
        # è·å–ä¼˜åŒ–é…ç½®
        self.optimization_config = self.get_config_section('optimization', {})
        
        # ä¼˜åŒ–å†å²è®°å½•ï¼ˆå¸¦å¤§å°é™åˆ¶ï¼‰
        self.optimization_history = []
        self.max_history_size = self.optimization_config.get('max_history_size', 100)
        
        # å½“å‰æœ€ä½³å‚æ•°
        self.best_params = None
        self.best_score = -np.inf
        
        # è¯„åˆ†æƒé‡é…ç½®
        self.scoring_weights = self._load_scoring_weights()
        
        # è´å¶æ–¯ä¼˜åŒ–é…ç½®
        self.bayesian_config = self.get_config_section('bayesian_optimization', {})
        self.ai_config = self.get_config_section('ai', {})  # æ·»åŠ ai_configå±æ€§
        
        self.logger.info(f"å‚æ•°ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œè´å¶æ–¯ä¼˜åŒ–å¯ç”¨: {BAYESIAN_AVAILABLE}")
    
    def _validate_module_config(self):
        """éªŒè¯å‚æ•°ä¼˜åŒ–å™¨é…ç½®"""
        # åŸºç¡€AIæ¨¡å—éªŒè¯
        super()._validate_module_config()
        
        # æ£€æŸ¥ä¼˜åŒ–é…ç½®
        if 'optimization' not in self.config:
            self.logger.warning("ç¼ºå°‘optimizationé…ç½®éƒ¨åˆ†ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    
    def _get_module_directories(self) -> List:
        """å‚æ•°ä¼˜åŒ–å™¨ç‰¹å®šç›®å½•"""
        base_dirs = super()._get_module_directories()
        return base_dirs + [
            self.project_root / 'results' / 'optimization',
            self.project_root / 'cache' / 'parameters'
        ]
    
    def _load_scoring_weights(self) -> Dict[str, float]:
        """åŠ è½½è¯„åˆ†æƒé‡é…ç½®"""
        default_weights = {
            'success_rate': 0.4,    # æˆåŠŸç‡æƒé‡
            'avg_rise': 0.3,        # å¹³å‡æ¶¨å¹…æƒé‡
            'avg_days': 0.2,        # å¹³å‡å¤©æ•°æƒé‡ï¼ˆè´Ÿæƒé‡ï¼Œå¤©æ•°è¶Šå°‘è¶Šå¥½ï¼‰
            'risk_penalty': 0.1     # é£é™©æƒ©ç½šæƒé‡
        }
        
        scoring_config = self.get_config_section('ai', {}).get('scoring', {})
        weights = scoring_config.get('strategy_scoring', default_weights)
        
        # éªŒè¯æƒé‡æ€»å’Œ
        total_weight = sum(weights.values())
        if abs(total_weight - 1.0) > 0.01:
            self.logger.warning(f"è¯„åˆ†æƒé‡æ€»å’Œä¸ç­‰äº1.0: {total_weight}ï¼Œè¿›è¡Œå½’ä¸€åŒ–")
            # å½’ä¸€åŒ–æƒé‡
            weights = {k: v / total_weight for k, v in weights.items()}
        
        return weights
    
    def optimize_parameters(self, 
                           strategy_module,
                           data,
                           param_ranges: Dict[str, Any],
                           method: str = 'random',
                           max_iterations: int = 100) -> Dict[str, Any]:
        """
        ä¼˜åŒ–ç­–ç•¥å‚æ•°
        
        å‚æ•°:
            strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
            data: è®­ç»ƒæ•°æ®
            param_ranges: å‚æ•°æœç´¢èŒƒå›´
            method: ä¼˜åŒ–æ–¹æ³• ('grid', 'random', 'bayesian')
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        
        è¿”å›:
            Dict[str, Any]: ä¼˜åŒ–ç»“æœ
        """
        with PerformanceMonitor(f"å‚æ•°ä¼˜åŒ–-{method}"):
            try:
                self.logger.info(f"å¼€å§‹å‚æ•°ä¼˜åŒ–ï¼Œæ–¹æ³•: {method}ï¼Œæœ€å¤§è¿­ä»£: {max_iterations}")
                
                # éªŒè¯è¾“å…¥æ•°æ®
                valid, errors = self._validate_optimization_inputs(data, param_ranges)
                if not valid:
                    return {'success': False, 'error': f"è¾“å…¥éªŒè¯å¤±è´¥: {errors}"}
                
                # æ ¹æ®æ–¹æ³•é€‰æ‹©ä¼˜åŒ–ç®—æ³•
                if method == 'grid':
                    result = self._grid_search_optimization(strategy_module, data, param_ranges)
                elif method == 'random':
                    result = self._random_search_optimization(strategy_module, data, param_ranges, max_iterations)
                elif method == 'bayesian':
                    result = self._bayesian_optimization(strategy_module, data, param_ranges, max_iterations)
                else:
                    return {'success': False, 'error': f"ä¸æ”¯æŒçš„ä¼˜åŒ–æ–¹æ³•: {method}"}
                
                # ä¿å­˜ä¼˜åŒ–ç»“æœ
                self._save_optimization_result(result, method)
                
                return result
                
            except Exception as e:
                self.logger.error(f"å‚æ•°ä¼˜åŒ–å¼‚å¸¸: {e}")
                return {'success': False, 'error': str(e)}
    
    def _validate_optimization_inputs(self, data, param_ranges) -> Tuple[bool, List[str]]:
        """éªŒè¯ä¼˜åŒ–è¾“å…¥"""
        errors = []
        
        # éªŒè¯æ•°æ®
        if data is None or data.empty:
            errors.append("æ•°æ®ä¸ºç©º")
        elif len(data) < 100:
            errors.append(f"æ•°æ®é‡ä¸è¶³ï¼Œéœ€è¦è‡³å°‘100æ¡ï¼Œå®é™…{len(data)}æ¡")
        
        # éªŒè¯å‚æ•°èŒƒå›´
        if not param_ranges:
            errors.append("å‚æ•°èŒƒå›´ä¸ºç©º")
        
        for param_name, param_config in param_ranges.items():
            if not isinstance(param_config, dict):
                errors.append(f"å‚æ•° {param_name} é…ç½®æ ¼å¼é”™è¯¯")
                continue
            
            required_keys = ['min', 'max']
            for key in required_keys:
                if key not in param_config:
                    errors.append(f"å‚æ•° {param_name} ç¼ºå°‘ {key} é…ç½®")
        
        return len(errors) == 0, errors
    
    def _grid_search_optimization(self, strategy_module, data, param_ranges) -> Dict[str, Any]:
        """ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        self.logger.info("æ‰§è¡Œç½‘æ ¼æœç´¢ä¼˜åŒ–")
        
        start_time = time.time()
        
        # ç”Ÿæˆå‚æ•°ç½‘æ ¼
        param_combinations = self._generate_parameter_grid(param_ranges)
        total_combinations = len(param_combinations)
        
        if total_combinations > 10000:
            self.logger.warning(f"å‚æ•°ç»„åˆæ•°é‡è¿‡å¤§: {total_combinations}ï¼Œå»ºè®®ä½¿ç”¨éšæœºæœç´¢")
            # éšæœºé‡‡æ ·
            import random
            param_combinations = random.sample(param_combinations, 10000)
            total_combinations = len(param_combinations)
        
        self.logger.info(f"ç½‘æ ¼æœç´¢ç»„åˆæ•°: {total_combinations}")
        
        best_params = None
        best_score = -np.inf
        best_metrics = None
        
        # éå†æ‰€æœ‰å‚æ•°ç»„åˆ
        for i, params in enumerate(param_combinations):
            try:
                # è¯„ä¼°å‚æ•°ç»„åˆ
                score, metrics = self._evaluate_parameters(strategy_module, data, params)
                
                # æ›´æ–°æœ€ä½³ç»“æœ
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
                    best_metrics = metrics.copy()
                    
                    self.logger.info(f"å‘ç°æ›´å¥½å‚æ•° (ç¬¬{i+1}æ¬¡): å¾—åˆ†={score:.4f}")
                
                # è¿›åº¦æŠ¥å‘Š
                if (i + 1) % max(1, total_combinations // 10) == 0:
                    progress = (i + 1) / total_combinations * 100
                    elapsed = time.time() - start_time
                    self.logger.info(f"ç½‘æ ¼æœç´¢è¿›åº¦: {progress:.1f}% ({i+1}/{total_combinations}), å·²ç”¨æ—¶: {elapsed:.1f}ç§’")
                
            except Exception as e:
                self.logger.warning(f"è¯„ä¼°å‚æ•°ç»„åˆå¤±è´¥ {params}: {e}")
                continue
        
        total_time = time.time() - start_time
        
        return {
            'success': True,
            'method': 'grid_search',
            'best_params': best_params,
            'best_score': best_score,
            'best_metrics': best_metrics,
            'total_combinations': total_combinations,
            'optimization_time': total_time,
            'timestamp': datetime.now().isoformat()
        }
    
    def _random_search_optimization(self, strategy_module, data, param_ranges, max_iterations) -> Dict[str, Any]:
        """éšæœºæœç´¢ä¼˜åŒ–"""
        self.logger.info(f"æ‰§è¡Œéšæœºæœç´¢ä¼˜åŒ–ï¼Œæœ€å¤§è¿­ä»£: {max_iterations}")
        
        start_time = time.time()
        
        best_params = None
        best_score = -np.inf
        best_metrics = None
        improvements = 0
        
        # éšæœºæœç´¢
        for i in range(max_iterations):
            try:
                # ç”Ÿæˆéšæœºå‚æ•°
                params = self._generate_random_parameters(param_ranges)
                
                # è¯„ä¼°å‚æ•°
                score, metrics = self._evaluate_parameters(strategy_module, data, params)
                
                # æ›´æ–°æœ€ä½³ç»“æœ
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
                    best_metrics = metrics.copy()
                    improvements += 1
                    
                    self.logger.info(f"å‘ç°æ›´å¥½å‚æ•° (ç¬¬{improvements}æ¬¡æ”¹è¿›, è¿­ä»£{i+1}): å¾—åˆ†={score:.4f}")
                
                # è¿›åº¦æŠ¥å‘Š
                if (i + 1) % max(1, max_iterations // 10) == 0:
                    progress = (i + 1) / max_iterations * 100
                    elapsed = time.time() - start_time
                    self.logger.info(f"éšæœºæœç´¢è¿›åº¦: {progress:.1f}% ({i+1}/{max_iterations}), å·²ç”¨æ—¶: {elapsed:.1f}ç§’")
                
            except Exception as e:
                self.logger.warning(f"è¯„ä¼°éšæœºå‚æ•°å¤±è´¥ {params}: {e}")
                continue
        
        total_time = time.time() - start_time
        
        return {
            'success': True,
            'method': 'random_search',
            'best_params': best_params,
            'best_score': best_score,
            'best_metrics': best_metrics,
            'iterations': max_iterations,
            'improvements': improvements,
            'optimization_time': total_time,
            'timestamp': datetime.now().isoformat()
        }
    
    def _bayesian_optimization(self, strategy_module, data, param_ranges, max_iterations) -> Dict[str, Any]:
        """çœŸæ­£çš„è´å¶æ–¯ä¼˜åŒ–å®ç°"""
        if not BAYESIAN_AVAILABLE:
            self.logger.warning("scikit-optimizeæœªå®‰è£…ï¼Œå›é€€åˆ°è‡ªé€‚åº”éšæœºæœç´¢")
            return self._adaptive_random_search(strategy_module, data, param_ranges, max_iterations)
        
        self.logger.info("ğŸ”¬ å¼€å§‹è´å¶æ–¯ä¼˜åŒ–ï¼ˆä½¿ç”¨scikit-optimizeï¼‰")
        start_time = time.time()
        
        # è·å–è´å¶æ–¯ä¼˜åŒ–é…ç½®
        n_calls = self.bayesian_config.get('n_calls', 120)
        n_initial_points = self.bayesian_config.get('n_initial_points', 25)
        acq_func = self.bayesian_config.get('acq_func', 'EI')  # Expected Improvement
        xi = self.bayesian_config.get('xi', 0.01)
        kappa = self.bayesian_config.get('kappa', 1.96)
        random_state = self.bayesian_config.get('random_state', 42)
        
        self.logger.info(f"ğŸ¯ è´å¶æ–¯ä¼˜åŒ–é…ç½®:")
        self.logger.info(f"   æ€»è°ƒç”¨æ¬¡æ•°: {n_calls}")
        self.logger.info(f"   åˆå§‹éšæœºç‚¹: {n_initial_points}")
        self.logger.info(f"   é‡‡é›†å‡½æ•°: {acq_func}")
        self.logger.info(f"   æ¢ç´¢å‚æ•° xi: {xi}")
        self.logger.info(f"   ç½®ä¿¡å‚æ•° kappa: {kappa}")
        
        # åˆ›å»ºæœç´¢ç©ºé—´
        search_space = []
        param_names = []
        
        for param_name, param_config in param_ranges.items():
            min_val = param_config['min']
            max_val = param_config['max']
            param_type = param_config.get('type', 'float')
            
            param_names.append(param_name)
            
            if param_type == 'int':
                search_space.append(Integer(min_val, max_val, name=param_name))
            else:
                search_space.append(Real(min_val, max_val, name=param_name))
        
        self.logger.info(f"ğŸ” æœç´¢ç©ºé—´: {len(search_space)} ä¸ªå‚æ•°")
        
        # å®šä¹‰ç›®æ ‡å‡½æ•°
        @use_named_args(search_space)
        def objective(**params):
            try:
                # è¯„ä¼°å‚æ•°ç»„åˆ
                score, metrics = self._evaluate_parameters(strategy_module, data, params)
                
                # è´å¶æ–¯ä¼˜åŒ–æœ€å°åŒ–ç›®æ ‡å‡½æ•°ï¼Œæ‰€ä»¥è¿”å›è´Ÿå€¼
                return -score
                
            except Exception as e:
                self.logger.warning(f"è´å¶æ–¯ä¼˜åŒ–è¯„ä¼°å‚æ•°å¤±è´¥ {params}: {e}")
                return 1.0  # è¿”å›ä¸€ä¸ªè¾ƒå¤§çš„å€¼è¡¨ç¤ºå¤±è´¥
        
        # è¿è¡Œè´å¶æ–¯ä¼˜åŒ–
        self.logger.info("ğŸš€ å¼€å§‹è´å¶æ–¯ä¼˜åŒ–æœç´¢...")
        
        try:
            result = gp_minimize(
                func=objective,
                dimensions=search_space,
                n_calls=n_calls,
                n_initial_points=n_initial_points,
                acq_func=acq_func,
                xi=xi,
                kappa=kappa,
                random_state=random_state,
                verbose=True
            )
            
            # æå–æœ€ä½³å‚æ•°
            best_params = dict(zip(param_names, result.x))
            best_score = -result.fun  # è½¬æ¢å›æ­£å€¼
            
            # è¯¦ç»†è¯„ä¼°æœ€ä½³å‚æ•°
            final_score, final_metrics = self._evaluate_parameters(strategy_module, data, best_params)
            
            total_time = time.time() - start_time
            
            self.logger.info(f"âœ… è´å¶æ–¯ä¼˜åŒ–å®Œæˆ (è€—æ—¶: {total_time:.2f}s)")
            self.logger.info(f"   æœ€ä½³å¾—åˆ†: {best_score:.6f}")
            self.logger.info(f"   æ”¶æ•›å€¼: {result.fun:.6f}")
            self.logger.info(f"   å‡½æ•°è°ƒç”¨æ¬¡æ•°: {len(result.func_vals)}")
            
            return {
                'success': True,
                'method': 'bayesian_optimization',
                'best_params': best_params,
                'best_score': best_score,
                'best_metrics': final_metrics,
                'convergence_info': {
                    'fun_value': result.fun,
                    'n_calls': len(result.func_vals),
                    'convergence_curve': result.func_vals
                },
                'optimization_time': total_time,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"è´å¶æ–¯ä¼˜åŒ–å¤±è´¥: {e}")
            # å›é€€åˆ°è‡ªé€‚åº”éšæœºæœç´¢
            self.logger.info("å›é€€åˆ°è‡ªé€‚åº”éšæœºæœç´¢...")
            return self._adaptive_random_search(strategy_module, data, param_ranges, max_iterations)
    
    def _adaptive_random_search(self, strategy_module, data, param_ranges, max_iterations) -> Dict[str, Any]:
        """è‡ªé€‚åº”éšæœºæœç´¢"""
        start_time = time.time()
        
        best_params = None
        best_score = -np.inf
        best_metrics = None
        improvements = 0
        
        # å†å²å‚æ•°å’Œå¾—åˆ†ï¼ˆå¸¦å†…å­˜ç®¡ç†ï¼‰
        param_history = []
        score_history = []
        max_history_items = min(max_iterations, 1000)  # é™åˆ¶å†å²è®°å½•å¤§å°
        
        for i in range(max_iterations):
            try:
                # è‡ªé€‚åº”ç”Ÿæˆå‚æ•°
                if i < max_iterations * 0.3:
                    # å‰30%ä½¿ç”¨çº¯éšæœºæœç´¢
                    params = self._generate_random_parameters(param_ranges)
                else:
                    # å70%åŸºäºå†å²ç»“æœè°ƒæ•´æœç´¢
                    params = self._generate_adaptive_parameters(param_ranges, param_history, score_history)
                
                # è¯„ä¼°å‚æ•°
                score, metrics = self._evaluate_parameters(strategy_module, data, params)
                
                # è®°å½•å†å²ï¼ˆä¿æŒå¤§å°é™åˆ¶ï¼‰
                param_history.append(params)
                score_history.append(score)
                
                # æ¸…ç†è¿‡å¤šçš„å†å²è®°å½•
                if len(param_history) > max_history_items:
                    # ä¿ç•™æœ€å¥½çš„ä¸€åŠå’Œæœ€è¿‘çš„ä¸€åŠ
                    keep_count = max_history_items // 2
                    
                    # æ‰¾åˆ°æœ€å¥½çš„å‚æ•°ç´¢å¼•
                    best_indices = np.argsort(score_history)[-keep_count:]
                    recent_indices = list(range(len(param_history) - keep_count, len(param_history)))
                    
                    # åˆå¹¶å¹¶å»é‡
                    keep_indices = sorted(set(best_indices.tolist() + recent_indices))
                    
                    param_history = [param_history[i] for i in keep_indices]
                    score_history = [score_history[i] for i in keep_indices]
                
                # æ›´æ–°æœ€ä½³ç»“æœ
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
                    best_metrics = metrics.copy()
                    improvements += 1
                    
                    self.logger.info(f"å‘ç°æ›´å¥½å‚æ•° (ç¬¬{improvements}æ¬¡æ”¹è¿›, è¿­ä»£{i+1}): å¾—åˆ†={score:.4f}")
                
                # è¿›åº¦æŠ¥å‘Š
                if (i + 1) % max(1, max_iterations // 10) == 0:
                    progress = (i + 1) / max_iterations * 100
                    elapsed = time.time() - start_time
                    eta = elapsed / (i + 1) * (max_iterations - i - 1)
                    self.logger.info(f"è‡ªé€‚åº”æœç´¢è¿›åº¦: {progress:.1f}% ({i+1}/{max_iterations}), å·²ç”¨æ—¶: {elapsed:.1f}ç§’, é¢„è®¡å‰©ä½™: {eta:.1f}ç§’")
                
            except Exception as e:
                self.logger.warning(f"è¯„ä¼°è‡ªé€‚åº”å‚æ•°å¤±è´¥: {e}")
                continue
        
        total_time = time.time() - start_time
        
        return {
            'success': True,
            'method': 'adaptive_search',
            'best_params': best_params,
            'best_score': best_score,
            'best_metrics': best_metrics,
            'iterations': max_iterations,
            'improvements': improvements,
            'optimization_time': total_time,
            'timestamp': datetime.now().isoformat()
        }
    
    def _generate_parameter_grid(self, param_ranges) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå‚æ•°ç½‘æ ¼"""
        param_names = []
        param_values = []
        
        for name, config in param_ranges.items():
            param_names.append(name)
            
            # ç”Ÿæˆå‚æ•°å€¼åˆ—è¡¨
            if 'values' in config:
                # é¢„å®šä¹‰çš„å€¼åˆ—è¡¨
                values = config['values']
            else:
                # æ ¹æ®èŒƒå›´ç”Ÿæˆå€¼
                min_val = config['min']
                max_val = config['max']
                step = config.get('step', (max_val - min_val) / 10)
                
                if isinstance(min_val, int) and isinstance(max_val, int):
                    # æ•´æ•°èŒƒå›´
                    values = list(range(int(min_val), int(max_val) + 1, max(1, int(step))))
                else:
                    # æµ®ç‚¹æ•°èŒƒå›´
                    values = [min_val + i * step for i in range(int((max_val - min_val) / step) + 1)]
                    values = [v for v in values if v <= max_val]
            
            param_values.append(values)
        
        # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
        combinations = []
        for combination in product(*param_values):
            param_dict = dict(zip(param_names, combination))
            combinations.append(param_dict)
        
        return combinations
    
    def _generate_random_parameters(self, param_ranges) -> Dict[str, Any]:
        """ç”Ÿæˆéšæœºå‚æ•°"""
        params = {}
        
        for name, config in param_ranges.items():
            if 'values' in config:
                # ä»é¢„å®šä¹‰å€¼ä¸­éšæœºé€‰æ‹©
                params[name] = np.random.choice(config['values'])
            else:
                # åœ¨èŒƒå›´å†…éšæœºç”Ÿæˆ
                min_val = config['min']
                max_val = config['max']
                
                if isinstance(min_val, int) and isinstance(max_val, int):
                    # æ•´æ•°ç±»å‹
                    params[name] = np.random.randint(min_val, max_val + 1)
                else:
                    # æµ®ç‚¹æ•°ç±»å‹
                    params[name] = np.random.uniform(min_val, max_val)
        
        return params
    
    def _generate_adaptive_parameters(self, param_ranges, param_history, score_history) -> Dict[str, Any]:
        """åŸºäºå†å²ç»“æœç”Ÿæˆè‡ªé€‚åº”å‚æ•°"""
        if not param_history:
            return self._generate_random_parameters(param_ranges)
        
        # æ‰¾åˆ°æœ€å¥½çš„å‡ ä¸ªå‚æ•°ç»„åˆ
        sorted_indices = np.argsort(score_history)[-5:]  # å–æœ€å¥½çš„5ä¸ª
        best_params = [param_history[i] for i in sorted_indices]
        
        # åœ¨æœ€å¥½å‚æ•°é™„è¿‘æœç´¢
        base_params = best_params[-1]  # ä½¿ç”¨æœ€å¥½çš„å‚æ•°ä½œä¸ºåŸºç¡€
        params = {}
        
        for name, config in param_ranges.items():
            base_value = base_params.get(name, (config['min'] + config['max']) / 2)
            
            # åœ¨åŸºç¡€å€¼é™„è¿‘æ·»åŠ å™ªå£°
            if 'values' in config:
                # é¢„å®šä¹‰å€¼ï¼šéšæœºé€‰æ‹©æˆ–ä¿æŒåŸå€¼
                if np.random.random() < 0.7:
                    params[name] = base_value
                else:
                    params[name] = np.random.choice(config['values'])
            else:
                # è¿ç»­å€¼ï¼šåœ¨åŸºç¡€å€¼é™„è¿‘æ·»åŠ é«˜æ–¯å™ªå£°
                min_val = config['min']
                max_val = config['max']
                
                noise_scale = (max_val - min_val) * 0.1  # 10%çš„èŒƒå›´ä½œä¸ºå™ªå£°
                new_value = base_value + np.random.normal(0, noise_scale)
                
                # ç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
                new_value = np.clip(new_value, min_val, max_val)
                
                if isinstance(min_val, int) and isinstance(max_val, int):
                    params[name] = int(round(new_value))
                else:
                    params[name] = new_value
        
        return params
    
    def _evaluate_parameters(self, strategy_module, data, params) -> Tuple[float, Dict[str, Any]]:
        """è¯„ä¼°å‚æ•°ç»„åˆ - ä¿®å¤ç‰ˆï¼šåªæœ‰æ›´ä¼˜å‚æ•°æ‰ä¿ç•™"""
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šä¿å­˜å½“å‰ç­–ç•¥æ¨¡å—çŠ¶æ€
        original_params = strategy_module.get_current_params() if hasattr(strategy_module, 'get_current_params') else None
        
        # ä¸´æ—¶åº”ç”¨æ–°å‚æ•°è¿›è¡Œè¯„ä¼°
        strategy_module.update_params(params)
        
        # è¿è¡Œå›æµ‹
        backtest_results = strategy_module.backtest(data)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        metrics = strategy_module.evaluate_strategy(backtest_results)
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        score = self._calculate_score(metrics)
        
        # ğŸ¯ ä¿®å¤åçš„å‚æ•°ç®¡ç†é€»è¾‘ï¼šå§‹ç»ˆæ¢å¤åŸå§‹å‚æ•°ï¼Œè®©å¤–éƒ¨ç»Ÿä¸€ç®¡ç†
        # è¿™æ ·é¿å…äº†å†…éƒ¨ç®¡ç†å’Œå¤–éƒ¨ç®¡ç†çš„å†²çª
        if original_params is not None:
            strategy_module.update_params(original_params)
        
        return score, metrics
    
    def _calculate_score(self, metrics: Dict[str, Any]) -> float:
        """è®¡ç®—ç»¼åˆå¾—åˆ†"""
        try:
            # è·å–åŸºç¡€æŒ‡æ ‡
            success_rate = metrics.get('success_rate', 0.0)
            avg_rise = metrics.get('avg_rise', 0.0)
            avg_days = metrics.get('avg_days', 20.0)
            total_signals = metrics.get('total_signals', 0)
            
            # æ•°å€¼å®‰å…¨æ£€æŸ¥
            success_rate = max(0.0, min(1.0, success_rate))  # é™åˆ¶åœ¨[0,1]èŒƒå›´
            avg_rise = max(0.0, avg_rise)  # ç¡®ä¿éè´Ÿ
            avg_days = max(1.0, avg_days)  # ç¡®ä¿è‡³å°‘1å¤©
            total_signals = max(0, total_signals)  # ç¡®ä¿éè´Ÿ
            
            # åŸºç¡€å¾—åˆ†è®¡ç®—
            success_score = success_rate * self.scoring_weights['success_rate']
            
            # æ¶¨å¹…å¾—åˆ†ï¼ˆç›¸å¯¹äºåŸºå‡†4%ï¼‰
            base_rise = 0.04
            if base_rise > 0:
                rise_score = min(avg_rise / base_rise, 2.0) * self.scoring_weights['avg_rise']
            else:
                rise_score = 0.0
            
            # å¤©æ•°å¾—åˆ†ï¼ˆå¤©æ•°è¶Šå°‘è¶Šå¥½ï¼Œæœ€å¤§20å¤©ï¼‰
            max_days = 20.0
            days_score = max(0, (max_days - avg_days) / max_days) * self.scoring_weights['avg_days']
            
            # é£é™©æƒ©ç½šï¼ˆä¿¡å·æ•°è¿‡å°‘æƒ©ç½šï¼‰
            risk_penalty = 0
            min_signals = 10
            if total_signals < min_signals:
                risk_penalty = (min_signals - total_signals) / min_signals * self.scoring_weights['risk_penalty']
            
            # ç»¼åˆå¾—åˆ†
            total_score = success_score + rise_score + days_score - risk_penalty
            
            # ç¡®ä¿å¾—åˆ†åœ¨åˆç†èŒƒå›´å†…
            total_score = max(0.0, min(10.0, total_score))
            
            return total_score
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—å¾—åˆ†å¤±è´¥: {e}")
            return 0.0
    
    def _save_optimization_result(self, result: Dict[str, Any], method: str):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"optimization_{method}_{timestamp}.json"
            file_path = self.get_file_path('results', filename)
            
            # ä¿å­˜ç»“æœ
            success = FileManager.safe_json_save(result, file_path)
            
            if success:
                self.logger.info(f"ä¼˜åŒ–ç»“æœå·²ä¿å­˜: {file_path}")
            else:
                self.logger.error(f"ä¿å­˜ä¼˜åŒ–ç»“æœå¤±è´¥: {file_path}")
                
            # æ›´æ–°å†å²è®°å½•ï¼ˆå¸¦å¤§å°é™åˆ¶ï¼‰
            self.optimization_history.append(result)
            
            # æ¸…ç†è¿‡å¤šçš„å†å²è®°å½•
            if len(self.optimization_history) > self.max_history_size:
                # ä¿ç•™æœ€è¿‘çš„è®°å½•
                self.optimization_history = self.optimization_history[-self.max_history_size:]
                self.logger.debug(f"æ¸…ç†ä¼˜åŒ–å†å²è®°å½•ï¼Œä¿ç•™æœ€è¿‘ {self.max_history_size} æ¡")
            
            # æ›´æ–°æœ€ä½³å‚æ•°
            if result.get('success') and result.get('best_score', -np.inf) > self.best_score:
                self.best_params = result['best_params']
                self.best_score = result['best_score']
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜ä¼˜åŒ–ç»“æœå¼‚å¸¸: {e}")
    
    def get_optimization_history(self) -> List[Dict[str, Any]]:
        """è·å–ä¼˜åŒ–å†å²"""
        return self.optimization_history.copy()
    
    def get_best_parameters(self) -> Optional[Dict[str, Any]]:
        """è·å–æœ€ä½³å‚æ•°"""
        return self.best_params.copy() if self.best_params else None
    
    def get_parameter_ranges(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤å‚æ•°èŒƒå›´é…ç½®"""
        return self.optimization_config.get('parameter_ranges', {
            'rsi_oversold_threshold': {'min': 25, 'max': 35, 'step': 1},
            'rsi_low_threshold': {'min': 35, 'max': 45, 'step': 1},
            'confidence_threshold': {'min': 0.3, 'max': 0.7, 'step': 0.05},
            'dynamic_confidence_adjustment': {'min': 0.1, 'max': 0.5, 'step': 0.05},
            'market_sentiment_weight': {'min': 0.1, 'max': 0.3, 'step': 0.05},
            'trend_strength_weight': {'min': 0.1, 'max': 0.3, 'step': 0.05}
        })


# æ¨¡å—å¯¼å‡º
__all__ = ['ParameterOptimizer'] 