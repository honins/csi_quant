#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
AIä¼˜åŒ–å™¨æ¨¡å—
è´Ÿè´£ä½¿ç”¨AIæŠ€æœ¯ä¼˜åŒ–ç­–ç•¥å‚æ•°
"""

import logging
import os
import json
import pickle
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, Any, List, Tuple, Optional
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# å¯¼å…¥ç­–ç•¥æ¨¡å—
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'strategy'))
from strategy_module import StrategyModule


class AIOptimizer:
    """AIä¼˜åŒ–å™¨ç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–AIä¼˜åŒ–å™¨
        
        å‚æ•°:
        config: é…ç½®ä¿¡æ¯
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # è®¾ç½®æ¨¡å‹ç›®å½•
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        self.models_dir = os.path.join(project_root, 'models')
        
        # ç¡®ä¿æ¨¡å‹ç›®å½•å­˜åœ¨
        if not os.path.exists(self.models_dir):
            os.makedirs(self.models_dir)
            
        # è®¾ç½®å‚æ•°å†å²è®°å½•æ–‡ä»¶è·¯å¾„
        cache_dir = os.path.join(project_root, 'cache')
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
        self.parameter_history_file = os.path.join(cache_dir, 'parameter_history.json')
        self.best_parameters_file = os.path.join(cache_dir, 'best_parameters.json')
        
        # åˆå§‹åŒ–æ¨¡å‹ç›¸å…³å±æ€§
        self.model = None
        self.feature_names = None
        
        # ä»é…ç½®è·å–æ¨¡å‹ç±»å‹
        ai_config = config.get('ai', {})
        self.model_type = ai_config.get('model_type', 'machine_learning')
        
        self.logger.info("AIä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹ç±»å‹: %s", self.model_type)

    def strict_data_split(self, data: pd.DataFrame, preserve_test_set: bool = True) -> Dict[str, pd.DataFrame]:
        """
        ä¸¥æ ¼çš„æ•°æ®åˆ†å‰²ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
        
        å‚æ•°:
        data: è¾“å…¥æ•°æ®
        preserve_test_set: æ˜¯å¦ä¿æŠ¤æµ‹è¯•é›†
        
        è¿”å›:
        dict: åŒ…å«è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„å­—å…¸
        """
        self.logger.info("ğŸ”’ å¼€å§‹ä¸¥æ ¼æ•°æ®åˆ†å‰²...")
        
        try:
            # ä»é…ç½®è·å–åˆ†å‰²æ¯”ä¾‹
            ai_config = self.config.get('ai', {})
            validation_config = ai_config.get('validation', {})
            
            train_ratio = validation_config.get('train_ratio', 0.65)
            validation_ratio = validation_config.get('validation_ratio', 0.20)
            test_ratio = validation_config.get('test_ratio', 0.15)
            
            # ç¡®ä¿æ¯”ä¾‹å’Œä¸º1
            total_ratio = train_ratio + validation_ratio + test_ratio
            if abs(total_ratio - 1.0) > 0.001:
                self.logger.warning(f"åˆ†å‰²æ¯”ä¾‹æ€»å’Œä¸ä¸º1: {total_ratio:.3f}ï¼Œè¿›è¡Œå½’ä¸€åŒ–")
                train_ratio /= total_ratio
                validation_ratio /= total_ratio
                test_ratio /= total_ratio
            
            # è®¡ç®—åˆ†å‰²ç‚¹
            n = len(data)
            train_end = int(n * train_ratio)
            validation_end = int(n * (train_ratio + validation_ratio))
            
            # æ—¶é—´åºåˆ—åˆ†å‰²ï¼ˆä¿æŒæ—¶é—´é¡ºåºï¼‰
            train_data = data.iloc[:train_end].copy()
            validation_data = data.iloc[train_end:validation_end].copy()
            test_data = data.iloc[validation_end:].copy()
            
            # æ£€æµ‹æ•°æ®æ³„éœ²
            train_dates = set(pd.to_datetime(train_data['date']).dt.date)
            test_dates = set(pd.to_datetime(test_data['date']).dt.date)
            overlap = train_dates.intersection(test_dates)
            
            if overlap:
                self.logger.warning(f"âŒ æ£€æµ‹åˆ°æ•°æ®æ³„éœ²ï¼š{len(overlap)}ä¸ªé‡å¤æ—¥æœŸ")
                for date in list(overlap)[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    self.logger.warning(f"   é‡å¤æ—¥æœŸ: {date}")
            else:
                self.logger.info("âœ… æ•°æ®æ³„éœ²æ£€æµ‹é€šè¿‡ï¼Œæ— é‡å¤æ—¥æœŸ")
            
            self.logger.info("ğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ:")
            self.logger.info(f"   - è®­ç»ƒé›†: {len(train_data)} æ¡ ({len(train_data)/n:.1%})")
            self.logger.info(f"   - éªŒè¯é›†: {len(validation_data)} æ¡ ({len(validation_data)/n:.1%})")
            self.logger.info(f"   - æµ‹è¯•é›†: {len(test_data)} æ¡ ({len(test_data)/n:.1%})")
            
            return {
                'train': train_data,
                'validation': validation_data,
                'test': test_data
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ä¸¥æ ¼æ•°æ®åˆ†å‰²å¤±è´¥: {str(e)}")
            raise

    def walk_forward_validation(self, data: pd.DataFrame, strategy_module, 
                              window_size: int = 252, step_size: int = 63) -> Dict[str, Any]:
        """
        èµ°å‰éªŒè¯ï¼Œæ¨¡æ‹ŸçœŸå®äº¤æ˜“ç¯å¢ƒ
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—
        window_size: è®­ç»ƒçª—å£å¤§å°ï¼ˆäº¤æ˜“æ—¥æ•°ï¼‰
        step_size: æ­¥è¿›å¤§å°ï¼ˆäº¤æ˜“æ—¥æ•°ï¼‰
        
        è¿”å›:
        dict: éªŒè¯ç»“æœ
        """
        self.logger.info("ğŸš¶ å¼€å§‹èµ°å‰éªŒè¯...")
        
        try:
            scores = []
            windows = []
            
            # è®¡ç®—æ€»çª—å£æ•°
            total_windows = max(1, (len(data) - window_size) // step_size)
            self.logger.info(f"æ€»éªŒè¯çª—å£æ•°: {total_windows}")
            
            for i in range(total_windows):
                start_idx = i * step_size
                train_end_idx = start_idx + window_size
                test_start_idx = train_end_idx
                test_end_idx = min(test_start_idx + step_size, len(data))
                
                if test_end_idx <= test_start_idx:
                    continue
                
                # åˆ†å‰²æ•°æ®
                train_window = data.iloc[start_idx:train_end_idx].copy()
                test_window = data.iloc[test_start_idx:test_end_idx].copy()
                
                self.logger.info(f"çª—å£ {i+1}/{total_windows}: è®­ç»ƒ {len(train_window)} æ¡, æµ‹è¯• {len(test_window)} æ¡")
                
                # åœ¨è®­ç»ƒçª—å£ä¸Šä¼˜åŒ–å‚æ•°
                optimized_params = self.optimize_strategy_parameters_on_train_only(strategy_module, train_window)
                
                # æ›´æ–°ç­–ç•¥å‚æ•°
                temp_strategy = StrategyModule(self.config)
                temp_strategy.update_params(optimized_params)
                
                # åœ¨æµ‹è¯•çª—å£ä¸Šè¯„ä¼°
                test_results = temp_strategy.backtest(test_window)
                evaluation = temp_strategy.evaluate_strategy(test_results)
                
                score = evaluation['score']
                scores.append(score)
                windows.append({
                    'window': i + 1,
                    'train_start': train_window.iloc[0]['date'],
                    'train_end': train_window.iloc[-1]['date'],
                    'test_start': test_window.iloc[0]['date'],
                    'test_end': test_window.iloc[-1]['date'],
                    'score': score
                })
                
                self.logger.info(f"çª—å£ {i+1} å¾—åˆ†: {score:.4f}")
            
            if not scores:
                self.logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„éªŒè¯çª—å£")
                return {'success': False, 'error': 'æ²¡æœ‰æœ‰æ•ˆçš„éªŒè¯çª—å£'}
            
            avg_score = np.mean(scores)
            std_score = np.std(scores)
            
            self.logger.info("âœ… èµ°å‰éªŒè¯å®Œæˆ")
            self.logger.info(f"å¹³å‡å¾—åˆ†: {avg_score:.4f} Â± {std_score:.4f}")
            
            return {
                'success': True,
                'avg_score': avg_score,
                'std_score': std_score,
                'all_scores': scores,
                'windows': windows
            }
            
        except Exception as e:
            self.logger.error(f"âŒ èµ°å‰éªŒè¯å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}

    def optimize_strategy_parameters_on_train_only(self, strategy_module, train_data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä»…åœ¨è®­ç»ƒé›†ä¸Šä¼˜åŒ–ç­–ç•¥å‚æ•°
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—
        train_data: è®­ç»ƒæ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–åçš„å‚æ•°
        """
        self.logger.info("ğŸ¯ å¼€å§‹è®­ç»ƒé›†ç­–ç•¥å‚æ•°ä¼˜åŒ–...")
        
        try:
            # å›ºå®šæ ¸å¿ƒå‚æ•°
            fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
            fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
            
            # è·å–åŸºå‡†ç­–ç•¥è¯†åˆ«ç»“æœ
            baseline_backtest = strategy_module.backtest(train_data)
            fixed_labels = baseline_backtest['is_low_point'].astype(int).values
            
            # å‚æ•°æœç´¢èŒƒå›´
            param_ranges = {
                'rsi_oversold_threshold': np.arange(25, 36, 1),
                'rsi_low_threshold': np.arange(35, 46, 1),
                'final_threshold': np.arange(0.3, 0.71, 0.05)
            }
            
            best_score = -1
            best_params = None
            
            # ç®€åŒ–æœç´¢ï¼ˆä»…é’ˆå¯¹è®­ç»ƒé›†ï¼‰
            max_iterations = 50
            
            for i in range(max_iterations):
                params = {
                    'rise_threshold': fixed_rise_threshold,
                    'max_days': fixed_max_days,
                    'rsi_oversold_threshold': int(np.random.choice(param_ranges['rsi_oversold_threshold'])),
                    'rsi_low_threshold': int(np.random.choice(param_ranges['rsi_low_threshold'])),
                    'final_threshold': np.random.choice(param_ranges['final_threshold'])
                }
                
                score = self._evaluate_params_with_fixed_labels(
                    train_data, fixed_labels, 
                    params['rise_threshold'], params['max_days']
                )
                
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
            
            self.logger.info(f"âœ… è®­ç»ƒé›†ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³å¾—åˆ†: {best_score:.4f}")
            
            return best_params if best_params else {
                'rise_threshold': fixed_rise_threshold,
                'max_days': fixed_max_days,
                'rsi_oversold_threshold': 30,
                'rsi_low_threshold': 40,
                'final_threshold': 0.5
            }
            
        except Exception as e:
            self.logger.error(f"âŒ è®­ç»ƒé›†ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04),
                'max_days': self.config.get('strategy', {}).get('max_days', 20),
                'rsi_oversold_threshold': 30,
                'rsi_low_threshold': 40,
                'final_threshold': 0.5
            }

    def _evaluate_params_with_fixed_labels(self, data: pd.DataFrame, fixed_labels: np.ndarray, 
                                         rise_threshold: float, max_days: int) -> float:
        """
        ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°ç­–ç•¥å‚æ•°
        
        å‚æ•°:
        data: å†å²æ•°æ®
        fixed_labels: å›ºå®šçš„æ ‡ç­¾ï¼ˆç›¸å¯¹ä½ç‚¹æ ‡è¯†ï¼‰
        rise_threshold: æ¶¨å¹…é˜ˆå€¼
        max_days: æœ€å¤§å¤©æ•°
        
        è¿”å›:
        float: ç­–ç•¥å¾—åˆ†
        """
        try:
            scores = []
            low_point_indices = np.where(fixed_labels == 1)[0]
            
            for idx in low_point_indices:
                if idx >= len(data) - max_days:
                    continue
                    
                current_price = data.iloc[idx]['close']
                max_rise = 0.0
                days_to_rise = 0
                
                # è®¡ç®—æœªæ¥max_dayså†…çš„æœ€å¤§æ¶¨å¹…
                for j in range(1, max_days + 1):
                    if idx + j >= len(data):
                        break
                    future_price = data.iloc[idx + j]['close']
                    rise_rate = (future_price - current_price) / current_price
                    
                    if rise_rate > max_rise:
                        max_rise = rise_rate
                        
                    if rise_rate >= rise_threshold and days_to_rise == 0:
                        days_to_rise = j
                
                # è®¡ç®—å•ä¸ªç‚¹çš„å¾—åˆ†
                success = max_rise >= rise_threshold
                point_score = self._calculate_point_score(success, max_rise, days_to_rise, max_days)
                scores.append(point_score)
            
            return np.mean(scores) if scores else 0.0
            
        except Exception as e:
            self.logger.error("è¯„ä¼°å‚æ•°å¤±è´¥: %s", str(e))
            return 0.0

    def _calculate_point_score(self, success: bool, max_rise: float, days_to_rise: int, max_days: int) -> float:
        """
        è®¡ç®—å•ä¸ªè¯†åˆ«ç‚¹çš„å¾—åˆ†
        
        å‚æ•°:
        success: æ˜¯å¦æˆåŠŸè¾¾åˆ°ç›®æ ‡æ¶¨å¹…
        max_rise: æœ€å¤§æ¶¨å¹…
        days_to_rise: è¾¾åˆ°ç›®æ ‡æ¶¨å¹…çš„å¤©æ•°
        max_days: æœ€å¤§è§‚å¯Ÿå¤©æ•°
        
        è¿”å›:
        float: å•ä¸ªç‚¹å¾—åˆ†
        """
        # æˆåŠŸç‡æƒé‡ï¼š60%
        success_score = 1.0 if success else 0.0
        
        # æ¶¨å¹…æƒé‡ï¼š30%
        rise_score = min(max_rise / 0.1, 1.0)  # ä»¥10%ä¸ºåŸºå‡†
        
        # é€Ÿåº¦æƒé‡ï¼š10%
        if days_to_rise > 0:
            speed_score = min(max_days / days_to_rise, 1.0)
        else:
            speed_score = 0.0
        
        total_score = success_score * 0.6 + rise_score * 0.3 + speed_score * 0.1
        return total_score

    def evaluate_on_test_set_only(self, strategy_module, test_data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä»…åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ç­–ç•¥
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—
        test_data: æµ‹è¯•æ•°æ®
        
        è¿”å›:
        dict: è¯„ä¼°ç»“æœ
        """
        self.logger.info("ğŸ¯ å¼€å§‹æµ‹è¯•é›†è¯„ä¼°...")
        
        try:
            # åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œå›æµ‹
            test_backtest = strategy_module.backtest(test_data)
            test_evaluation = strategy_module.evaluate_strategy(test_backtest)
            
            test_score = test_evaluation['score']
            
            self.logger.info(f"âœ… æµ‹è¯•é›†è¯„ä¼°å®Œæˆ")
            self.logger.info(f"   - æµ‹è¯•é›†å¾—åˆ†: {test_score:.4f}")
            self.logger.info(f"   - è¯†åˆ«ç‚¹æ•°: {test_evaluation.get('total_points', 0)}")
            self.logger.info(f"   - æˆåŠŸç‡: {test_evaluation.get('success_rate', 0):.2%}")
            
            return {
                'success': True,
                'test_score': test_score,
                'test_evaluation': test_evaluation,
                'test_size': len(test_data)
            }
            
        except Exception as e:
            self.logger.error(f"âŒ æµ‹è¯•é›†è¯„ä¼°å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}

    def train_model(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        åªè´Ÿè´£è®­ç»ƒæ¨¡å‹å¹¶ä¿å­˜ï¼Œä¸åšè¯„ä¼°ã€‚
        """
        self.logger.info("å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼ˆä¸åšéªŒè¯è¯„ä¼°ï¼‰")
        try:
            features, feature_names = self.prepare_features(data)
            labels = self.prepare_labels(data, strategy_module)
            if len(features) == 0 or len(labels) == 0:
                self.logger.error("ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
                return {'success': False, 'error': 'ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©º'}
            min_length = min(len(features), len(labels))
            features = features[:min_length]
            labels = labels[:min_length]
            aligned_data = data.iloc[:min_length].copy()
            split_ratio = self.config.get("ai", {}).get("train_test_split_ratio", 0.8)
            split_index = int(len(features) * split_ratio)
            X_train = features[:split_index]
            y_train = labels[:split_index]
            train_dates = aligned_data["date"].iloc[:split_index]
            sample_weights = self._calculate_sample_weights(train_dates)
            if self.model_type == 'machine_learning':
                model = Pipeline([
                    ('scaler', StandardScaler()),
                    ('classifier', RandomForestClassifier(
                        n_estimators=100,
                        max_depth=10,
                        min_samples_split=5,
                        min_samples_leaf=2,
                        random_state=42,
                        class_weight='balanced'
                    ))
                ])
            else:
                model = Pipeline([
                    ('scaler', StandardScaler()),
                    ('classifier', RandomForestClassifier(
                        n_estimators=100,
                        random_state=42,
                        class_weight='balanced'
                    ))
                ])
            self.logger.info(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, sample_weights shape: {sample_weights.shape}")
            model.fit(X_train, y_train, classifier__sample_weight=sample_weights)
            self.model = model
            self.feature_names = feature_names
            self._save_model()
            self.logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")
            return {'success': True, 'train_samples': len(X_train), 'feature_count': len(feature_names)}
        except Exception as e:
            self.logger.error("è®­ç»ƒæ¨¡å‹å¤±è´¥: %s", str(e))
            return {'success': False, 'error': str(e)}

    def validate_model(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        åªè´Ÿè´£è¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°ã€‚
        """
        self.logger.info("å¼€å§‹éªŒè¯æ¨¡å‹ï¼ˆåªåšè¯„ä¼°ï¼Œä¸è®­ç»ƒï¼‰")
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    return {'success': False, 'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'}
            features, feature_names = self.prepare_features(data)
            labels = self.prepare_labels(data, strategy_module)
            if len(features) == 0 or len(labels) == 0:
                self.logger.error("ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œæ— æ³•éªŒè¯æ¨¡å‹")
                return {'success': False, 'error': 'ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©º'}
            min_length = min(len(features), len(labels))
            features = features[:min_length]
            labels = labels[:min_length]
            split_ratio = self.config.get("ai", {}).get("train_test_split_ratio", 0.8)
            split_index = int(len(features) * split_ratio)
            X_test = features[split_index:]
            y_test = labels[split_index:]
            if len(X_test) == 0 or len(y_test) == 0:
                self.logger.warning("éªŒè¯é›†ä¸ºç©ºï¼Œæ— æ³•è¯„ä¼°æ¨¡å‹")
                return {'success': False, 'error': 'éªŒè¯é›†ä¸ºç©º'}
            y_pred = self.model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, zero_division=0)
            recall = recall_score(y_test, y_pred, zero_division=0)
            f1 = f1_score(y_test, y_pred, zero_division=0)
            positive_count_test = np.sum(y_test)
            self.logger.info("æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°å®Œæˆï¼Œå‡†ç¡®ç‡: %.4f, ç²¾ç¡®ç‡: %.4f, å¬å›ç‡: %.4f, F1: %.4f", accuracy, precision, recall, f1)
            return {
                'success': True,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'test_samples': len(X_test),
                'positive_samples_test': positive_count_test
            }
        except Exception as e:
            self.logger.error("éªŒè¯æ¨¡å‹å¤±è´¥: %s", str(e))
            return {'success': False, 'error': str(e)}

    def predict_low_point(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        é¢„æµ‹ç›¸å¯¹ä½ç‚¹
        
        å‚æ•°:
        data: å¸‚åœºæ•°æ®
        
        è¿”å›:
        dict: é¢„æµ‹ç»“æœ
        """
        self.logger.info("é¢„æµ‹ç›¸å¯¹ä½ç‚¹")
        
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    return {
                        'is_low_point': False,
                        'confidence': 0.0,
                        'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'
                    }
                    
            if len(data) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'error': 'æ•°æ®ä¸ºç©º'
                }
                
            # å‡†å¤‡ç‰¹å¾
            features, _ = self.prepare_features(data)
            
            if len(features) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'error': 'æ— æ³•æå–ç‰¹å¾'
                }
                
            # ä½¿ç”¨æœ€æ–°æ•°æ®è¿›è¡Œé¢„æµ‹
            latest_features = features[-1:].reshape(1, -1)
            
            # é¢„æµ‹
            prediction = self.model.predict(latest_features)[0]
            prediction_proba = self.model.predict_proba(latest_features)[0]
            
            # è·å–ç½®ä¿¡åº¦
            confidence = prediction_proba[1] if len(prediction_proba) > 1 else 0.0
            
            result = {
                'is_low_point': bool(prediction),
                'confidence': float(confidence),
                'prediction_proba': prediction_proba.tolist()
            }
            
            self.logger.info("----------------------------------------------------");
            self.logger.info("AIé¢„æµ‹ç»“æœ: \033[1m%s\033[0m, ç½®ä¿¡åº¦: \033[1m%.4f\033[0m", 
                           "ç›¸å¯¹ä½ç‚¹" if prediction else "éç›¸å¯¹ä½ç‚¹", confidence)
            self.logger.info("----------------------------------------------------");
            return result
            
        except Exception as e:
            self.logger.error("é¢„æµ‹ç›¸å¯¹ä½ç‚¹å¤±è´¥: %s", str(e))
            return {
                'is_low_point': False,
                'confidence': 0.0,
                'error': str(e)
            }

    def prepare_features(self, data: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        å‡†å¤‡æœºå™¨å­¦ä¹ ç‰¹å¾
        
        å‚æ•°:
        data: å†å²æ•°æ®
        
        è¿”å›:
        tuple: (ç‰¹å¾çŸ©é˜µ, ç‰¹å¾åç§°åˆ—è¡¨)
        """
        self.logger.info("å‡†å¤‡æœºå™¨å­¦ä¹ ç‰¹å¾")
        
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_columns = [
            'ma5', 'ma10', 'ma20', 'ma60',
            'rsi', 'macd', 'signal', 'hist',
            'bb_upper', 'bb_lower',
            'dist_ma5', 'dist_ma10', 'dist_ma20',
            'volume_change', 'volatility',
            'price_change', 'price_change_5d', 'price_change_10d'
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„åˆ—
        available_columns = [col for col in feature_columns if col in data.columns]
        
        if len(available_columns) == 0:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾åˆ—")
            return np.array([]), []
            
        # æå–ç‰¹å¾
        features = data[available_columns].fillna(0).values
        
        self.logger.info("ç‰¹å¾å‡†å¤‡å®Œæˆï¼Œç‰¹å¾æ•°é‡: %d, æ ·æœ¬æ•°é‡: %d", 
                        len(available_columns), len(features))
        
        return features, available_columns
        
    def prepare_labels(self, data: pd.DataFrame, strategy_module) -> np.ndarray:
        """
        å‡†å¤‡æœºå™¨å­¦ä¹ æ ‡ç­¾
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        
        è¿”å›:
        numpy.ndarray: æ ‡ç­¾æ•°ç»„
        """
        self.logger.info("å‡†å¤‡æœºå™¨å­¦ä¹ æ ‡ç­¾")
        
        # è¿è¡Œå›æµ‹è·å–çœŸå®çš„ç›¸å¯¹ä½ç‚¹æ ‡ç­¾
        backtest_results = strategy_module.backtest(data)
        labels = backtest_results['is_low_point'].astype(int).values
        
        positive_count = np.sum(labels)
        total_count = len(labels)
        
        self.logger.info("æ ‡ç­¾å‡†å¤‡å®Œæˆï¼Œæ­£æ ·æœ¬: %d, æ€»æ ·æœ¬: %d, æ­£æ ·æœ¬æ¯”ä¾‹: %.2f%%", 
                        positive_count, total_count, positive_count / total_count * 100)
        
        return labels

    def _save_model(self) -> bool:
        """
        ä¿å­˜æ¨¡å‹
        
        è¿”å›:
        bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ä¿å­˜æ¨¡å‹
            model_path = os.path.join(self.models_dir, f'model_{timestamp}.pkl')
            with open(model_path, 'wb') as f:
                pickle.dump(self.model, f)
                
            # ä¿å­˜ç‰¹å¾åç§°
            features_path = os.path.join(self.models_dir, f'features_{timestamp}.json')
            with open(features_path, 'w') as f:
                json.dump(self.feature_names, f)
                
            # ä¿å­˜æœ€æ–°æ¨¡å‹çš„è·¯å¾„
            latest_path = os.path.join(self.models_dir, 'latest_model.txt')
            with open(latest_path, 'w') as f:
                f.write(f'{model_path}\n{features_path}')
                
            self.logger.info("æ¨¡å‹ä¿å­˜æˆåŠŸ: %s", model_path)
            return True
            
        except Exception as e:
            self.logger.error("ä¿å­˜æ¨¡å‹å¤±è´¥: %s", str(e))
            return False

    def _load_model(self) -> bool:
        """
        åŠ è½½æ¨¡å‹
        
        è¿”å›:
        bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            latest_path = os.path.join(self.models_dir, 'latest_model.txt')
            
            if not os.path.exists(latest_path):
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„æ¨¡å‹")
                return False
                
            # è¯»å–æœ€æ–°æ¨¡å‹è·¯å¾„
            with open(latest_path, 'r') as f:
                lines = f.read().strip().split('\n')
                if len(lines) < 2:
                    self.logger.error("æ¨¡å‹è·¯å¾„æ–‡ä»¶æ ¼å¼é”™è¯¯")
                    return False
                    
                model_path = lines[0]
                features_path = lines[1]
                
            # åŠ è½½æ¨¡å‹
            with open(model_path, 'rb') as f:
                self.model = pickle.load(f)
                
            # åŠ è½½ç‰¹å¾åç§°
            with open(features_path, 'r') as f:
                self.feature_names = json.load(f)
                
            self.logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ: %s", model_path)
            return True
            
        except Exception as e:
            self.logger.error("åŠ è½½æ¨¡å‹å¤±è´¥: %s", str(e))
            return False

    def _calculate_sample_weights(self, dates: pd.Series) -> np.ndarray:
        """
        æ ¹æ®æ•°æ®æ—¥æœŸè®¡ç®—æ ·æœ¬æƒé‡ï¼Œè¶Šè¿‘çš„æ•°æ®æƒé‡è¶Šé«˜ã€‚
        æƒé‡è¡°å‡æ¨¡å‹ï¼šV(t) = Vâ‚€ Ã— e^(-Î»t)
        å…¶ä¸­Î»æ˜¯è¡°å‡ç³»æ•°ï¼Œæ ¹æ®åˆ†ææŠ¥å‘Šï¼ŒÎ»çº¦ä¸º0.3-0.5ã€‚
        è¿™é‡Œæˆ‘ä»¬å–Î»=0.4ï¼Œå¹¶æ ¹æ®æ—¶é—´å·®è®¡ç®—æƒé‡ã€‚
        
        å‚æ•°:
        dates: è®­ç»ƒé›†æ•°æ®çš„æ—¥æœŸåºåˆ—
        
        è¿”å›:
        numpy.ndarray: æ ·æœ¬æƒé‡æ•°ç»„
        """
        self.logger.info("è®¡ç®—æ ·æœ¬æƒé‡")
        
        weights = np.ones(len(dates))
        if len(dates) == 0: # Handle empty dates series
            return weights

        latest_date = dates.max()
        
        for i, date in enumerate(dates):
            time_diff = (latest_date - date).days / 365.25  # å¹´ä¸ºå•ä½
            # è¡°å‡ç³»æ•°Î»ï¼Œå¯ä»¥æ ¹æ®configé…ç½®
            decay_rate = self.config.get("ai", {}).get("data_decay_rate", 0.4)
            weight = np.exp(-decay_rate * time_diff)
            weights[i] = weight
            
        # å½’ä¸€åŒ–æƒé‡ï¼Œä½¿å…¶å’Œä¸º1ï¼Œæˆ–è€…ä¿æŒåŸå§‹æ¯”ä¾‹
        # è¿™é‡Œé€‰æ‹©ä¿æŒåŸå§‹æ¯”ä¾‹ï¼Œå› ä¸ºRandomForestClassifierçš„sample_weightå‚æ•°æ˜¯ä¹˜æ³•å…³ç³»
        # ä¹Ÿå¯ä»¥é€‰æ‹©å½’ä¸€åŒ–åˆ°æŸä¸ªèŒƒå›´ï¼Œä¾‹å¦‚0-1
        
        self.logger.info("æ ·æœ¬æƒé‡è®¡ç®—å®Œæˆï¼Œæœ€å¤§æƒé‡: %.4f, æœ€å°æƒé‡: %.4f", 
                        np.max(weights), np.min(weights))
        
        return weights


class EarlyStopping:
    """æ—©åœæœºåˆ¶ç±»"""
    
    def __init__(self, patience: int = 20, min_delta: float = 0.001):
        """
        åˆå§‹åŒ–æ—©åœæœºåˆ¶
        
        å‚æ•°:
        patience: è€å¿ƒå€¼ï¼Œè¿ç»­å¤šå°‘æ¬¡æ— æ”¹è¿›ååœæ­¢
        min_delta: æœ€å°æ”¹è¿›å¹…åº¦
        """
        self.patience = patience
        self.min_delta = min_delta
        self.best_score = -np.inf
        self.wait = 0
        
    def __call__(self, val_score: float) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ
        
        å‚æ•°:
        val_score: å½“å‰éªŒè¯å¾—åˆ†
        
        è¿”å›:
        bool: æ˜¯å¦åº”è¯¥åœæ­¢
        """
        if val_score > self.best_score + self.min_delta:
            self.best_score = val_score
            self.wait = 0
            return False
        else:
            self.wait += 1
            return self.wait >= self.patience 