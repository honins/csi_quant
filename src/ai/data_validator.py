#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ•°æ®éªŒè¯å’Œåˆ†å‰²æ¨¡å—
è´Ÿè´£æ•°æ®çš„ä¸¥æ ¼åˆ†å‰²ã€èµ°å‰éªŒè¯ç­‰åŠŸèƒ½
"""

import logging
import numpy as np
import pandas as pd
from typing import Dict, Any


class DataValidator:
    """æ•°æ®éªŒè¯å’Œåˆ†å‰²ç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ•°æ®éªŒè¯å™¨
        
        å‚æ•°:
        config: é…ç½®ä¿¡æ¯
        """
        self.config = config
        self.logger = logging.getLogger(__name__)

    def strict_data_split(self, data: pd.DataFrame, preserve_test_set: bool = True) -> Dict[str, pd.DataFrame]:
        """
        ä¸¥æ ¼çš„æ•°æ®åˆ†å‰²ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
        
        å‚æ•°:
        data: è¾“å…¥æ•°æ®
        preserve_test_set: æ˜¯å¦ä¿æŠ¤æµ‹è¯•é›†
        
        è¿”å›:
        dict: åŒ…å«è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„å­—å…¸
        """
        self.logger.info("ğŸ”’ å¼€å§‹ä¸¥æ ¼æ•°æ®åˆ†å‰²...")
        
        try:
            # ä»é…ç½®è·å–åˆ†å‰²æ¯”ä¾‹
            ai_config = self.config.get('ai', {})
            validation_config = ai_config.get('validation', {})
            
            train_ratio = validation_config.get('train_ratio', 0.65)
            validation_ratio = validation_config.get('validation_ratio', 0.20)
            test_ratio = validation_config.get('test_ratio', 0.15)
            
            # ç¡®ä¿æ¯”ä¾‹å’Œä¸º1
            total_ratio = train_ratio + validation_ratio + test_ratio
            if abs(total_ratio - 1.0) > 0.001:
                self.logger.warning(f"åˆ†å‰²æ¯”ä¾‹æ€»å’Œä¸ä¸º1: {total_ratio:.3f}ï¼Œè¿›è¡Œå½’ä¸€åŒ–")
                train_ratio /= total_ratio
                validation_ratio /= total_ratio
                test_ratio /= total_ratio
            
            # è®¡ç®—åˆ†å‰²ç‚¹
            n = len(data)
            train_end = int(n * train_ratio)
            validation_end = int(n * (train_ratio + validation_ratio))
            
            # æ—¶é—´åºåˆ—åˆ†å‰²ï¼ˆä¿æŒæ—¶é—´é¡ºåºï¼‰
            train_data = data.iloc[:train_end].copy()
            validation_data = data.iloc[train_end:validation_end].copy()
            test_data = data.iloc[validation_end:].copy()
            
            # æ£€æµ‹æ•°æ®æ³„éœ²
            train_dates = set(pd.to_datetime(train_data['date']).dt.date)
            test_dates = set(pd.to_datetime(test_data['date']).dt.date)
            overlap = train_dates.intersection(test_dates)
            
            if overlap:
                self.logger.warning(f"âŒ æ£€æµ‹åˆ°æ•°æ®æ³„éœ²ï¼š{len(overlap)}ä¸ªé‡å¤æ—¥æœŸ")
                for date in list(overlap)[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    self.logger.warning(f"   é‡å¤æ—¥æœŸ: {date}")
            else:
                self.logger.info("âœ… æ•°æ®æ³„éœ²æ£€æµ‹é€šè¿‡ï¼Œæ— é‡å¤æ—¥æœŸ")
            
            self.logger.info("ğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ:")
            self.logger.info(f"   - è®­ç»ƒé›†: {len(train_data)} æ¡ ({len(train_data)/n:.1%})")
            self.logger.info(f"   - éªŒè¯é›†: {len(validation_data)} æ¡ ({len(validation_data)/n:.1%})")
            self.logger.info(f"   - æµ‹è¯•é›†: {len(test_data)} æ¡ ({len(test_data)/n:.1%})")
            
            return {
                'train': train_data,
                'validation': validation_data,
                'test': test_data
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ä¸¥æ ¼æ•°æ®åˆ†å‰²å¤±è´¥: {str(e)}")
            raise

    def walk_forward_validation(self, data: pd.DataFrame, strategy_module, 
                              window_size: int = 252, step_size: int = 63) -> Dict[str, Any]:
        """
        èµ°å‰éªŒè¯ï¼Œæ¨¡æ‹ŸçœŸå®äº¤æ˜“ç¯å¢ƒ
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—
        window_size: è®­ç»ƒçª—å£å¤§å°ï¼ˆäº¤æ˜“æ—¥æ•°ï¼‰
        step_size: æ­¥è¿›å¤§å°ï¼ˆäº¤æ˜“æ—¥æ•°ï¼‰
        
        è¿”å›:
        dict: éªŒè¯ç»“æœ
        """
        self.logger.info("ğŸš¶ å¼€å§‹èµ°å‰éªŒè¯...")
        
        try:
            scores = []
            windows = []
            
            # è®¡ç®—æ€»çª—å£æ•°
            total_windows = max(1, (len(data) - window_size) // step_size)
            self.logger.info(f"æ€»éªŒè¯çª—å£æ•°: {total_windows}")
            
            for i in range(total_windows):
                start_idx = i * step_size
                train_end_idx = start_idx + window_size
                test_start_idx = train_end_idx
                test_end_idx = min(test_start_idx + step_size, len(data))
                
                if test_end_idx <= test_start_idx:
                    continue
                
                # åˆ†å‰²æ•°æ®
                train_window = data.iloc[start_idx:train_end_idx].copy()
                test_window = data.iloc[test_start_idx:test_end_idx].copy()
                
                self.logger.info(f"çª—å£ {i+1}/{total_windows}: è®­ç»ƒ {len(train_window)} æ¡, æµ‹è¯• {len(test_window)} æ¡")
                
                # åœ¨è®­ç»ƒçª—å£ä¸Šä¼˜åŒ–å‚æ•°ï¼ˆè¿™é‡Œéœ€è¦ä¼ å…¥ä¼˜åŒ–å™¨ï¼‰
                # åœ¨æµ‹è¯•çª—å£ä¸Šè¯„ä¼°
                temp_strategy = strategy_module.__class__(self.config)
                
                # åœ¨æµ‹è¯•çª—å£ä¸Šè¯„ä¼°
                test_results = temp_strategy.backtest(test_window)
                evaluation = temp_strategy.evaluate_strategy(test_results)
                
                score = evaluation['score']
                scores.append(score)
                windows.append({
                    'window': i + 1,
                    'train_start': train_window.iloc[0]['date'],
                    'train_end': train_window.iloc[-1]['date'],
                    'test_start': test_window.iloc[0]['date'],
                    'test_end': test_window.iloc[-1]['date'],
                    'score': score
                })
                
                self.logger.info(f"çª—å£ {i+1} å¾—åˆ†: {score:.4f}")
            
            if not scores:
                self.logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„éªŒè¯çª—å£")
                return {'success': False, 'error': 'æ²¡æœ‰æœ‰æ•ˆçš„éªŒè¯çª—å£'}
            
            avg_score = np.mean(scores)
            std_score = np.std(scores)
            
            self.logger.info("âœ… èµ°å‰éªŒè¯å®Œæˆ")
            self.logger.info(f"å¹³å‡å¾—åˆ†: {avg_score:.4f} Â± {std_score:.4f}")
            
            return {
                'success': True,
                'avg_score': avg_score,
                'std_score': std_score,
                'all_scores': scores,
                'windows': windows
            }
            
        except Exception as e:
            self.logger.error(f"âŒ èµ°å‰éªŒè¯å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)} 