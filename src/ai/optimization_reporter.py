#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
AIä¼˜åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
æ¯æ¬¡ä¼˜åŒ–å®Œæˆåè‡ªåŠ¨ç”Ÿæˆè¯¦ç»†çš„æŠ¥å‘Šæ–‡ä»¶
"""

import os
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional
import matplotlib.pyplot as plt

import pandas as pd
import numpy as np

class OptimizationReporter:
    """ä¼˜åŒ–æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.project_root = Path(__file__).parent.parent.parent
        self.reports_dir = self.project_root / "results" / "optimization_reports"
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        
    def generate_report(self, optimization_result: Dict[str, Any], 
                       model_info: Dict[str, Any] = None,
                       overfitting_detection: Dict[str, Any] = None) -> str:
        """
        ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
        
        å‚æ•°:
        optimization_result: ä¼˜åŒ–ç»“æœ
        model_info: æ¨¡å‹ä¿¡æ¯
        overfitting_detection: è¿‡æ‹Ÿåˆæ£€æµ‹ç»“æœ
        
        è¿”å›:
        str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = f"optimization_report_{timestamp}.md"
        report_path = self.reports_dir / report_filename
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = self._generate_report_content(
            optimization_result, model_info, overfitting_detection, timestamp
        )
        
        # ä¿å­˜æŠ¥å‘Š
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        # ç”ŸæˆJSONæ ¼å¼çš„æ•°æ®æ–‡ä»¶
        self._save_json_data(optimization_result, model_info, overfitting_detection, timestamp)
        
        # ç”Ÿæˆå›¾è¡¨
        self._generate_charts(optimization_result, timestamp)
        
        self.logger.info(f"âœ… ä¼˜åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return str(report_path)
    
    def _generate_report_content(self, optimization_result: Dict[str, Any], 
                               model_info: Dict[str, Any],
                               overfitting_detection: Dict[str, Any],
                               timestamp: str) -> str:
        """ç”ŸæˆæŠ¥å‘Šå†…å®¹"""
        
        report = f"""# AIä¼˜åŒ–æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**æŠ¥å‘Šç¼–å·**: {timestamp}

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

### ä¼˜åŒ–çŠ¶æ€
- **ä¼˜åŒ–æ–¹æ³•**: {optimization_result.get('method', 'N/A')}
- **æ‰§è¡ŒçŠ¶æ€**: {'âœ… æˆåŠŸ' if optimization_result.get('success', False) else 'âŒ å¤±è´¥'}
- **æ€»è€—æ—¶**: {optimization_result.get('total_time', 0):.2f} ç§’
- **ä¼˜åŒ–è½®æ¬¡**: {optimization_result.get('iterations', 'N/A')}

### å…³é”®æŒ‡æ ‡
- **æœ€ç»ˆå¾—åˆ†**: {optimization_result.get('best_score', 0):.4f}
- **å‡†ç¡®ç‡**: {optimization_result.get('accuracy', 0) * 100:.2f}%
- **æˆåŠŸç‡**: {optimization_result.get('success_rate', 0) * 100:.2f}%
- **å¹³å‡æ”¶ç›Š**: {optimization_result.get('avg_return', optimization_result.get('avg_rise', 0)) * 100:.2f}%
- **æ€»åˆ©æ¶¦**: {optimization_result.get('total_profit', 0):.4f}

---

## ğŸ¯ ä¼˜åŒ–ç»“æœè¯¦æƒ…

### æœ€ä¼˜å‚æ•°
"""
        
        # æ·»åŠ æœ€ä¼˜å‚æ•°
        best_params = optimization_result.get('best_params', {})
        if best_params:
            report += "```yaml\n"
            for key, value in best_params.items():
                if isinstance(value, float):
                    report += f"{key}: {value:.4f}\n"
                else:
                    report += f"{key}: {value}\n"
            report += "```\n\n"
        
        # æ·»åŠ æ¨¡å‹ä¿¡æ¯
        if model_info:
            report += f"""### æ¨¡å‹é…ç½®
- **æ¨¡å‹ç±»å‹**: {model_info.get('model_type', 'RandomForest')}
- **ç‰¹å¾æ•°é‡**: {model_info.get('feature_count', 'N/A')}
- **è®­ç»ƒæ ·æœ¬**: {model_info.get('train_samples', 'N/A')}
- **æ­£æ ·æœ¬æ¯”ä¾‹**: {model_info.get('positive_ratio', 0) * 100:.2f}%

### æ¨¡å‹å‚æ•°
- **å†³ç­–æ ‘æ•°é‡**: {model_info.get('n_estimators', 'N/A')}
- **æœ€å¤§æ·±åº¦**: {model_info.get('max_depth', 'N/A')}
- **æœ€å°åˆ†å‰²æ ·æœ¬**: {model_info.get('min_samples_split', 'N/A')}
- **æœ€å°å¶å­æ ·æœ¬**: {model_info.get('min_samples_leaf', 'N/A')}

"""
        
        # æ·»åŠ è¿‡æ‹Ÿåˆæ£€æµ‹ç»“æœ
        if overfitting_detection:
            report += f"""---

## ğŸ” è¿‡æ‹Ÿåˆæ£€æµ‹

### æ£€æµ‹ç»“æœ
- **è¿‡æ‹ŸåˆçŠ¶æ€**: {'ğŸš¨ æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆ' if overfitting_detection.get('overfitting_detected', False) else 'âœ… æœªæ£€æµ‹åˆ°è¿‡æ‹Ÿåˆ'}

### å…³é”®æŒ‡æ ‡
"""
            metrics = overfitting_detection.get('metrics', {})
            for key, value in metrics.items():
                if isinstance(value, float):
                    report += f"- **{key}**: {value:.4f}\n"
                else:
                    report += f"- **{key}**: {value}\n"
            
            # æ·»åŠ è­¦å‘Šå’Œå»ºè®®
            warnings = overfitting_detection.get('warnings', [])
            if warnings:
                report += "\n### âš ï¸ è­¦å‘Š\n"
                for warning in warnings:
                    report += f"- {warning}\n"
            
            recommendations = overfitting_detection.get('recommendations', [])
            if recommendations:
                report += "\n### ğŸ’¡ å»ºè®®\n"
                for rec in recommendations:
                    report += f"- {rec}\n"
        
        # æ·»åŠ é…ç½®ä¿¡æ¯
        report += f"""

---

## âš™ï¸ é…ç½®ä¿¡æ¯

### æ•°æ®åˆ†å‰²
- **è®­ç»ƒé›†æ¯”ä¾‹**: {self.config.get('ai', {}).get('validation', {}).get('train_ratio', 0.6) * 100:.0f}%
- **éªŒè¯é›†æ¯”ä¾‹**: {self.config.get('ai', {}).get('validation', {}).get('validation_ratio', 0.25) * 100:.0f}%
- **æµ‹è¯•é›†æ¯”ä¾‹**: {self.config.get('ai', {}).get('validation', {}).get('test_ratio', 0.15) * 100:.0f}%

### æ—©åœé…ç½®
- **è€å¿ƒå€¼**: {self.config.get('ai', {}).get('early_stopping', {}).get('patience', 20)}
- **æœ€å°æ”¹å–„**: {self.config.get('ai', {}).get('early_stopping', {}).get('min_delta', 0.005)}

### ç­–ç•¥å‚æ•°
- **æ¶¨å¹…é˜ˆå€¼**: {self.config.get('strategy', {}).get('rise_threshold', 0.04) * 100:.1f}%
- **æœ€å¤§å¤©æ•°**: {self.config.get('strategy_params', {}).get('max_days', 20)}

---

## ğŸ“Š æ€§èƒ½åˆ†æ

### è®­ç»ƒæ•ˆç‡
"""
        
        # æ·»åŠ è®­ç»ƒæ—¶é—´åˆ†æ
        if 'training_time_breakdown' in optimization_result:
            breakdown = optimization_result['training_time_breakdown']
            total_time = sum(breakdown.values())
            for phase, time_spent in breakdown.items():
                percentage = (time_spent / total_time) * 100 if total_time > 0 else 0
                report += f"- **{phase}**: {time_spent:.2f}s ({percentage:.1f}%)\n"
        
        # æ·»åŠ å†å²å¯¹æ¯”
        report += """

### å†å²å¯¹æ¯”
*æ³¨: ä¸ä¹‹å‰çš„ä¼˜åŒ–ç»“æœå¯¹æ¯”ï¼Œéœ€è¦ç§¯ç´¯æ›´å¤šå†å²æ•°æ®*

---

## ğŸ“ å»ºè®®ä¸‹ä¸€æ­¥

"""
        
        # æ ¹æ®ç»“æœç”Ÿæˆå»ºè®®
        if optimization_result.get('success', False):
            if overfitting_detection and overfitting_detection.get('overfitting_detected', False):
                report += """
1. **é™ä½æ¨¡å‹å¤æ‚åº¦**: å‡å°‘å†³ç­–æ ‘æ•°é‡æˆ–æœ€å¤§æ·±åº¦
2. **å¢åŠ æ­£åˆ™åŒ–**: æé«˜min_samples_splitå’Œmin_samples_leaf
3. **æ•°æ®å¢å¼º**: æ”¶é›†æ›´å¤šè®­ç»ƒæ•°æ®
4. **ç‰¹å¾é€‰æ‹©**: ç§»é™¤å†—ä½™æˆ–å™ªå£°ç‰¹å¾
"""
            else:
                report += """
1. **è¿è¡Œæ»šåŠ¨å›æµ‹**: `python run.py r 2025-06-27 2025-07-07`
2. **å•æ—¥é¢„æµ‹æµ‹è¯•**: `python run.py p 2025-07-08`
3. **å®ç›˜éªŒè¯**: åœ¨çœŸå®ç¯å¢ƒä¸­æµ‹è¯•æ¨¡å‹è¡¨ç°
4. **å®šæœŸé‡è®­ç»ƒ**: æ ¹æ®æ–°æ•°æ®å®šæœŸæ›´æ–°æ¨¡å‹
"""
        else:
            report += """
1. **æ£€æŸ¥æ•°æ®è´¨é‡**: ç¡®è®¤è®­ç»ƒæ•°æ®çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
2. **è°ƒæ•´å‚æ•°èŒƒå›´**: æ‰©å¤§æˆ–ç¼©å°å‚æ•°æœç´¢ç©ºé—´
3. **å¢åŠ è®­ç»ƒæ•°æ®**: æ”¶é›†æ›´å¤šå†å²æ•°æ®
4. **æ£€æŸ¥ç‰¹å¾å·¥ç¨‹**: éªŒè¯ç‰¹å¾æå–çš„æ­£ç¡®æ€§
"""
        
        report += f"""

---

## ğŸ“ æ–‡ä»¶ä¿¡æ¯

- **æŠ¥å‘Šæ–‡ä»¶**: `{self.reports_dir.name}/optimization_report_{timestamp}.md`
- **æ•°æ®æ–‡ä»¶**: `{self.reports_dir.name}/optimization_data_{timestamp}.json`
- **å›¾è¡¨æ–‡ä»¶**: `{self.reports_dir.name}/charts/optimization_charts_{timestamp}.png`

---

*æŠ¥å‘Šç”Ÿæˆäº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        return report
    
    def _save_json_data(self, optimization_result: Dict[str, Any], 
                       model_info: Dict[str, Any],
                       overfitting_detection: Dict[str, Any],
                       timestamp: str):
        """ä¿å­˜JSONæ ¼å¼çš„æ•°æ®"""
        data = {
            'timestamp': timestamp,
            'generated_at': datetime.now().isoformat(),
            'optimization_result': optimization_result,
            'model_info': model_info,
            'overfitting_detection': overfitting_detection,
            'config_snapshot': {
                'data_split': self.config.get('ai', {}).get('validation', {}),
                'early_stopping': self.config.get('ai', {}).get('early_stopping', {}),
                'strategy': self.config.get('strategy', {})
            }
        }
        
        json_path = self.reports_dir / f"optimization_data_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False, default=str)
    
    def _generate_charts(self, optimization_result: Dict[str, Any], timestamp: str):
        """ç”Ÿæˆå›¾è¡¨"""
        try:
            charts_dir = self.reports_dir / "charts"
            charts_dir.mkdir(exist_ok=True)
            
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
            
            # å›¾è¡¨1: ä¼˜åŒ–å†å²ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if 'optimization_history' in optimization_result:
                history = optimization_result['optimization_history']
                iterations = list(range(len(history)))
                scores = [h.get('score', 0) for h in history]
                
                ax1.plot(iterations, scores, 'b-', linewidth=2)
                ax1.set_title('ä¼˜åŒ–å†å²', fontsize=14, fontweight='bold')
                ax1.set_xlabel('è¿­ä»£æ¬¡æ•°')
                ax1.set_ylabel('å¾—åˆ†')
                ax1.grid(True, alpha=0.3)
            else:
                ax1.text(0.5, 0.5, 'æš‚æ— ä¼˜åŒ–å†å²æ•°æ®', ha='center', va='center', 
                        transform=ax1.transAxes, fontsize=12)
                ax1.set_title('ä¼˜åŒ–å†å²', fontsize=14, fontweight='bold')
            
            # å›¾è¡¨2: å…³é”®æŒ‡æ ‡
            metrics = ['å‡†ç¡®ç‡', 'æˆåŠŸç‡', 'å¹³å‡æ”¶ç›Š', 'æœ€ç»ˆå¾—åˆ†']
            values = [
                optimization_result.get('accuracy', 0) * 100,
                optimization_result.get('success_rate', 0) * 100,
                optimization_result.get('avg_return', optimization_result.get('avg_rise', 0)) * 100,
                optimization_result.get('best_score', 0) * 100
            ]
            
            bars = ax2.bar(metrics, values, color=['#2E8B57', '#4682B4', '#FF6347', '#FFD700'])
            ax2.set_title('å…³é”®æŒ‡æ ‡', fontsize=14, fontweight='bold')
            ax2.set_ylabel('ç™¾åˆ†æ¯” (%)')
            
            # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars, values):
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                        f'{value:.1f}%', ha='center', va='bottom')
            
            # å›¾è¡¨3: æ—¶é—´åˆ†è§£ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if 'training_time_breakdown' in optimization_result:
                breakdown = optimization_result['training_time_breakdown']
                labels = list(breakdown.keys())
                sizes = list(breakdown.values())
                
                ax3.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
                ax3.set_title('è®­ç»ƒæ—¶é—´åˆ†è§£', fontsize=14, fontweight='bold')
            else:
                ax3.text(0.5, 0.5, 'æš‚æ— è®­ç»ƒæ—¶é—´æ•°æ®', ha='center', va='center', 
                        transform=ax3.transAxes, fontsize=12)
                ax3.set_title('è®­ç»ƒæ—¶é—´åˆ†è§£', fontsize=14, fontweight='bold')
            
            # å›¾è¡¨4: è¿‡æ‹Ÿåˆæ£€æµ‹æŒ‡æ ‡
            if 'overfitting_detection' in optimization_result:
                detection = optimization_result['overfitting_detection']
                metrics = detection.get('metrics', {})
                
                metric_names = []
                metric_values = []
                for key, value in metrics.items():
                    if isinstance(value, (int, float)) and not isinstance(value, bool):
                        metric_names.append(key.replace('_', '\n'))
                        metric_values.append(value)
                
                if metric_names:
                    ax4.bar(metric_names, metric_values, color='#FF4500' if detection.get('overfitting_detected', False) else '#32CD32')
                    ax4.set_title('è¿‡æ‹Ÿåˆæ£€æµ‹æŒ‡æ ‡', fontsize=14, fontweight='bold')
                    ax4.set_ylabel('æ•°å€¼')
                    
                    # æ—‹è½¬xè½´æ ‡ç­¾ä»¥é¿å…é‡å 
                    plt.setp(ax4.get_xticklabels(), rotation=45, ha='right')
                else:
                    ax4.text(0.5, 0.5, 'æš‚æ— è¿‡æ‹Ÿåˆæ£€æµ‹æ•°æ®', ha='center', va='center', 
                            transform=ax4.transAxes, fontsize=12)
            else:
                ax4.text(0.5, 0.5, 'æš‚æ— è¿‡æ‹Ÿåˆæ£€æµ‹æ•°æ®', ha='center', va='center', 
                        transform=ax4.transAxes, fontsize=12)
                ax4.set_title('è¿‡æ‹Ÿåˆæ£€æµ‹æŒ‡æ ‡', fontsize=14, fontweight='bold')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            chart_path = charts_dir / f"optimization_charts_{timestamp}.png"
            plt.savefig(chart_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            self.logger.info(f"âœ… ä¼˜åŒ–å›¾è¡¨å·²ç”Ÿæˆ: {chart_path}")
            
        except Exception as e:
            self.logger.error(f"âŒ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
    
    def create_summary_report(self, days_back: int = 7) -> str:
        """
        åˆ›å»ºæœ€è¿‘å‡ å¤©çš„ä¼˜åŒ–æ±‡æ€»æŠ¥å‘Š
        
        å‚æ•°:
        days_back: å›æº¯å¤©æ•°
        
        è¿”å›:
        str: æ±‡æ€»æŠ¥å‘Šè·¯å¾„
        """
        # æŸ¥æ‰¾æœ€è¿‘çš„æŠ¥å‘Šæ–‡ä»¶
        cutoff_date = datetime.now().timestamp() - (days_back * 24 * 3600)
        recent_reports = []
        
        for json_file in self.reports_dir.glob("optimization_data_*.json"):
            try:
                # ä»æ–‡ä»¶åæå–æ—¶é—´æˆ³
                timestamp_str = json_file.stem.replace('optimization_data_', '')
                file_time = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S').timestamp()
                
                if file_time >= cutoff_date:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        recent_reports.append(data)
            except Exception as e:
                self.logger.warning(f"æ— æ³•è§£ææŠ¥å‘Šæ–‡ä»¶ {json_file}: {e}")
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        if recent_reports:
            summary_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            summary_path = self.reports_dir / f"summary_report_{summary_timestamp}.md"
            
            summary_content = self._generate_summary_content(recent_reports, days_back)
            
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(summary_content)
            
            self.logger.info(f"âœ… æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {summary_path}")
            return str(summary_path)
        else:
            self.logger.warning(f"æœ€è¿‘{days_back}å¤©å†…æ²¡æœ‰æ‰¾åˆ°ä¼˜åŒ–æŠ¥å‘Š")
            return ""
    
    def _generate_summary_content(self, reports: List[Dict[str, Any]], days_back: int) -> str:
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå†…å®¹"""
        
        summary = f"""# AIä¼˜åŒ–æ±‡æ€»æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**ç»Ÿè®¡å‘¨æœŸ**: æœ€è¿‘ {days_back} å¤©  
**æŠ¥å‘Šæ•°é‡**: {len(reports)}

---

## ğŸ“Š æ•´ä½“è¶‹åŠ¿

"""
        
        # è®¡ç®—è¶‹åŠ¿ç»Ÿè®¡
        scores = []
        accuracies = []
        overfitting_count = 0
        
        for report in reports:
            opt_result = report.get('optimization_result', {})
            scores.append(opt_result.get('best_score', 0))
            accuracies.append(opt_result.get('accuracy', 0))
            
            overfitting = report.get('overfitting_detection', {})
            if overfitting.get('overfitting_detected', False):
                overfitting_count += 1
        
        if scores:
            summary += f"""
### å¾—åˆ†è¶‹åŠ¿
- **æœ€é«˜å¾—åˆ†**: {max(scores):.4f}
- **æœ€ä½å¾—åˆ†**: {min(scores):.4f}
- **å¹³å‡å¾—åˆ†**: {np.mean(scores):.4f}
- **å¾—åˆ†æ ‡å‡†å·®**: {np.std(scores):.4f}

### å‡†ç¡®ç‡è¶‹åŠ¿
- **æœ€é«˜å‡†ç¡®ç‡**: {max(accuracies) * 100:.2f}%
- **æœ€ä½å‡†ç¡®ç‡**: {min(accuracies) * 100:.2f}%
- **å¹³å‡å‡†ç¡®ç‡**: {np.mean(accuracies) * 100:.2f}%

### è¿‡æ‹Ÿåˆæƒ…å†µ
- **è¿‡æ‹Ÿåˆæ¬¡æ•°**: {overfitting_count} / {len(reports)}
- **è¿‡æ‹Ÿåˆæ¯”ä¾‹**: {overfitting_count / len(reports) * 100:.1f}%

"""
        
        # æ·»åŠ è¯¦ç»†è®°å½•
        summary += "## ğŸ“‹ è¯¦ç»†è®°å½•\n\n"
        summary += "| æ—¶é—´ | å¾—åˆ† | å‡†ç¡®ç‡ | è¿‡æ‹Ÿåˆ | è€—æ—¶ |\n"
        summary += "|------|------|--------|--------|------|\n"
        
        for report in sorted(reports, key=lambda x: x.get('timestamp', ''), reverse=True):
            timestamp = report.get('timestamp', 'N/A')
            opt_result = report.get('optimization_result', {})
            overfitting = report.get('overfitting_detection', {})
            
            time_str = timestamp[:8] + ' ' + timestamp[9:].replace('_', ':') if len(timestamp) >= 15 else timestamp
            score = opt_result.get('best_score', 0)
            accuracy = opt_result.get('accuracy', 0) * 100
            overfitting_status = 'ğŸš¨' if overfitting.get('overfitting_detected', False) else 'âœ…'
            duration = opt_result.get('total_time', 0)
            
            summary += f"| {time_str} | {score:.4f} | {accuracy:.1f}% | {overfitting_status} | {duration:.1f}s |\n"
        
        summary += f"""

---

## ğŸ’¡ æ€»ç»“ä¸å»ºè®®

"""
        
        # æ ¹æ®ç»Ÿè®¡ç»“æœç”Ÿæˆå»ºè®®
        if overfitting_count > len(reports) * 0.5:
            summary += """
### âš ï¸ è¿‡æ‹Ÿåˆé—®é¢˜ä¸¥é‡
- è¿‡æ‹Ÿåˆå‘ç”Ÿé¢‘ç‡è¿‡é«˜
- å»ºè®®è¿›ä¸€æ­¥é™ä½æ¨¡å‹å¤æ‚åº¦
- è€ƒè™‘å¢åŠ æ›´å¤šè®­ç»ƒæ•°æ®
- åŠ å¼ºæ­£åˆ™åŒ–æªæ–½
"""
        elif overfitting_count > 0:
            summary += """
### âš ï¸ å¶æœ‰è¿‡æ‹Ÿåˆ
- å¶å°”å‡ºç°è¿‡æ‹Ÿåˆç°è±¡
- å½“å‰é…ç½®åŸºæœ¬åˆç†
- å»ºè®®æŒç»­ç›‘æ§
- å¯è€ƒè™‘å¾®è°ƒå‚æ•°
"""
        else:
            summary += """
### âœ… è¿‡æ‹Ÿåˆæ§åˆ¶è‰¯å¥½
- æœªæ£€æµ‹åˆ°æ˜æ˜¾è¿‡æ‹Ÿåˆ
- å½“å‰é…ç½®æ•ˆæœè‰¯å¥½
- å¯ç»§ç»­ä½¿ç”¨å½“å‰è®¾ç½®
- å»ºè®®å®šæœŸè¯„ä¼°
"""
        
        if scores and np.std(scores) > 0.1:
            summary += """
### ğŸ“ˆ å¾—åˆ†æ³¢åŠ¨è¾ƒå¤§
- æ¨¡å‹ç¨³å®šæ€§éœ€è¦æ”¹å–„
- è€ƒè™‘å¢åŠ è®­ç»ƒæ•°æ®
- æ£€æŸ¥ç‰¹å¾å·¥ç¨‹ä¸€è‡´æ€§
- è¯„ä¼°å‚æ•°æœç´¢èŒƒå›´
"""
        
        summary += f"""

---

*æ±‡æ€»æŠ¥å‘Šç”Ÿæˆäº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        return summary


def create_optimization_report(optimization_result: Dict[str, Any], 
                             config: Dict[str, Any],
                             model_info: Dict[str, Any] = None,
                             overfitting_detection: Dict[str, Any] = None) -> str:
    """
    åˆ›å»ºä¼˜åŒ–æŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°
    
    å‚æ•°:
    optimization_result: ä¼˜åŒ–ç»“æœ
    config: é…ç½®ä¿¡æ¯
    model_info: æ¨¡å‹ä¿¡æ¯
    overfitting_detection: è¿‡æ‹Ÿåˆæ£€æµ‹ç»“æœ
    
    è¿”å›:
    str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    """
    reporter = OptimizationReporter(config)
    return reporter.generate_report(optimization_result, model_info, overfitting_detection)