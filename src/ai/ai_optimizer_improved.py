#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ”¹è¿›ç‰ˆAIä¼˜åŒ–å™¨
é›†æˆå¢é‡å­¦ä¹ ã€ç‰¹å¾æƒé‡ä¼˜åŒ–å’Œè¶‹åŠ¿ç¡®è®¤æŒ‡æ ‡
å·²åºŸå¼ƒç½®ä¿¡åº¦å¹³æ»‘åŠŸèƒ½ï¼Œç›´æ¥ä½¿ç”¨AIæ¨¡å‹åŸå§‹è¾“å‡º
"""

import logging
import os
import pickle
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from typing import Dict, Any, Tuple, List, Optional
import json
import yaml
from itertools import product
import sys
import time


# æ³¨é‡Šï¼šä»¥ä¸‹ConfidenceSmootherç±»å·²åºŸå¼ƒï¼Œä¸å†ä½¿ç”¨å¹³æ»‘å¤„ç†
# ç°åœ¨ç›´æ¥ä½¿ç”¨æ¨¡å‹çš„åŸå§‹è¾“å‡ºï¼Œä¿æŒä¿¡æ¯å®Œæ•´æ€§


class AIOptimizerImproved:
    """æ”¹è¿›ç‰ˆAIä¼˜åŒ–å™¨"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)

        # åˆå§‹åŒ–æ¨¡å‹ç›¸å…³å±æ€§
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        self.models_dir = os.path.join(project_root, 'models')
        os.makedirs(self.models_dir, exist_ok=True)

        self.model = None
        self.scaler = None
        self.feature_names = None
        self.model_type = config.get('ai', {}).get('model_type', 'machine_learning')

        # å¢é‡å­¦ä¹ é…ç½®
        incremental_config = config.get('ai', {}).get('incremental_learning', {})
        self.incremental_enabled = incremental_config.get('enabled', True)
        self.retrain_threshold = incremental_config.get('retrain_threshold', 0.1)  # æ¨¡å‹æ€§èƒ½ä¸‹é™é˜ˆå€¼
        self.max_incremental_updates = incremental_config.get('max_updates', 10)  # æœ€å¤§å¢é‡æ›´æ–°æ¬¡æ•°
        self.incremental_count = 0

        # ç§»é™¤ç½®ä¿¡åº¦å¹³æ»‘å™¨ - ä½¿ç”¨æ¨¡å‹åŸå§‹è¾“å‡º
        # self.confidence_smoother = ConfidenceSmoother(config)

        self.logger.info("æ”¹è¿›ç‰ˆAIä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")

    def prepare_features_improved(self, data: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        æ”¹è¿›çš„ç‰¹å¾å‡†å¤‡ï¼Œè°ƒæ•´æƒé‡å’Œå¢åŠ è¶‹åŠ¿ç¡®è®¤æŒ‡æ ‡
        
        å‚æ•°:
        data: å†å²æ•°æ®
        
        è¿”å›:
        tuple: (ç‰¹å¾çŸ©é˜µ, ç‰¹å¾åç§°åˆ—è¡¨)
        """
        self.logger.info("å‡†å¤‡æ”¹è¿›çš„æœºå™¨å­¦ä¹ ç‰¹å¾")

        # æ£€æŸ¥æ•°æ®ä¸­å·²æœ‰çš„æŠ€æœ¯æŒ‡æ ‡
        self.logger.info(f"è¾“å…¥æ•°æ®åˆ—: {list(data.columns)}")

        # è®¡ç®—é¢å¤–çš„è¶‹åŠ¿ç¡®è®¤æŒ‡æ ‡
        data = self._calculate_trend_indicators(data)

        # ğŸ”§ ç¡®ä¿é‡è¦æŠ€æœ¯æŒ‡æ ‡å­˜åœ¨ä¸”æœ‰æ•ˆï¼ˆå¦‚æœDataModuleå·²è®¡ç®—åˆ™ä¿ç•™ï¼Œå¦åˆ™é‡æ–°è®¡ç®—ï¼‰
        data = self._ensure_technical_indicators(data)

        # ğŸ¯ ä¼˜åŒ–ï¼šä½¿ç”¨ç²¾é€‰çš„é«˜æ•ˆç‰¹å¾ï¼Œä¿ç•™é‡è¦çš„æŠ€æœ¯æŒ‡æ ‡åŒ…æ‹¬RSI
        # åŸºäºç‰¹å¾é‡è¦æ€§åˆ†æ + ä¿ç•™å…³é”®æŠ€æœ¯æŒ‡æ ‡
        optimized_feature_columns = [
            # ğŸ”¥ æ ¸å¿ƒè¶‹åŠ¿æŒ‡æ ‡ï¼ˆæœ€é«˜é‡è¦æ€§ï¼š0.21 + 0.11 = 32%ï¼‰
            'trend_strength_60', 'trend_strength_20',

            # ğŸ”¥ æˆäº¤é‡æŒ‡æ ‡ï¼ˆé«˜é‡è¦æ€§ï¼š0.10 + 0.07 = 17%ï¼‰
            'volume_strength', 'volume_trend',

            # âš¡ å‡çº¿ç³»ç»Ÿï¼ˆä¸­é«˜é‡è¦æ€§ï¼š0.06 + 0.06 + 0.05 = 17%ï¼‰
            'ma5', 'ma10', 'ma20',

            # âš¡ ä»·æ ¼åŠ¨é‡å’Œå‡çº¿è·ç¦»ï¼ˆä¸­ç­‰é‡è¦æ€§ï¼š0.05 + 0.05 + 0.05 = 15%ï¼‰
            'price_change_5d', 'dist_ma20', 'macd',

            # âš¡ è¡¥å……ç‰¹å¾ï¼ˆè¾ƒä½ä½†æœ‰æ•ˆï¼š0.05 + 0.05 + 0.04 + 0.04 = 18%ï¼‰
            'dist_ma10', 'dist_ma5', 'ma60', 'price_change_10d',

            # ğŸ“Š é‡è¦æŠ€æœ¯æŒ‡æ ‡ï¼ˆä¿ç•™ç”¨äºç­–ç•¥ä¸€è‡´æ€§ï¼‰
            'rsi',  # RSIå¿…é¡»ä¿ç•™
            'bb_upper', 'bb_lower',  # å¸ƒæ—å¸¦ä¸Šä¸‹è½¨
            'signal', 'hist'  # MACDä¿¡å·å’ŒæŸ±çŠ¶çº¿
        ]

        # âŒ ç§»é™¤çš„çœŸæ­£å™ªéŸ³ç‰¹å¾ï¼š
        # 'price_position_20', 'price_position_60', 'volatility', 'volatility_normalized'

        # ğŸš¨ é‡è¦ï¼šç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å¡«å……åˆç†çš„é»˜è®¤å€¼
        for col in optimized_feature_columns:
            if col not in data.columns:
                self.logger.warning(f"ç¼ºå°‘ç‰¹å¾ {col}ï¼Œå°†å¡«å……é»˜è®¤å€¼")
                # æ ¹æ®ç‰¹å¾ç±»å‹å¡«å……åˆç†çš„é»˜è®¤å€¼
                if 'ma' in col or 'price' in col.lower():
                    # å‡çº¿å’Œä»·æ ¼ç›¸å…³ï¼šä½¿ç”¨æ”¶ç›˜ä»·
                    data[col] = data['close'] if 'close' in data.columns else 0.0
                elif col in ['rsi']:
                    # RSIï¼šå¡«å……ä¸­æ€§å€¼50
                    data[col] = 50.0
                elif 'dist_' in col:
                    # è·ç¦»ç›¸å…³ï¼šå¡«å……0ï¼ˆè¡¨ç¤ºåœ¨å‡çº¿ä¸Šï¼‰
                    data[col] = 0.0
                elif 'volume' in col.lower():
                    # æˆäº¤é‡ç›¸å…³ï¼šå¡«å……1.0ï¼ˆè¡¨ç¤ºæ­£å¸¸ï¼‰
                    data[col] = 1.0
                elif 'volatility' in col.lower():
                    # æ³¢åŠ¨ç‡ç›¸å…³ï¼šå¡«å……é€‚ä¸­å€¼
                    data[col] = 0.02 if 'normalized' not in col else 1.0
                else:
                    # å…¶ä»–ç‰¹å¾ï¼šå¡«å……0
                    data[col] = 0.0

        # ä½¿ç”¨ç²¾é€‰ç‰¹å¾é›†åˆ
        available_columns = optimized_feature_columns.copy()

        if len(available_columns) == 0:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾åˆ—")
            return np.array([]), []

        # æå–ç‰¹å¾å¹¶åº”ç”¨æƒé‡
        features_df = data[available_columns].fillna(0).copy()
        features = self._apply_feature_weights(features_df, available_columns)

        self.logger.info("æ”¹è¿›ç‰¹å¾å‡†å¤‡å®Œæˆï¼Œç‰¹å¾æ•°é‡: %d, æ ·æœ¬æ•°é‡: %d",
                         len(available_columns), len(features))

        return features, available_columns

    def _calculate_trend_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—è¶‹åŠ¿ç¡®è®¤æŒ‡æ ‡
        
        å‚æ•°:
        data: åŸå§‹æ•°æ®
        
        è¿”å›:
        pd.DataFrame: æ·»åŠ äº†è¶‹åŠ¿æŒ‡æ ‡çš„æ•°æ®
        """
        # è¶‹åŠ¿å¼ºåº¦æŒ‡æ ‡ï¼ˆåŸºäºçº¿æ€§å›å½’æ–œç‡ï¼‰
        for period in [20, 60]:
            slopes = []
            for i in range(len(data)):
                if i >= period - 1:
                    prices = data['close'].iloc[i - period + 1:i + 1].values
                    x = np.arange(period)
                    slope = np.polyfit(x, prices, 1)[0]
                    # æ ‡å‡†åŒ–æ–œç‡
                    normalized_slope = slope / prices.mean()
                    slopes.append(normalized_slope)
                else:
                    slopes.append(0)
            data[f'trend_strength_{period}'] = slopes

        # ä»·æ ¼åœ¨å‡çº¿ç³»ç»Ÿä¸­çš„ä½ç½®
        # ç¡®ä¿ma20å’Œma60åˆ—å­˜åœ¨ä¸”ä¸ä¸ºNaN
        if 'ma20' in data.columns and data['ma20'].notna().any():
            data['price_position_20'] = (data['close'] - data['ma20']) / data['ma20']
        else:
            data['price_position_20'] = 0

        if 'ma60' in data.columns and data['ma60'].notna().any():
            data['price_position_60'] = (data['close'] - data['ma60']) / data['ma60']
        else:
            data['price_position_60'] = 0

        # æ ‡å‡†åŒ–æ³¢åŠ¨ç‡
        if 'volatility' in data.columns and data['volatility'].notna().any():
            volatility_mean = data['volatility'].rolling(60).mean()
            data['volatility_normalized'] = data['volatility'] / volatility_mean
            # å¤„ç†é™¤é›¶æƒ…å†µ
            data['volatility_normalized'] = data['volatility_normalized'].fillna(1.0)
        else:
            data['volatility_normalized'] = 1.0

        # æˆäº¤é‡è¶‹åŠ¿æŒ‡æ ‡
        volume_ma20 = data['volume'].rolling(20).mean()
        data['volume_trend'] = (data['volume'] - volume_ma20) / volume_ma20
        # å¤„ç†é™¤é›¶æƒ…å†µ
        data['volume_trend'] = data['volume_trend'].fillna(0)

        # æˆäº¤é‡å¼ºåº¦ï¼ˆç›¸å¯¹äºå†å²ï¼‰
        volume_ma60 = data['volume'].rolling(60).mean()
        data['volume_strength'] = data['volume'] / volume_ma60
        # å¤„ç†é™¤é›¶æƒ…å†µ
        data['volume_strength'] = data['volume_strength'].fillna(1.0)

        return data

    def _ensure_technical_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        ç¡®ä¿é‡è¦æŠ€æœ¯æŒ‡æ ‡å­˜åœ¨ä¸”æœ‰æ•ˆ
        
        å‚æ•°:
        data: åŸå§‹æ•°æ®
        
        è¿”å›:
        pd.DataFrame: åŒ…å«æ‰€æœ‰å¿…è¦æŠ€æœ¯æŒ‡æ ‡çš„æ•°æ®
        """
        self.logger.info("ğŸ”§ ç¡®ä¿æŠ€æœ¯æŒ‡æ ‡å®Œæ•´æ€§")

        # æ£€æŸ¥å¹¶è®¡ç®—RSI
        if 'rsi' not in data.columns or data['rsi'].isna().all():
            self.logger.info("é‡æ–°è®¡ç®—RSIæŒ‡æ ‡")
            delta = data['close'].diff()
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)
            avg_gain = gain.rolling(14).mean()
            avg_loss = loss.rolling(14).mean()

            # ä¿®å¤é™¤é›¶é”™è¯¯
            rs = np.where(avg_loss == 0, np.inf, avg_gain / avg_loss)
            rs = np.where(avg_gain == 0, 0, rs)
            data['rsi'] = 100 - (100 / (1 + rs))

        # æ£€æŸ¥å¹¶è®¡ç®—MACD
        if 'macd' not in data.columns or data['macd'].isna().all():
            self.logger.info("é‡æ–°è®¡ç®—MACDæŒ‡æ ‡")
            exp1 = data['close'].ewm(span=12, adjust=False).mean()
            exp2 = data['close'].ewm(span=26, adjust=False).mean()
            data['macd'] = exp1 - exp2
            data['signal'] = data['macd'].ewm(span=9, adjust=False).mean()
            data['hist'] = data['macd'] - data['signal']

        # æ£€æŸ¥å¹¶è®¡ç®—å¸ƒæ—å¸¦
        if 'bb_upper' not in data.columns or data['bb_upper'].isna().all():
            self.logger.info("é‡æ–°è®¡ç®—å¸ƒæ—å¸¦æŒ‡æ ‡")
            # ç¡®ä¿ma20å­˜åœ¨
            if 'ma20' not in data.columns:
                data['ma20'] = data['close'].rolling(20).mean()
            data['bb_upper'] = data['ma20'] + (data['close'].rolling(20).std() * 2)
            data['bb_lower'] = data['ma20'] - (data['close'].rolling(20).std() * 2)

        # æ£€æŸ¥ç§»åŠ¨å¹³å‡çº¿
        if 'ma5' not in data.columns:
            data['ma5'] = data['close'].rolling(5).mean()
        if 'ma10' not in data.columns:
            data['ma10'] = data['close'].rolling(10).mean()
        if 'ma20' not in data.columns:
            data['ma20'] = data['close'].rolling(20).mean()
        if 'ma60' not in data.columns:
            data['ma60'] = data['close'].rolling(60).mean()

        # æ£€æŸ¥ä»·æ ¼ä¸å‡çº¿è·ç¦»
        if 'dist_ma5' not in data.columns:
            data['dist_ma5'] = (data['close'] - data['ma5']) / data['ma5']
        if 'dist_ma10' not in data.columns:
            data['dist_ma10'] = (data['close'] - data['ma10']) / data['ma10']
        if 'dist_ma20' not in data.columns:
            data['dist_ma20'] = (data['close'] - data['ma20']) / data['ma20']

        # æ£€æŸ¥ä»·æ ¼å˜åŒ–ç‡
        if 'price_change_5d' not in data.columns:
            data['price_change_5d'] = data['close'].pct_change(5)
        if 'price_change_10d' not in data.columns:
            data['price_change_10d'] = data['close'].pct_change(10)

        # éªŒè¯å…³é”®æŒ‡æ ‡
        key_indicators = ['rsi', 'macd', 'signal', 'hist', 'bb_upper', 'bb_lower']
        for indicator in key_indicators:
            if indicator in data.columns:
                valid_count = data[indicator].notna().sum()
                total_count = len(data)
                self.logger.info(f"âœ… {indicator}: {valid_count}/{total_count} æœ‰æ•ˆå€¼")
            else:
                self.logger.warning(f"âŒ {indicator} ä¸å­˜åœ¨")

        return data

    def _apply_feature_weights(self, features_df: pd.DataFrame, feature_names: List[str]) -> np.ndarray:
        """
        åº”ç”¨ç‰¹å¾æƒé‡ï¼Œé™ä½çŸ­æœŸæŒ‡æ ‡å½±å“
        
        å‚æ•°:
        features_df: ç‰¹å¾æ•°æ®æ¡†
        feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        
        è¿”å›:
        np.ndarray: åŠ æƒåçš„ç‰¹å¾çŸ©é˜µ
        """
        # å®šä¹‰ç‰¹å¾æƒé‡
        feature_weights = {
            # é•¿æœŸè¶‹åŠ¿æŒ‡æ ‡ï¼ˆé«˜æƒé‡ï¼‰
            'ma20': 1.5, 'ma60': 1.5,
            'trend_strength_20': 2.0, 'trend_strength_60': 2.0,
            'price_position_20': 1.8, 'price_position_60': 1.8,

            # ä¸­æœŸæŒ‡æ ‡ï¼ˆæ­£å¸¸æƒé‡ï¼‰
            'ma10': 1.0, 'dist_ma10': 1.2, 'dist_ma20': 1.2,
            'rsi': 1.0, 'macd': 1.0, 'signal': 1.0,
            'bb_upper': 1.0, 'bb_lower': 1.0,
            'volatility_normalized': 1.0,

            # çŸ­æœŸæŒ‡æ ‡ï¼ˆé™ä½æƒé‡ï¼‰
            'ma5': 0.6, 'dist_ma5': 0.6, 'hist': 0.7,
            'price_change_5d': 0.5, 'price_change_10d': 0.7,

            # æˆäº¤é‡æŒ‡æ ‡ï¼ˆå¹³è¡¡æƒé‡ï¼‰
            'volume_trend': 1.1, 'volume_strength': 1.1,
            'volatility': 0.9
        }

        # åº”ç”¨æƒé‡
        weighted_features = features_df.copy()
        for feature in feature_names:
            weight = feature_weights.get(feature, 1.0)
            weighted_features[feature] = weighted_features[feature] * weight

        return weighted_features.values

    def incremental_train(self, new_data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        å¢é‡è®­ç»ƒæ¨¡å‹
        
        å‚æ•°:
        new_data: æ–°å¢æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—
        
        è¿”å›:
        dict: è®­ç»ƒç»“æœ
        """
        self.logger.info("å¼€å§‹å¢é‡è®­ç»ƒæ¨¡å‹")

        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å®Œå…¨é‡è®­ç»ƒ
            if self.model is None or self.incremental_count >= self.max_incremental_updates:
                self.logger.info("è§¦å‘å®Œå…¨é‡è®­ç»ƒæ¡ä»¶")
                return self.full_train(new_data, strategy_module)

            # å‡†å¤‡æ–°æ•°æ®çš„ç‰¹å¾å’Œæ ‡ç­¾
            new_features, feature_names = self.prepare_features_improved(new_data)
            new_labels = self._prepare_labels(new_data, strategy_module)

            if len(new_features) == 0 or len(new_labels) == 0:
                self.logger.warning("æ–°æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡å¢é‡è®­ç»ƒ")
                return {'success': False, 'error': 'æ–°æ•°æ®ä¸ºç©º'}

            # æ£€æŸ¥ç‰¹å¾ä¸€è‡´æ€§
            if self.feature_names and feature_names != self.feature_names:
                self.logger.warning("ç‰¹å¾ä¸ä¸€è‡´ï¼Œè¿›è¡Œå®Œå…¨é‡è®­ç»ƒ")
                return self.full_train(new_data, strategy_module)

            # ä½¿ç”¨æœ€è¿‘çš„æ•°æ®è¿›è¡Œå¢é‡æ›´æ–°
            recent_features = new_features[-10:]  # æœ€è¿‘10å¤©çš„æ•°æ®
            recent_labels = new_labels[-10:]

            if len(recent_features) > 0:
                # å¯¹æ–°æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆä½¿ç”¨å·²æœ‰çš„scalerï¼‰
                if self.scaler is not None:
                    recent_features_scaled = self.scaler.transform(recent_features)
                else:
                    self.logger.warning("ç¼ºå°‘scalerï¼Œè¿›è¡Œå®Œå…¨é‡è®­ç»ƒ")
                    return self.full_train(new_data, strategy_module)

                # ä½¿ç”¨warm_startè¿›è¡Œå¢é‡å­¦ä¹ 
                if hasattr(self.model.named_steps['classifier'], 'n_estimators'):
                    classifier = self.model.named_steps['classifier']
                    classifier.n_estimators += 10  # å¢åŠ æ ‘çš„æ•°é‡
                    classifier.warm_start = True

                    # é‡æ–°è®­ç»ƒï¼ˆè¿™é‡Œå®é™…ä¸Šæ˜¯å¢é‡çš„ï¼‰
                    self.model.named_steps['classifier'].fit(recent_features_scaled, recent_labels)

                    self.incremental_count += 1
                    self.logger.info(f"å¢é‡è®­ç»ƒå®Œæˆï¼Œæ›´æ–°æ¬¡æ•°: {self.incremental_count}")

                    return {
                        'success': True,
                        'method': 'incremental',
                        'update_count': self.incremental_count,
                        'new_samples': len(recent_features)
                    }
                else:
                    self.logger.warning("æ¨¡å‹ä¸æ”¯æŒå¢é‡å­¦ä¹ ï¼Œè¿›è¡Œå®Œå…¨é‡è®­ç»ƒ")
                    return self.full_train(new_data, strategy_module)

            return {'success': False, 'error': 'æ²¡æœ‰è¶³å¤Ÿçš„æ–°æ•°æ®è¿›è¡Œå¢é‡è®­ç»ƒ'}

        except Exception as e:
            self.logger.error(f"å¢é‡è®­ç»ƒå¤±è´¥: {e}")
            # å¤±è´¥æ—¶è¿›è¡Œå®Œå…¨é‡è®­ç»ƒ
            return self.full_train(new_data, strategy_module)

    def full_train(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        å®Œæ•´è®­ç»ƒæ”¹è¿›ç‰ˆAIæ¨¡å‹
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—
        
        è¿”å›:
        dict: è®­ç»ƒç»“æœ
        """
        train_start_time = time.time()
        self.logger.info("ğŸ¤– å¼€å§‹æ”¹è¿›ç‰ˆAIæ¨¡å‹å®Œæ•´è®­ç»ƒ")
        self.logger.info("=" * 80)

        try:
            # æ­¥éª¤1: ç‰¹å¾å·¥ç¨‹
            self.logger.info("âš™ï¸ æ­¥éª¤1: ç‰¹å¾å·¥ç¨‹...")
            feature_start_time = time.time()

            features, feature_names = self.prepare_features_improved(data)

            if len(features) == 0:
                return {
                    'success': False,
                    'error': 'æ— æ³•æå–ç‰¹å¾'
                }

            self.feature_names = feature_names
            feature_time = time.time() - feature_start_time

            self.logger.info(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ (è€—æ—¶: {feature_time:.2f}s)")
            self.logger.info(f"   ç‰¹å¾æ•°é‡: {len(feature_names)}")
            self.logger.info(f"   æ ·æœ¬æ•°é‡: {len(features)}")
            self.logger.info(f"   ç‰¹å¾åˆ—è¡¨: {', '.join(feature_names[:10])}{'...' if len(feature_names) > 10 else ''}")
            self.logger.info("-" * 60)

            # æ­¥éª¤2: æ ‡ç­¾å‡†å¤‡
            self.logger.info("ğŸ·ï¸ æ­¥éª¤2: æ ‡ç­¾å‡†å¤‡...")
            label_start_time = time.time()

            labels = self._prepare_labels(data, strategy_module)

            if len(labels) != len(features):
                return {
                    'success': False,
                    'error': f'ç‰¹å¾æ•°é‡({len(features)})ä¸æ ‡ç­¾æ•°é‡({len(labels)})ä¸åŒ¹é…'
                }

            label_time = time.time() - label_start_time
            positive_ratio = np.mean(labels)

            self.logger.info(f"âœ… æ ‡ç­¾å‡†å¤‡å®Œæˆ (è€—æ—¶: {label_time:.2f}s)")
            self.logger.info(f"   æ­£æ ·æœ¬æ¯”ä¾‹: {positive_ratio:.2%}")
            self.logger.info(f"   æ­£æ ·æœ¬æ•°é‡: {np.sum(labels)} / {len(labels)}")
            self.logger.info("-" * 60)

            # æ­¥éª¤3: æ ·æœ¬æƒé‡è®¡ç®—
            self.logger.info("âš–ï¸ æ­¥éª¤3: æ ·æœ¬æƒé‡è®¡ç®—...")
            weight_start_time = time.time()

            # ä¸¥æ ¼è¦æ±‚æ•°æ®åŒ…å«æ­£ç¡®çš„æ—¥æœŸä¿¡æ¯
            if 'date' in data.columns:
                date_series = data['date']
                if not pd.api.types.is_datetime64_any_dtype(date_series):
                    raise ValueError(f"data['date']åˆ—ä¸æ˜¯datetimeç±»å‹ï¼Œå®é™…ç±»å‹: {date_series.dtype}")
            elif pd.api.types.is_datetime64_any_dtype(data.index):
                date_series = data.index.to_series()
            else:
                raise ValueError(
                    "æ•°æ®ç¼ºå°‘æœ‰æ•ˆçš„æ—¥æœŸä¿¡æ¯ã€‚è¦æ±‚ï¼š\n"
                    "1. åŒ…å«datetimeç±»å‹çš„'date'åˆ—ï¼Œæˆ–\n"
                    "2. ä½¿ç”¨datetimeç±»å‹çš„ç´¢å¼•\n"
                    f"å®é™…æƒ…å†µï¼š\n"
                    f"  - 'date'åˆ—: {'å­˜åœ¨' if 'date' in data.columns else 'ä¸å­˜åœ¨'}\n"
                    f"  - ç´¢å¼•ç±»å‹: {type(data.index).__name__}\n"
                    f"  - ç´¢å¼•dtype: {data.index.dtype}"
                )

            sample_weights = self._calculate_sample_weights(date_series)
            weight_time = time.time() - weight_start_time

            self.logger.info(f"âœ… æ ·æœ¬æƒé‡è®¡ç®—å®Œæˆ (è€—æ—¶: {weight_time:.2f}s)")
            self.logger.info(f"   æƒé‡èŒƒå›´: {np.min(sample_weights):.4f} - {np.max(sample_weights):.4f}")
            self.logger.info(f"   å¹³å‡æƒé‡: {np.mean(sample_weights):.4f}")
            self.logger.info("-" * 60)

            # æ­¥éª¤4: æ¨¡å‹è®­ç»ƒ
            self.logger.info("ğŸ‹ï¸ æ­¥éª¤4: æ¨¡å‹è®­ç»ƒ...")
            model_start_time = time.time()

            # åˆ›å»ºæ”¹è¿›çš„æ¨¡å‹pipelineï¼ˆé™ä½å¤æ‚åº¦é˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
            model = Pipeline([
                ('scaler', StandardScaler()),
                ('classifier', RandomForestClassifier(
                    n_estimators=100,  # ä»150é™åˆ°100
                    max_depth=8,  # ä»12é™åˆ°8
                    min_samples_split=15,  # ä»8æé«˜åˆ°15
                    min_samples_leaf=8,  # ä»3æé«˜åˆ°8
                    class_weight='balanced',
                    n_jobs=-1,
                    random_state=42,
                    verbose=1  # å¯ç”¨è®­ç»ƒè¿›åº¦è¾“å‡º
                ))
            ])

            self.logger.info("ğŸŒ² RandomForestæ¨¡å‹é…ç½®ï¼ˆé˜²è¿‡æ‹Ÿåˆï¼‰:")
            self.logger.info("   n_estimators: 100 (å†³ç­–æ ‘æ•°é‡) - é™ä½å¤æ‚åº¦")
            self.logger.info("   max_depth: 8 (æœ€å¤§æ·±åº¦) - å‡å°‘è¿‡æ‹Ÿåˆ")
            self.logger.info("   min_samples_split: 15 (æœ€å°åˆ†å‰²æ ·æœ¬æ•°) - å¢åŠ ç¨³å®šæ€§")
            self.logger.info("   min_samples_leaf: 8 (æœ€å°å¶å­èŠ‚ç‚¹æ ·æœ¬æ•°) - å¢åŠ ç¨³å®šæ€§")
            self.logger.info("   class_weight: balanced (è‡ªåŠ¨å¹³è¡¡ç±»åˆ«æƒé‡)")
            self.logger.info("   n_jobs: -1 (å¹¶è¡Œè®­ç»ƒ)")

            self.logger.info("ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
            # è®­ç»ƒæ¨¡å‹
            model.fit(features, labels, classifier__sample_weight=sample_weights)

            model_time = time.time() - model_start_time
            self.model = model

            self.logger.info(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ (è€—æ—¶: {model_time:.2f}s)")
            self.logger.info("-" * 60)

            # æ­¥éª¤5: æ¨¡å‹ä¿å­˜
            self.logger.info("ğŸ’¾ æ­¥éª¤5: æ¨¡å‹ä¿å­˜...")
            save_start_time = time.time()

            save_success = self._save_model()
            save_time = time.time() - save_start_time

            if save_success:
                self.logger.info(f"âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ (è€—æ—¶: {save_time:.2f}s)")
            else:
                self.logger.warning(f"âš ï¸ æ¨¡å‹ä¿å­˜å¤±è´¥ (è€—æ—¶: {save_time:.2f}s)")

            # è®­ç»ƒæ€»ç»“
            total_train_time = time.time() - train_start_time
            self.logger.info("=" * 80)
            self.logger.info("ğŸ‰ æ”¹è¿›ç‰ˆAIæ¨¡å‹è®­ç»ƒå®Œæˆ!")
            self.logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_train_time:.2f}s ({total_train_time / 60:.1f}åˆ†é’Ÿ)")
            self.logger.info(f"ğŸ“Š è®­ç»ƒç»Ÿè®¡:")
            self.logger.info(f"   ç‰¹å¾å·¥ç¨‹: {feature_time:.2f}s")
            self.logger.info(f"   æ ‡ç­¾å‡†å¤‡: {label_time:.2f}s")
            self.logger.info(f"   æƒé‡è®¡ç®—: {weight_time:.2f}s")
            self.logger.info(f"   æ¨¡å‹è®­ç»ƒ: {model_time:.2f}s")
            self.logger.info(f"   æ¨¡å‹ä¿å­˜: {save_time:.2f}s")
            self.logger.info(f"ğŸ¯ è®­ç»ƒç»“æœ:")
            self.logger.info(f"   æ ·æœ¬æ•°é‡: {len(features)}")
            self.logger.info(f"   ç‰¹å¾æ•°é‡: {len(feature_names)}")
            self.logger.info(f"   æ­£æ ·æœ¬æ¯”ä¾‹: {positive_ratio:.2%}")
            self.logger.info(f"   æ¨¡å‹ä¿å­˜: {'æˆåŠŸ' if save_success else 'å¤±è´¥'}")
            self.logger.info("=" * 80)

            return {
                'success': True,
                'method': 'improved_full_training',
                'train_samples': len(features),
                'feature_count': len(feature_names),
                'positive_ratio': positive_ratio,
                'training_time': total_train_time,
                'feature_time': feature_time,
                'model_time': model_time,
                'save_time': save_time,
                'save_success': save_success,
                'feature_names': feature_names,
                'training_time_breakdown': {
                    'feature_engineering': feature_time,
                    'label_preparation': label_time,
                    'weight_calculation': weight_time,
                    'model_training': model_time,
                    'model_saving': save_time
                }
            }

        except Exception as e:
            self.logger.error(f"æ”¹è¿›ç‰ˆæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def predict_low_point(self, data: pd.DataFrame, prediction_date: str = None) -> Dict[str, Any]:
        """
        é¢„æµ‹ç›¸å¯¹ä½ç‚¹ï¼ˆå¸¦ç½®ä¿¡åº¦å¹³æ»‘ï¼‰
        
        å‚æ•°:
        data: å¸‚åœºæ•°æ®
        prediction_date: é¢„æµ‹æ—¥æœŸï¼ˆç”¨äºç½®ä¿¡åº¦å¹³æ»‘ï¼‰
        
        è¿”å›:
        dict: é¢„æµ‹ç»“æœ
        """
        self.logger.info("é¢„æµ‹ç›¸å¯¹ä½ç‚¹ï¼ˆæ”¹è¿›ç‰ˆï¼‰")

        try:
            # åŠ è½½æ¨¡å‹ï¼ˆå¦‚æœæœªåŠ è½½ï¼‰
            if self.model is None:
                if not self._load_model():
                    return {
                        'is_low_point': False,
                        'confidence': 0.0,
                        'final_confidence': 0.0,
                        'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'
                    }

            if len(data) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'final_confidence': 0.0,
                    'error': 'æ•°æ®ä¸ºç©º'
                }

            # å‡†å¤‡ç‰¹å¾
            features, feature_names = self.prepare_features_improved(data)

            if len(features) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'final_confidence': 0.0,
                    'error': 'æ— æ³•æå–ç‰¹å¾'
                }

            # ä½¿ç”¨æœ€æ–°æ•°æ®è¿›è¡Œé¢„æµ‹
            latest_features = features[-1:].reshape(1, -1)

            # è·å–é¢„æµ‹æ¦‚ç‡ï¼ˆä¸ä½¿ç”¨predictæ–¹æ³•ï¼Œé¿å…å†…ç½®é˜ˆå€¼å½±å“ï¼‰
            prediction_proba = self.model.predict_proba(latest_features)[0]

            # è·å–åŸå§‹ç½®ä¿¡åº¦ï¼ˆä¸å†è¿›è¡Œå¹³æ»‘å¤„ç†ï¼‰
            raw_confidence = prediction_proba[1] if len(prediction_proba) > 1 else 0.0

            # ç›´æ¥ä½¿ç”¨åŸå§‹ç½®ä¿¡åº¦ï¼Œä¸è¿›è¡Œå¹³æ»‘å¤„ç†
            final_confidence = raw_confidence

            # ä½¿ç”¨é…ç½®çš„é˜ˆå€¼å’ŒåŸå§‹ç½®ä¿¡åº¦è¿›è¡Œæœ€ç»ˆé¢„æµ‹
            confidence_config = self.config.get('strategy', {}).get('confidence_weights', {})
            final_threshold = confidence_config.get('final_threshold', 0.5)

            # åŸºäºåŸå§‹ç½®ä¿¡åº¦å’Œé…ç½®é˜ˆå€¼è¿›è¡Œé¢„æµ‹
            is_low_point = final_confidence >= final_threshold

            result = {
                'is_low_point': bool(is_low_point),
                'confidence': float(raw_confidence),
                'final_confidence': float(final_confidence),  # ç°åœ¨ç­‰äºåŸå§‹ç½®ä¿¡åº¦
                'prediction_proba': prediction_proba.tolist(),
                'feature_count': len(feature_names),
                'model_type': type(self.model.named_steps['classifier']).__name__,
                'threshold_used': final_threshold
            }

            # è¾“å‡ºé¢„æµ‹ç»“æœ
            self.logger.info("----------------------------------------------------")
            self.logger.info("AIé¢„æµ‹ç»“æœï¼ˆæ— å¹³æ»‘ï¼‰: \033[1m%s\033[0m",
                             "ç›¸å¯¹ä½ç‚¹" if is_low_point else "éç›¸å¯¹ä½ç‚¹")
            self.logger.info("åŸå§‹ç½®ä¿¡åº¦: \033[1m%.4f\033[0m, é˜ˆå€¼: \033[1m%.2f\033[0m",
                             raw_confidence, final_threshold)
            self.logger.info("----------------------------------------------------")

            return result

        except Exception as e:
            self.logger.error(f"é¢„æµ‹ç›¸å¯¹ä½ç‚¹å¤±è´¥: {e}")
            return {
                'is_low_point': False,
                'confidence': 0.0,
                'final_confidence': 0.0,
                'error': str(e)
            }

    def _prepare_labels(self, data: pd.DataFrame, strategy_module) -> np.ndarray:
        """å‡†å¤‡æ ‡ç­¾"""
        # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿æ•°æ®åŒ…å«æŠ€æœ¯æŒ‡æ ‡
        if 'rsi' not in data.columns or 'macd' not in data.columns:
            self.logger.warning("æ•°æ®ç¼ºå°‘æŠ€æœ¯æŒ‡æ ‡ï¼Œè·³è¿‡é¢„å¤„ç†...")
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å‡è®¾å¤–éƒ¨å·²ç»å¤„ç†äº†æ•°æ®é¢„å¤„ç†
            # å¦‚æœç¡®å®éœ€è¦åœ¨è¿™é‡Œå¤„ç†ï¼Œå¯ä»¥æ·»åŠ æ•°æ®æ¨¡å—è°ƒç”¨

        backtest_results = strategy_module.backtest(data)
        return backtest_results['is_low_point'].astype(int).values

    def _calculate_sample_weights(self, dates: pd.Series) -> np.ndarray:
        """
        è®¡ç®—åŸºäºæ—¶é—´è¡°å‡çš„æ ·æœ¬æƒé‡
        
        å‚æ•°:
        dates: æ—¥æœŸåºåˆ—ï¼Œå¿…é¡»æ˜¯datetimeç±»å‹
        
        è¿”å›:
        np.ndarray: æ ·æœ¬æƒé‡æ•°ç»„ï¼Œè¶Šæ–°çš„æ•°æ®æƒé‡è¶Šé«˜
        
        å¼‚å¸¸:
        ValueError: å½“datesä¸æ˜¯datetimeç±»å‹æˆ–ä¸ºç©ºæ—¶
        """
        if len(dates) == 0:
            raise ValueError("æ—¥æœŸåºåˆ—ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—æ ·æœ¬æƒé‡")

        # ä¸¥æ ¼æ£€æŸ¥æ•°æ®ç±»å‹ï¼šåªæ¥å—datetimeç±»å‹
        if not pd.api.types.is_datetime64_any_dtype(dates):
            raise ValueError(f"æ ·æœ¬æƒé‡è®¡ç®—è¦æ±‚datetimeç±»å‹çš„æ—¥æœŸæ•°æ®ï¼Œå®é™…ç±»å‹: {dates.dtype}")

        # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºå€¼
        if dates.isnull().any():
            raise ValueError("æ—¥æœŸåºåˆ—åŒ…å«ç©ºå€¼ï¼Œæ— æ³•è®¡ç®—å‡†ç¡®çš„æ ·æœ¬æƒé‡")

        # è®¡ç®—æ—¶é—´è¡°å‡æƒé‡
        latest_date = dates.max()
        decay_rate = self.config.get("ai", {}).get("data_decay_rate", 0.4)

        weights = np.zeros(len(dates))
        for i, date in enumerate(dates):
            time_diff_days = (latest_date - date).days
            if time_diff_days < 0:
                raise ValueError(f"å‘ç°æœªæ¥æ—¥æœŸ: {date} > {latest_date}")

            time_diff_years = time_diff_days / 365.25
            weight = np.exp(-decay_rate * time_diff_years)
            weights[i] = weight

        # éªŒè¯æƒé‡è®¡ç®—ç»“æœ
        if np.any(weights <= 0) or np.any(np.isnan(weights)) or np.any(np.isinf(weights)):
            raise ValueError("æ ·æœ¬æƒé‡è®¡ç®—ç»“æœå¼‚å¸¸ï¼ŒåŒ…å«éæ­£å€¼æˆ–NaN/Inf")

        return weights

    def _save_model(self) -> bool:
        """ä¿å­˜æ¨¡å‹"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

            # ä¿å­˜æ¨¡å‹
            model_path = os.path.join(self.models_dir, f'improved_model_{timestamp}.pkl')
            with open(model_path, 'wb') as f:
                pickle.dump({
                    'model': self.model,
                    'feature_names': self.feature_names,
                    'incremental_count': self.incremental_count,
                    'scaler': self.scaler
                }, f)

            # ä¿å­˜æœ€æ–°æ¨¡å‹è·¯å¾„
            latest_path = os.path.join(self.models_dir, 'latest_improved_model.txt')
            with open(latest_path, 'w') as f:
                f.write(model_path)

            self.logger.info(f"æ”¹è¿›æ¨¡å‹ä¿å­˜æˆåŠŸ: {model_path}")
            return True

        except Exception as e:
            self.logger.error(f"ä¿å­˜æ”¹è¿›æ¨¡å‹å¤±è´¥: {e}")
            return False

    def _load_model(self) -> bool:
        """åŠ è½½æ¨¡å‹ï¼ˆå®‰å…¨ç‰ˆæœ¬ï¼‰"""
        try:
            latest_path = os.path.join(self.models_dir, 'latest_improved_model.txt')

            if not os.path.exists(latest_path):
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„æ”¹è¿›æ¨¡å‹")
                return False

            with open(latest_path, 'r') as f:
                model_path = f.read().strip()

            # å®‰å…¨æ£€æŸ¥ï¼šéªŒè¯æ¨¡å‹æ–‡ä»¶è·¯å¾„
            if not os.path.abspath(model_path).startswith(os.path.abspath(self.models_dir)):
                self.logger.error(f"æ¨¡å‹æ–‡ä»¶è·¯å¾„ä¸å®‰å…¨: {model_path}")
                return False

            # å®‰å…¨æ£€æŸ¥ï¼šéªŒè¯æ–‡ä»¶å¤§å°ï¼ˆé˜²æ­¢è¿‡å¤§çš„æ¶æ„æ–‡ä»¶ï¼‰
            max_file_size = 500 * 1024 * 1024  # 500MBé™åˆ¶
            if os.path.getsize(model_path) > max_file_size:
                self.logger.error(f"æ¨¡å‹æ–‡ä»¶è¿‡å¤§ï¼Œå¯èƒ½å­˜åœ¨å®‰å…¨é£é™©: {model_path}")
                return False

            with open(model_path, 'rb') as f:
                # ä½¿ç”¨å—é™çš„pickleåŠ è½½å™¨ï¼ˆé™åˆ¶å¯å¯¼å…¥çš„æ¨¡å—ï¼‰
                import pickle
                import builtins

                # åˆ›å»ºå®‰å…¨çš„unpickler
                logger = self.logger  # ä¿å­˜loggerå¼•ç”¨

                class SafeUnpickler(pickle.Unpickler):
                    def find_class(self, module, name):
                        # åªå…è®¸åŠ è½½ç‰¹å®šçš„å®‰å…¨æ¨¡å—
                        safe_modules = {
                            'sklearn.ensemble._forest',
                            'sklearn.ensemble',
                            'sklearn.pipeline',
                            'sklearn.preprocessing._data',
                            'sklearn.preprocessing',
                            'numpy',
                            'pandas.core.frame',
                            'pandas',
                            'builtins'
                        }

                        if module in safe_modules or module.startswith('numpy') or module.startswith('sklearn'):
                            return getattr(__import__(module, fromlist=[name]), name)
                        else:
                            logger.warning(f"æ‹’ç»åŠ è½½ä¸å®‰å…¨çš„æ¨¡å—: {module}.{name}")
                            raise pickle.PicklingError(f"Unsafe module: {module}")

                # ä½¿ç”¨å®‰å…¨çš„unpickleråŠ è½½æ•°æ®
                safe_unpickler = SafeUnpickler(f)
                data = safe_unpickler.load()

                # éªŒè¯åŠ è½½çš„æ•°æ®ç»“æ„
                required_keys = ['model', 'feature_names']
                if not isinstance(data, dict) or not all(key in data for key in required_keys):
                    self.logger.error("æ¨¡å‹æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
                    return False

                self.model = data['model']
                self.feature_names = data['feature_names']
                self.incremental_count = data.get('incremental_count', 0)
                self.scaler = data.get('scaler')

            self.logger.info(f"æ”¹è¿›æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
            return True

        except Exception as e:
            self.logger.error(f"åŠ è½½æ”¹è¿›æ¨¡å‹å¤±è´¥: {e}")
            return False

    def get_feature_importance(self) -> Dict[str, float]:
        """
        è·å–ç‰¹å¾é‡è¦æ€§
        
        è¿”å›:
        dict: ç‰¹å¾é‡è¦æ€§å­—å…¸ï¼ŒæŒ‰é‡è¦æ€§é™åºæ’åˆ—
        """
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    self.logger.error("æ— æ³•è·å–ç‰¹å¾é‡è¦æ€§ï¼šæ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½")
                    return {}

            if self.feature_names is None:
                self.logger.error("ç‰¹å¾åç§°æœªè®¾ç½®ï¼Œæ— æ³•è·å–ç‰¹å¾é‡è¦æ€§")
                return {}

            # ä»Pipelineä¸­è·å–åˆ†ç±»å™¨
            if hasattr(self.model, 'named_steps') and 'classifier' in self.model.named_steps:
                classifier = self.model.named_steps['classifier']
            else:
                # å¦‚æœæ¨¡å‹ä¸æ˜¯Pipelineï¼Œç›´æ¥ä½¿ç”¨
                classifier = self.model

            # æ£€æŸ¥åˆ†ç±»å™¨æ˜¯å¦æœ‰feature_importances_å±æ€§
            if hasattr(classifier, 'feature_importances_'):
                importances = classifier.feature_importances_

                # åˆ›å»ºç‰¹å¾é‡è¦æ€§å­—å…¸
                feature_importance = dict(zip(self.feature_names, importances))

                # æŒ‰é‡è¦æ€§é™åºæ’åˆ—
                sorted_importance = dict(sorted(
                    feature_importance.items(),
                    key=lambda x: x[1],
                    reverse=True
                ))

                self.logger.info(f"æˆåŠŸè·å– {len(sorted_importance)} ä¸ªç‰¹å¾çš„é‡è¦æ€§")
                return sorted_importance
            else:
                self.logger.warning(f"åˆ†ç±»å™¨ {type(classifier).__name__} ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§")
                return {}

        except Exception as e:
            self.logger.error(f"è·å–ç‰¹å¾é‡è¦æ€§å¤±è´¥: {e}")
            return {}

    def run_complete_optimization(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„AIä¼˜åŒ–æµç¨‹ï¼ˆåŒ…å«å‚æ•°ä¼˜åŒ– + æ¨¡å‹è®­ç»ƒï¼‰
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—
        
        è¿”å›:
        dict: ä¼˜åŒ–ç»“æœ
        """
        from datetime import datetime
        complete_start_time = time.time()

        # åŒæ—¶ä½¿ç”¨printå’Œloggerç¡®ä¿è¾“å‡ºå¯è§
        current_time = datetime.now().strftime("%H:%M:%S")
        print(f"ğŸš€ å¼€å§‹å®Œæ•´çš„AIä¼˜åŒ–æµç¨‹ï¼ˆæ”¹è¿›ç‰ˆï¼‰ [{current_time}]")
        print("=" * 80)
        self.logger.info("ğŸš€ å¼€å§‹å®Œæ•´çš„AIä¼˜åŒ–æµç¨‹ï¼ˆæ”¹è¿›ç‰ˆï¼‰")
        self.logger.info("=" * 80)

        try:
            optimization_result = {
                'success': False,
                'strategy_optimization': {},
                'model_training': {},
                'final_evaluation': {},
                'errors': []
            }

            # æ­¥éª¤é¢„è§ˆ
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ“‹ ä¼˜åŒ–æµç¨‹æ¦‚è§ˆ: [{current_time}]")
            print("   ğŸ”§ æ­¥éª¤A: ç­–ç•¥å‚æ•°ä¼˜åŒ– (é—ä¼ ç®—æ³•/ç½‘æ ¼æœç´¢)")
            print("   ğŸ¤– æ­¥éª¤B: æ”¹è¿›ç‰ˆæ¨¡å‹è®­ç»ƒ")
            print("   ğŸ“Š æ­¥éª¤C: æœ€ç»ˆæ€§èƒ½è¯„ä¼°")
            print("   ğŸ’¾ æ­¥éª¤D: ç»“æœä¿å­˜")
            print("-" * 80)

            # æ­¥éª¤A: ç­–ç•¥å‚æ•°ä¼˜åŒ–
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ”§ æ­¥éª¤A: ç­–ç•¥å‚æ•°ä¼˜åŒ– [{current_time}]")
            print("   ğŸ¯ ç›®æ ‡: å¯»æ‰¾æœ€ä¼˜ç­–ç•¥å‚æ•°ç»„åˆ")
            print("   ğŸ“Š æ–¹æ³•: é—ä¼ ç®—æ³•é«˜ç²¾åº¦ä¼˜åŒ–")
            
            # ğŸ”§ ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–å›ºå®šå‚æ•°å€¼
            strategy_config = self.config.get('strategy', {})
            fixed_rise_threshold = strategy_config.get('rise_threshold', 0.04)
            fixed_max_days = strategy_config.get('max_days', 20)
            print(f"   ğŸ”’ å›ºå®šå‚æ•°: rise_threshold={fixed_rise_threshold}, max_days={fixed_max_days}")

            # ğŸ”§ è·å–å½“å‰ç­–ç•¥åŸºå‡†å¾—åˆ†
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"   ğŸ“Š è¯„ä¼°å½“å‰ç­–ç•¥åŸºå‡†å¾—åˆ†... [{current_time}]")

            current_backtest = strategy_module.backtest(data)
            current_evaluation = strategy_module.evaluate_strategy(current_backtest)
            baseline_score = current_evaluation.get('score', 0)

            print(f"   ğŸ“ˆ å½“å‰ç­–ç•¥åŸºå‡†å¾—åˆ†: {baseline_score:.6f}")
            self.logger.info(f"å½“å‰ç­–ç•¥åŸºå‡†å¾—åˆ†: {baseline_score:.6f}")

            step_a_start = time.time()

            strategy_result = self.optimize_strategy_parameters_improved(strategy_module, data)
            step_a_time = time.time() - step_a_start
            optimization_result['strategy_optimization'] = strategy_result

            if strategy_result['success']:
                optimized_score = strategy_result.get('best_score', 0)

                # ğŸ¯ å…³é”®ä¿®å¤ï¼šåªæœ‰æ–°å¾—åˆ†æ›´é«˜æ‰æ›´æ–°ç­–ç•¥å‚æ•°
                if optimized_score > baseline_score:
                    # æ›´æ–°ç­–ç•¥æ¨¡å—å‚æ•°
                    strategy_module.update_params(strategy_result['best_params'])
                    score_improvement = optimized_score - baseline_score

                    current_time = datetime.now().strftime("%H:%M:%S")
                    print(f"âœ… æ­¥éª¤Aå®Œæˆ - ç­–ç•¥å¾—åˆ†æå‡! (è€—æ—¶: {step_a_time:.2f}s) [{current_time}]")
                    print(f"   ğŸ¯ ä¼˜åŒ–æ–¹æ³•: {strategy_result.get('optimization_method', 'unknown')}")
                    print(f"   ğŸ“ˆ ä¼˜åŒ–å‰å¾—åˆ†: {baseline_score:.6f}")
                    print(f"   ğŸ“ˆ ä¼˜åŒ–åå¾—åˆ†: {optimized_score:.6f}")
                    print(
                        f"   ğŸš€ å¾—åˆ†æå‡: +{score_improvement:.6f} ({(score_improvement / baseline_score * 100):.2f}%)")
                    print(f"   ğŸ“Š æµ‹è¯•é›†æˆåŠŸç‡: {strategy_result.get('test_success_rate', 0):.2%}")

                    self.logger.info(f"âœ… æ­¥éª¤Aå®Œæˆ - ç­–ç•¥å¾—åˆ†æå‡! (è€—æ—¶: {step_a_time:.2f}s)")
                    self.logger.info(f"   ğŸ“ˆ ä¼˜åŒ–å‰å¾—åˆ†: {baseline_score:.6f}")
                    self.logger.info(f"   ğŸ“ˆ ä¼˜åŒ–åå¾—åˆ†: {optimized_score:.6f}")
                    self.logger.info(f"   ğŸš€ å¾—åˆ†æå‡: +{score_improvement:.6f}")
                else:
                    # ä¼˜åŒ–å¾—åˆ†æœªè¶…è¿‡åŸºå‡†ï¼Œä¿æŒåŸå‚æ•°ä¸å˜
                    current_time = datetime.now().strftime("%H:%M:%S")
                    print(f"âš ï¸ æ­¥éª¤Aå®Œæˆä½†æ— æ”¹è¿› (è€—æ—¶: {step_a_time:.2f}s) - ä¿æŒåŸå‚æ•° [{current_time}]")
                    print(f"   ğŸ¯ ä¼˜åŒ–æ–¹æ³•: {strategy_result.get('optimization_method', 'unknown')}")
                    print(f"   ğŸ“ˆ å½“å‰å¾—åˆ†: {baseline_score:.6f}")
                    print(f"   ğŸ“ˆ ä¼˜åŒ–å¾—åˆ†: {optimized_score:.6f}")
                    print(f"   ğŸ“‰ æœªè¾¾åˆ°æ”¹è¿›é˜ˆå€¼ï¼Œä¿æŒåŸç­–ç•¥å‚æ•°")

                    self.logger.info(f"âš ï¸ æ­¥éª¤Aå®Œæˆä½†æ— æ”¹è¿› (è€—æ—¶: {step_a_time:.2f}s)")
                    self.logger.info(f"   ğŸ“ˆ å½“å‰å¾—åˆ†: {baseline_score:.6f} > ä¼˜åŒ–å¾—åˆ†: {optimized_score:.6f}")
                    optimization_result['errors'].append("ä¼˜åŒ–åå¾—åˆ†æœªè¶…è¿‡åŸºå‡†ï¼Œä¿æŒåŸå‚æ•°")

            else:
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"âš ï¸ æ­¥éª¤Aå¤±è´¥ (è€—æ—¶: {step_a_time:.2f}s) - ä½¿ç”¨é»˜è®¤å‚æ•°ç»§ç»­ [{current_time}]")
                self.logger.warning(f"âš ï¸ æ­¥éª¤Aå¤±è´¥ (è€—æ—¶: {step_a_time:.2f}s) - ä½¿ç”¨é»˜è®¤å‚æ•°ç»§ç»­")
                optimization_result['errors'].append("ç­–ç•¥å‚æ•°ä¼˜åŒ–å¤±è´¥")

            print("-" * 80)
            self.logger.info("-" * 80)

            # æ­¥éª¤B: æ”¹è¿›ç‰ˆæ¨¡å‹è®­ç»ƒ
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ¤– æ­¥éª¤B: æ”¹è¿›ç‰ˆæ¨¡å‹è®­ç»ƒ [{current_time}]")
            print("   ğŸ¯ ç›®æ ‡: è®­ç»ƒRandomForeståˆ†ç±»æ¨¡å‹")
            print("   âš™ï¸ é…ç½®: 150æ£µæ ‘, æ·±åº¦12, å¹³è¡¡æƒé‡")
            print("   ğŸ“Š æ•°æ®: ç‰¹å¾å·¥ç¨‹ + æ ·æœ¬æƒé‡ + æ ‡å‡†åŒ–")

            self.logger.info("ğŸ¤– æ­¥éª¤B: æ”¹è¿›ç‰ˆæ¨¡å‹è®­ç»ƒ")
            self.logger.info("   ğŸ¯ ç›®æ ‡: è®­ç»ƒRandomForeståˆ†ç±»æ¨¡å‹")
            self.logger.info("   âš™ï¸ é…ç½®: 150æ£µæ ‘, æ·±åº¦12, å¹³è¡¡æƒé‡")
            self.logger.info("   ğŸ“Š æ•°æ®: ç‰¹å¾å·¥ç¨‹ + æ ·æœ¬æƒé‡ + æ ‡å‡†åŒ–")
            step_b_start = time.time()

            model_result = self.full_train(data, strategy_module)
            step_b_time = time.time() - step_b_start
            optimization_result['model_training'] = model_result

            if model_result['success']:
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"âœ… æ­¥éª¤Bå®Œæˆ (è€—æ—¶: {step_b_time:.2f}s) [{current_time}]")
                print(f"   ğŸ“Š è®­ç»ƒæ ·æœ¬: {model_result.get('train_samples', 0):,}æ¡")
                print(f"   ğŸ“ˆ ç‰¹å¾æ•°é‡: {model_result.get('feature_count', 0)}ä¸ª")
                print(f"   ğŸ“Š æ­£æ ·æœ¬æ¯”ä¾‹: {model_result.get('positive_ratio', 0):.2%}")
                print(f"   ğŸ’¾ æ¨¡å‹ä¿å­˜: {'æˆåŠŸ' if model_result.get('save_success', False) else 'å¤±è´¥'}")

                self.logger.info(f"âœ… æ­¥éª¤Bå®Œæˆ (è€—æ—¶: {step_b_time:.2f}s)")
                self.logger.info(f"   ğŸ“Š è®­ç»ƒæ ·æœ¬: {model_result.get('train_samples', 0):,}æ¡")
                self.logger.info(f"   ğŸ“ˆ ç‰¹å¾æ•°é‡: {model_result.get('feature_count', 0)}ä¸ª")
                self.logger.info(f"   ğŸ“Š æ­£æ ·æœ¬æ¯”ä¾‹: {model_result.get('positive_ratio', 0):.2%}")
                self.logger.info(f"   ğŸ’¾ æ¨¡å‹ä¿å­˜: {'æˆåŠŸ' if model_result.get('save_success', False) else 'å¤±è´¥'}")
            else:
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"âŒ æ­¥éª¤Bå¤±è´¥ (è€—æ—¶: {step_b_time:.2f}s) [{current_time}]")
                self.logger.error(f"âŒ æ­¥éª¤Bå¤±è´¥ (è€—æ—¶: {step_b_time:.2f}s)")
                optimization_result['errors'].append("æ¨¡å‹è®­ç»ƒå¤±è´¥")

                # è®¡ç®—å·²è€—æ—¶é—´
                elapsed_time = time.time() - complete_start_time
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"ğŸ’” ä¼˜åŒ–æµç¨‹ä¸­æ–­ (å·²è¿è¡Œ: {elapsed_time:.2f}s) [{current_time}]")
                self.logger.error(f"ğŸ’” ä¼˜åŒ–æµç¨‹ä¸­æ–­ (å·²è¿è¡Œ: {elapsed_time:.2f}s)")
                return optimization_result

            print("-" * 80)
            self.logger.info("-" * 80)

            # æ­¥éª¤C: æœ€ç»ˆæ€§èƒ½è¯„ä¼°
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ“Š æ­¥éª¤C: æœ€ç»ˆæ€§èƒ½è¯„ä¼° [{current_time}]")
            print("   ğŸ¯ ç›®æ ‡: éªŒè¯æ•´ä½“ç³»ç»Ÿæ€§èƒ½")
            print("   ğŸ“Š æŒ‡æ ‡: ç­–ç•¥å¾—åˆ† + AIç½®ä¿¡åº¦ + è¯†åˆ«æ•ˆæœ")

            self.logger.info("ğŸ“Š æ­¥éª¤C: æœ€ç»ˆæ€§èƒ½è¯„ä¼°")
            self.logger.info("   ğŸ¯ ç›®æ ‡: éªŒè¯æ•´ä½“ç³»ç»Ÿæ€§èƒ½")
            self.logger.info("   ğŸ“Š æŒ‡æ ‡: ç­–ç•¥å¾—åˆ† + AIç½®ä¿¡åº¦ + è¯†åˆ«æ•ˆæœ")
            step_c_start = time.time()

            evaluation_result = self.evaluate_optimized_system(data, strategy_module)
            step_c_time = time.time() - step_c_start
            optimization_result['final_evaluation'] = evaluation_result

            if evaluation_result.get('success'):
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"âœ… æ­¥éª¤Cå®Œæˆ (è€—æ—¶: {step_c_time:.2f}s) [{current_time}]")
                print(f"   ğŸ¯ ç­–ç•¥å¾—åˆ†: {evaluation_result.get('strategy_score', 0):.4f}")
                print(f"   ğŸ“Š æˆåŠŸç‡: {evaluation_result.get('strategy_success_rate', 0):.2%}")
                print(f"   ğŸ” è¯†åˆ«ç‚¹æ•°: {evaluation_result.get('identified_points', 0)}")
                print(f"   ğŸ¤– AIç½®ä¿¡åº¦: {evaluation_result.get('ai_confidence', 0):.4f}")

                self.logger.info(f"âœ… æ­¥éª¤Cå®Œæˆ (è€—æ—¶: {step_c_time:.2f}s)")
                self.logger.info(f"   ğŸ¯ ç­–ç•¥å¾—åˆ†: {evaluation_result.get('strategy_score', 0):.4f}")
                self.logger.info(f"   ğŸ“Š æˆåŠŸç‡: {evaluation_result.get('strategy_success_rate', 0):.2%}")
                self.logger.info(f"   ğŸ” è¯†åˆ«ç‚¹æ•°: {evaluation_result.get('identified_points', 0)}")
                self.logger.info(f"   ğŸ¤– AIç½®ä¿¡åº¦: {evaluation_result.get('ai_confidence', 0):.4f}")
            else:
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"âš ï¸ æ­¥éª¤Céƒ¨åˆ†å¤±è´¥ (è€—æ—¶: {step_c_time:.2f}s) [{current_time}]")
                self.logger.warning(f"âš ï¸ æ­¥éª¤Céƒ¨åˆ†å¤±è´¥ (è€—æ—¶: {step_c_time:.2f}s)")
                optimization_result['errors'].append("æœ€ç»ˆè¯„ä¼°éƒ¨åˆ†å¤±è´¥")

            print("-" * 80)
            self.logger.info("-" * 80)

            # æ­¥éª¤D: ä¿å­˜ä¼˜åŒ–ç»“æœ
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ’¾ æ­¥éª¤D: ä¿å­˜ä¼˜åŒ–ç»“æœ [{current_time}]")
            self.logger.info("ğŸ’¾ æ­¥éª¤D: ä¿å­˜ä¼˜åŒ–ç»“æœ")
            step_d_start = time.time()

            if strategy_result['success']:
                print("   ğŸ“ ä¿å­˜æœ€ä¼˜å‚æ•°åˆ°é…ç½®æ–‡ä»¶...")
                self.logger.info("   ğŸ“ ä¿å­˜æœ€ä¼˜å‚æ•°åˆ°é…ç½®æ–‡ä»¶...")
                self.save_optimized_params(strategy_result['best_params'])
                print("   âœ… å‚æ•°ä¿å­˜å®Œæˆ")
                self.logger.info("   âœ… å‚æ•°ä¿å­˜å®Œæˆ")
            else:
                print("   âš ï¸ è·³è¿‡å‚æ•°ä¿å­˜ (ç­–ç•¥ä¼˜åŒ–å¤±è´¥)")
                self.logger.info("   âš ï¸ è·³è¿‡å‚æ•°ä¿å­˜ (ç­–ç•¥ä¼˜åŒ–å¤±è´¥)")

            step_d_time = time.time() - step_d_start
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"âœ… æ­¥éª¤Då®Œæˆ (è€—æ—¶: {step_d_time:.2f}s) [{current_time}]")
            self.logger.info(f"âœ… æ­¥éª¤Då®Œæˆ (è€—æ—¶: {step_d_time:.2f}s)")

            # è®¾ç½®æœ€ç»ˆæˆåŠŸçŠ¶æ€å’Œæœ€ä½³å¾—åˆ†
            optimization_result['success'] = model_result['success']

            # è®¾ç½®æœ€ä½³å¾—åˆ† - ä¼˜å…ˆä½¿ç”¨ç­–ç•¥ä¼˜åŒ–çš„å¾—åˆ†
            if strategy_result.get('success') and 'best_score' in strategy_result:
                optimization_result['best_score'] = strategy_result['best_score']
            elif model_result.get('success') and 'score' in model_result:
                optimization_result['best_score'] = model_result['score']
            elif evaluation_result.get('success') and 'score' in evaluation_result:
                optimization_result['best_score'] = evaluation_result['score']
            else:
                optimization_result['best_score'] = 0.0

            # æ€»ç»“æŠ¥å‘Š
            total_time = time.time() - complete_start_time
            current_time = datetime.now().strftime("%H:%M:%S")
            print("=" * 80)
            print(f"ğŸ‰ å®Œæ•´AIä¼˜åŒ–æµç¨‹å®Œæˆ! [{current_time}]")
            print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}s ({total_time / 60:.1f}åˆ†é’Ÿ)")
            print("ğŸ“Š å„æ­¥éª¤è€—æ—¶åˆ†æ:")
            print(f"   ğŸ”§ ç­–ç•¥ä¼˜åŒ–: {step_a_time:.2f}s ({(step_a_time / total_time) * 100:.1f}%)")
            print(f"   ğŸ¤– æ¨¡å‹è®­ç»ƒ: {step_b_time:.2f}s ({(step_b_time / total_time) * 100:.1f}%)")
            print(f"   ğŸ“Š æ€§èƒ½è¯„ä¼°: {step_c_time:.2f}s ({(step_c_time / total_time) * 100:.1f}%)")
            print(f"   ğŸ’¾ ç»“æœä¿å­˜: {step_d_time:.2f}s ({(step_d_time / total_time) * 100:.1f}%)")

            self.logger.info("=" * 80)
            self.logger.info("ğŸ‰ å®Œæ•´AIä¼˜åŒ–æµç¨‹å®Œæˆ!")
            self.logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}s ({total_time / 60:.1f}åˆ†é’Ÿ)")
            self.logger.info("ğŸ“Š å„æ­¥éª¤è€—æ—¶åˆ†æ:")
            self.logger.info(f"   ğŸ”§ ç­–ç•¥ä¼˜åŒ–: {step_a_time:.2f}s ({(step_a_time / total_time) * 100:.1f}%)")
            self.logger.info(f"   ğŸ¤– æ¨¡å‹è®­ç»ƒ: {step_b_time:.2f}s ({(step_b_time / total_time) * 100:.1f}%)")
            self.logger.info(f"   ğŸ“Š æ€§èƒ½è¯„ä¼°: {step_c_time:.2f}s ({(step_c_time / total_time) * 100:.1f}%)")
            self.logger.info(f"   ğŸ’¾ ç»“æœä¿å­˜: {step_d_time:.2f}s ({(step_d_time / total_time) * 100:.1f}%)")

            success_steps = sum([
                1 if strategy_result['success'] else 0,
                1 if model_result['success'] else 0,
                1 if evaluation_result.get('success', False) else 0
            ])
            print(f"âœ… æˆåŠŸæ­¥éª¤: {success_steps}/3")
            self.logger.info(f"âœ… æˆåŠŸæ­¥éª¤: {success_steps}/3")

            if optimization_result['errors']:
                print("âš ï¸ é‡åˆ°çš„é—®é¢˜:")
                self.logger.warning("âš ï¸ é‡åˆ°çš„é—®é¢˜:")
                for error in optimization_result['errors']:
                    print(f"   - {error}")
                    self.logger.warning(f"   - {error}")

            print("=" * 80)
            self.logger.info("=" * 80)
            return optimization_result

        except Exception as e:
            elapsed_time = time.time() - complete_start_time
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ’¥ å®Œæ•´AIä¼˜åŒ–æµç¨‹å¼‚å¸¸å¤±è´¥ (å·²è¿è¡Œ: {elapsed_time:.2f}s): {e} [{current_time}]")
            self.logger.error(f"ğŸ’¥ å®Œæ•´AIä¼˜åŒ–æµç¨‹å¼‚å¸¸å¤±è´¥ (å·²è¿è¡Œ: {elapsed_time:.2f}s): {e}")
            import traceback
            traceback_str = traceback.format_exc()
            print(f"å¼‚å¸¸è¯¦æƒ…: {traceback_str}")
            self.logger.error(f"å¼‚å¸¸è¯¦æƒ…: {traceback_str}")
            return {
                'success': False,
                'error': str(e),
                'strategy_optimization': {},
                'model_training': {},
                'final_evaluation': {},
                'elapsed_time': elapsed_time,
                'best_score': 0.0
            }

    def optimize_strategy_parameters_improved(self, strategy_module, data: pd.DataFrame) -> Dict[str, Any]:
        """
        æ”¹è¿›ç‰ˆç­–ç•¥å‚æ•°ä¼˜åŒ–ï¼ˆé›†æˆè´å¶æ–¯ä¼˜åŒ–å’Œé—ä¼ ç®—æ³•çš„é«˜ç²¾åº¦æ¨¡å¼ï¼‰
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–ç»“æœ
        """
        from datetime import datetime
        optimization_start_time = time.time()

        # åŒæ—¶ä½¿ç”¨printå’Œloggerç¡®ä¿è¾“å‡ºå¯è§
        current_time = datetime.now().strftime("%H:%M:%S")
        print(f"    ğŸš€ å¯åŠ¨ç­–ç•¥å‚æ•°ä¼˜åŒ–å­æµç¨‹ [{current_time}]")
        print(f"    ğŸ“Š æ•°æ®è§„æ¨¡: {len(data)} æ¡è®°å½•")

        self.logger.info("ğŸš€ å¼€å§‹æ”¹è¿›ç‰ˆç­–ç•¥å‚æ•°ä¼˜åŒ–ï¼ˆé›†æˆè´å¶æ–¯ä¼˜åŒ–å’Œé—ä¼ ç®—æ³•ï¼‰")
        self.logger.info("=" * 80)

        try:
            # æ­¥éª¤1: æ•°æ®åˆ†å‰²ä¸éªŒè¯
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    ğŸ“Š å­æ­¥éª¤1: æ•°æ®åˆ†å‰²ä¸éªŒè¯ [{current_time}]")
            self.logger.info("ğŸ“Š æ­¥éª¤1: æ•°æ®åˆ†å‰²ä¸éªŒè¯...")
            split_start_time = time.time()

            # ä½¿ç”¨é…ç½®ä¸­çš„æ•°æ®åˆ†å‰²æ¯”ä¾‹
            train_ratio = self.config.get('validation', {}).get('train_ratio', 0.7)
            validation_ratio = self.config.get('validation', {}).get('validation_ratio', 0.2)
            test_ratio = self.config.get('validation', {}).get('test_ratio', 0.1)

            # æ•°æ®åˆ†å‰²
            train_size = int(len(data) * train_ratio)
            val_size = int(len(data) * validation_ratio)

            train_data = data.iloc[:train_size].copy()
            validation_data = data.iloc[train_size:train_size + val_size].copy()
            test_data = data.iloc[train_size + val_size:].copy()

            split_time = time.time() - split_start_time

            print(f"    âœ… æ•°æ®åˆ†å‰²å®Œæˆ (è€—æ—¶: {split_time:.2f}s)")
            print(f"       ğŸ“Š è®­ç»ƒé›†: {len(train_data)}æ¡ ({train_ratio * 100:.1f}%)")
            print(f"       ğŸ“ˆ éªŒè¯é›†: {len(validation_data)}æ¡ ({validation_ratio * 100:.1f}%)")
            print(f"       ğŸ”’ æµ‹è¯•é›†: {len(test_data)}æ¡ ({test_ratio * 100:.1f}%)")

            self.logger.info(f"âœ… æ•°æ®åˆ†å‰²å®Œæˆ (è€—æ—¶: {split_time:.2f}s):")
            self.logger.info(f"   ğŸ“Š è®­ç»ƒé›†: {len(train_data)}æ¡ ({train_ratio * 100:.1f}%) - ä»…ç”¨äºå‚æ•°ä¼˜åŒ–")
            self.logger.info(
                f"   ğŸ“ˆ éªŒè¯é›†: {len(validation_data)}æ¡ ({validation_ratio * 100:.1f}%) - ç”¨äºæ¨¡å‹éªŒè¯å’Œè¿‡æ‹Ÿåˆæ£€æµ‹")
            self.logger.info(f"   ğŸ”’ æµ‹è¯•é›†: {len(test_data)}æ¡ ({test_ratio * 100:.1f}%) - å®Œå…¨é”å®šï¼Œä»…æœ€ç»ˆè¯„ä¼°")
            self.logger.info("-" * 50)

            # æ­¥éª¤2: é€‰æ‹©ä¼˜åŒ–æ–¹æ³•ï¼ˆä¼˜å…ˆè´å¶æ–¯ä¼˜åŒ–ï¼‰
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    ğŸ”§ å­æ­¥éª¤2: å‚æ•°ä¼˜åŒ–æ–¹æ³•é€‰æ‹© [{current_time}]")
            self.logger.info("ğŸ”§ æ­¥éª¤2: å‚æ•°ä¼˜åŒ–æ–¹æ³•é€‰æ‹©...")

            # æ£€æŸ¥é…ç½®
            bayesian_config = self.config.get('bayesian_optimization', {})
            bayesian_enabled = bayesian_config.get('enabled', True)
            genetic_config = self.config.get('genetic_algorithm', {})
            genetic_enabled = genetic_config.get('enabled', True)
            advanced_config = self.config.get('advanced_optimization', {})
            advanced_enabled = advanced_config.get('enabled', True)

            if not advanced_config:
                print("    âš ï¸ advanced_optimizationé…ç½®ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                self.logger.warning("advanced_optimizationé…ç½®ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼")

            best_params = {}
            best_score = -float('inf')
            optimization_method = 'unknown'

            # ğŸ”§ ä¿®å¤ï¼šä¿å­˜åˆå§‹ç­–ç•¥å‚æ•°ä½œä¸ºåŸºå‡†
            initial_params = strategy_module.get_current_params() if hasattr(strategy_module,
                                                                             'get_current_params') else {}
            if initial_params:
                # è¯„ä¼°åˆå§‹å‚æ•°ä½œä¸ºåŸºå‡†
                initial_backtest = strategy_module.backtest(train_data)
                initial_evaluation = strategy_module.evaluate_strategy(initial_backtest)
                initial_score = initial_evaluation.get('score', 0)

                best_params = initial_params.copy()
                best_score = initial_score

                print(f"    ğŸ“Š åˆå§‹å‚æ•°åŸºå‡†å¾—åˆ†: {initial_score:.6f}")
                self.logger.info(f"ğŸ“Š åˆå§‹å‚æ•°åŸºå‡†å¾—åˆ†: {initial_score:.6f}")

            # ğŸ”§ ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–å›ºå®šå‚æ•°å€¼
            strategy_config = self.config.get('strategy', {})
            fixed_rise_threshold = strategy_config.get('rise_threshold', 0.04)
            fixed_max_days = strategy_config.get('max_days', 20)
            
            print(f"   ğŸ”’ å›ºå®šå‚æ•°: rise_threshold={fixed_rise_threshold}, max_days={fixed_max_days}")
            self.logger.info(f"ğŸ”’ å›ºå®šå‚æ•°: rise_threshold={fixed_rise_threshold}, max_days={fixed_max_days}")

            # ä¼˜å…ˆå°è¯•è´å¶æ–¯ä¼˜åŒ–
            if bayesian_enabled and advanced_enabled:
                print("    ğŸ”¬ é€‰æ‹©è´å¶æ–¯ä¼˜åŒ–è¿›è¡Œé«˜ç²¾åº¦å‚æ•°ä¼˜åŒ–")
                print("    ğŸ¯ é…ç½®å‚æ•°: é«˜æ–¯è¿‡ç¨‹å›å½’ + æœŸæœ›æ”¹è¿›é‡‡é›†å‡½æ•°")
                print("    â³ é¢„è®¡è€—æ—¶: 10-20åˆ†é’Ÿï¼ˆæ™ºèƒ½æœç´¢ï¼‰")

                self.logger.info("ğŸ”¬ é€‰æ‹©è´å¶æ–¯ä¼˜åŒ–è¿›è¡Œé«˜ç²¾åº¦å‚æ•°ä¼˜åŒ–")
                bayesian_start_time = time.time()

                try:
                    # ä½¿ç”¨å‚æ•°ä¼˜åŒ–å™¨è¿›è¡Œè´å¶æ–¯ä¼˜åŒ–
                    from .parameter_optimizer import ParameterOptimizer
                    param_optimizer = ParameterOptimizer(self.config)

                    # ğŸ”§ å¯ç”¨å¤–éƒ¨å‚æ•°ç®¡ç†ï¼Œé¿å…parameter_optimizerå†…éƒ¨ç®¡ç†å‚æ•°
                    param_optimizer._external_best_management = True

                    # è·å–å‚æ•°èŒƒå›´
                    param_ranges = self._get_enhanced_parameter_ranges({})

                    # ğŸ”§ ä¸ºè´å¶æ–¯ä¼˜åŒ–å®ç°ç›¸åŒçš„å‚æ•°ç®¡ç†é€»è¾‘
                    current_best_params_in_bayesian = initial_params.copy()
                    current_best_score_in_bayesian = best_score

                    # å®šä¹‰è´å¶æ–¯ä¼˜åŒ–çš„è¯„ä¼°åŒ…è£…å‡½æ•°
                    original_evaluate = param_optimizer._evaluate_parameters

                    def bayesian_evaluate_wrapper(strategy_module, data, params):
                        nonlocal current_best_params_in_bayesian, current_best_score_in_bayesian

                        # è°ƒç”¨åŸå§‹è¯„ä¼°ï¼ˆç°åœ¨ä¼šæ¢å¤åŸå§‹å‚æ•°ï¼‰
                        score, metrics = original_evaluate(strategy_module, data, params)

                        # ğŸ¯ ä¿®å¤åçš„å‚æ•°ç®¡ç†é€»è¾‘ï¼šåªæœ‰æ›´ä¼˜å‚æ•°æ‰ä¿ç•™
                        if score > current_best_score_in_bayesian:
                            # æ–°å‚æ•°æ›´ä¼˜ï¼Œåº”ç”¨åˆ°ç­–ç•¥æ¨¡å—
                            prev_score = current_best_score_in_bayesian
                            strategy_module.update_params(params)
                            current_best_params_in_bayesian = params.copy()
                            current_best_score_in_bayesian = score
                            self.logger.info(f"è´å¶æ–¯ä¼˜åŒ–å‘ç°æ›´ä¼˜å‚æ•°: å¾—åˆ† {score:.6f} > {prev_score:.6f}")
                        else:
                            # æ–°å‚æ•°è¾ƒå·®ï¼Œç¡®ä¿ç­–ç•¥æ¨¡å—æ¢å¤åˆ°å½“å‰æœ€ä½³å‚æ•°
                            if current_best_params_in_bayesian:
                                strategy_module.update_params(current_best_params_in_bayesian)

                        return score, metrics

                    # æ›¿æ¢è¯„ä¼°å‡½æ•°
                    param_optimizer._evaluate_parameters = bayesian_evaluate_wrapper

                    # è¿è¡Œè´å¶æ–¯ä¼˜åŒ–
                    print(f"    ğŸš€ å¼€å§‹è´å¶æ–¯ä¼˜åŒ–å‚æ•°æœç´¢... [{datetime.now().strftime('%H:%M:%S')}]")
                    self.logger.info("ğŸš€ å¼€å§‹è´å¶æ–¯ä¼˜åŒ–å‚æ•°æœç´¢...")

                    bayesian_result = param_optimizer.optimize_parameters(
                        strategy_module, train_data, param_ranges,
                        method='bayesian', max_iterations=120
                    )

                    bayesian_time = time.time() - bayesian_start_time

                    if bayesian_result.get('success') and bayesian_result.get('best_params'):
                        # ğŸ”§ ä¿®å¤ï¼šè´å¶æ–¯ä¼˜åŒ–å·²ç»é€šè¿‡åŒ…è£…å‡½æ•°ç®¡ç†äº†æœ€ä½³å‚æ•°
                        # è·å–å½“å‰ç­–ç•¥æ¨¡å—ä¸­çš„å‚æ•°ï¼ˆåº”è¯¥æ˜¯æœ€ä½³çš„ï¼‰
                        final_bayesian_params = strategy_module.get_current_params() if hasattr(strategy_module,
                                                                                                'get_current_params') else \
                        bayesian_result['best_params']

                        # æœ€ç»ˆè¯„ä¼°è´å¶æ–¯ä¼˜åŒ–ç»“æœï¼ˆç­–ç•¥æ¨¡å—å·²ç»æ˜¯æœ€ä½³çŠ¶æ€ï¼‰
                        bayesian_backtest = strategy_module.backtest(train_data)
                        bayesian_evaluation = strategy_module.evaluate_strategy(bayesian_backtest)
                        bayesian_score = bayesian_evaluation.get('score', 0)

                        best_params = final_bayesian_params.copy()
                        best_score = bayesian_score
                        optimization_method = 'bayesian_optimization'

                        current_time = datetime.now().strftime("%H:%M:%S")
                        print(f"    ğŸ”¬ è´å¶æ–¯ä¼˜åŒ–å®Œæˆ (è€—æ—¶: {bayesian_time:.2f}s) [{current_time}]")
                        print(f"       ğŸ“ˆ æœ€ä¼˜å¾—åˆ†: {bayesian_score:.6f}")
                        print(f"       ğŸ“Š æˆåŠŸç‡: {bayesian_evaluation.get('success_rate', 0):.2%}")
                        print(f"       ğŸ” è¯†åˆ«ç‚¹æ•°: {bayesian_evaluation.get('total_points', 0)}")
                        print(f"       ğŸ“ˆ å¹³å‡æ¶¨å¹…: {bayesian_evaluation.get('avg_rise', 0):.2%}")
                        print(
                            f"       ğŸ”§ æ”¶æ•›ä¿¡æ¯: {bayesian_result.get('convergence_info', {}).get('n_calls', 0)} æ¬¡å‡½æ•°è°ƒç”¨")

                        self.logger.info(f"ğŸ”¬ è´å¶æ–¯ä¼˜åŒ–å®Œæˆ (è€—æ—¶: {bayesian_time:.2f}s)")
                        self.logger.info(f"   æœ€ä¼˜å¾—åˆ†: {bayesian_score:.6f}")
                        self.logger.info(f"   æˆåŠŸç‡: {bayesian_evaluation.get('success_rate', 0):.2%}")
                        self.logger.info(f"   è¯†åˆ«ç‚¹æ•°: {bayesian_evaluation.get('total_points', 0)}")
                        self.logger.info(f"   å¹³å‡æ¶¨å¹…: {bayesian_evaluation.get('avg_rise', 0):.2%}")
                    else:
                        print("    âš ï¸ è´å¶æ–¯ä¼˜åŒ–æœªæ‰¾åˆ°æœ‰æ•ˆè§£ï¼Œå›é€€åˆ°é—ä¼ ç®—æ³•")
                        self.logger.warning("âš ï¸ è´å¶æ–¯ä¼˜åŒ–æœªæ‰¾åˆ°æœ‰æ•ˆè§£ï¼Œå›é€€åˆ°é—ä¼ ç®—æ³•")
                        bayesian_enabled = False

                except Exception as e:
                    print(f"    âŒ è´å¶æ–¯ä¼˜åŒ–å¤±è´¥: {e}ï¼Œå›é€€åˆ°é—ä¼ ç®—æ³•")
                    self.logger.error(f"âŒ è´å¶æ–¯ä¼˜åŒ–å¤±è´¥: {e}ï¼Œå›é€€åˆ°é—ä¼ ç®—æ³•")
                    bayesian_enabled = False

            # å¦‚æœè´å¶æ–¯ä¼˜åŒ–å¤±è´¥æˆ–æœªå¯ç”¨ï¼Œä½¿ç”¨é—ä¼ ç®—æ³•
            if (not bayesian_enabled or not best_params) and genetic_enabled and advanced_enabled:
                print("    ğŸ§¬ ä½¿ç”¨é—ä¼ ç®—æ³•è¿›è¡Œå‚æ•°ä¼˜åŒ–")
                print("    ğŸ¯ é…ç½®å‚æ•°: 200ä¸ªä½“ Ã— 20ä»£ = 4000æ¬¡è¯„ä¼°")
                print("    â³ é¢„è®¡è€—æ—¶: 15-30åˆ†é’Ÿï¼ˆè¿›åŒ–æœç´¢ï¼‰")

                self.logger.info("ğŸ§¬ ä½¿ç”¨é—ä¼ ç®—æ³•è¿›è¡Œå‚æ•°ä¼˜åŒ–")
                genetic_start_time = time.time()

                # ğŸ”§ å…³é”®ä¿®å¤ï¼šå®šä¹‰ä¸å½±å“ç­–ç•¥æ¨¡å—çŠ¶æ€çš„è¯„ä¼°å‡½æ•°
                current_best_params_in_genetic = initial_params.copy()
                current_best_score_in_genetic = best_score

                def evaluate_strategy_params(params):
                    nonlocal current_best_params_in_genetic, current_best_score_in_genetic

                    try:
                        # ğŸš¨ é‡è¦ï¼šæ·»åŠ å›ºå®šå‚æ•°ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
                        complete_params = params.copy()
                        complete_params['rise_threshold'] = fixed_rise_threshold  # ä»é…ç½®æ–‡ä»¶è¯»å–
                        complete_params['max_days'] = fixed_max_days  # ä»é…ç½®æ–‡ä»¶è¯»å–

                        # ğŸ”§ å…³é”®ä¿®å¤ï¼šä¿å­˜å½“å‰ç­–ç•¥æ¨¡å—çŠ¶æ€
                        original_params = strategy_module.get_current_params() if hasattr(strategy_module,
                                                                                          'get_current_params') else None

                        # ä¸´æ—¶åº”ç”¨å‚æ•°è¿›è¡Œè¯„ä¼°
                        print("    ä¸´æ—¶åº”ç”¨å‚æ•°è¿›è¡Œè¯„ä¼°")
                        strategy_module.update_params(complete_params)

                        # åœ¨è®­ç»ƒé›†ä¸Šè¯„ä¼°
                        backtest_results = strategy_module.backtest(train_data)
                        evaluation = strategy_module.evaluate_strategy(backtest_results)

                        # è®¡ç®—è¯„åˆ†
                        score = evaluation.get('score', 0)
                        success_rate = evaluation.get('success_rate', 0)
                        avg_rise = evaluation.get('avg_rise', 0)

                        # é«˜ç²¾åº¦è¯„åˆ†ï¼šæ›´é‡è§†æˆåŠŸç‡
                        final_score = (
                                success_rate * 0.7 +  # 70%æƒé‡ç»™æˆåŠŸç‡
                                min(avg_rise / 0.1, 1.0) * 0.2 +  # 20%æƒé‡ç»™æ¶¨å¹…ï¼ˆæœ€é«˜10%ï¼‰
                                score * 0.1  # 10%æƒé‡ç»™ç»¼åˆåˆ†
                        )
                        final_score = max(0.0, min(1.0, final_score))

                        # ğŸ¯ ä¿®å¤åçš„å‚æ•°ç®¡ç†é€»è¾‘ï¼šåªæœ‰æ›´å¥½çš„å‚æ•°æ‰ä¿ç•™åœ¨ç­–ç•¥æ¨¡å—ä¸­
                        if final_score > current_best_score_in_genetic:
                            # æ–°å‚æ•°æ›´å¥½ï¼Œä¿ç•™åœ¨ç­–ç•¥æ¨¡å—ä¸­
                            prev_score = current_best_score_in_genetic
                            current_best_params_in_genetic = complete_params.copy()
                            current_best_score_in_genetic = final_score
                            # ç­–ç•¥æ¨¡å—å·²ç»æ›´æ–°ä¸ºæ–°å‚æ•°ï¼Œä¸éœ€è¦é¢å¤–æ“ä½œ
                            self.logger.info(f"é—ä¼ ç®—æ³•å‘ç°æ›´ä¼˜å‚æ•°: å¾—åˆ† {final_score:.6f} > {prev_score:.6f}")
                        else:
                            # æ–°å‚æ•°è¾ƒå·®ï¼Œå¿…é¡»æ¢å¤åˆ°ä¹‹å‰çš„æœ€ä½³å‚æ•°
                            if current_best_params_in_genetic:
                                strategy_module.update_params(current_best_params_in_genetic)
                            else:
                                # å¦‚æœæ²¡æœ‰æœ€ä½³å‚æ•°ï¼Œæ¢å¤åˆ°åŸå§‹å‚æ•°
                                if original_params:
                                    strategy_module.update_params(original_params)

                        return final_score

                    except Exception as e:
                        self.logger.warning(f"å‚æ•°è¯„ä¼°å¤±è´¥: {e}")
                        # å‡ºé”™æ—¶æ¢å¤åˆ°æœ€ä½³å‚æ•°æˆ–åŸå§‹å‚æ•°
                        if current_best_params_in_genetic:
                            strategy_module.update_params(current_best_params_in_genetic)
                        elif original_params:
                            strategy_module.update_params(original_params)
                        return -1.0

                # è¿è¡Œé—ä¼ ç®—æ³•
                print(f"    ğŸ”¬ å¼€å§‹é—ä¼ ç®—æ³•å‚æ•°æœç´¢... [{datetime.now().strftime('%H:%M:%S')}]")
                self.logger.info("ğŸ”¬ å¼€å§‹é—ä¼ ç®—æ³•å‚æ•°æœç´¢...")
                genetic_params = self.run_genetic_algorithm(evaluate_strategy_params)
                genetic_time = time.time() - genetic_start_time

                if genetic_params:
                    # ğŸ”§ ä¿®å¤ï¼šé—ä¼ ç®—æ³•å·²ç»é€šè¿‡è¯„ä¼°å‡½æ•°ç®¡ç†äº†æœ€ä½³å‚æ•°
                    # è·å–é—ä¼ ç®—æ³•è¿‡ç¨‹ä¸­æ‰¾åˆ°çš„æœ€ä½³å‚æ•°ï¼ˆå·²ç»åœ¨ç­–ç•¥æ¨¡å—ä¸­ï¼‰
                    final_genetic_params = strategy_module.get_current_params() if hasattr(strategy_module,
                                                                                           'get_current_params') else genetic_params

                    # æœ€ç»ˆè¯„ä¼°é—ä¼ ç®—æ³•ç»“æœï¼ˆæ­¤æ—¶ç­–ç•¥æ¨¡å—å·²ç»æ˜¯æœ€ä½³çŠ¶æ€ï¼‰
                    genetic_backtest = strategy_module.backtest(train_data)
                    genetic_evaluation = strategy_module.evaluate_strategy(genetic_backtest)
                    genetic_score = genetic_evaluation.get('score', 0)

                    # å¦‚æœé—ä¼ ç®—æ³•ç»“æœæ›´å¥½ï¼Œæ›´æ–°å…¨å±€æœ€ä½³å‚æ•°
                    if genetic_score > best_score:
                        best_params = final_genetic_params.copy()  # ä½¿ç”¨é—ä¼ ç®—æ³•ç®¡ç†çš„æœ€ä½³å‚æ•°
                        best_score = genetic_score
                        optimization_method = 'genetic_algorithm'

                        print(f"    âœ… é—ä¼ ç®—æ³•æ‰¾åˆ°æ›´ä¼˜å‚æ•°! å¾—åˆ†æå‡: {best_score:.6f}")
                        self.logger.info(f"âœ… é—ä¼ ç®—æ³•æ‰¾åˆ°æ›´ä¼˜å‚æ•°! å¾—åˆ†æå‡: {best_score:.6f}")
                    else:
                        print(f"    âš ï¸ é—ä¼ ç®—æ³•ç»“æœæœªè¶…è¿‡å½“å‰æœ€ä¼˜ï¼Œæ¢å¤ä¹‹å‰æœ€ä½³å‚æ•°")
                        self.logger.info(f"âš ï¸ é—ä¼ ç®—æ³•ç»“æœæœªè¶…è¿‡å½“å‰æœ€ä¼˜ï¼Œæ¢å¤ä¹‹å‰æœ€ä½³å‚æ•°")
                        # æ¢å¤åˆ°ä¹‹å‰çš„æœ€ä½³å‚æ•°
                        strategy_module.update_params(best_params)

                    current_time = datetime.now().strftime("%H:%M:%S")
                    print(f"    ğŸ§¬ é—ä¼ ç®—æ³•å®Œæˆ (è€—æ—¶: {genetic_time:.2f}s) [{current_time}]")
                    print(f"       ğŸ“ˆ æœ€ä¼˜å¾—åˆ†: {genetic_score:.6f}")
                    print(f"       ğŸ“Š æˆåŠŸç‡: {genetic_evaluation.get('success_rate', 0):.2%}")
                    print(f"       ğŸ” è¯†åˆ«ç‚¹æ•°: {genetic_evaluation.get('total_points', 0)}")
                    print(f"       ğŸ“ˆ å¹³å‡æ¶¨å¹…: {genetic_evaluation.get('avg_rise', 0):.2%}")

                    self.logger.info(f"ğŸ§¬ é—ä¼ ç®—æ³•å®Œæˆ (è€—æ—¶: {genetic_time:.2f}s)")
                    self.logger.info(f"   æœ€ä¼˜å¾—åˆ†: {genetic_score:.6f}")
                    self.logger.info(f"   æˆåŠŸç‡: {genetic_evaluation.get('success_rate', 0):.2%}")
                    self.logger.info(f"   è¯†åˆ«ç‚¹æ•°: {genetic_evaluation.get('total_points', 0)}")
                    self.logger.info(f"   å¹³å‡æ¶¨å¹…: {genetic_evaluation.get('avg_rise', 0):.2%}")
                else:
                    print("    âš ï¸ é—ä¼ ç®—æ³•æœªæ‰¾åˆ°æœ‰æ•ˆè§£")
                    self.logger.warning("âš ï¸ é—ä¼ ç®—æ³•æœªæ‰¾åˆ°æœ‰æ•ˆè§£")

            # éªŒè¯æœ€ä½³å‚æ•°
            if not best_params:
                print("    âŒ æ‰€æœ‰ä¼˜åŒ–æ–¹æ³•éƒ½æœªæ‰¾åˆ°æœ‰æ•ˆå‚æ•°")
                return {
                    'success': False,
                    'error': 'æ‰€æœ‰ä¼˜åŒ–æ–¹æ³•éƒ½æœªæ‰¾åˆ°æœ‰æ•ˆå‚æ•°'
                }

            # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿ç­–ç•¥æ¨¡å—åº”ç”¨æœ€ç»ˆçš„æœ€ä½³å‚æ•°
            print(f"    ğŸ¯ åº”ç”¨æœ€ä½³å‚æ•°åˆ°ç­–ç•¥æ¨¡å— (å¾—åˆ†: {best_score:.6f})")
            self.logger.info(f"ğŸ¯ åº”ç”¨æœ€ä½³å‚æ•°åˆ°ç­–ç•¥æ¨¡å— (å¾—åˆ†: {best_score:.6f})")
            strategy_module.update_params(best_params)

            self.logger.info("-" * 60)

            # æ­¥éª¤3: éªŒè¯é›†éªŒè¯
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    ğŸ“ˆ å­æ­¥éª¤3: éªŒè¯é›†éªŒè¯ [{current_time}]")
            self.logger.info("ğŸ“ˆ æ­¥éª¤3: åœ¨éªŒè¯é›†ä¸ŠéªŒè¯æœ€ä½³å‚æ•°...")
            validation_start_time = time.time()

            val_backtest = strategy_module.backtest(validation_data)
            val_evaluation = strategy_module.evaluate_strategy(val_backtest)
            val_score = val_evaluation['score']
            val_success_rate = val_evaluation.get('success_rate', 0)
            val_total_points = val_evaluation.get('total_points', 0)
            val_avg_rise = val_evaluation.get('avg_rise', 0)

            validation_time = time.time() - validation_start_time

            # æ£€æŸ¥è¿‡æ‹Ÿåˆ
            overfitting_threshold = 0.8  # éªŒè¯é›†å¾—åˆ†åº”è¯¥è‡³å°‘æ˜¯è®­ç»ƒé›†å¾—åˆ†çš„80%
            overfitting_passed = val_score >= best_score * overfitting_threshold

            print(f"    âœ… éªŒè¯é›†è¯„ä¼°å®Œæˆ (è€—æ—¶: {validation_time:.2f}s)")
            print(f"       å¾—åˆ†: {val_score:.6f}")
            print(f"       æˆåŠŸç‡: {val_success_rate:.2%}")
            print(f"       è¯†åˆ«ç‚¹æ•°: {val_total_points}")
            print(f"       å¹³å‡æ¶¨å¹…: {val_avg_rise:.2%}")
            print(f"       è¿‡æ‹Ÿåˆæ£€æµ‹: {'âœ… é€šè¿‡' if overfitting_passed else 'âš ï¸ è­¦å‘Š'}")

            self.logger.info(f"âœ… éªŒè¯é›†è¯„ä¼°å®Œæˆ (è€—æ—¶: {validation_time:.2f}s)")
            self.logger.info(f"   å¾—åˆ†: {val_score:.6f}")
            self.logger.info(f"   æˆåŠŸç‡: {val_success_rate:.2%}")
            self.logger.info(f"   è¯†åˆ«ç‚¹æ•°: {val_total_points}")
            self.logger.info(f"   å¹³å‡æ¶¨å¹…: {val_avg_rise:.2%}")
            self.logger.info(f"   è¿‡æ‹Ÿåˆæ£€æµ‹: {'âœ… é€šè¿‡' if overfitting_passed else 'âš ï¸ è­¦å‘Š'}")
            self.logger.info("-" * 60)

            # æ­¥éª¤4: æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼°
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    ğŸ”’ å­æ­¥éª¤4: æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼° [{current_time}]")
            self.logger.info("ğŸ”’ æ­¥éª¤4: åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼°...")
            test_start_time = time.time()

            test_backtest = strategy_module.backtest(test_data)
            test_evaluation = strategy_module.evaluate_strategy(test_backtest)
            test_score = test_evaluation['score']
            test_success_rate = test_evaluation.get('success_rate', 0)
            test_total_points = test_evaluation.get('total_points', 0)
            test_avg_rise = test_evaluation.get('avg_rise', 0)

            test_time = time.time() - test_start_time

            # è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼ˆæ·»åŠ å®‰å…¨æ£€æŸ¥ï¼‰
            if val_score > 0.001:  # é¿å…é™¤é›¶é”™è¯¯
                generalization_ratio = test_score / val_score
            else:
                generalization_ratio = 0.0
                print("    âš ï¸ éªŒè¯é›†å¾—åˆ†è¿‡ä½ï¼Œæ— æ³•è®¡ç®—æ³›åŒ–æ¯”ç‡")
                self.logger.warning("éªŒè¯é›†å¾—åˆ†è¿‡ä½ï¼Œæ— æ³•è®¡ç®—æ³›åŒ–æ¯”ç‡")

            generalization_passed = generalization_ratio >= 0.85  # æµ‹è¯•é›†å¾—åˆ†åº”è¯¥æ¥è¿‘éªŒè¯é›†

            print(f"    âœ… æµ‹è¯•é›†è¯„ä¼°å®Œæˆ (è€—æ—¶: {test_time:.2f}s)")
            print(f"       å¾—åˆ†: {test_score:.6f}")
            print(f"       æˆåŠŸç‡: {test_success_rate:.2%}")
            print(f"       è¯†åˆ«ç‚¹æ•°: {test_total_points}")
            print(f"       å¹³å‡æ¶¨å¹…: {test_avg_rise:.2%}")
            print(
                f"       æ³›åŒ–èƒ½åŠ›: {'âœ… è‰¯å¥½' if generalization_passed else 'âš ï¸ ä¸€èˆ¬'} (æ¯”ç‡: {generalization_ratio:.3f})")

            self.logger.info(f"âœ… æµ‹è¯•é›†è¯„ä¼°å®Œæˆ (è€—æ—¶: {test_time:.2f}s)")
            self.logger.info(f"   å¾—åˆ†: {test_score:.6f}")
            self.logger.info(f"   æˆåŠŸç‡: {test_success_rate:.2%}")
            self.logger.info(f"   è¯†åˆ«ç‚¹æ•°: {test_total_points}")
            self.logger.info(f"   å¹³å‡æ¶¨å¹…: {test_avg_rise:.2%}")
            self.logger.info(
                f"   æ³›åŒ–èƒ½åŠ›: {'âœ… è‰¯å¥½' if generalization_passed else 'âš ï¸ ä¸€èˆ¬'} (æ¯”ç‡: {generalization_ratio:.3f})")

            # æ€»ç»“
            optimization_total_time = time.time() - optimization_start_time
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    ğŸ‰ ç­–ç•¥å‚æ•°ä¼˜åŒ–å­æµç¨‹å®Œæˆ! [{current_time}]")
            print(f"    â±ï¸ æ€»è€—æ—¶: {optimization_total_time:.2f}s ({optimization_total_time / 60:.1f}åˆ†é’Ÿ)")
            print(f"    ğŸ”§ ä¼˜åŒ–æ–¹æ³•: {optimization_method}")
            print(f"    ğŸ“Š ä¸‰å±‚éªŒè¯ç»“æœ:")
            print(f"       è®­ç»ƒé›†å¾—åˆ†: {best_score:.6f}")
            print(f"       éªŒè¯é›†å¾—åˆ†: {val_score:.6f} | æˆåŠŸç‡: {val_success_rate:.2%}")
            print(f"       æµ‹è¯•é›†å¾—åˆ†: {test_score:.6f} | æˆåŠŸç‡: {test_success_rate:.2%}")
            print(f"       ğŸ›¡ï¸ è¿‡æ‹Ÿåˆæ£€æµ‹: {'é€šè¿‡' if overfitting_passed else 'è­¦å‘Š'}")
            print(f"       ğŸ¯ æ³›åŒ–èƒ½åŠ›: {'è‰¯å¥½' if generalization_passed else 'ä¸€èˆ¬'}")

            self.logger.info("=" * 80)
            self.logger.info(f"ğŸ‰ ç­–ç•¥å‚æ•°ä¼˜åŒ–å®Œæˆ!")
            self.logger.info(f"â±ï¸ æ€»è€—æ—¶: {optimization_total_time:.2f}s ({optimization_total_time / 60:.1f}åˆ†é’Ÿ)")
            self.logger.info(f"ğŸ”§ ä¼˜åŒ–æ–¹æ³•: {optimization_method}")
            self.logger.info(f"ğŸ“Š ä¸‰å±‚éªŒè¯ç»“æœ:")
            self.logger.info(f"   è®­ç»ƒé›†å¾—åˆ†: {best_score:.6f}")
            self.logger.info(f"   éªŒè¯é›†å¾—åˆ†: {val_score:.6f} | æˆåŠŸç‡: {val_success_rate:.2%}")
            self.logger.info(f"   æµ‹è¯•é›†å¾—åˆ†: {test_score:.6f} | æˆåŠŸç‡: {test_success_rate:.2%}")
            self.logger.info(f"   ğŸ›¡ï¸ è¿‡æ‹Ÿåˆæ£€æµ‹: {'é€šè¿‡' if overfitting_passed else 'è­¦å‘Š'}")
            self.logger.info(f"   ğŸ¯ æ³›åŒ–èƒ½åŠ›: {'è‰¯å¥½' if generalization_passed else 'ä¸€èˆ¬'}")

            # å¦‚æœä½¿ç”¨äº†é—ä¼ ç®—æ³•ï¼Œè¾“å‡ºè¯¦ç»†çš„å‚æ•°ä¿¡æ¯
            if optimization_method == 'genetic_algorithm':
                print(f"    ğŸ§¬ é—ä¼ ç®—æ³•æœ€ä¼˜å‚æ•°è¯¦æƒ…:")
                self.logger.info(f"\nğŸ§¬ é—ä¼ ç®—æ³•æœ€ä¼˜å‚æ•°è¯¦æƒ…:")
                for param_name, param_value in best_params.items():
                    print(f"       {param_name}: {param_value}")
                    self.logger.info(f"   {param_name}: {param_value}")

            self.logger.info("=" * 80)

            return {
                'success': True,
                'best_params': best_params,
                'best_score': best_score,
                'validation_score': val_score,
                'validation_success_rate': val_success_rate,
                'validation_total_points': val_total_points,
                'validation_avg_rise': val_avg_rise,
                'test_score': test_score,
                'test_success_rate': test_success_rate,
                'test_total_points': test_total_points,
                'test_avg_rise': test_avg_rise,
                'overfitting_passed': overfitting_passed,
                'generalization_passed': generalization_passed,
                'generalization_ratio': generalization_ratio,
                'optimization_method': optimization_method,
                'optimization_time': optimization_total_time,
                'genetic_algorithm_used': optimization_method == 'genetic_algorithm'
            }

        except Exception as e:
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    âŒ ç­–ç•¥å‚æ•°ä¼˜åŒ–å¤±è´¥: {e} [{current_time}]")
            self.logger.error(f"ç­–ç•¥å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def _grid_search_optimization(self, strategy_module, train_data: pd.DataFrame, param_ranges: dict) -> tuple:
        """
        ç½‘æ ¼æœç´¢ä¼˜åŒ–
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—
        train_data: è®­ç»ƒæ•°æ®
        param_ranges: å‚æ•°èŒƒå›´
        
        è¿”å›:
        tuple: (æœ€ä½³å‚æ•°, æœ€ä½³å¾—åˆ†)
        """
        self.logger.info("å¼€å§‹ç½‘æ ¼æœç´¢ä¼˜åŒ–")

        # ğŸ”§ ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–å‚æ•°èŒƒå›´ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç 
        optimization_ranges = self.config.get('optimization_ranges', {})
        
        # è½¬æ¢é…ç½®æ–‡ä»¶æ ¼å¼ä¸ºæœç´¢æ ¼å¼
        default_ranges = {}
        for param_name, param_config in optimization_ranges.items():
            default_ranges[param_name] = {
                'min': param_config.get('min', 0),
                'max': param_config.get('max', 1),
                'step': param_config.get('step', 0.01)
            }

        # åˆå¹¶ç”¨æˆ·é…ç½®å’Œé»˜è®¤é…ç½®
        search_ranges = {**default_ranges, **param_ranges}

        # ç”Ÿæˆå‚æ•°ç»„åˆ
        param_combinations = []
        param_names = list(search_ranges.keys())

        def generate_range(param_config):
            start = param_config['min']
            end = param_config['max']
            step = param_config['step']
            return [start + i * step for i in range(int((end - start) / step) + 1)]

        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆï¼ˆé™åˆ¶æ•°é‡ä»¥é¿å…è¿‡é•¿æ—¶é—´ï¼‰
        ranges = [generate_range(search_ranges[param]) for param in param_names]
        all_combinations = list(product(*ranges))

        # é™åˆ¶æœç´¢æ•°é‡
        max_combinations = 50
        if len(all_combinations) > max_combinations:
            import random
            random.seed(42)
            all_combinations = random.sample(all_combinations, max_combinations)

        self.logger.info(f"å°†æµ‹è¯• {len(all_combinations)} ä¸ªå‚æ•°ç»„åˆ")

        best_score = -float('inf')
        best_params = {}

        for i, combination in enumerate(all_combinations):
            # æ„å»ºå‚æ•°å­—å…¸
            params = dict(zip(param_names, combination))

            try:
                # æ›´æ–°å‚æ•°å¹¶æµ‹è¯•
                strategy_module.update_params(params)
                backtest_results = strategy_module.backtest(train_data)
                evaluation = strategy_module.evaluate_strategy(backtest_results)
                score = evaluation['score']

                if score > best_score:
                    best_score = score
                    best_params = params.copy()

                if (i + 1) % 10 == 0:
                    self.logger.info(f"å·²æµ‹è¯• {i + 1}/{len(all_combinations)} ä¸ªç»„åˆï¼Œå½“å‰æœ€ä½³å¾—åˆ†: {best_score:.4f}")

            except Exception as e:
                self.logger.warning(f"å‚æ•°ç»„åˆ {params} æµ‹è¯•å¤±è´¥: {e}")
                continue

        self.logger.info(f"ç½‘æ ¼æœç´¢å®Œæˆï¼Œæœ€ä½³å¾—åˆ†: {best_score:.4f}")
        return best_params, best_score

    def evaluate_optimized_system(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        è¯„ä¼°ä¼˜åŒ–åçš„ç³»ç»Ÿ
        
        å‚æ•°:
        data: æµ‹è¯•æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—
        
        è¿”å›:
        dict: è¯„ä¼°ç»“æœ
        """
        self.logger.info("è¯„ä¼°ä¼˜åŒ–åçš„ç³»ç»Ÿ")

        try:
            # ç­–ç•¥è¯„ä¼°
            backtest_results = strategy_module.backtest(data)
            strategy_evaluation = strategy_module.evaluate_strategy(backtest_results)

            # AIæ¨¡å‹é¢„æµ‹è¯„ä¼°
            prediction_result = self.predict_low_point(data)

            return {
                'success': True,
                'strategy_score': strategy_evaluation['score'],
                'strategy_success_rate': strategy_evaluation['success_rate'],
                'identified_points': strategy_evaluation['total_points'],
                'avg_rise': strategy_evaluation['avg_rise'],
                'ai_confidence': prediction_result.get('final_confidence', 0),
                'ai_prediction': prediction_result.get('is_low_point', False)
            }

        except Exception as e:
            self.logger.error(f"ç³»ç»Ÿè¯„ä¼°å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def save_optimized_params(self, params: dict):
        """
        ä¿å­˜ä¼˜åŒ–åçš„å‚æ•°åˆ°é…ç½®æ–‡ä»¶ï¼ˆä¿ç•™æ³¨é‡Šç‰ˆï¼‰
        
        å‚æ•°:
        params: ä¼˜åŒ–åçš„å‚æ•°
        """
        try:
            # å°è¯•ä½¿ç”¨ä¿ç•™æ³¨é‡Šçš„ä¿å­˜å™¨
            try:
                from src.utils.config_saver import CommentPreservingConfigSaver
                saver = CommentPreservingConfigSaver()
                saver.save_optimized_parameters(params)
                self.logger.info("å‚æ•°å·²ä¿å­˜ï¼ˆä¿ç•™æ³¨é‡Šç‰ˆæœ¬ï¼‰")
                return
            except ImportError as e:
                self.logger.warning(f"ruamel.yamlæ¨¡å—æœªå®‰è£…ï¼Œä½¿ç”¨ä¼ ç»Ÿä¿å­˜æ–¹å¼: {e}")
            except Exception as e:
                self.logger.warning(f"ä¿ç•™æ³¨é‡Šç‰ˆæœ¬ä¿å­˜å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼: {e}")

            # ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼ä¿å­˜
            self._save_params_fallback(params)

        except Exception as e:
            self.logger.error(f"ä¿å­˜ä¼˜åŒ–å‚æ•°å¤±è´¥: {e}")
            raise

    def _save_params_fallback(self, params: dict):
        """
        ä¼ ç»Ÿçš„å‚æ•°ä¿å­˜æ–¹å¼ï¼ˆåŸå­æ€§å†™å…¥ï¼‰
        
        å‚æ•°:
        params: ä¼˜åŒ–åçš„å‚æ•°
        """
        import tempfile
        import shutil

        # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
        def convert_numpy_types(obj):
            if isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            elif isinstance(obj, tuple):
                return tuple(convert_numpy_types(item) for item in obj)
            else:
                return obj

        # è½¬æ¢å‚æ•°
        converted_params = convert_numpy_types(params)

        try:
            config_path = 'config/strategy.yaml'
            backup_path = f"{config_path}.backup"

            # åˆ›å»ºå¤‡ä»½
            if os.path.exists(config_path):
                shutil.copy2(config_path, backup_path)
                self.logger.info(f"å·²åˆ›å»ºé…ç½®æ–‡ä»¶å¤‡ä»½: {backup_path}")

            # è¯»å–ç°æœ‰é…ç½®
            config = {}
            if os.path.exists(config_path):
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config = yaml.safe_load(f) or {}
                except yaml.YAMLError as e:
                    self.logger.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
                    if os.path.exists(backup_path):
                        shutil.copy2(backup_path, config_path)
                        self.logger.info("å·²ä»å¤‡ä»½æ¢å¤é…ç½®æ–‡ä»¶")
                        with open(config_path, 'r', encoding='utf-8') as f:
                            config = yaml.safe_load(f) or {}

            # æ›´æ–°å‚æ•°
            for param_name, param_value in converted_params.items():
                if param_name == 'final_threshold':
                    if 'strategy' not in config:
                        config['strategy'] = {}
                    if 'confidence_weights' not in config['strategy']:
                        config['strategy']['confidence_weights'] = {}
                    config['strategy']['confidence_weights']['final_threshold'] = float(param_value)
                elif param_name in ['rsi_oversold_threshold', 'rsi_low_threshold']:
                    if 'strategy' not in config:
                        config['strategy'] = {}
                    if 'confidence_weights' not in config['strategy']:
                        config['strategy']['confidence_weights'] = {}
                    config['strategy']['confidence_weights'][param_name] = float(param_value)
                else:
                    # å…¶ä»–å‚æ•°æŒ‰åŸæœ‰é€»è¾‘å¤„ç†
                    if 'strategy' not in config:
                        config['strategy'] = {}

                    # ç±»å‹è½¬æ¢
                    if isinstance(param_value, (int, float)):
                        config['strategy'][param_name] = float(param_value)
                    else:
                        config['strategy'][param_name] = param_value

            # åŸå­æ€§å†™å…¥ï¼šå…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œå†ç§»åŠ¨
            with tempfile.NamedTemporaryFile(mode='w', encoding='utf-8',
                                             dir=os.path.dirname(config_path),
                                             delete=False) as temp_file:
                yaml.dump(config, temp_file, default_flow_style=False, allow_unicode=True)
                temp_path = temp_file.name

            # ç§»åŠ¨ä¸´æ—¶æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
            shutil.move(temp_path, config_path)

            self.logger.info(f"å‚æ•°å·²å®‰å…¨ä¿å­˜åˆ°é…ç½®æ–‡ä»¶: {len(converted_params)} ä¸ªå‚æ•°")

            # éªŒè¯ä¿å­˜æ˜¯å¦æˆåŠŸ
            if os.path.exists(config_path):
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        saved_config = yaml.safe_load(f)
                    # éªŒè¯å‚æ•°æ˜¯å¦æ­£ç¡®ä¿å­˜
                    saved_count = 0
                    for param_name in converted_params.keys():
                        if param_name == 'final_threshold':
                            if saved_config.get('strategy', {}).get('confidence_weights', {}).get(
                                    'final_threshold') is not None:
                                saved_count += 1
                        elif param_name in ['rsi_oversold_threshold', 'rsi_low_threshold']:
                            if saved_config.get('strategy', {}).get('confidence_weights', {}).get(
                                    param_name) is not None:
                                saved_count += 1
                        else:
                            if saved_config.get('strategy', {}).get(param_name) is not None:
                                saved_count += 1

                    self.logger.info(f"éªŒè¯æˆåŠŸ: {saved_count}/{len(converted_params)} ä¸ªå‚æ•°å·²æ­£ç¡®ä¿å­˜")

                    # æ¸…ç†æ—§å¤‡ä»½
                    if os.path.exists(backup_path):
                        os.remove(backup_path)
                except Exception as verify_error:
                    self.logger.warning(f"å‚æ•°ä¿å­˜éªŒè¯å¤±è´¥: {verify_error}")
            else:
                self.logger.error("é…ç½®æ–‡ä»¶ä¿å­˜åä¸å­˜åœ¨")

        except Exception as e:
            self.logger.error(f"ä¼ ç»Ÿæ–¹å¼ä¿å­˜å‚æ•°å¤±è´¥: {e}")
            # å°è¯•ä»å¤‡ä»½æ¢å¤
            if os.path.exists(backup_path):
                try:
                    shutil.copy2(backup_path, config_path)
                    self.logger.info("å·²ä»å¤‡ä»½æ¢å¤é…ç½®æ–‡ä»¶")
                except Exception as restore_error:
                    self.logger.error(f"å¤‡ä»½æ¢å¤å¤±è´¥: {restore_error}")
            raise

    def run_genetic_algorithm(self, evaluate_func, param_ranges=None) -> Dict[str, Any]:
        """
        é—ä¼ ç®—æ³•å‚æ•°ä¼˜åŒ–ï¼ˆé«˜ç²¾åº¦ç‰ˆæœ¬ï¼‰
        
        ä¸“ä¸ºé«˜å‡†ç¡®åº¦è®¾è®¡ï¼Œä¸è€ƒè™‘æ‰§è¡Œæ—¶é—´é™åˆ¶
        
        å‚æ•°:
        evaluate_func: è¯„ä¼°å‡½æ•°ï¼Œæ¥æ”¶å‚æ•°å­—å…¸ï¼Œè¿”å›è¯„åˆ†
        param_ranges: å‚æ•°èŒƒå›´å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶
        
        è¿”å›:
        dict: æœ€ä¼˜å‚æ•°å­—å…¸
        """
        from datetime import datetime

        print(f"        ğŸ§¬ åˆå§‹åŒ–é—ä¼ ç®—æ³• [{datetime.now().strftime('%H:%M:%S')}]")
        self.logger.info("ğŸ§¬ å¯åŠ¨é—ä¼ ç®—æ³•ä¼˜åŒ–ï¼ˆé«˜ç²¾åº¦æ¨¡å¼ï¼‰")
        start_time = time.time()

        try:
            # è·å–é—ä¼ ç®—æ³•é…ç½®ï¼ˆé’ˆå¯¹é«˜ç²¾åº¦è°ƒæ•´ï¼‰
            genetic_config = self.config.get('genetic_algorithm', {})

            # é«˜ç²¾åº¦é…ç½®ï¼šå¢åŠ ç§ç¾¤å’Œä»£æ•°
            population_size = genetic_config.get('population_size', 50)  # å¢åŠ åˆ°50
            generations = genetic_config.get('generations', 30)  # å¢åŠ åˆ°30
            crossover_rate = genetic_config.get('crossover_rate', 0.8)
            mutation_rate = genetic_config.get('mutation_rate', 0.15)  # ç¨å¾®æé«˜å˜å¼‚ç‡
            elite_ratio = genetic_config.get('elite_ratio', 0.1)  # ä¿ç•™10%ç²¾è‹±

            print(f"        ğŸ“Š é—ä¼ ç®—æ³•é…ç½®:")
            print(f"           ç§ç¾¤å¤§å°: {population_size} ä¸ªä½“")
            print(f"           è¿›åŒ–ä»£æ•°: {generations} ä»£")
            print(f"           äº¤å‰æ¦‚ç‡: {crossover_rate:.1%}")
            print(f"           å˜å¼‚æ¦‚ç‡: {mutation_rate:.1%}")
            print(f"           ç²¾è‹±æ¯”ä¾‹: {elite_ratio:.1%}")

            self.logger.info(f"é«˜ç²¾åº¦é—ä¼ ç®—æ³•é…ç½®: ç§ç¾¤{population_size}, ä»£æ•°{generations}")

            # è·å–æˆ–ç”Ÿæˆå‚æ•°èŒƒå›´
            if param_ranges is None:
                param_ranges = self._get_enhanced_parameter_ranges({})

            print(f"        ğŸ¯ ä¼˜åŒ–å‚æ•°æ•°é‡: {len(param_ranges)} ä¸ª")

            # åˆå§‹åŒ–ç§ç¾¤
            print(f"        ğŸŒ± ç”Ÿæˆåˆå§‹ç§ç¾¤... [{datetime.now().strftime('%H:%M:%S')}]")
            population = self._initialize_population(param_ranges, population_size)

            best_individual = None
            best_score = -float('inf')
            best_generation = 0
            stagnation_count = 0
            recent_generations = []

            print(f"        ğŸš€ å¼€å§‹è¿›åŒ–è¿‡ç¨‹ (æ€»è®¡ {population_size * generations} æ¬¡è¯„ä¼°)")
            total_evaluations = population_size * generations

            # æ”¶æ•›æ£€æµ‹ç›¸å…³å˜é‡
            convergence_history = []  # è®°å½•æœ€è¿‘å‡ ä»£çš„æ”¶æ•›ä¿¡æ¯
            convergence_threshold = 0.001  # æ”¶æ•›é˜ˆå€¼
            convergence_generations = 3  # è¿ç»­æ”¶æ•›ä»£æ•°è¦æ±‚

            # è¿›åŒ–ä¸»å¾ªç¯
            for generation in range(generations):
                generation_start_time = time.time()
                current_time = datetime.now().strftime("%H:%M:%S")

                print(
                    f"        ğŸ§¬ ç¬¬ {generation + 1}/{generations} ä»£è¿›åŒ– ({((generation + 1) / generations) * 100:.1f}% å®Œæˆ) [{current_time}]")
                self.logger.info(f"\nğŸ§¬ ç¬¬ {generation + 1}/{generations} ä»£è¿›åŒ– "
                                 f"({((generation + 1) / generations) * 100:.1f}% å®Œæˆ)")
                self.logger.info("------------------------------------------------------------")

                # è¯„ä¼°å½“å‰ç§ç¾¤
                scores = []
                valid_evaluations = 0
                failed_evaluations = 0

                # æ¯10ä¸ªä¸ªä½“æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦ï¼Œé¿å…è¿‡å¤šè¾“å‡º
                for i, individual in enumerate(population):
                    if (i + 1) % 10 == 0 or i == len(population) - 1:
                        current_progress = ((generation * population_size + i + 1) / total_evaluations) * 100
                        print(
                            f"        ğŸ” è¯„ä¼°è¿›åº¦: {i + 1}/{population_size} ä¸ªä½“ | æ€»è¿›åº¦: {current_progress:.1f}% | ç¬¬{generation + 1}ä»£")
                        self.logger.info(f"ğŸ” è¯„ä¼°è¿›åº¦: {i + 1}/{population_size} ä¸ªä½“ | "
                                         f"æ€»è¿›åº¦: {current_progress:.1f}% | ç¬¬{generation + 1}ä»£")

                    try:
                        score = evaluate_func(individual)
                        if score is not None and score >= 0:
                            scores.append(score)
                            valid_evaluations += 1
                        else:
                            scores.append(0.0)
                            failed_evaluations += 1
                    except Exception as e:
                        self.logger.warning(f"ä¸ªä½“è¯„ä¼°å¤±è´¥: {e}")
                        scores.append(0.0)
                        failed_evaluations += 1

                # æ›´æ–°å…¨å±€æœ€ä¼˜
                generation_best_idx = np.argmax(scores)
                generation_best_score = scores[generation_best_idx]

                if generation_best_score > best_score:
                    best_score = generation_best_score
                    best_individual = population[generation_best_idx].copy()
                    best_generation = generation + 1
                    stagnation_count = 0
                    print(f"        ğŸ‰ å‘ç°æ–°æœ€ä½³è§£! å¾—åˆ†: {best_score:.6f}")
                    self.logger.info(f"ğŸ‰ å‘ç°æ–°æœ€ä½³è§£! å¾—åˆ†: {best_score:.6f}")
                else:
                    stagnation_count += 1

                # ç»Ÿè®¡ä¿¡æ¯
                if len(scores) > 0:
                    max_score = max(scores)
                    avg_score = sum(scores) / len(scores)
                    min_score = min(scores)
                    std_score = np.std(scores)

                    generation_time = time.time() - generation_start_time

                    # é¢„è®¡å‰©ä½™æ—¶é—´
                    remaining_generations = generations - generation - 1
                    if generation > 0:
                        avg_generation_time = (time.time() - start_time) / (generation + 1)
                        estimated_remaining = remaining_generations * avg_generation_time
                    else:
                        estimated_remaining = remaining_generations * generation_time

                    print(f"        ğŸ“Š ç¬¬{generation + 1}ä»£ç»Ÿè®¡:")
                    print(f"           âœ… æœ‰æ•ˆä¸ªä½“: {valid_evaluations}/{population_size}")
                    print(f"           âŒ å¤±è´¥ä¸ªä½“: {failed_evaluations}")
                    print(f"           ğŸ“ˆ æœ€é«˜åˆ†: {max_score:.6f}")
                    print(f"           ğŸ“Š å¹³å‡åˆ†: {avg_score:.6f}")
                    print(f"           ğŸ“‰ æœ€ä½åˆ†: {min_score:.6f}")
                    print(f"           ğŸ“ æ ‡å‡†å·®: {std_score:.6f}")
                    print(f"           ğŸ† å†å²æœ€ä¼˜: {best_score:.6f}")
                    print(f"           â±ï¸ æœ¬ä»£è€—æ—¶: {generation_time:.2f}s")
                    print(f"           â³ é¢„è®¡å‰©ä½™æ—¶é—´: {estimated_remaining:.1f}s ({estimated_remaining / 60:.1f}åˆ†é’Ÿ)")

                    self.logger.info(f"ğŸ“Š ç¬¬{generation + 1}ä»£ç»Ÿè®¡:")
                    self.logger.info(f"   âœ… æœ‰æ•ˆä¸ªä½“: {valid_evaluations}/{population_size}")
                    self.logger.info(f"   âŒ å¤±è´¥ä¸ªä½“: {failed_evaluations}")
                    self.logger.info(f"   ğŸ“ˆ æœ€é«˜åˆ†: {max_score:.6f}")
                    self.logger.info(f"   ğŸ“Š å¹³å‡åˆ†: {avg_score:.6f}")
                    self.logger.info(f"   ğŸ“‰ æœ€ä½åˆ†: {min_score:.6f}")
                    self.logger.info(f"   ğŸ“ æ ‡å‡†å·®: {std_score:.6f}")
                    self.logger.info(f"   ğŸ† å†å²æœ€ä¼˜: {best_score:.6f}")
                    self.logger.info(f"   â±ï¸ æœ¬ä»£è€—æ—¶: {generation_time:.2f}s")
                    self.logger.info(
                        f"   â³ é¢„è®¡å‰©ä½™æ—¶é—´: {estimated_remaining:.1f}s ({estimated_remaining / 60:.1f}åˆ†é’Ÿ)")

                    # ä¿å­˜æœ€è¿‘å‡ ä»£çš„ç»Ÿè®¡ä¿¡æ¯
                    recent_generations.append({
                        'generation': generation + 1,
                        'max_score': max_score,
                        'avg_score': avg_score,
                        'std_score': std_score,
                        'best_score': best_score
                    })

                # æ¯5ä»£åˆ†æä¸€æ¬¡æ”¶æ•›è¶‹åŠ¿
                if (generation + 1) % 5 == 0 and len(recent_generations) >= 5:
                    self._log_genetic_statistics(recent_generations[-5:])

                # ğŸ”§ æ–°å¢ï¼šè¿ç»­3ä»£æ”¶æ•›æ£€æµ‹
                if len(recent_generations) >= 2:
                    # è®°å½•å½“å‰ä»£çš„æ”¶æ•›ä¿¡æ¯
                    current_convergence = {
                        'generation': generation + 1,
                        'best_score': best_score,
                        'max_score': max_score,
                        'std_score': std_score
                    }
                    convergence_history.append(current_convergence)

                    # ä¿æŒæœ€è¿‘çš„convergence_generationsä»£è®°å½•
                    if len(convergence_history) > convergence_generations:
                        convergence_history = convergence_history[-convergence_generations:]

                    # æ£€æµ‹æ˜¯å¦è¿ç»­æ”¶æ•›
                    if len(convergence_history) >= convergence_generations:
                        is_converged = self._check_convergence(convergence_history, convergence_threshold)

                        if is_converged:
                            print(f"        ğŸ¯ æ£€æµ‹åˆ°è¿ç»­{convergence_generations}ä»£æ”¶æ•›ï¼Œæå‰åœæ­¢ä¼˜åŒ–")
                            print(f"        ğŸ“Š æ”¶æ•›é˜ˆå€¼: {convergence_threshold:.6f}")
                            print(f"        ğŸ† æœ€ç»ˆå¾—åˆ†: {best_score:.6f}")

                            self.logger.info(f"ğŸ¯ æ£€æµ‹åˆ°è¿ç»­{convergence_generations}ä»£æ”¶æ•›ï¼Œæå‰åœæ­¢ä¼˜åŒ–")
                            self.logger.info(f"ğŸ“Š æ”¶æ•›é˜ˆå€¼: {convergence_threshold:.6f}")
                            self.logger.info(f"ğŸ† æœ€ç»ˆå¾—åˆ†: {best_score:.6f}")
                            break

                # å¦‚æœä¸æ˜¯æœ€åä¸€ä»£ï¼Œè¿›è¡Œè¿›åŒ–æ“ä½œ
                if generation < generations - 1:
                    evolution_start = time.time()
                    print(f"        ğŸ”„ å¼€å§‹ç¬¬{generation + 1}ä»£è¿›åŒ–æ“ä½œ... [{datetime.now().strftime('%H:%M:%S')}]")
                    self.logger.info(f"ğŸ”„ å¼€å§‹ç¬¬{generation + 1}ä»£è¿›åŒ–æ“ä½œ...")

                    # è¿›åŒ–ç§ç¾¤
                    population = self._evolve_population(
                        population, scores, param_ranges, population_size,
                        crossover_rate, mutation_rate, elite_ratio
                    )

                    evolution_time = time.time() - evolution_start
                    print(f"        âœ… è¿›åŒ–æ“ä½œå®Œæˆ (è€—æ—¶: {evolution_time:.2f}s)")
                    self.logger.info(f"âœ… è¿›åŒ–æ“ä½œå®Œæˆ (è€—æ—¶: {evolution_time:.2f}s)")

                # æå‰åœæ­¢æ¡ä»¶ï¼šè¿ç»­å¤šä»£æ— æ”¹å–„
                if stagnation_count >= 10:
                    print(f"        ğŸ›‘ è¿ç»­{stagnation_count}ä»£æ— æ”¹å–„ï¼Œæå‰åœæ­¢")
                    self.logger.info(f"è¿ç»­{stagnation_count}ä»£æ— æ”¹å–„ï¼Œæå‰åœæ­¢")
                    break

                print(f"        {'=' * 60}")
                self.logger.info("------------------------------------------------------------")

            total_time = time.time() - start_time
            current_time = datetime.now().strftime('%H:%M:%S')

            print(f"        ğŸ‰ é—ä¼ ç®—æ³•ä¼˜åŒ–å®Œæˆ! [{current_time}]")
            print(f"        â±ï¸ æ€»è€—æ—¶: {total_time:.2f}s ({total_time / 60:.1f}åˆ†é’Ÿ)")
            print(f"        ğŸ† æœ€ä¼˜å¾—åˆ†: {best_score:.6f}")
            print(f"        ğŸ“ æœ€ä½³ä»£æ•°: ç¬¬{best_generation}ä»£")

            if best_individual:
                print(f"        ğŸ”§ æœ€ä¼˜å‚æ•°:")
                for param_name, param_value in best_individual.items():
                    print(f"           {param_name}: {param_value}")

            self.logger.info("ğŸ‰ é—ä¼ ç®—æ³•ä¼˜åŒ–å®Œæˆ!")
            self.logger.info(f"æ€»è€—æ—¶: {total_time:.2f}s, æœ€ä¼˜å¾—åˆ†: {best_score:.6f}")
            self.logger.info(f"æœ€ä½³è§£åœ¨ç¬¬{best_generation}ä»£å‘ç°")

            return best_individual if best_individual else {}

        except Exception as e:
            current_time = datetime.now().strftime('%H:%M:%S')
            print(f"        âŒ é—ä¼ ç®—æ³•æ‰§è¡Œå¤±è´¥: {e} [{current_time}]")
            self.logger.error(f"é—ä¼ ç®—æ³•æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return {}

    def _get_enhanced_parameter_ranges(self, base_ranges: dict) -> dict:
        """
        è·å–å¢å¼ºçš„å‚æ•°èŒƒå›´ï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„èŒƒå›´ï¼‰
        
        å‚æ•°:
        base_ranges: åŸºç¡€å‚æ•°èŒƒå›´
        
        è¿”å›:
        dict: å¢å¼ºçš„å‚æ•°èŒƒå›´
        """
        # ğŸš¨ é‡è¦ï¼šå›ºå®šå‚æ•°ï¼Œä¸å‚ä¸é—ä¼ ç®—æ³•ä¼˜åŒ–
        # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–å›ºå®šå‚æ•°å€¼
        strategy_config = self.config.get('strategy', {})
        fixed_rise_threshold = strategy_config.get('rise_threshold', 0.04)
        fixed_max_days = strategy_config.get('max_days', 20)

        # ä»é…ç½®æ–‡ä»¶ä¸­è·å–å‚æ•°èŒƒå›´
        config = self.config
        strategy_ranges = config.get('strategy_ranges', {})
        optimization_ranges = config.get('optimization_ranges', {})

        enhanced_ranges = {}

        # æ·»åŠ strategy_rangesä¸­çš„å‚æ•°
        for param_name, param_config in strategy_ranges.items():
            # ğŸš¨ è·³è¿‡å›ºå®šå‚æ•°ï¼Œä¸å…è®¸ä¼˜åŒ–
            if param_name in ['rise_threshold', 'max_days']:
                self.logger.info(f"âš ï¸ è·³è¿‡å›ºå®šå‚æ•° {param_name}ï¼Œæ­¤å‚æ•°ä¸å‚ä¸ä¼˜åŒ–")
                continue

            # è½¬æ¢é…ç½®æ ¼å¼
            enhanced_ranges[param_name] = {
                'min': param_config.get('min', 0),
                'max': param_config.get('max', 1),
                'type': 'int' if param_name.endswith('_threshold') and 'rsi' in param_name else 'float',
                'precision': 4
            }

        # æ·»åŠ optimization_rangesä¸­çš„å‚æ•°
        for param_name, param_config in optimization_ranges.items():
            enhanced_ranges[param_name] = {
                'min': param_config.get('min', 0),
                'max': param_config.get('max', 1),
                'type': 'float',
                'precision': 4
            }

        # åˆå¹¶ç”¨æˆ·é…ç½®çš„èŒƒå›´ï¼ˆä½†æ’é™¤å›ºå®šå‚æ•°ï¼‰
        for param_name, param_config in base_ranges.items():
            # ğŸš¨ è·³è¿‡å›ºå®šå‚æ•°ï¼Œä¸å…è®¸ä¼˜åŒ–
            if param_name in ['rise_threshold', 'max_days']:
                self.logger.info(f"âš ï¸ è·³è¿‡å›ºå®šå‚æ•° {param_name}ï¼Œæ­¤å‚æ•°ä¸å‚ä¸ä¼˜åŒ–")
                continue

            if param_name in enhanced_ranges:
                # æ›´æ–°ç°æœ‰å‚æ•°èŒƒå›´
                enhanced_ranges[param_name].update(param_config)
            else:
                # æ·»åŠ æ–°å‚æ•°
                enhanced_ranges[param_name] = param_config.copy()
                enhanced_ranges[param_name]['type'] = 'float'  # é»˜è®¤ä¸ºæµ®ç‚¹æ•°
                enhanced_ranges[param_name]['precision'] = 4

        self.logger.info(f"ğŸ¯ å‚æ•°æœç´¢ç©ºé—´: {len(enhanced_ranges)} ä¸ªå‚æ•°")
        self.logger.info(f"ğŸ”’ å›ºå®šå‚æ•°: rise_threshold={fixed_rise_threshold}, max_days={fixed_max_days} (ä¸å‚ä¸ä¼˜åŒ–)")

        # è®°å½•å‚æ•°èŒƒå›´
        for param_name, param_config in enhanced_ranges.items():
            self.logger.info(f"   {param_name}: {param_config['min']} - {param_config['max']} ({param_config['type']})")

        return enhanced_ranges

    def _initialize_population(self, param_ranges: dict, population_size: int) -> List[Dict]:
        """
        åˆå§‹åŒ–ç§ç¾¤
        
        å‚æ•°:
        param_ranges: å‚æ•°èŒƒå›´
        population_size: ç§ç¾¤å¤§å°
        
        è¿”å›:
        List[Dict]: åˆå§‹ç§ç¾¤
        """
        if not param_ranges:
            raise ValueError("å‚æ•°èŒƒå›´ä¸èƒ½ä¸ºç©º")

        if population_size <= 0:
            raise ValueError(f"ç§ç¾¤å¤§å°å¿…é¡»å¤§äº0ï¼Œå½“å‰å€¼: {population_size}")

        population = []

        # éªŒè¯å‚æ•°èŒƒå›´çš„æœ‰æ•ˆæ€§
        for param_name, param_config in param_ranges.items():
            if 'min' not in param_config or 'max' not in param_config:
                raise ValueError(f"å‚æ•° {param_name} ç¼ºå°‘ min æˆ– max é…ç½®")

            min_val = param_config['min']
            max_val = param_config['max']

            if min_val >= max_val:
                raise ValueError(f"å‚æ•° {param_name} çš„æœ€å°å€¼({min_val})å¿…é¡»å°äºæœ€å¤§å€¼({max_val})")

        for _ in range(population_size):
            individual = {}
            for param_name, param_config in param_ranges.items():
                min_val = param_config['min']
                max_val = param_config['max']
                param_type = param_config.get('type', 'float')

                try:
                    if param_type == 'int':
                        # ç¡®ä¿æ•´æ•°èŒƒå›´æœ‰æ•ˆ
                        if max_val - min_val < 1:
                            individual[param_name] = min_val
                        else:
                            individual[param_name] = np.random.randint(min_val, max_val + 1)
                    else:  # float
                        individual[param_name] = np.random.uniform(min_val, max_val)
                        precision = param_config.get('precision', 4)
                        individual[param_name] = round(individual[param_name], precision)

                except Exception as e:
                    self.logger.error(f"åˆå§‹åŒ–å‚æ•° {param_name} å¤±è´¥: {e}")
                    # ä½¿ç”¨ä¸­é—´å€¼ä½œä¸ºé»˜è®¤å€¼
                    if param_type == 'int':
                        individual[param_name] = int((min_val + max_val) / 2)
                    else:
                        individual[param_name] = round((min_val + max_val) / 2,
                                                       param_config.get('precision', 4))

            population.append(individual)

        self.logger.info(f"âœ… åˆå§‹åŒ–ç§ç¾¤: {population_size} ä¸ªä¸ªä½“ï¼ŒåŒ…å« {len(param_ranges)} ä¸ªå‚æ•°")
        return population

    def _evolve_population(self, population: List[Dict], scores: List[float],
                           param_ranges: dict, population_size: int,
                           crossover_rate: float, mutation_rate: float,
                           elite_ratio: float) -> List[Dict]:
        """
        è¿›åŒ–ç§ç¾¤
        
        å‚æ•°:
        population: å½“å‰ç§ç¾¤
        scores: è¯„åˆ†åˆ—è¡¨
        param_ranges: å‚æ•°èŒƒå›´
        population_size: ç§ç¾¤å¤§å°
        crossover_rate: äº¤å‰æ¦‚ç‡
        mutation_rate: å˜å¼‚æ¦‚ç‡
        elite_ratio: ç²¾è‹±ä¿ç•™æ¯”ä¾‹
        
        è¿”å›:
        List[Dict]: æ–°ç§ç¾¤
        """
        # æ’åºä¸ªä½“ï¼ˆæŒ‰å¾—åˆ†é™åºï¼‰
        sorted_indices = np.argsort(scores)[::-1]
        sorted_population = [population[i] for i in sorted_indices]
        sorted_scores = [scores[i] for i in sorted_indices]

        # ç²¾è‹±ä¿ç•™ï¼ˆæ·±æ‹·è´ä»¥é¿å…å¼•ç”¨é—®é¢˜ï¼‰
        elite_count = int(population_size * elite_ratio)
        new_population = [individual.copy() for individual in sorted_population[:elite_count]]

        # ç”Ÿæˆå‰©ä½™ä¸ªä½“
        remaining_count = population_size - elite_count
        children_needed = remaining_count // 2 * 2  # ç¡®ä¿å¶æ•°ä¸ªå­ä»£

        for _ in range(children_needed // 2):
            # é€‰æ‹©çˆ¶æ¯ï¼ˆé”¦æ ‡èµ›é€‰æ‹©ï¼‰
            parent1 = self._tournament_selection(sorted_population, sorted_scores)
            parent2 = self._tournament_selection(sorted_population, sorted_scores)

            # äº¤å‰
            if np.random.random() < crossover_rate:
                child1, child2 = self._crossover(parent1, parent2, param_ranges)
            else:
                child1, child2 = parent1.copy(), parent2.copy()

            # å˜å¼‚ï¼ˆæ¯ä¸ªå­ä»£ç‹¬ç«‹å†³å®šæ˜¯å¦å˜å¼‚ï¼‰
            if np.random.random() < mutation_rate:
                child1 = self._mutate(child1, param_ranges)
            if np.random.random() < mutation_rate:
                child2 = self._mutate(child2, param_ranges)

            # æ·»åŠ åˆ°æ–°ç§ç¾¤
            new_population.extend([child1, child2])

        # å¦‚æœè¿˜éœ€è¦è¡¥å……ä¸ªä½“ï¼ˆå¥‡æ•°æƒ…å†µï¼‰
        while len(new_population) < population_size:
            parent = self._tournament_selection(sorted_population, sorted_scores)
            child = self._mutate(parent.copy(), param_ranges) if np.random.random() < mutation_rate else parent.copy()
            new_population.append(child)

        # ç¡®ä¿ç²¾ç¡®çš„ç§ç¾¤å¤§å°
        return new_population[:population_size]

    def _tournament_selection(self, population: List[Dict], scores: List[float],
                              tournament_size: int = 5) -> Dict:
        """
        é”¦æ ‡èµ›é€‰æ‹©
        
        å‚æ•°:
        population: ç§ç¾¤
        scores: è¯„åˆ†
        tournament_size: é”¦æ ‡èµ›å¤§å°
        
        è¿”å›:
        Dict: é€‰ä¸­çš„ä¸ªä½“
        """
        if not population or not scores:
            raise ValueError("ç§ç¾¤æˆ–è¯„åˆ†åˆ—è¡¨ä¸ºç©º")

        if len(population) != len(scores):
            raise ValueError(f"ç§ç¾¤å¤§å°({len(population)})ä¸è¯„åˆ†æ•°é‡({len(scores)})ä¸åŒ¹é…")

        # è¿‡æ»¤æœ‰æ•ˆçš„ä¸ªä½“ï¼ˆè¯„åˆ†ä¸æ˜¯è´Ÿæ— ç©·æˆ–NaNï¼‰
        valid_indices = [i for i, score in enumerate(scores)
                         if score != -float('inf') and not np.isnan(score)]

        if not valid_indices:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆä¸ªä½“ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª
            self.logger.warning("é”¦æ ‡èµ›é€‰æ‹©ï¼šæ²¡æœ‰æœ‰æ•ˆä¸ªä½“ï¼Œéšæœºé€‰æ‹©")
            return population[np.random.randint(len(population))].copy()

        # ä»æœ‰æ•ˆä¸ªä½“ä¸­è¿›è¡Œé”¦æ ‡èµ›é€‰æ‹©
        available_size = len(valid_indices)
        actual_tournament_size = min(tournament_size, available_size)

        tournament_indices = np.random.choice(valid_indices,
                                              size=actual_tournament_size,
                                              replace=False)

        # æ‰¾åˆ°æœ€ä½³ä¸ªä½“
        best_idx = max(tournament_indices, key=lambda i: scores[i])
        return population[best_idx].copy()

    def _crossover(self, parent1: Dict, parent2: Dict, param_ranges: dict) -> Tuple[Dict, Dict]:
        """
        äº¤å‰æ“ä½œï¼ˆç»Ÿä¸€äº¤å‰ + ç®—æœ¯äº¤å‰ï¼‰
        
        å‚æ•°:
        parent1: çˆ¶æ¯1
        parent2: çˆ¶æ¯2
        param_ranges: å‚æ•°èŒƒå›´
        
        è¿”å›:
        Tuple[Dict, Dict]: ä¸¤ä¸ªå­ä»£
        """
        # å‚æ•°ä¸€è‡´æ€§æ£€æŸ¥
        if set(parent1.keys()) != set(parent2.keys()):
            self.logger.warning("çˆ¶æ¯ä¸ªä½“å‚æ•°ä¸ä¸€è‡´ï¼Œä½¿ç”¨äº¤é›†")
            common_params = set(parent1.keys()) & set(parent2.keys())
        else:
            common_params = set(parent1.keys())

        child1, child2 = {}, {}

        for param_name in common_params:
            # ç¡®ä¿å‚æ•°åœ¨ä¸¤ä¸ªçˆ¶æ¯ä¸­éƒ½å­˜åœ¨
            if param_name not in parent2:
                child1[param_name] = parent1[param_name]
                child2[param_name] = parent1[param_name]
                continue

            if np.random.random() < 0.5:
                # äº¤æ¢åŸºå› 
                child1[param_name] = parent2[param_name]
                child2[param_name] = parent1[param_name]
            else:
                child1[param_name] = parent1[param_name]
                child2[param_name] = parent2[param_name]

            # ç®—æœ¯äº¤å‰ï¼ˆç”¨äºæ•°å€¼å‚æ•°ï¼‰
            if np.random.random() < 0.3:  # 30%æ¦‚ç‡è¿›è¡Œç®—æœ¯äº¤å‰
                alpha = np.random.random()
                val1 = parent1[param_name]
                val2 = parent2[param_name]

                new_val1 = alpha * val1 + (1 - alpha) * val2
                new_val2 = (1 - alpha) * val1 + alpha * val2

                # ç¡®ä¿åœ¨èŒƒå›´å†…
                param_config = param_ranges.get(param_name, {})
                min_val = param_config.get('min', 0)
                max_val = param_config.get('max', 1)
                param_type = param_config.get('type', 'float')

                new_val1 = np.clip(new_val1, min_val, max_val)
                new_val2 = np.clip(new_val2, min_val, max_val)

                if param_type == 'int':
                    new_val1 = int(round(new_val1))
                    new_val2 = int(round(new_val2))
                else:
                    precision = param_config.get('precision', 4)
                    new_val1 = round(new_val1, precision)
                    new_val2 = round(new_val2, precision)

                child1[param_name] = new_val1
                child2[param_name] = new_val2

        return child1, child2

    def _mutate(self, individual: Dict, param_ranges: dict,
                mutation_strength: float = 0.1) -> Dict:
        """
        å˜å¼‚æ“ä½œ
        
        å‚æ•°:
        individual: ä¸ªä½“
        param_ranges: å‚æ•°èŒƒå›´
        mutation_strength: å˜å¼‚å¼ºåº¦
        
        è¿”å›:
        Dict: å˜å¼‚åçš„ä¸ªä½“
        """
        mutated = individual.copy()

        for param_name, param_value in individual.items():
            if np.random.random() < 0.3:  # æ¯ä¸ªåŸºå› 30%æ¦‚ç‡å˜å¼‚
                param_config = param_ranges.get(param_name, {})
                min_val = param_config.get('min', 0)
                max_val = param_config.get('max', 1)
                param_type = param_config.get('type', 'float')

                if param_type == 'int':
                    # æ•´æ•°å˜å¼‚ï¼šéšæœºé€‰æ‹©é‚»è¿‘å€¼
                    mutation_range = max(1, int((max_val - min_val) * mutation_strength))
                    delta = np.random.randint(-mutation_range, mutation_range + 1)
                    new_val = param_value + delta
                    new_val = np.clip(new_val, min_val, max_val)
                    mutated[param_name] = int(new_val)
                else:
                    # æµ®ç‚¹æ•°å˜å¼‚ï¼šé«˜æ–¯å˜å¼‚
                    mutation_range = (max_val - min_val) * mutation_strength
                    delta = np.random.normal(0, mutation_range)
                    new_val = param_value + delta
                    new_val = np.clip(new_val, min_val, max_val)

                    precision = param_config.get('precision', 4)
                    mutated[param_name] = round(new_val, precision)

        return mutated

    def _validate_and_fix_parameters(self, params: Dict, param_ranges: dict) -> Dict:
        """
        éªŒè¯å¹¶ä¿®å¤å‚æ•°
        
        å‚æ•°:
        params: å‚æ•°å­—å…¸
        param_ranges: å‚æ•°èŒƒå›´
        
        è¿”å›:
        Dict: ä¿®å¤åçš„å‚æ•°
        """
        fixed_params = {}

        for param_name, param_value in params.items():
            if param_name in param_ranges:
                param_config = param_ranges[param_name]
                min_val = param_config.get('min', 0)
                max_val = param_config.get('max', 1)
                param_type = param_config.get('type', 'float')

                # ç¡®ä¿åœ¨èŒƒå›´å†…
                fixed_value = np.clip(param_value, min_val, max_val)

                if param_type == 'int':
                    fixed_value = int(round(fixed_value))
                else:
                    precision = param_config.get('precision', 4)
                    fixed_value = round(fixed_value, precision)

                fixed_params[param_name] = fixed_value
            else:
                fixed_params[param_name] = param_value

        return fixed_params

    def _log_genetic_statistics(self, recent_generations: List[Dict]):
        """
        è®°å½•é—ä¼ ç®—æ³•ç»Ÿè®¡ä¿¡æ¯
        
        å‚æ•°:
        recent_generations: æœ€è¿‘å‡ ä»£çš„ç»Ÿè®¡ä¿¡æ¯
        """
        if not recent_generations or len(recent_generations) == 0:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„ä»£æ•°ç»Ÿè®¡ä¿¡æ¯")
            return

        try:
            avg_scores = [gen.get('avg_score', 0) for gen in recent_generations if
                          gen.get('avg_score') is not None and gen.get('avg_score') != -1.0]
            max_scores = [gen.get('max_score', 0) for gen in recent_generations if
                          gen.get('max_score') is not None and gen.get('max_score') != -1.0]
            generation_times = [gen.get('generation_time', 0) for gen in recent_generations if
                                gen.get('generation_time') is not None]

            if not avg_scores or not max_scores:
                self.logger.warning("ç»Ÿè®¡æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡ç»Ÿè®¡æŠ¥å‘Š")
                return

            self.logger.info(f"ğŸ“Š æœ€è¿‘ {len(recent_generations)} ä»£æ€§èƒ½åˆ†æ:")
            self.logger.info(f"   ğŸ“ˆ å¹³å‡åˆ†è¶‹åŠ¿: {avg_scores[0]:.4f} â†’ {avg_scores[-1]:.4f} "
                             f"(å˜åŒ–: {avg_scores[-1] - avg_scores[0]:+.4f})")
            self.logger.info(f"   ğŸ¯ æœ€é«˜åˆ†è¶‹åŠ¿: {max_scores[0]:.4f} â†’ {max_scores[-1]:.4f} "
                             f"(æ”¹å–„: {max_scores[-1] - max_scores[0]:+.4f})")

            if generation_times:
                avg_time = np.mean(generation_times)
                self.logger.info(f"   â±ï¸ å¹³å‡ä»£è€—æ—¶: {avg_time:.2f}s")

            # æ”¶æ•›æ€§åˆ†æ
            if len(max_scores) >= 3:
                recent_improvement = max_scores[-1] - max_scores[-3]
                if abs(recent_improvement) < 0.001:
                    self.logger.info(f"   ğŸ¯ æ”¶æ•›çŠ¶æ€: ç¨³å®š (è¿‘æœŸæ”¹å–„: {recent_improvement:+.6f})")
                else:
                    self.logger.info(f"   ğŸš€ æ”¶æ•›çŠ¶æ€: ä¼˜åŒ–ä¸­ (è¿‘æœŸæ”¹å–„: {recent_improvement:+.6f})")

        except Exception as e:
            self.logger.warning(f"ç»Ÿè®¡ä¿¡æ¯ç”Ÿæˆå¤±è´¥: {e}")

    def _check_convergence(self, convergence_history: List[Dict], threshold: float) -> bool:
        """
        æ£€æµ‹é—ä¼ ç®—æ³•æ˜¯å¦æ”¶æ•›
        
        å‚æ•°:
        convergence_history: æœ€è¿‘å‡ ä»£çš„æ”¶æ•›ä¿¡æ¯
        threshold: æ”¶æ•›é˜ˆå€¼
        
        è¿”å›:
        bool: æ˜¯å¦æ”¶æ•›
        """
        try:
            if len(convergence_history) < 3:
                return False

            # æå–æœ€è¿‘3ä»£çš„å¾—åˆ†
            scores = [gen['best_score'] for gen in convergence_history[-3:]]
            std_scores = [gen['std_score'] for gen in convergence_history[-3:]]

            # æ¡ä»¶1ï¼šæœ€ä½³å¾—åˆ†å˜åŒ–å°äºé˜ˆå€¼
            score_changes = [abs(scores[i] - scores[i - 1]) for i in range(1, len(scores))]
            score_stable = all(change < threshold for change in score_changes)

            # æ¡ä»¶2ï¼šç§ç¾¤æ ‡å‡†å·®éƒ½å¾ˆå°ï¼ˆè¡¨ç¤ºç§ç¾¤æ”¶æ•›ï¼‰
            std_threshold = 0.01  # æ ‡å‡†å·®é˜ˆå€¼
            std_stable = all(std < std_threshold for std in std_scores)

            # æ¡ä»¶3ï¼šè¿ç»­æ”¹å–„å¹…åº¦å¾ˆå°
            improvements = [scores[i] - scores[i - 1] for i in range(1, len(scores))]
            improvement_stable = all(abs(imp) < threshold for imp in improvements)

            # æ”¶æ•›åˆ¤æ–­ï¼šå¾—åˆ†ç¨³å®šä¸”ç§ç¾¤æ”¶æ•›ï¼Œæˆ–è€…æ”¹å–„å¹…åº¦å¾ˆå°
            is_converged = (score_stable and std_stable) or improvement_stable

            if is_converged:
                self.logger.info(f"æ”¶æ•›æ£€æµ‹è¯¦æƒ…:")
                self.logger.info(f"  å¾—åˆ†å˜åŒ–: {score_changes}")
                self.logger.info(f"  æ ‡å‡†å·®: {std_scores}")
                self.logger.info(f"  æ”¹å–„å¹…åº¦: {improvements}")
                self.logger.info(f"  å¾—åˆ†ç¨³å®š: {score_stable}, ç§ç¾¤æ”¶æ•›: {std_stable}, æ”¹å–„å¾®å°: {improvement_stable}")

            return is_converged

        except Exception as e:
            self.logger.warning(f"æ”¶æ•›æ£€æµ‹å¤±è´¥: {e}")
            return False

    def _save_optimized_parameters(self, best_params: Dict[str, Any]) -> bool:
        """
        ä¿å­˜ä¼˜åŒ–åçš„å‚æ•°åˆ°é…ç½®æ–‡ä»¶
        
        å‚æ•°:
        best_params: æœ€ä¼˜å‚æ•°å­—å…¸
        
        è¿”å›:
        bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            from src.utils.config_saver import save_strategy_config

            # æ„å»ºç­–ç•¥å‚æ•°å­—å…¸
            strategy_params = {}

            # åŸºç¡€å‚æ•°
            if 'rise_threshold' in best_params:
                strategy_params['rise_threshold'] = best_params['rise_threshold']
            if 'max_days' in best_params:
                strategy_params['max_days'] = best_params['max_days']

            # ç½®ä¿¡åº¦æƒé‡å‚æ•°
            confidence_weights = {}
            confidence_weight_keys = [
                'rsi_oversold_threshold', 'rsi_low_threshold', 'final_threshold',
                'dynamic_confidence_adjustment', 'market_sentiment_weight', 'trend_strength_weight'
            ]

            for key in confidence_weight_keys:
                if key in best_params:
                    confidence_weights[key] = best_params[key]

            if confidence_weights:
                strategy_params['confidence_weights'] = confidence_weights

            # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
            if strategy_params:
                success = save_strategy_config(strategy_params)

                if success:
                    print(f"   ğŸ’¾ æœ€ä¼˜å‚æ•°å·²ä¿å­˜åˆ°é…ç½®æ–‡ä»¶")
                    self.logger.info("ğŸ’¾ æœ€ä¼˜å‚æ•°å·²ä¿å­˜åˆ°é…ç½®æ–‡ä»¶")
                    self.logger.info(f"   ä¿å­˜çš„å‚æ•°: {strategy_params}")
                    return True
                else:
                    print(f"   âš ï¸ å‚æ•°ä¿å­˜å¤±è´¥ï¼Œä½†ä¼˜åŒ–ç»“æœä»ç„¶æœ‰æ•ˆ")
                    self.logger.warning("å‚æ•°ä¿å­˜å¤±è´¥ï¼Œä½†ä¼˜åŒ–ç»“æœä»ç„¶æœ‰æ•ˆ")
                    return False
            else:
                self.logger.info("æ²¡æœ‰éœ€è¦ä¿å­˜çš„ç­–ç•¥å‚æ•°")
                return True

        except ImportError as e:
            self.logger.warning(f"é…ç½®ä¿å­˜æ¨¡å—ä¸å¯ç”¨: {e}")
            print(f"   âš ï¸ é…ç½®ä¿å­˜æ¨¡å—ä¸å¯ç”¨ï¼Œå‚æ•°æœªæŒä¹…åŒ–")
            return False
        except Exception as e:
            self.logger.error(f"ä¿å­˜ä¼˜åŒ–å‚æ•°å¤±è´¥: {e}")
            print(f"   âŒ å‚æ•°ä¿å­˜å¤±è´¥: {e}")
            return False
