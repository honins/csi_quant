#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ”¹è¿›ç‰ˆAIä¼˜åŒ–å™¨
é›†æˆå¢é‡å­¦ä¹ ã€ç‰¹å¾æƒé‡ä¼˜åŒ–å’Œè¶‹åŠ¿ç¡®è®¤æŒ‡æ ‡
å·²åºŸå¼ƒç½®ä¿¡åº¦å¹³æ»‘åŠŸèƒ½ï¼Œç›´æ¥ä½¿ç”¨AIæ¨¡å‹åŸå§‹è¾“å‡º
"""

import logging
import os
import pickle
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from typing import Dict, Any, Tuple, List, Optional
import json
import yaml
from itertools import product
import sys
import time

# æ³¨é‡Šï¼šä»¥ä¸‹ConfidenceSmootherç±»å·²åºŸå¼ƒï¼Œä¸å†ä½¿ç”¨å¹³æ»‘å¤„ç†
# ç°åœ¨ç›´æ¥ä½¿ç”¨æ¨¡å‹çš„åŸå§‹è¾“å‡ºï¼Œä¿æŒä¿¡æ¯å®Œæ•´æ€§


class AIOptimizerImproved:
    """æ”¹è¿›ç‰ˆAIä¼˜åŒ–å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–æ¨¡å‹ç›¸å…³å±æ€§
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        self.models_dir = os.path.join(project_root, 'models')
        os.makedirs(self.models_dir, exist_ok=True)
        
        self.model = None
        self.scaler = None
        self.feature_names = None
        self.model_type = config.get('ai', {}).get('model_type', 'machine_learning')
        
        # å¢é‡å­¦ä¹ é…ç½®
        incremental_config = config.get('ai', {}).get('incremental_learning', {})
        self.incremental_enabled = incremental_config.get('enabled', True)
        self.retrain_threshold = incremental_config.get('retrain_threshold', 0.1)  # æ¨¡å‹æ€§èƒ½ä¸‹é™é˜ˆå€¼
        self.max_incremental_updates = incremental_config.get('max_updates', 10)  # æœ€å¤§å¢é‡æ›´æ–°æ¬¡æ•°
        self.incremental_count = 0
        
        # ç§»é™¤ç½®ä¿¡åº¦å¹³æ»‘å™¨ - ä½¿ç”¨æ¨¡å‹åŸå§‹è¾“å‡º
        # self.confidence_smoother = ConfidenceSmoother(config)
        
        self.logger.info("æ”¹è¿›ç‰ˆAIä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def prepare_features_improved(self, data: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        æ”¹è¿›çš„ç‰¹å¾å‡†å¤‡ï¼Œè°ƒæ•´æƒé‡å’Œå¢åŠ è¶‹åŠ¿ç¡®è®¤æŒ‡æ ‡
        
        å‚æ•°:
        data: å†å²æ•°æ®
        
        è¿”å›:
        tuple: (ç‰¹å¾çŸ©é˜µ, ç‰¹å¾åç§°åˆ—è¡¨)
        """
        self.logger.info("å‡†å¤‡æ”¹è¿›çš„æœºå™¨å­¦ä¹ ç‰¹å¾")
        
        # è®¡ç®—é¢å¤–çš„è¶‹åŠ¿ç¡®è®¤æŒ‡æ ‡
        data = self._calculate_trend_indicators(data)
        
        # é‡æ–°è®¾è®¡ç‰¹å¾åˆ—ï¼Œé™ä½çŸ­æœŸæŒ‡æ ‡æƒé‡ï¼Œå¢åŠ è¶‹åŠ¿ç¡®è®¤æŒ‡æ ‡
        feature_columns = [
            # é•¿æœŸè¶‹åŠ¿æŒ‡æ ‡ï¼ˆé«˜æƒé‡ï¼‰
            'ma20', 'ma60',  # é•¿æœŸå‡çº¿
            'trend_strength_20', 'trend_strength_60',  # è¶‹åŠ¿å¼ºåº¦
            'price_position_20', 'price_position_60',  # ä»·æ ¼åœ¨å‡çº¿ç³»ç»Ÿä¸­çš„ä½ç½®
            
            # ä¸­æœŸè¶‹åŠ¿æŒ‡æ ‡ï¼ˆä¸­ç­‰æƒé‡ï¼‰
            'ma10', 'dist_ma10', 'dist_ma20',
            'rsi', 'macd', 'signal',
            'bb_upper', 'bb_lower',
            'volatility_normalized',  # æ ‡å‡†åŒ–æ³¢åŠ¨ç‡
            
            # çŸ­æœŸæŒ‡æ ‡ï¼ˆé™ä½æƒé‡ï¼‰
            'ma5', 'dist_ma5', 'hist',
            'price_change_5d', 'price_change_10d',
            
            # æˆäº¤é‡å’Œæ³¢åŠ¨ç‡ï¼ˆå¹³è¡¡æƒé‡ï¼‰
            'volume_trend', 'volume_strength',  # æˆäº¤é‡è¶‹åŠ¿
            'volatility'
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„åˆ—
        available_columns = [col for col in feature_columns if col in data.columns]
        
        if len(available_columns) == 0:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾åˆ—")
            return np.array([]), []
        
        # æå–ç‰¹å¾å¹¶åº”ç”¨æƒé‡
        features_df = data[available_columns].fillna(0).copy()
        features = self._apply_feature_weights(features_df, available_columns)
        
        self.logger.info("æ”¹è¿›ç‰¹å¾å‡†å¤‡å®Œæˆï¼Œç‰¹å¾æ•°é‡: %d, æ ·æœ¬æ•°é‡: %d", 
                        len(available_columns), len(features))
        
        return features, available_columns
    
    def _calculate_trend_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—è¶‹åŠ¿ç¡®è®¤æŒ‡æ ‡
        
        å‚æ•°:
        data: åŸå§‹æ•°æ®
        
        è¿”å›:
        pd.DataFrame: æ·»åŠ äº†è¶‹åŠ¿æŒ‡æ ‡çš„æ•°æ®
        """
        # è¶‹åŠ¿å¼ºåº¦æŒ‡æ ‡ï¼ˆåŸºäºçº¿æ€§å›å½’æ–œç‡ï¼‰
        for period in [20, 60]:
            slopes = []
            for i in range(len(data)):
                if i >= period - 1:
                    prices = data['close'].iloc[i-period+1:i+1].values
                    x = np.arange(period)
                    slope = np.polyfit(x, prices, 1)[0]
                    # æ ‡å‡†åŒ–æ–œç‡
                    normalized_slope = slope / prices.mean()
                    slopes.append(normalized_slope)
                else:
                    slopes.append(0)
            data[f'trend_strength_{period}'] = slopes
        
        # ä»·æ ¼åœ¨å‡çº¿ç³»ç»Ÿä¸­çš„ä½ç½®
        data['price_position_20'] = (data['close'] - data['ma20']) / data['ma20']
        data['price_position_60'] = (data['close'] - data['ma60']) / data['ma60']
        
        # æ ‡å‡†åŒ–æ³¢åŠ¨ç‡
        data['volatility_normalized'] = data['volatility'] / data['volatility'].rolling(60).mean()
        
        # æˆäº¤é‡è¶‹åŠ¿æŒ‡æ ‡
        data['volume_ma20'] = data['volume'].rolling(20).mean()
        data['volume_trend'] = (data['volume'] - data['volume_ma20']) / data['volume_ma20']
        
        # æˆäº¤é‡å¼ºåº¦ï¼ˆç›¸å¯¹äºå†å²ï¼‰
        data['volume_strength'] = data['volume'] / data['volume'].rolling(60).mean()
        
        return data
    
    def _apply_feature_weights(self, features_df: pd.DataFrame, feature_names: List[str]) -> np.ndarray:
        """
        åº”ç”¨ç‰¹å¾æƒé‡ï¼Œé™ä½çŸ­æœŸæŒ‡æ ‡å½±å“
        
        å‚æ•°:
        features_df: ç‰¹å¾æ•°æ®æ¡†
        feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        
        è¿”å›:
        np.ndarray: åŠ æƒåçš„ç‰¹å¾çŸ©é˜µ
        """
        # å®šä¹‰ç‰¹å¾æƒé‡
        feature_weights = {
            # é•¿æœŸè¶‹åŠ¿æŒ‡æ ‡ï¼ˆé«˜æƒé‡ï¼‰
            'ma20': 1.5, 'ma60': 1.5,
            'trend_strength_20': 2.0, 'trend_strength_60': 2.0,
            'price_position_20': 1.8, 'price_position_60': 1.8,
            
            # ä¸­æœŸæŒ‡æ ‡ï¼ˆæ­£å¸¸æƒé‡ï¼‰
            'ma10': 1.0, 'dist_ma10': 1.2, 'dist_ma20': 1.2,
            'rsi': 1.0, 'macd': 1.0, 'signal': 1.0,
            'bb_upper': 1.0, 'bb_lower': 1.0,
            'volatility_normalized': 1.0,
            
            # çŸ­æœŸæŒ‡æ ‡ï¼ˆé™ä½æƒé‡ï¼‰
            'ma5': 0.6, 'dist_ma5': 0.6, 'hist': 0.7,
            'price_change_5d': 0.5, 'price_change_10d': 0.7,
            
            # æˆäº¤é‡æŒ‡æ ‡ï¼ˆå¹³è¡¡æƒé‡ï¼‰
            'volume_trend': 1.1, 'volume_strength': 1.1,
            'volatility': 0.9
        }
        
        # åº”ç”¨æƒé‡
        weighted_features = features_df.copy()
        for feature in feature_names:
            weight = feature_weights.get(feature, 1.0)
            weighted_features[feature] = weighted_features[feature] * weight
        
        return weighted_features.values
    
    def incremental_train(self, new_data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        å¢é‡è®­ç»ƒæ¨¡å‹
        
        å‚æ•°:
        new_data: æ–°å¢æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—
        
        è¿”å›:
        dict: è®­ç»ƒç»“æœ
        """
        self.logger.info("å¼€å§‹å¢é‡è®­ç»ƒæ¨¡å‹")
        
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å®Œå…¨é‡è®­ç»ƒ
            if self.model is None or self.incremental_count >= self.max_incremental_updates:
                self.logger.info("è§¦å‘å®Œå…¨é‡è®­ç»ƒæ¡ä»¶")
                return self.full_train(new_data, strategy_module)
            
            # å‡†å¤‡æ–°æ•°æ®çš„ç‰¹å¾å’Œæ ‡ç­¾
            new_features, feature_names = self.prepare_features_improved(new_data)
            new_labels = self._prepare_labels(new_data, strategy_module)
            
            if len(new_features) == 0 or len(new_labels) == 0:
                self.logger.warning("æ–°æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡å¢é‡è®­ç»ƒ")
                return {'success': False, 'error': 'æ–°æ•°æ®ä¸ºç©º'}
            
            # æ£€æŸ¥ç‰¹å¾ä¸€è‡´æ€§
            if self.feature_names and feature_names != self.feature_names:
                self.logger.warning("ç‰¹å¾ä¸ä¸€è‡´ï¼Œè¿›è¡Œå®Œå…¨é‡è®­ç»ƒ")
                return self.full_train(new_data, strategy_module)
            
            # ä½¿ç”¨æœ€è¿‘çš„æ•°æ®è¿›è¡Œå¢é‡æ›´æ–°
            recent_features = new_features[-10:]  # æœ€è¿‘10å¤©çš„æ•°æ®
            recent_labels = new_labels[-10:]
            
            if len(recent_features) > 0:
                # å¯¹æ–°æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆä½¿ç”¨å·²æœ‰çš„scalerï¼‰
                if self.scaler is not None:
                    recent_features_scaled = self.scaler.transform(recent_features)
                else:
                    self.logger.warning("ç¼ºå°‘scalerï¼Œè¿›è¡Œå®Œå…¨é‡è®­ç»ƒ")
                    return self.full_train(new_data, strategy_module)
                
                # ä½¿ç”¨warm_startè¿›è¡Œå¢é‡å­¦ä¹ 
                if hasattr(self.model.named_steps['classifier'], 'n_estimators'):
                    classifier = self.model.named_steps['classifier']
                    classifier.n_estimators += 10  # å¢åŠ æ ‘çš„æ•°é‡
                    classifier.warm_start = True
                    
                    # é‡æ–°è®­ç»ƒï¼ˆè¿™é‡Œå®é™…ä¸Šæ˜¯å¢é‡çš„ï¼‰
                    self.model.named_steps['classifier'].fit(recent_features_scaled, recent_labels)
                    
                    self.incremental_count += 1
                    self.logger.info(f"å¢é‡è®­ç»ƒå®Œæˆï¼Œæ›´æ–°æ¬¡æ•°: {self.incremental_count}")
                    
                    return {
                        'success': True,
                        'method': 'incremental',
                        'update_count': self.incremental_count,
                        'new_samples': len(recent_features)
                    }
                else:
                    self.logger.warning("æ¨¡å‹ä¸æ”¯æŒå¢é‡å­¦ä¹ ï¼Œè¿›è¡Œå®Œå…¨é‡è®­ç»ƒ")
                    return self.full_train(new_data, strategy_module)
            
            return {'success': False, 'error': 'æ²¡æœ‰è¶³å¤Ÿçš„æ–°æ•°æ®è¿›è¡Œå¢é‡è®­ç»ƒ'}
            
        except Exception as e:
            self.logger.error(f"å¢é‡è®­ç»ƒå¤±è´¥: {e}")
            # å¤±è´¥æ—¶è¿›è¡Œå®Œå…¨é‡è®­ç»ƒ
            return self.full_train(new_data, strategy_module)
    
    def full_train(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        å®Œæ•´è®­ç»ƒæ”¹è¿›ç‰ˆAIæ¨¡å‹
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—
        
        è¿”å›:
        dict: è®­ç»ƒç»“æœ
        """
        train_start_time = time.time()
        self.logger.info("ğŸ¤– å¼€å§‹æ”¹è¿›ç‰ˆAIæ¨¡å‹å®Œæ•´è®­ç»ƒ")
        self.logger.info("=" * 80)
        
        try:
            # æ­¥éª¤1: ç‰¹å¾å·¥ç¨‹
            self.logger.info("âš™ï¸ æ­¥éª¤1: ç‰¹å¾å·¥ç¨‹...")
            feature_start_time = time.time()
            
            features, feature_names = self.prepare_features_improved(data)
            
            if len(features) == 0:
                return {
                    'success': False,
                    'error': 'æ— æ³•æå–ç‰¹å¾'
                }
            
            self.feature_names = feature_names
            feature_time = time.time() - feature_start_time
            
            self.logger.info(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ (è€—æ—¶: {feature_time:.2f}s)")
            self.logger.info(f"   ç‰¹å¾æ•°é‡: {len(feature_names)}")
            self.logger.info(f"   æ ·æœ¬æ•°é‡: {len(features)}")
            self.logger.info(f"   ç‰¹å¾åˆ—è¡¨: {', '.join(feature_names[:10])}{'...' if len(feature_names) > 10 else ''}")
            self.logger.info("-" * 60)
            
            # æ­¥éª¤2: æ ‡ç­¾å‡†å¤‡
            self.logger.info("ğŸ·ï¸ æ­¥éª¤2: æ ‡ç­¾å‡†å¤‡...")
            label_start_time = time.time()
            
            labels = self._prepare_labels(data, strategy_module)
            
            if len(labels) != len(features):
                return {
                    'success': False,
                    'error': f'ç‰¹å¾æ•°é‡({len(features)})ä¸æ ‡ç­¾æ•°é‡({len(labels)})ä¸åŒ¹é…'
                }
            
            label_time = time.time() - label_start_time
            positive_ratio = np.mean(labels)
            
            self.logger.info(f"âœ… æ ‡ç­¾å‡†å¤‡å®Œæˆ (è€—æ—¶: {label_time:.2f}s)")
            self.logger.info(f"   æ­£æ ·æœ¬æ¯”ä¾‹: {positive_ratio:.2%}")
            self.logger.info(f"   æ­£æ ·æœ¬æ•°é‡: {np.sum(labels)} / {len(labels)}")
            self.logger.info("-" * 60)
            
            # æ­¥éª¤3: æ ·æœ¬æƒé‡è®¡ç®—
            self.logger.info("âš–ï¸ æ­¥éª¤3: æ ·æœ¬æƒé‡è®¡ç®—...")
            weight_start_time = time.time()
            
            # ä¸¥æ ¼è¦æ±‚æ•°æ®åŒ…å«æ­£ç¡®çš„æ—¥æœŸä¿¡æ¯
            if 'date' in data.columns:
                date_series = data['date']
                if not pd.api.types.is_datetime64_any_dtype(date_series):
                    raise ValueError(f"data['date']åˆ—ä¸æ˜¯datetimeç±»å‹ï¼Œå®é™…ç±»å‹: {date_series.dtype}")
            elif pd.api.types.is_datetime64_any_dtype(data.index):
                date_series = data.index.to_series()
            else:
                raise ValueError(
                    "æ•°æ®ç¼ºå°‘æœ‰æ•ˆçš„æ—¥æœŸä¿¡æ¯ã€‚è¦æ±‚ï¼š\n"
                    "1. åŒ…å«datetimeç±»å‹çš„'date'åˆ—ï¼Œæˆ–\n"
                    "2. ä½¿ç”¨datetimeç±»å‹çš„ç´¢å¼•\n"
                    f"å®é™…æƒ…å†µï¼š\n"
                    f"  - 'date'åˆ—: {'å­˜åœ¨' if 'date' in data.columns else 'ä¸å­˜åœ¨'}\n"
                    f"  - ç´¢å¼•ç±»å‹: {type(data.index).__name__}\n"
                    f"  - ç´¢å¼•dtype: {data.index.dtype}"
                )
            
            sample_weights = self._calculate_sample_weights(date_series)
            weight_time = time.time() - weight_start_time
            
            self.logger.info(f"âœ… æ ·æœ¬æƒé‡è®¡ç®—å®Œæˆ (è€—æ—¶: {weight_time:.2f}s)")
            self.logger.info(f"   æƒé‡èŒƒå›´: {np.min(sample_weights):.4f} - {np.max(sample_weights):.4f}")
            self.logger.info(f"   å¹³å‡æƒé‡: {np.mean(sample_weights):.4f}")
            self.logger.info("-" * 60)
            
            # æ­¥éª¤4: æ¨¡å‹è®­ç»ƒ
            self.logger.info("ğŸ‹ï¸ æ­¥éª¤4: æ¨¡å‹è®­ç»ƒ...")
            model_start_time = time.time()
            
            # åˆ›å»ºæ”¹è¿›çš„æ¨¡å‹pipelineï¼ˆé™ä½å¤æ‚åº¦é˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
            model = Pipeline([
                ('scaler', StandardScaler()),
                ('classifier', RandomForestClassifier(
                    n_estimators=100,      # ä»150é™åˆ°100
                    max_depth=8,           # ä»12é™åˆ°8
                    min_samples_split=15,  # ä»8æé«˜åˆ°15
                    min_samples_leaf=8,    # ä»3æé«˜åˆ°8
                    class_weight='balanced',
                    n_jobs=-1,
                    random_state=42,
                    verbose=1  # å¯ç”¨è®­ç»ƒè¿›åº¦è¾“å‡º
                ))
            ])
            
            self.logger.info("ğŸŒ² RandomForestæ¨¡å‹é…ç½®ï¼ˆé˜²è¿‡æ‹Ÿåˆï¼‰:")
            self.logger.info("   n_estimators: 100 (å†³ç­–æ ‘æ•°é‡) - é™ä½å¤æ‚åº¦")
            self.logger.info("   max_depth: 8 (æœ€å¤§æ·±åº¦) - å‡å°‘è¿‡æ‹Ÿåˆ")
            self.logger.info("   min_samples_split: 15 (æœ€å°åˆ†å‰²æ ·æœ¬æ•°) - å¢åŠ ç¨³å®šæ€§")
            self.logger.info("   min_samples_leaf: 8 (æœ€å°å¶å­èŠ‚ç‚¹æ ·æœ¬æ•°) - å¢åŠ ç¨³å®šæ€§")
            self.logger.info("   class_weight: balanced (è‡ªåŠ¨å¹³è¡¡ç±»åˆ«æƒé‡)")
            self.logger.info("   n_jobs: -1 (å¹¶è¡Œè®­ç»ƒ)")
            
            self.logger.info("ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
            # è®­ç»ƒæ¨¡å‹
            model.fit(features, labels, classifier__sample_weight=sample_weights)
            
            model_time = time.time() - model_start_time
            self.model = model
            
            self.logger.info(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ (è€—æ—¶: {model_time:.2f}s)")
            self.logger.info("-" * 60)
            
            # æ­¥éª¤5: æ¨¡å‹ä¿å­˜
            self.logger.info("ğŸ’¾ æ­¥éª¤5: æ¨¡å‹ä¿å­˜...")
            save_start_time = time.time()
            
            save_success = self._save_model()
            save_time = time.time() - save_start_time
            
            if save_success:
                self.logger.info(f"âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ (è€—æ—¶: {save_time:.2f}s)")
            else:
                self.logger.warning(f"âš ï¸ æ¨¡å‹ä¿å­˜å¤±è´¥ (è€—æ—¶: {save_time:.2f}s)")
            
            # è®­ç»ƒæ€»ç»“
            total_train_time = time.time() - train_start_time
            self.logger.info("=" * 80)
            self.logger.info("ğŸ‰ æ”¹è¿›ç‰ˆAIæ¨¡å‹è®­ç»ƒå®Œæˆ!")
            self.logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_train_time:.2f}s ({total_train_time/60:.1f}åˆ†é’Ÿ)")
            self.logger.info(f"ğŸ“Š è®­ç»ƒç»Ÿè®¡:")
            self.logger.info(f"   ç‰¹å¾å·¥ç¨‹: {feature_time:.2f}s")
            self.logger.info(f"   æ ‡ç­¾å‡†å¤‡: {label_time:.2f}s")
            self.logger.info(f"   æƒé‡è®¡ç®—: {weight_time:.2f}s")
            self.logger.info(f"   æ¨¡å‹è®­ç»ƒ: {model_time:.2f}s")
            self.logger.info(f"   æ¨¡å‹ä¿å­˜: {save_time:.2f}s")
            self.logger.info(f"ğŸ¯ è®­ç»ƒç»“æœ:")
            self.logger.info(f"   æ ·æœ¬æ•°é‡: {len(features)}")
            self.logger.info(f"   ç‰¹å¾æ•°é‡: {len(feature_names)}")
            self.logger.info(f"   æ­£æ ·æœ¬æ¯”ä¾‹: {positive_ratio:.2%}")
            self.logger.info(f"   æ¨¡å‹ä¿å­˜: {'æˆåŠŸ' if save_success else 'å¤±è´¥'}")
            self.logger.info("=" * 80)
            
            return {
                'success': True,
                'method': 'improved_full_training',
                'train_samples': len(features),
                'feature_count': len(feature_names),
                'positive_ratio': positive_ratio,
                'training_time': total_train_time,
                'feature_time': feature_time,
                'model_time': model_time,
                'save_time': save_time,
                'save_success': save_success,
                'feature_names': feature_names
            }
            
        except Exception as e:
            self.logger.error(f"æ”¹è¿›ç‰ˆæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def predict_low_point(self, data: pd.DataFrame, prediction_date: str = None) -> Dict[str, Any]:
        """
        é¢„æµ‹ç›¸å¯¹ä½ç‚¹ï¼ˆå¸¦ç½®ä¿¡åº¦å¹³æ»‘ï¼‰
        
        å‚æ•°:
        data: å¸‚åœºæ•°æ®
        prediction_date: é¢„æµ‹æ—¥æœŸï¼ˆç”¨äºç½®ä¿¡åº¦å¹³æ»‘ï¼‰
        
        è¿”å›:
        dict: é¢„æµ‹ç»“æœ
        """
        self.logger.info("é¢„æµ‹ç›¸å¯¹ä½ç‚¹ï¼ˆæ”¹è¿›ç‰ˆï¼‰")
        
        try:
            # åŠ è½½æ¨¡å‹ï¼ˆå¦‚æœæœªåŠ è½½ï¼‰
            if self.model is None:
                if not self._load_model():
                    return {
                        'is_low_point': False,
                        'confidence': 0.0,
                        'smoothed_confidence': 0.0,
                        'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'
                    }
            
            if len(data) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'smoothed_confidence': 0.0,
                    'error': 'æ•°æ®ä¸ºç©º'
                }
            
            # å‡†å¤‡ç‰¹å¾
            features, feature_names = self.prepare_features_improved(data)
            
            if len(features) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'final_confidence': 0.0,
                    'error': 'æ— æ³•æå–ç‰¹å¾'
                }
            
            # ä½¿ç”¨æœ€æ–°æ•°æ®è¿›è¡Œé¢„æµ‹
            latest_features = features[-1:].reshape(1, -1)
            
            # è·å–é¢„æµ‹æ¦‚ç‡ï¼ˆä¸ä½¿ç”¨predictæ–¹æ³•ï¼Œé¿å…å†…ç½®é˜ˆå€¼å½±å“ï¼‰
            prediction_proba = self.model.predict_proba(latest_features)[0]
            
            # è·å–åŸå§‹ç½®ä¿¡åº¦ï¼ˆä¸å†è¿›è¡Œå¹³æ»‘å¤„ç†ï¼‰
            raw_confidence = prediction_proba[1] if len(prediction_proba) > 1 else 0.0
            
            # ç›´æ¥ä½¿ç”¨åŸå§‹ç½®ä¿¡åº¦ï¼Œä¸è¿›è¡Œå¹³æ»‘å¤„ç†
            final_confidence = raw_confidence
            
            # ä½¿ç”¨é…ç½®çš„é˜ˆå€¼å’ŒåŸå§‹ç½®ä¿¡åº¦è¿›è¡Œæœ€ç»ˆé¢„æµ‹
            confidence_config = self.config.get('strategy', {}).get('confidence_weights', {})
            final_threshold = confidence_config.get('final_threshold', 0.5)
            
            # åŸºäºåŸå§‹ç½®ä¿¡åº¦å’Œé…ç½®é˜ˆå€¼è¿›è¡Œé¢„æµ‹
            is_low_point = final_confidence >= final_threshold
            
            result = {
                'is_low_point': bool(is_low_point),
                'confidence': float(raw_confidence),
                'final_confidence': float(final_confidence),  # ç°åœ¨ç­‰äºåŸå§‹ç½®ä¿¡åº¦
                'prediction_proba': prediction_proba.tolist(),
                'feature_count': len(feature_names),
                'model_type': type(self.model.named_steps['classifier']).__name__,
                'threshold_used': final_threshold
            }
            
            # è¾“å‡ºé¢„æµ‹ç»“æœ
            self.logger.info("----------------------------------------------------")
            self.logger.info("AIé¢„æµ‹ç»“æœï¼ˆæ— å¹³æ»‘ï¼‰: \033[1m%s\033[0m", 
                           "ç›¸å¯¹ä½ç‚¹" if is_low_point else "éç›¸å¯¹ä½ç‚¹")
            self.logger.info("åŸå§‹ç½®ä¿¡åº¦: \033[1m%.4f\033[0m, é˜ˆå€¼: \033[1m%.2f\033[0m", 
                           raw_confidence, final_threshold)
            self.logger.info("----------------------------------------------------")
            
            return result
            
        except Exception as e:
            self.logger.error(f"é¢„æµ‹ç›¸å¯¹ä½ç‚¹å¤±è´¥: {e}")
            return {
                'is_low_point': False,
                'confidence': 0.0,
                'final_confidence': 0.0,
                'error': str(e)
            }
    
    def _prepare_labels(self, data: pd.DataFrame, strategy_module) -> np.ndarray:
        """å‡†å¤‡æ ‡ç­¾"""
        backtest_results = strategy_module.backtest(data)
        return backtest_results['is_low_point'].astype(int).values
    
    def _calculate_sample_weights(self, dates: pd.Series) -> np.ndarray:
        """
        è®¡ç®—åŸºäºæ—¶é—´è¡°å‡çš„æ ·æœ¬æƒé‡
        
        å‚æ•°:
        dates: æ—¥æœŸåºåˆ—ï¼Œå¿…é¡»æ˜¯datetimeç±»å‹
        
        è¿”å›:
        np.ndarray: æ ·æœ¬æƒé‡æ•°ç»„ï¼Œè¶Šæ–°çš„æ•°æ®æƒé‡è¶Šé«˜
        
        å¼‚å¸¸:
        ValueError: å½“datesä¸æ˜¯datetimeç±»å‹æˆ–ä¸ºç©ºæ—¶
        """
        if len(dates) == 0:
            raise ValueError("æ—¥æœŸåºåˆ—ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—æ ·æœ¬æƒé‡")
        
        # ä¸¥æ ¼æ£€æŸ¥æ•°æ®ç±»å‹ï¼šåªæ¥å—datetimeç±»å‹
        if not pd.api.types.is_datetime64_any_dtype(dates):
            raise ValueError(f"æ ·æœ¬æƒé‡è®¡ç®—è¦æ±‚datetimeç±»å‹çš„æ—¥æœŸæ•°æ®ï¼Œå®é™…ç±»å‹: {dates.dtype}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºå€¼
        if dates.isnull().any():
            raise ValueError("æ—¥æœŸåºåˆ—åŒ…å«ç©ºå€¼ï¼Œæ— æ³•è®¡ç®—å‡†ç¡®çš„æ ·æœ¬æƒé‡")
        
        # è®¡ç®—æ—¶é—´è¡°å‡æƒé‡
        latest_date = dates.max()
        decay_rate = self.config.get("ai", {}).get("data_decay_rate", 0.4)
        
        weights = np.zeros(len(dates))
        for i, date in enumerate(dates):
            time_diff_days = (latest_date - date).days
            if time_diff_days < 0:
                raise ValueError(f"å‘ç°æœªæ¥æ—¥æœŸ: {date} > {latest_date}")
            
            time_diff_years = time_diff_days / 365.25
            weight = np.exp(-decay_rate * time_diff_years)
            weights[i] = weight
        
        # éªŒè¯æƒé‡è®¡ç®—ç»“æœ
        if np.any(weights <= 0) or np.any(np.isnan(weights)) or np.any(np.isinf(weights)):
            raise ValueError("æ ·æœ¬æƒé‡è®¡ç®—ç»“æœå¼‚å¸¸ï¼ŒåŒ…å«éæ­£å€¼æˆ–NaN/Inf")
        
        return weights
    
    def _save_model(self) -> bool:
        """ä¿å­˜æ¨¡å‹"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ä¿å­˜æ¨¡å‹
            model_path = os.path.join(self.models_dir, f'improved_model_{timestamp}.pkl')
            with open(model_path, 'wb') as f:
                pickle.dump({
                    'model': self.model,
                    'feature_names': self.feature_names,
                    'incremental_count': self.incremental_count,
                    'scaler': self.scaler
                }, f)
            
            # ä¿å­˜æœ€æ–°æ¨¡å‹è·¯å¾„
            latest_path = os.path.join(self.models_dir, 'latest_improved_model.txt')
            with open(latest_path, 'w') as f:
                f.write(model_path)
            
            self.logger.info(f"æ”¹è¿›æ¨¡å‹ä¿å­˜æˆåŠŸ: {model_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ”¹è¿›æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def _load_model(self) -> bool:
        """åŠ è½½æ¨¡å‹ï¼ˆå®‰å…¨ç‰ˆæœ¬ï¼‰"""
        try:
            latest_path = os.path.join(self.models_dir, 'latest_improved_model.txt')
            
            if not os.path.exists(latest_path):
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„æ”¹è¿›æ¨¡å‹")
                return False
            
            with open(latest_path, 'r') as f:
                model_path = f.read().strip()
            
            # å®‰å…¨æ£€æŸ¥ï¼šéªŒè¯æ¨¡å‹æ–‡ä»¶è·¯å¾„
            if not os.path.abspath(model_path).startswith(os.path.abspath(self.models_dir)):
                self.logger.error(f"æ¨¡å‹æ–‡ä»¶è·¯å¾„ä¸å®‰å…¨: {model_path}")
                return False
            
            # å®‰å…¨æ£€æŸ¥ï¼šéªŒè¯æ–‡ä»¶å¤§å°ï¼ˆé˜²æ­¢è¿‡å¤§çš„æ¶æ„æ–‡ä»¶ï¼‰
            max_file_size = 500 * 1024 * 1024  # 500MBé™åˆ¶
            if os.path.getsize(model_path) > max_file_size:
                self.logger.error(f"æ¨¡å‹æ–‡ä»¶è¿‡å¤§ï¼Œå¯èƒ½å­˜åœ¨å®‰å…¨é£é™©: {model_path}")
                return False
            
            with open(model_path, 'rb') as f:
                # ä½¿ç”¨å—é™çš„pickleåŠ è½½å™¨ï¼ˆé™åˆ¶å¯å¯¼å…¥çš„æ¨¡å—ï¼‰
                import pickle
                import builtins
                
                # åˆ›å»ºå®‰å…¨çš„unpickler
                logger = self.logger  # ä¿å­˜loggerå¼•ç”¨
                class SafeUnpickler(pickle.Unpickler):
                    def find_class(self, module, name):
                        # åªå…è®¸åŠ è½½ç‰¹å®šçš„å®‰å…¨æ¨¡å—
                        safe_modules = {
                            'sklearn.ensemble._forest',
                            'sklearn.ensemble',
                            'sklearn.pipeline',
                            'sklearn.preprocessing._data',
                            'sklearn.preprocessing',
                            'numpy',
                            'pandas.core.frame',
                            'pandas',
                            'builtins'
                        }
                        
                        if module in safe_modules or module.startswith('numpy') or module.startswith('sklearn'):
                            return getattr(__import__(module, fromlist=[name]), name)
                        else:
                            logger.warning(f"æ‹’ç»åŠ è½½ä¸å®‰å…¨çš„æ¨¡å—: {module}.{name}")
                            raise pickle.PicklingError(f"Unsafe module: {module}")
                
                # ä½¿ç”¨å®‰å…¨çš„unpickleråŠ è½½æ•°æ®
                safe_unpickler = SafeUnpickler(f)
                data = safe_unpickler.load()
                
                # éªŒè¯åŠ è½½çš„æ•°æ®ç»“æ„
                required_keys = ['model', 'feature_names']
                if not isinstance(data, dict) or not all(key in data for key in required_keys):
                    self.logger.error("æ¨¡å‹æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
                    return False
                
                self.model = data['model']
                self.feature_names = data['feature_names']
                self.incremental_count = data.get('incremental_count', 0)
                self.scaler = data.get('scaler')
            
            self.logger.info(f"æ”¹è¿›æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"åŠ è½½æ”¹è¿›æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def get_feature_importance(self) -> Dict[str, float]:
        """
        è·å–ç‰¹å¾é‡è¦æ€§
        
        è¿”å›:
        dict: ç‰¹å¾é‡è¦æ€§å­—å…¸ï¼ŒæŒ‰é‡è¦æ€§é™åºæ’åˆ—
        """
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    self.logger.error("æ— æ³•è·å–ç‰¹å¾é‡è¦æ€§ï¼šæ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½")
                    return {}
            
            if self.feature_names is None:
                self.logger.error("ç‰¹å¾åç§°æœªè®¾ç½®ï¼Œæ— æ³•è·å–ç‰¹å¾é‡è¦æ€§")
                return {}
            
            # ä»Pipelineä¸­è·å–åˆ†ç±»å™¨
            if hasattr(self.model, 'named_steps') and 'classifier' in self.model.named_steps:
                classifier = self.model.named_steps['classifier']
            else:
                # å¦‚æœæ¨¡å‹ä¸æ˜¯Pipelineï¼Œç›´æ¥ä½¿ç”¨
                classifier = self.model
            
            # æ£€æŸ¥åˆ†ç±»å™¨æ˜¯å¦æœ‰feature_importances_å±æ€§
            if hasattr(classifier, 'feature_importances_'):
                importances = classifier.feature_importances_
                
                # åˆ›å»ºç‰¹å¾é‡è¦æ€§å­—å…¸
                feature_importance = dict(zip(self.feature_names, importances))
                
                # æŒ‰é‡è¦æ€§é™åºæ’åˆ—
                sorted_importance = dict(sorted(
                    feature_importance.items(), 
                    key=lambda x: x[1], 
                    reverse=True
                ))
                
                self.logger.info(f"æˆåŠŸè·å– {len(sorted_importance)} ä¸ªç‰¹å¾çš„é‡è¦æ€§")
                return sorted_importance
            else:
                self.logger.warning(f"åˆ†ç±»å™¨ {type(classifier).__name__} ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§")
                return {}
                
        except Exception as e:
            self.logger.error(f"è·å–ç‰¹å¾é‡è¦æ€§å¤±è´¥: {e}")
            return {}
    
    def run_complete_optimization(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„AIä¼˜åŒ–æµç¨‹ï¼ˆåŒ…å«å‚æ•°ä¼˜åŒ– + æ¨¡å‹è®­ç»ƒï¼‰
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—
        
        è¿”å›:
        dict: ä¼˜åŒ–ç»“æœ
        """
        from datetime import datetime
        complete_start_time = time.time()
        
        # åŒæ—¶ä½¿ç”¨printå’Œloggerç¡®ä¿è¾“å‡ºå¯è§
        current_time = datetime.now().strftime("%H:%M:%S")
        print(f"ğŸš€ å¼€å§‹å®Œæ•´çš„AIä¼˜åŒ–æµç¨‹ï¼ˆæ”¹è¿›ç‰ˆï¼‰ [{current_time}]")
        print("=" * 80)
        self.logger.info("ğŸš€ å¼€å§‹å®Œæ•´çš„AIä¼˜åŒ–æµç¨‹ï¼ˆæ”¹è¿›ç‰ˆï¼‰")
        self.logger.info("=" * 80)
        
        try:
            optimization_result = {
                'success': False,
                'strategy_optimization': {},
                'model_training': {},
                'final_evaluation': {},
                'errors': []
            }
            
            # æ­¥éª¤é¢„è§ˆ
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ“‹ ä¼˜åŒ–æµç¨‹æ¦‚è§ˆ: [{current_time}]")
            print("   ğŸ”§ æ­¥éª¤A: ç­–ç•¥å‚æ•°ä¼˜åŒ– (é—ä¼ ç®—æ³•/ç½‘æ ¼æœç´¢)")
            print("   ğŸ¤– æ­¥éª¤B: æ”¹è¿›ç‰ˆæ¨¡å‹è®­ç»ƒ")  
            print("   ğŸ“Š æ­¥éª¤C: æœ€ç»ˆæ€§èƒ½è¯„ä¼°")
            print("   ğŸ’¾ æ­¥éª¤D: ç»“æœä¿å­˜")
            print("-" * 80)
            
            self.logger.info("ğŸ“‹ ä¼˜åŒ–æµç¨‹æ¦‚è§ˆ:")
            self.logger.info("   ğŸ”§ æ­¥éª¤A: ç­–ç•¥å‚æ•°ä¼˜åŒ– (é—ä¼ ç®—æ³•/ç½‘æ ¼æœç´¢)")
            self.logger.info("   ğŸ¤– æ­¥éª¤B: æ”¹è¿›ç‰ˆæ¨¡å‹è®­ç»ƒ")  
            self.logger.info("   ğŸ“Š æ­¥éª¤C: æœ€ç»ˆæ€§èƒ½è¯„ä¼°")
            self.logger.info("   ğŸ’¾ æ­¥éª¤D: ç»“æœä¿å­˜")
            self.logger.info("-" * 80)
            
            # æ­¥éª¤A: ç­–ç•¥å‚æ•°ä¼˜åŒ–
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ”§ æ­¥éª¤A: ç­–ç•¥å‚æ•°ä¼˜åŒ– [{current_time}]")
            print("   ğŸ¯ ç›®æ ‡: å¯»æ‰¾æœ€ä¼˜ç­–ç•¥å‚æ•°ç»„åˆ")
            print("   ğŸ“Š æ–¹æ³•: é—ä¼ ç®—æ³•é«˜ç²¾åº¦ä¼˜åŒ–")
            print("   ğŸ”’ å›ºå®šå‚æ•°: rise_threshold=0.04, max_days=20")
            
            self.logger.info("ğŸ”§ æ­¥éª¤A: ç­–ç•¥å‚æ•°ä¼˜åŒ–")
            self.logger.info("   ğŸ¯ ç›®æ ‡: å¯»æ‰¾æœ€ä¼˜ç­–ç•¥å‚æ•°ç»„åˆ")
            self.logger.info("   ğŸ“Š æ–¹æ³•: é—ä¼ ç®—æ³•é«˜ç²¾åº¦ä¼˜åŒ–")
            self.logger.info("   ğŸ”’ å›ºå®šå‚æ•°: rise_threshold=0.04, max_days=20")
            step_a_start = time.time()
            
            strategy_result = self.optimize_strategy_parameters_improved(strategy_module, data)
            step_a_time = time.time() - step_a_start
            optimization_result['strategy_optimization'] = strategy_result
            
            if strategy_result['success']:
                # æ›´æ–°ç­–ç•¥æ¨¡å—å‚æ•°
                strategy_module.update_params(strategy_result['best_params'])
                
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"âœ… æ­¥éª¤Aå®Œæˆ (è€—æ—¶: {step_a_time:.2f}s) [{current_time}]")
                print(f"   ğŸ¯ ä¼˜åŒ–æ–¹æ³•: {strategy_result.get('optimization_method', 'unknown')}")
                print(f"   ğŸ“ˆ æœ€ä¼˜å¾—åˆ†: {strategy_result.get('best_score', 0):.6f}")
                print(f"   ğŸ“Š æµ‹è¯•é›†æˆåŠŸç‡: {strategy_result.get('test_success_rate', 0):.2%}")
                
                self.logger.info(f"âœ… æ­¥éª¤Aå®Œæˆ (è€—æ—¶: {step_a_time:.2f}s)")
                self.logger.info(f"   ğŸ¯ ä¼˜åŒ–æ–¹æ³•: {strategy_result.get('optimization_method', 'unknown')}")
                self.logger.info(f"   ğŸ“ˆ æœ€ä¼˜å¾—åˆ†: {strategy_result.get('best_score', 0):.6f}")
                self.logger.info(f"   ğŸ“Š æµ‹è¯•é›†æˆåŠŸç‡: {strategy_result.get('test_success_rate', 0):.2%}")
                
                # ç®€è¦æ˜¾ç¤ºä¼˜åŒ–å‚æ•°
                best_params = strategy_result.get('best_params', {})
                if len(best_params) <= 5:
                    print(f"   ğŸ”§ æœ€ä¼˜å‚æ•°: {best_params}")
                    self.logger.info(f"   ğŸ”§ æœ€ä¼˜å‚æ•°: {best_params}")
                else:
                    # æ˜¾ç¤ºå‰5ä¸ªé‡è¦å‚æ•°
                    key_params = dict(list(best_params.items())[:5])
                    print(f"   ğŸ”§ å…³é”®å‚æ•°: {key_params}... (å…±{len(best_params)}ä¸ª)")
                    self.logger.info(f"   ğŸ”§ å…³é”®å‚æ•°: {key_params}... (å…±{len(best_params)}ä¸ª)")
            else:
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"âš ï¸ æ­¥éª¤Aå¤±è´¥ (è€—æ—¶: {step_a_time:.2f}s) - ä½¿ç”¨é»˜è®¤å‚æ•°ç»§ç»­ [{current_time}]")
                self.logger.warning(f"âš ï¸ æ­¥éª¤Aå¤±è´¥ (è€—æ—¶: {step_a_time:.2f}s) - ä½¿ç”¨é»˜è®¤å‚æ•°ç»§ç»­")
                optimization_result['errors'].append("ç­–ç•¥å‚æ•°ä¼˜åŒ–å¤±è´¥")
            
            print("-" * 80)
            self.logger.info("-" * 80)
            
            # æ­¥éª¤B: æ”¹è¿›ç‰ˆæ¨¡å‹è®­ç»ƒ
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ¤– æ­¥éª¤B: æ”¹è¿›ç‰ˆæ¨¡å‹è®­ç»ƒ [{current_time}]")
            print("   ğŸ¯ ç›®æ ‡: è®­ç»ƒRandomForeståˆ†ç±»æ¨¡å‹")
            print("   âš™ï¸ é…ç½®: 150æ£µæ ‘, æ·±åº¦12, å¹³è¡¡æƒé‡")
            print("   ğŸ“Š æ•°æ®: ç‰¹å¾å·¥ç¨‹ + æ ·æœ¬æƒé‡ + æ ‡å‡†åŒ–")
            
            self.logger.info("ğŸ¤– æ­¥éª¤B: æ”¹è¿›ç‰ˆæ¨¡å‹è®­ç»ƒ")
            self.logger.info("   ğŸ¯ ç›®æ ‡: è®­ç»ƒRandomForeståˆ†ç±»æ¨¡å‹")
            self.logger.info("   âš™ï¸ é…ç½®: 150æ£µæ ‘, æ·±åº¦12, å¹³è¡¡æƒé‡")
            self.logger.info("   ğŸ“Š æ•°æ®: ç‰¹å¾å·¥ç¨‹ + æ ·æœ¬æƒé‡ + æ ‡å‡†åŒ–")
            step_b_start = time.time()
            
            model_result = self.full_train(data, strategy_module)
            step_b_time = time.time() - step_b_start
            optimization_result['model_training'] = model_result
            
            if model_result['success']:
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"âœ… æ­¥éª¤Bå®Œæˆ (è€—æ—¶: {step_b_time:.2f}s) [{current_time}]")
                print(f"   ğŸ“Š è®­ç»ƒæ ·æœ¬: {model_result.get('train_samples', 0):,}æ¡")
                print(f"   ğŸ“ˆ ç‰¹å¾æ•°é‡: {model_result.get('feature_count', 0)}ä¸ª")
                print(f"   ğŸ“Š æ­£æ ·æœ¬æ¯”ä¾‹: {model_result.get('positive_ratio', 0):.2%}")
                print(f"   ğŸ’¾ æ¨¡å‹ä¿å­˜: {'æˆåŠŸ' if model_result.get('save_success', False) else 'å¤±è´¥'}")
                
                self.logger.info(f"âœ… æ­¥éª¤Bå®Œæˆ (è€—æ—¶: {step_b_time:.2f}s)")
                self.logger.info(f"   ğŸ“Š è®­ç»ƒæ ·æœ¬: {model_result.get('train_samples', 0):,}æ¡")
                self.logger.info(f"   ğŸ“ˆ ç‰¹å¾æ•°é‡: {model_result.get('feature_count', 0)}ä¸ª")
                self.logger.info(f"   ğŸ“Š æ­£æ ·æœ¬æ¯”ä¾‹: {model_result.get('positive_ratio', 0):.2%}")
                self.logger.info(f"   ğŸ’¾ æ¨¡å‹ä¿å­˜: {'æˆåŠŸ' if model_result.get('save_success', False) else 'å¤±è´¥'}")
            else:
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"âŒ æ­¥éª¤Bå¤±è´¥ (è€—æ—¶: {step_b_time:.2f}s) [{current_time}]")
                self.logger.error(f"âŒ æ­¥éª¤Bå¤±è´¥ (è€—æ—¶: {step_b_time:.2f}s)")
                optimization_result['errors'].append("æ¨¡å‹è®­ç»ƒå¤±è´¥")
                
                # è®¡ç®—å·²è€—æ—¶é—´
                elapsed_time = time.time() - complete_start_time
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"ğŸ’” ä¼˜åŒ–æµç¨‹ä¸­æ–­ (å·²è¿è¡Œ: {elapsed_time:.2f}s) [{current_time}]")
                self.logger.error(f"ğŸ’” ä¼˜åŒ–æµç¨‹ä¸­æ–­ (å·²è¿è¡Œ: {elapsed_time:.2f}s)")
                return optimization_result
            
            print("-" * 80)
            self.logger.info("-" * 80)
            
            # æ­¥éª¤C: æœ€ç»ˆæ€§èƒ½è¯„ä¼°
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ“Š æ­¥éª¤C: æœ€ç»ˆæ€§èƒ½è¯„ä¼° [{current_time}]")
            print("   ğŸ¯ ç›®æ ‡: éªŒè¯æ•´ä½“ç³»ç»Ÿæ€§èƒ½")
            print("   ğŸ“Š æŒ‡æ ‡: ç­–ç•¥å¾—åˆ† + AIç½®ä¿¡åº¦ + è¯†åˆ«æ•ˆæœ")
            
            self.logger.info("ğŸ“Š æ­¥éª¤C: æœ€ç»ˆæ€§èƒ½è¯„ä¼°")
            self.logger.info("   ğŸ¯ ç›®æ ‡: éªŒè¯æ•´ä½“ç³»ç»Ÿæ€§èƒ½")
            self.logger.info("   ğŸ“Š æŒ‡æ ‡: ç­–ç•¥å¾—åˆ† + AIç½®ä¿¡åº¦ + è¯†åˆ«æ•ˆæœ")
            step_c_start = time.time()
            
            evaluation_result = self.evaluate_optimized_system(data, strategy_module)
            step_c_time = time.time() - step_c_start
            optimization_result['final_evaluation'] = evaluation_result
            
            if evaluation_result.get('success'):
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"âœ… æ­¥éª¤Cå®Œæˆ (è€—æ—¶: {step_c_time:.2f}s) [{current_time}]")
                print(f"   ğŸ¯ ç­–ç•¥å¾—åˆ†: {evaluation_result.get('strategy_score', 0):.4f}")
                print(f"   ğŸ“Š æˆåŠŸç‡: {evaluation_result.get('strategy_success_rate', 0):.2%}")
                print(f"   ğŸ” è¯†åˆ«ç‚¹æ•°: {evaluation_result.get('identified_points', 0)}")
                print(f"   ğŸ¤– AIç½®ä¿¡åº¦: {evaluation_result.get('ai_confidence', 0):.4f}")
                
                self.logger.info(f"âœ… æ­¥éª¤Cå®Œæˆ (è€—æ—¶: {step_c_time:.2f}s)")
                self.logger.info(f"   ğŸ¯ ç­–ç•¥å¾—åˆ†: {evaluation_result.get('strategy_score', 0):.4f}")
                self.logger.info(f"   ğŸ“Š æˆåŠŸç‡: {evaluation_result.get('strategy_success_rate', 0):.2%}")
                self.logger.info(f"   ğŸ” è¯†åˆ«ç‚¹æ•°: {evaluation_result.get('identified_points', 0)}")
                self.logger.info(f"   ğŸ¤– AIç½®ä¿¡åº¦: {evaluation_result.get('ai_confidence', 0):.4f}")
            else:
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"âš ï¸ æ­¥éª¤Céƒ¨åˆ†å¤±è´¥ (è€—æ—¶: {step_c_time:.2f}s) [{current_time}]")
                self.logger.warning(f"âš ï¸ æ­¥éª¤Céƒ¨åˆ†å¤±è´¥ (è€—æ—¶: {step_c_time:.2f}s)")
                optimization_result['errors'].append("æœ€ç»ˆè¯„ä¼°éƒ¨åˆ†å¤±è´¥")
            
            print("-" * 80)
            self.logger.info("-" * 80)
            
            # æ­¥éª¤D: ä¿å­˜ä¼˜åŒ–ç»“æœ
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ’¾ æ­¥éª¤D: ä¿å­˜ä¼˜åŒ–ç»“æœ [{current_time}]")
            self.logger.info("ğŸ’¾ æ­¥éª¤D: ä¿å­˜ä¼˜åŒ–ç»“æœ")
            step_d_start = time.time()
            
            if strategy_result['success']:
                print("   ğŸ“ ä¿å­˜æœ€ä¼˜å‚æ•°åˆ°é…ç½®æ–‡ä»¶...")
                self.logger.info("   ğŸ“ ä¿å­˜æœ€ä¼˜å‚æ•°åˆ°é…ç½®æ–‡ä»¶...")
                self.save_optimized_params(strategy_result['best_params'])
                print("   âœ… å‚æ•°ä¿å­˜å®Œæˆ")
                self.logger.info("   âœ… å‚æ•°ä¿å­˜å®Œæˆ")
            else:
                print("   âš ï¸ è·³è¿‡å‚æ•°ä¿å­˜ (ç­–ç•¥ä¼˜åŒ–å¤±è´¥)")
                self.logger.info("   âš ï¸ è·³è¿‡å‚æ•°ä¿å­˜ (ç­–ç•¥ä¼˜åŒ–å¤±è´¥)")
            
            step_d_time = time.time() - step_d_start
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"âœ… æ­¥éª¤Då®Œæˆ (è€—æ—¶: {step_d_time:.2f}s) [{current_time}]")
            self.logger.info(f"âœ… æ­¥éª¤Då®Œæˆ (è€—æ—¶: {step_d_time:.2f}s)")
            
            # è®¾ç½®æœ€ç»ˆæˆåŠŸçŠ¶æ€
            optimization_result['success'] = model_result['success']
            
            # æ€»ç»“æŠ¥å‘Š
            total_time = time.time() - complete_start_time
            current_time = datetime.now().strftime("%H:%M:%S")
            print("=" * 80)
            print(f"ğŸ‰ å®Œæ•´AIä¼˜åŒ–æµç¨‹å®Œæˆ! [{current_time}]")
            print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}s ({total_time/60:.1f}åˆ†é’Ÿ)")
            print("ğŸ“Š å„æ­¥éª¤è€—æ—¶åˆ†æ:")
            print(f"   ğŸ”§ ç­–ç•¥ä¼˜åŒ–: {step_a_time:.2f}s ({(step_a_time/total_time)*100:.1f}%)")
            print(f"   ğŸ¤– æ¨¡å‹è®­ç»ƒ: {step_b_time:.2f}s ({(step_b_time/total_time)*100:.1f}%)")
            print(f"   ğŸ“Š æ€§èƒ½è¯„ä¼°: {step_c_time:.2f}s ({(step_c_time/total_time)*100:.1f}%)")
            print(f"   ğŸ’¾ ç»“æœä¿å­˜: {step_d_time:.2f}s ({(step_d_time/total_time)*100:.1f}%)")
            
            self.logger.info("=" * 80)
            self.logger.info("ğŸ‰ å®Œæ•´AIä¼˜åŒ–æµç¨‹å®Œæˆ!")
            self.logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}s ({total_time/60:.1f}åˆ†é’Ÿ)")
            self.logger.info("ğŸ“Š å„æ­¥éª¤è€—æ—¶åˆ†æ:")
            self.logger.info(f"   ğŸ”§ ç­–ç•¥ä¼˜åŒ–: {step_a_time:.2f}s ({(step_a_time/total_time)*100:.1f}%)")
            self.logger.info(f"   ğŸ¤– æ¨¡å‹è®­ç»ƒ: {step_b_time:.2f}s ({(step_b_time/total_time)*100:.1f}%)")
            self.logger.info(f"   ğŸ“Š æ€§èƒ½è¯„ä¼°: {step_c_time:.2f}s ({(step_c_time/total_time)*100:.1f}%)")
            self.logger.info(f"   ğŸ’¾ ç»“æœä¿å­˜: {step_d_time:.2f}s ({(step_d_time/total_time)*100:.1f}%)")
            
            success_steps = sum([
                1 if strategy_result['success'] else 0,
                1 if model_result['success'] else 0,
                1 if evaluation_result.get('success', False) else 0
            ])
            print(f"âœ… æˆåŠŸæ­¥éª¤: {success_steps}/3")
            self.logger.info(f"âœ… æˆåŠŸæ­¥éª¤: {success_steps}/3")
            
            if optimization_result['errors']:
                print("âš ï¸ é‡åˆ°çš„é—®é¢˜:")
                self.logger.warning("âš ï¸ é‡åˆ°çš„é—®é¢˜:")
                for error in optimization_result['errors']:
                    print(f"   - {error}")
                    self.logger.warning(f"   - {error}")
            
            print("=" * 80)
            self.logger.info("=" * 80)
            return optimization_result
            
        except Exception as e:
            elapsed_time = time.time() - complete_start_time
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"ğŸ’¥ å®Œæ•´AIä¼˜åŒ–æµç¨‹å¼‚å¸¸å¤±è´¥ (å·²è¿è¡Œ: {elapsed_time:.2f}s): {e} [{current_time}]")
            self.logger.error(f"ğŸ’¥ å®Œæ•´AIä¼˜åŒ–æµç¨‹å¼‚å¸¸å¤±è´¥ (å·²è¿è¡Œ: {elapsed_time:.2f}s): {e}")
            import traceback
            traceback_str = traceback.format_exc()
            print(f"å¼‚å¸¸è¯¦æƒ…: {traceback_str}")
            self.logger.error(f"å¼‚å¸¸è¯¦æƒ…: {traceback_str}")
            return {
                'success': False,
                'error': str(e),
                'strategy_optimization': {},
                'model_training': {},
                'final_evaluation': {},
                'elapsed_time': elapsed_time
            }
    
    def optimize_strategy_parameters_improved(self, strategy_module, data: pd.DataFrame) -> Dict[str, Any]:
        """
        æ”¹è¿›ç‰ˆç­–ç•¥å‚æ•°ä¼˜åŒ–ï¼ˆé›†æˆé—ä¼ ç®—æ³•çš„é«˜ç²¾åº¦æ¨¡å¼ï¼‰
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–ç»“æœ
        """
        from datetime import datetime
        optimization_start_time = time.time()
        
        # åŒæ—¶ä½¿ç”¨printå’Œloggerç¡®ä¿è¾“å‡ºå¯è§
        current_time = datetime.now().strftime("%H:%M:%S")
        print(f"    ğŸš€ å¯åŠ¨ç­–ç•¥å‚æ•°ä¼˜åŒ–å­æµç¨‹ [{current_time}]")
        print(f"    ğŸ“Š æ•°æ®è§„æ¨¡: {len(data)} æ¡è®°å½•")
        
        self.logger.info("ğŸš€ å¼€å§‹æ”¹è¿›ç‰ˆç­–ç•¥å‚æ•°ä¼˜åŒ–ï¼ˆé›†æˆé—ä¼ ç®—æ³•ï¼‰")
        self.logger.info("=" * 80)
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®
            if len(data) < 100:
                print(f"    âŒ æ•°æ®é‡ä¸è¶³ (ä»…{len(data)}æ¡)")
                return {
                    'success': False,
                    'error': 'æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå‚æ•°ä¼˜åŒ–'
                }
            
            # æ­¥éª¤1: æ•°æ®åˆ†å‰²å‡†å¤‡
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    ğŸ“Š å­æ­¥éª¤1: æ•°æ®åˆ†å‰²ä¸éªŒè¯ [{current_time}]")
            self.logger.info("ğŸ“Š æ­¥éª¤1: æ•°æ®åˆ†å‰²ä¸éªŒè¯...")
            data_prep_start = time.time()
            
            # ä»é…ç½®æ–‡ä»¶è·å–ä¸‰å±‚æ•°æ®åˆ†å‰²æ¯”ä¾‹
            validation_config = self.config.get('ai', {}).get('validation', {})
            train_ratio = validation_config.get('train_ratio', 0.65)
            val_ratio = validation_config.get('validation_ratio', 0.2) 
            test_ratio = validation_config.get('test_ratio', 0.15)
            
            # éªŒè¯æ¯”ä¾‹æ€»å’Œ
            total_ratio = train_ratio + val_ratio + test_ratio
            if abs(total_ratio - 1.0) > 0.01:
                print(f"    âš ï¸ æ•°æ®åˆ†å‰²æ¯”ä¾‹è°ƒæ•´: {total_ratio:.3f} â†’ 1.0")
                self.logger.warning(f"æ•°æ®åˆ†å‰²æ¯”ä¾‹æ€»å’Œä¸ç­‰äº1.0: {total_ratio:.3f}ï¼Œè‡ªåŠ¨è°ƒæ•´")
                # é‡æ–°å½’ä¸€åŒ–
                train_ratio = train_ratio / total_ratio
                val_ratio = val_ratio / total_ratio 
                test_ratio = test_ratio / total_ratio
            
            # è®¡ç®—åˆ†å‰²ç‚¹
            train_end = int(len(data) * train_ratio)
            val_end = int(len(data) * (train_ratio + val_ratio))
            
            # ä¸¥æ ¼ä¸‰å±‚æ•°æ®åˆ†å‰²
            train_data = data.iloc[:train_end].copy()
            validation_data = data.iloc[train_end:val_end].copy()
            test_data = data.iloc[val_end:].copy()
            
            data_prep_time = time.time() - data_prep_start
            
            print(f"    âœ… æ•°æ®åˆ†å‰²å®Œæˆ (è€—æ—¶: {data_prep_time:.2f}s)")
            print(f"       ğŸ“Š è®­ç»ƒé›†: {len(train_data)}æ¡ ({train_ratio:.1%})")
            print(f"       ğŸ“ˆ éªŒè¯é›†: {len(validation_data)}æ¡ ({val_ratio:.1%})")
            print(f"       ğŸ”’ æµ‹è¯•é›†: {len(test_data)}æ¡ ({test_ratio:.1%})")
            
            self.logger.info(f"âœ… æ•°æ®åˆ†å‰²å®Œæˆ (è€—æ—¶: {data_prep_time:.2f}s):")
            self.logger.info(f"   ğŸ“Š è®­ç»ƒé›†: {len(train_data)}æ¡ ({train_ratio:.1%}) - ä»…ç”¨äºå‚æ•°ä¼˜åŒ–")
            self.logger.info(f"   ğŸ“ˆ éªŒè¯é›†: {len(validation_data)}æ¡ ({val_ratio:.1%}) - ç”¨äºæ¨¡å‹éªŒè¯å’Œè¿‡æ‹Ÿåˆæ£€æµ‹")
            self.logger.info(f"   ğŸ”’ æµ‹è¯•é›†: {len(test_data)}æ¡ ({test_ratio:.1%}) - å®Œå…¨é”å®šï¼Œä»…æœ€ç»ˆè¯„ä¼°")
            self.logger.info("-" * 60)
            
            # æ­¥éª¤2: å‚æ•°ä¼˜åŒ–æ–¹æ³•é€‰æ‹©
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    ğŸ”§ å­æ­¥éª¤2: å‚æ•°ä¼˜åŒ–æ–¹æ³•é€‰æ‹© [{current_time}]")
            self.logger.info("ğŸ”§ æ­¥éª¤2: å‚æ•°ä¼˜åŒ–æ–¹æ³•é€‰æ‹©...")
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨é—ä¼ ç®—æ³•ï¼ˆå¸¦é»˜è®¤å€¼ï¼‰
            genetic_config = self.config.get('genetic_algorithm', {})
            advanced_config = self.config.get('advanced_optimization', {})
            
            genetic_enabled = genetic_config.get('enabled', True)
            advanced_enabled = advanced_config.get('enabled', True)
            
            # å¦‚æœé…ç½®ä¸å®Œæ•´ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­æ‰§è¡Œ
            if not genetic_config:
                print("    âš ï¸ genetic_algorithmé…ç½®ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                self.logger.warning("genetic_algorithmé…ç½®ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            if not advanced_config:
                print("    âš ï¸ advanced_optimizationé…ç½®ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                self.logger.warning("advanced_optimizationé…ç½®ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            
            best_params = {}
            best_score = -float('inf')
            optimization_method = 'unknown'
            
            if genetic_enabled and advanced_enabled:
                print("    ğŸ§¬ é€‰æ‹©é—ä¼ ç®—æ³•è¿›è¡Œé«˜ç²¾åº¦å‚æ•°ä¼˜åŒ–")
                print("    ğŸ¯ é…ç½®å‚æ•°: 50ä¸ªä½“ Ã— 30ä»£ = 1500æ¬¡è¯„ä¼°")
                print("    â³ é¢„è®¡è€—æ—¶: 15-30åˆ†é’Ÿï¼ˆå–å†³äºæ•°æ®é‡ï¼‰")
                
                self.logger.info("ğŸ§¬ é€‰æ‹©é—ä¼ ç®—æ³•è¿›è¡Œé«˜ç²¾åº¦å‚æ•°ä¼˜åŒ–")
                genetic_start_time = time.time()
                
                # å®šä¹‰è¯„ä¼°å‡½æ•°
                def evaluate_strategy_params(params):
                    try:
                        # ğŸš¨ é‡è¦ï¼šæ·»åŠ å›ºå®šå‚æ•°
                        # ç¡®ä¿å›ºå®šå‚æ•°å§‹ç»ˆä½¿ç”¨é¢„è®¾å€¼
                        complete_params = params.copy()
                        complete_params['rise_threshold'] = 0.04  # å›ºå®šæ¶¨å¹…é˜ˆå€¼
                        complete_params['max_days'] = 20          # å›ºå®šäº¤æ˜“æ—¥æœŸ
                        
                        # ä¿å­˜åŸå§‹å‚æ•°ä»¥ä¾¿æ¢å¤
                        original_params = strategy_module.get_current_params() if hasattr(strategy_module, 'get_current_params') else None
                        
                        # åº”ç”¨å®Œæ•´å‚æ•°ï¼ˆåŒ…å«å›ºå®šå‚æ•°ï¼‰
                        strategy_module.update_params(complete_params)
                        
                        # åœ¨è®­ç»ƒé›†ä¸Šè¯„ä¼°
                        backtest_results = strategy_module.backtest(train_data)
                        evaluation = strategy_module.evaluate_strategy(backtest_results)
                        
                        # æ¢å¤åŸå§‹å‚æ•°ï¼ˆå¯é€‰ï¼Œä½†æ›´å®‰å…¨ï¼‰
                        if original_params is not None:
                            strategy_module.update_params(original_params)
                        
                        # ç»¼åˆè¯„åˆ†ï¼ˆé‡ç‚¹å…³æ³¨å‡†ç¡®åº¦ï¼‰
                        score = evaluation.get('score', 0)
                        success_rate = evaluation.get('success_rate', 0)
                        avg_rise = evaluation.get('avg_rise', 0)
                        
                        # é«˜ç²¾åº¦è¯„åˆ†ï¼šæ›´é‡è§†æˆåŠŸç‡ï¼Œæ·»åŠ å®‰å…¨æ£€æŸ¥
                        final_score = (
                            success_rate * 0.7 +          # 70%æƒé‡ç»™æˆåŠŸç‡
                            min(avg_rise / 0.1, 1.0) * 0.2 +  # 20%æƒé‡ç»™æ¶¨å¹…ï¼ˆæœ€é«˜10%ï¼‰
                            score * 0.1                     # 10%æƒé‡ç»™ç»¼åˆåˆ†
                        )
                        
                        # ç¡®ä¿è¿”å›å€¼åœ¨åˆç†èŒƒå›´å†…
                        return max(0.0, min(1.0, final_score))
                        
                    except Exception as e:
                        self.logger.warning(f"å‚æ•°è¯„ä¼°å¤±è´¥: {e}")
                        return -1.0
                
                # è¿è¡Œé—ä¼ ç®—æ³•
                print(f"    ğŸ”¬ å¼€å§‹é—ä¼ ç®—æ³•å‚æ•°æœç´¢... [{datetime.now().strftime('%H:%M:%S')}]")
                self.logger.info("ğŸ”¬ å¼€å§‹é—ä¼ ç®—æ³•å‚æ•°æœç´¢...")
                genetic_params = self.run_genetic_algorithm(evaluate_strategy_params)
                genetic_time = time.time() - genetic_start_time
                
                if genetic_params:
                    # è¯„ä¼°é—ä¼ ç®—æ³•ç»“æœ
                    strategy_module.update_params(genetic_params)
                    genetic_backtest = strategy_module.backtest(train_data)
                    genetic_evaluation = strategy_module.evaluate_strategy(genetic_backtest)
                    genetic_score = genetic_evaluation.get('score', 0)
                    
                    best_params = genetic_params
                    best_score = genetic_score
                    optimization_method = 'genetic_algorithm_high_precision'
                    
                    current_time = datetime.now().strftime("%H:%M:%S")
                    print(f"    ğŸ§¬ é—ä¼ ç®—æ³•å®Œæˆ (è€—æ—¶: {genetic_time:.2f}s) [{current_time}]")
                    print(f"       ğŸ“ˆ æœ€ä¼˜å¾—åˆ†: {genetic_score:.6f}")
                    print(f"       ğŸ“Š æˆåŠŸç‡: {genetic_evaluation.get('success_rate', 0):.2%}")
                    print(f"       ğŸ” è¯†åˆ«ç‚¹æ•°: {genetic_evaluation.get('total_points', 0)}")
                    print(f"       ğŸ“ˆ å¹³å‡æ¶¨å¹…: {genetic_evaluation.get('avg_rise', 0):.2%}")
                    
                    self.logger.info(f"ğŸ§¬ é—ä¼ ç®—æ³•å®Œæˆ (è€—æ—¶: {genetic_time:.2f}s)")
                    self.logger.info(f"   æœ€ä¼˜å¾—åˆ†: {genetic_score:.6f}")
                    self.logger.info(f"   æˆåŠŸç‡: {genetic_evaluation.get('success_rate', 0):.2%}")
                    self.logger.info(f"   è¯†åˆ«ç‚¹æ•°: {genetic_evaluation.get('total_points', 0)}")
                    self.logger.info(f"   å¹³å‡æ¶¨å¹…: {genetic_evaluation.get('avg_rise', 0):.2%}")
                else:
                    print("    âš ï¸ é—ä¼ ç®—æ³•æœªæ‰¾åˆ°æœ‰æ•ˆè§£ï¼Œå›é€€åˆ°ç½‘æ ¼æœç´¢")
                    self.logger.warning("âš ï¸ é—ä¼ ç®—æ³•æœªæ‰¾åˆ°æœ‰æ•ˆè§£ï¼Œå›é€€åˆ°ç½‘æ ¼æœç´¢")
                    genetic_enabled = False
            
            # å¦‚æœé—ä¼ ç®—æ³•æœªå¯ç”¨æˆ–å¤±è´¥ï¼Œä½¿ç”¨ç½‘æ ¼æœç´¢ä½œä¸ºå¤‡é€‰
            if not genetic_enabled or not best_params:
                current_time = datetime.now().strftime("%H:%M:%S")
                print(f"    ğŸ”§ ä½¿ç”¨ç½‘æ ¼æœç´¢è¿›è¡Œå‚æ•°ä¼˜åŒ– [{current_time}]")
                self.logger.info("ğŸ”§ ä½¿ç”¨ç½‘æ ¼æœç´¢è¿›è¡Œå‚æ•°ä¼˜åŒ–")
                grid_start_time = time.time()
                
                param_ranges = self.config.get('optimization', {}).get('strategy_ranges', {})
                grid_params, grid_score = self._grid_search_optimization(
                    strategy_module, train_data, param_ranges
                )
                
                grid_time = time.time() - grid_start_time
                
                if grid_score > best_score:
                    best_params = grid_params
                    best_score = grid_score
                    optimization_method = 'grid_search_fallback'
                
                print(f"    ğŸ”§ ç½‘æ ¼æœç´¢å®Œæˆ (è€—æ—¶: {grid_time:.2f}s)")
                print(f"       æœ€ä¼˜å¾—åˆ†: {grid_score:.6f}")
                self.logger.info(f"ğŸ”§ ç½‘æ ¼æœç´¢å®Œæˆ (è€—æ—¶: {grid_time:.2f}s)")
                self.logger.info(f"   æœ€ä¼˜å¾—åˆ†: {grid_score:.6f}")
            
            # éªŒè¯æœ€ä½³å‚æ•°
            if not best_params:
                print("    âŒ æ‰€æœ‰ä¼˜åŒ–æ–¹æ³•éƒ½æœªæ‰¾åˆ°æœ‰æ•ˆå‚æ•°")
                return {
                    'success': False,
                    'error': 'æ‰€æœ‰ä¼˜åŒ–æ–¹æ³•éƒ½æœªæ‰¾åˆ°æœ‰æ•ˆå‚æ•°'
                }
            
            self.logger.info("-" * 60)
            
            # æ­¥éª¤3: éªŒè¯é›†éªŒè¯
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    ğŸ“ˆ å­æ­¥éª¤3: éªŒè¯é›†éªŒè¯ [{current_time}]")
            self.logger.info("ğŸ“ˆ æ­¥éª¤3: åœ¨éªŒè¯é›†ä¸ŠéªŒè¯æœ€ä½³å‚æ•°...")
            validation_start_time = time.time()
            
            strategy_module.update_params(best_params)
            val_backtest = strategy_module.backtest(validation_data)
            val_evaluation = strategy_module.evaluate_strategy(val_backtest)
            val_score = val_evaluation['score']
            val_success_rate = val_evaluation.get('success_rate', 0)
            val_total_points = val_evaluation.get('total_points', 0)
            val_avg_rise = val_evaluation.get('avg_rise', 0)
            
            validation_time = time.time() - validation_start_time
            
            # æ£€æŸ¥è¿‡æ‹Ÿåˆ
            overfitting_threshold = 0.8  # éªŒè¯é›†å¾—åˆ†åº”è¯¥è‡³å°‘æ˜¯è®­ç»ƒé›†å¾—åˆ†çš„80%
            overfitting_passed = val_score >= best_score * overfitting_threshold
            
            print(f"    âœ… éªŒè¯é›†è¯„ä¼°å®Œæˆ (è€—æ—¶: {validation_time:.2f}s)")
            print(f"       å¾—åˆ†: {val_score:.6f}")
            print(f"       æˆåŠŸç‡: {val_success_rate:.2%}")
            print(f"       è¯†åˆ«ç‚¹æ•°: {val_total_points}")
            print(f"       å¹³å‡æ¶¨å¹…: {val_avg_rise:.2%}")
            print(f"       è¿‡æ‹Ÿåˆæ£€æµ‹: {'âœ… é€šè¿‡' if overfitting_passed else 'âš ï¸ è­¦å‘Š'}")
            
            self.logger.info(f"âœ… éªŒè¯é›†è¯„ä¼°å®Œæˆ (è€—æ—¶: {validation_time:.2f}s)")
            self.logger.info(f"   å¾—åˆ†: {val_score:.6f}")
            self.logger.info(f"   æˆåŠŸç‡: {val_success_rate:.2%}")
            self.logger.info(f"   è¯†åˆ«ç‚¹æ•°: {val_total_points}")
            self.logger.info(f"   å¹³å‡æ¶¨å¹…: {val_avg_rise:.2%}")
            self.logger.info(f"   è¿‡æ‹Ÿåˆæ£€æµ‹: {'âœ… é€šè¿‡' if overfitting_passed else 'âš ï¸ è­¦å‘Š'}")
            self.logger.info("-" * 60)
            
            # æ­¥éª¤4: æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼°
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    ğŸ”’ å­æ­¥éª¤4: æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼° [{current_time}]")
            self.logger.info("ğŸ”’ æ­¥éª¤4: åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼°...")
            test_start_time = time.time()
            
            test_backtest = strategy_module.backtest(test_data)
            test_evaluation = strategy_module.evaluate_strategy(test_backtest)
            test_score = test_evaluation['score']
            test_success_rate = test_evaluation.get('success_rate', 0)
            test_total_points = test_evaluation.get('total_points', 0)
            test_avg_rise = test_evaluation.get('avg_rise', 0)
            
            test_time = time.time() - test_start_time
            
            # è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼ˆæ·»åŠ å®‰å…¨æ£€æŸ¥ï¼‰
            if val_score > 0.001:  # é¿å…é™¤é›¶é”™è¯¯
                generalization_ratio = test_score / val_score
            else:
                generalization_ratio = 0.0
                print("    âš ï¸ éªŒè¯é›†å¾—åˆ†è¿‡ä½ï¼Œæ— æ³•è®¡ç®—æ³›åŒ–æ¯”ç‡")
                self.logger.warning("éªŒè¯é›†å¾—åˆ†è¿‡ä½ï¼Œæ— æ³•è®¡ç®—æ³›åŒ–æ¯”ç‡")
            
            generalization_passed = generalization_ratio >= 0.85  # æµ‹è¯•é›†å¾—åˆ†åº”è¯¥æ¥è¿‘éªŒè¯é›†
            
            print(f"    âœ… æµ‹è¯•é›†è¯„ä¼°å®Œæˆ (è€—æ—¶: {test_time:.2f}s)")
            print(f"       å¾—åˆ†: {test_score:.6f}")
            print(f"       æˆåŠŸç‡: {test_success_rate:.2%}")
            print(f"       è¯†åˆ«ç‚¹æ•°: {test_total_points}")
            print(f"       å¹³å‡æ¶¨å¹…: {test_avg_rise:.2%}")
            print(f"       æ³›åŒ–èƒ½åŠ›: {'âœ… è‰¯å¥½' if generalization_passed else 'âš ï¸ ä¸€èˆ¬'} (æ¯”ç‡: {generalization_ratio:.3f})")
            
            self.logger.info(f"âœ… æµ‹è¯•é›†è¯„ä¼°å®Œæˆ (è€—æ—¶: {test_time:.2f}s)")
            self.logger.info(f"   å¾—åˆ†: {test_score:.6f}")
            self.logger.info(f"   æˆåŠŸç‡: {test_success_rate:.2%}")
            self.logger.info(f"   è¯†åˆ«ç‚¹æ•°: {test_total_points}")
            self.logger.info(f"   å¹³å‡æ¶¨å¹…: {test_avg_rise:.2%}")
            self.logger.info(f"   æ³›åŒ–èƒ½åŠ›: {'âœ… è‰¯å¥½' if generalization_passed else 'âš ï¸ ä¸€èˆ¬'} (æ¯”ç‡: {generalization_ratio:.3f})")
            
            # æ€»ç»“
            optimization_total_time = time.time() - optimization_start_time
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    ğŸ‰ ç­–ç•¥å‚æ•°ä¼˜åŒ–å­æµç¨‹å®Œæˆ! [{current_time}]")
            print(f"    â±ï¸ æ€»è€—æ—¶: {optimization_total_time:.2f}s ({optimization_total_time/60:.1f}åˆ†é’Ÿ)")
            print(f"    ğŸ”§ ä¼˜åŒ–æ–¹æ³•: {optimization_method}")
            print(f"    ğŸ“Š ä¸‰å±‚éªŒè¯ç»“æœ:")
            print(f"       è®­ç»ƒé›†å¾—åˆ†: {best_score:.6f}")
            print(f"       éªŒè¯é›†å¾—åˆ†: {val_score:.6f} | æˆåŠŸç‡: {val_success_rate:.2%}")
            print(f"       æµ‹è¯•é›†å¾—åˆ†: {test_score:.6f} | æˆåŠŸç‡: {test_success_rate:.2%}")
            print(f"       ğŸ›¡ï¸ è¿‡æ‹Ÿåˆæ£€æµ‹: {'é€šè¿‡' if overfitting_passed else 'è­¦å‘Š'}")
            print(f"       ğŸ¯ æ³›åŒ–èƒ½åŠ›: {'è‰¯å¥½' if generalization_passed else 'ä¸€èˆ¬'}")
            
            self.logger.info("=" * 80)
            self.logger.info(f"ğŸ‰ ç­–ç•¥å‚æ•°ä¼˜åŒ–å®Œæˆ!")
            self.logger.info(f"â±ï¸ æ€»è€—æ—¶: {optimization_total_time:.2f}s ({optimization_total_time/60:.1f}åˆ†é’Ÿ)")
            self.logger.info(f"ğŸ”§ ä¼˜åŒ–æ–¹æ³•: {optimization_method}")
            self.logger.info(f"ğŸ“Š ä¸‰å±‚éªŒè¯ç»“æœ:")
            self.logger.info(f"   è®­ç»ƒé›†å¾—åˆ†: {best_score:.6f}")
            self.logger.info(f"   éªŒè¯é›†å¾—åˆ†: {val_score:.6f} | æˆåŠŸç‡: {val_success_rate:.2%}")
            self.logger.info(f"   æµ‹è¯•é›†å¾—åˆ†: {test_score:.6f} | æˆåŠŸç‡: {test_success_rate:.2%}")
            self.logger.info(f"   ğŸ›¡ï¸ è¿‡æ‹Ÿåˆæ£€æµ‹: {'é€šè¿‡' if overfitting_passed else 'è­¦å‘Š'}")
            self.logger.info(f"   ğŸ¯ æ³›åŒ–èƒ½åŠ›: {'è‰¯å¥½' if generalization_passed else 'ä¸€èˆ¬'}")
            
            # å¦‚æœä½¿ç”¨äº†é—ä¼ ç®—æ³•ï¼Œè¾“å‡ºè¯¦ç»†çš„å‚æ•°ä¿¡æ¯
            if optimization_method == 'genetic_algorithm_high_precision':
                print(f"    ğŸ§¬ é—ä¼ ç®—æ³•æœ€ä¼˜å‚æ•°è¯¦æƒ…:")
                self.logger.info(f"\nğŸ§¬ é—ä¼ ç®—æ³•æœ€ä¼˜å‚æ•°è¯¦æƒ…:")
                for param_name, param_value in best_params.items():
                    print(f"       {param_name}: {param_value}")
                    self.logger.info(f"   {param_name}: {param_value}")
            
            self.logger.info("=" * 80)
            
            return {
                'success': True,
                'best_params': best_params,
                'best_score': best_score,
                'validation_score': val_score,
                'validation_success_rate': val_success_rate,
                'validation_total_points': val_total_points,
                'validation_avg_rise': val_avg_rise,
                'test_score': test_score,
                'test_success_rate': test_success_rate,
                'test_total_points': test_total_points,
                'test_avg_rise': test_avg_rise,
                'overfitting_passed': overfitting_passed,
                'generalization_passed': generalization_passed,
                'generalization_ratio': generalization_ratio,
                'optimization_method': optimization_method,
                'optimization_time': optimization_total_time,
                'genetic_algorithm_used': optimization_method == 'genetic_algorithm_high_precision'
            }
            
        except Exception as e:
            current_time = datetime.now().strftime("%H:%M:%S")
            print(f"    âŒ ç­–ç•¥å‚æ•°ä¼˜åŒ–å¤±è´¥: {e} [{current_time}]")
            self.logger.error(f"ç­–ç•¥å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _grid_search_optimization(self, strategy_module, train_data: pd.DataFrame, param_ranges: dict) -> tuple:
        """
        ç½‘æ ¼æœç´¢ä¼˜åŒ–
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—
        train_data: è®­ç»ƒæ•°æ®
        param_ranges: å‚æ•°èŒƒå›´
        
        è¿”å›:
        tuple: (æœ€ä½³å‚æ•°, æœ€ä½³å¾—åˆ†)
        """
        self.logger.info("å¼€å§‹ç½‘æ ¼æœç´¢ä¼˜åŒ–")
        
        # å®šä¹‰é»˜è®¤å‚æ•°èŒƒå›´
        default_ranges = {
            'rsi_oversold_threshold': {'min': 25, 'max': 35, 'step': 2},
            'rsi_low_threshold': {'min': 35, 'max': 45, 'step': 2},
            'final_threshold': {'min': 0.3, 'max': 0.7, 'step': 0.1}
        }
        
        # åˆå¹¶ç”¨æˆ·é…ç½®å’Œé»˜è®¤é…ç½®
        search_ranges = {**default_ranges, **param_ranges}
        
        # ç”Ÿæˆå‚æ•°ç»„åˆ
        param_combinations = []
        param_names = list(search_ranges.keys())
        
        def generate_range(param_config):
            start = param_config['min']
            end = param_config['max']
            step = param_config['step']
            return [start + i * step for i in range(int((end - start) / step) + 1)]
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆï¼ˆé™åˆ¶æ•°é‡ä»¥é¿å…è¿‡é•¿æ—¶é—´ï¼‰
        ranges = [generate_range(search_ranges[param]) for param in param_names]
        all_combinations = list(product(*ranges))
        
        # é™åˆ¶æœç´¢æ•°é‡
        max_combinations = 50
        if len(all_combinations) > max_combinations:
            import random
            random.seed(42)
            all_combinations = random.sample(all_combinations, max_combinations)
        
        self.logger.info(f"å°†æµ‹è¯• {len(all_combinations)} ä¸ªå‚æ•°ç»„åˆ")
        
        best_score = -float('inf')
        best_params = {}
        
        for i, combination in enumerate(all_combinations):
            # æ„å»ºå‚æ•°å­—å…¸
            params = dict(zip(param_names, combination))
            
            try:
                # æ›´æ–°å‚æ•°å¹¶æµ‹è¯•
                strategy_module.update_params(params)
                backtest_results = strategy_module.backtest(train_data)
                evaluation = strategy_module.evaluate_strategy(backtest_results)
                score = evaluation['score']
                
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
                
                if (i + 1) % 10 == 0:
                    self.logger.info(f"å·²æµ‹è¯• {i + 1}/{len(all_combinations)} ä¸ªç»„åˆï¼Œå½“å‰æœ€ä½³å¾—åˆ†: {best_score:.4f}")
                    
            except Exception as e:
                self.logger.warning(f"å‚æ•°ç»„åˆ {params} æµ‹è¯•å¤±è´¥: {e}")
                continue
        
        self.logger.info(f"ç½‘æ ¼æœç´¢å®Œæˆï¼Œæœ€ä½³å¾—åˆ†: {best_score:.4f}")
        return best_params, best_score
    
    def evaluate_optimized_system(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        è¯„ä¼°ä¼˜åŒ–åçš„ç³»ç»Ÿ
        
        å‚æ•°:
        data: æµ‹è¯•æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—
        
        è¿”å›:
        dict: è¯„ä¼°ç»“æœ
        """
        self.logger.info("è¯„ä¼°ä¼˜åŒ–åçš„ç³»ç»Ÿ")
        
        try:
            # ç­–ç•¥è¯„ä¼°
            backtest_results = strategy_module.backtest(data)
            strategy_evaluation = strategy_module.evaluate_strategy(backtest_results)
            
            # AIæ¨¡å‹é¢„æµ‹è¯„ä¼°
            prediction_result = self.predict_low_point(data)
            
            return {
                'success': True,
                'strategy_score': strategy_evaluation['score'],
                'strategy_success_rate': strategy_evaluation['success_rate'],
                'identified_points': strategy_evaluation['total_points'],
                'avg_rise': strategy_evaluation['avg_rise'],
                'ai_confidence': prediction_result.get('final_confidence', 0),
                'ai_prediction': prediction_result.get('is_low_point', False)
            }
            
        except Exception as e:
            self.logger.error(f"ç³»ç»Ÿè¯„ä¼°å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def save_optimized_params(self, params: dict):
        """
        ä¿å­˜ä¼˜åŒ–åçš„å‚æ•°åˆ°é…ç½®æ–‡ä»¶ï¼ˆä¿ç•™æ³¨é‡Šç‰ˆï¼‰
        
        å‚æ•°:
        params: ä¼˜åŒ–åçš„å‚æ•°
        """
        try:
            # å°è¯•ä½¿ç”¨ä¿ç•™æ³¨é‡Šçš„ä¿å­˜å™¨
            try:
                from src.utils.config_saver import ConfigSaver
                saver = ConfigSaver()
                saver.save_optimized_params(params)
                self.logger.info("å‚æ•°å·²ä¿å­˜ï¼ˆä¿ç•™æ³¨é‡Šç‰ˆæœ¬ï¼‰")
                return
            except Exception as e:
                self.logger.warning(f"ä¿ç•™æ³¨é‡Šç‰ˆæœ¬ä¿å­˜å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼: {e}")
                self._save_params_fallback(params)
        except Exception as e:
            self.logger.error(f"ä¿å­˜ä¼˜åŒ–å‚æ•°å¤±è´¥: {e}")
    
    def _save_params_fallback(self, params: dict):
        """
        ä¼ ç»Ÿçš„å‚æ•°ä¿å­˜æ–¹å¼ï¼ˆåŸå­æ€§å†™å…¥ï¼‰
        
        å‚æ•°:
        params: ä¼˜åŒ–åçš„å‚æ•°
        """
        import tempfile
        import shutil
        
        try:
            config_path = 'config/config_improved.yaml'
            backup_path = f"{config_path}.backup"
            
            # åˆ›å»ºå¤‡ä»½
            if os.path.exists(config_path):
                shutil.copy2(config_path, backup_path)
                self.logger.info(f"å·²åˆ›å»ºé…ç½®æ–‡ä»¶å¤‡ä»½: {backup_path}")
            
            # è¯»å–ç°æœ‰é…ç½®
            config = {}
            if os.path.exists(config_path):
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config = yaml.safe_load(f) or {}
                except yaml.YAMLError as e:
                    self.logger.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
                    if os.path.exists(backup_path):
                        shutil.copy2(backup_path, config_path)
                        self.logger.info("å·²ä»å¤‡ä»½æ¢å¤é…ç½®æ–‡ä»¶")
                        with open(config_path, 'r', encoding='utf-8') as f:
                            config = yaml.safe_load(f) or {}
            
            # æ›´æ–°å‚æ•°
            for param_name, param_value in params.items():
                if param_name == 'final_threshold':
                    if 'strategy' not in config:
                        config['strategy'] = {}
                    if 'confidence_weights' not in config['strategy']:
                        config['strategy']['confidence_weights'] = {}
                    config['strategy']['confidence_weights']['final_threshold'] = float(param_value)
                elif param_name in ['rsi_oversold_threshold', 'rsi_low_threshold']:
                    if 'strategy' not in config:
                        config['strategy'] = {}
                    if 'confidence_weights' not in config['strategy']:
                        config['strategy']['confidence_weights'] = {}
                    config['strategy']['confidence_weights'][param_name] = float(param_value)
                else:
                    # å…¶ä»–å‚æ•°æŒ‰åŸæœ‰é€»è¾‘å¤„ç†
                    if 'strategy' not in config:
                        config['strategy'] = {}
                    
                    # ç±»å‹è½¬æ¢
                    if isinstance(param_value, (int, float)):
                        config['strategy'][param_name] = float(param_value)
                    else:
                        config['strategy'][param_name] = param_value
            
            # åŸå­æ€§å†™å…¥ï¼šå…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œå†ç§»åŠ¨
            with tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', 
                                           dir=os.path.dirname(config_path), 
                                           delete=False) as temp_file:
                yaml.dump(config, temp_file, default_flow_style=False, allow_unicode=True)
                temp_path = temp_file.name
            
            # ç§»åŠ¨ä¸´æ—¶æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
            shutil.move(temp_path, config_path)
            
            self.logger.info(f"å‚æ•°å·²å®‰å…¨ä¿å­˜åˆ°é…ç½®æ–‡ä»¶: {len(params)} ä¸ªå‚æ•°")
            
            # æ¸…ç†æ—§å¤‡ä»½
            if os.path.exists(backup_path):
                os.remove(backup_path)
                
        except Exception as e:
            self.logger.error(f"ä¼ ç»Ÿæ–¹å¼ä¿å­˜å‚æ•°å¤±è´¥: {e}")
            # å°è¯•ä»å¤‡ä»½æ¢å¤
            if os.path.exists(backup_path) and os.path.exists(config_path):
                try:
                    shutil.copy2(backup_path, config_path)
                    self.logger.info("å·²ä»å¤‡ä»½æ¢å¤é…ç½®æ–‡ä»¶")
                except Exception as restore_error:
                    self.logger.error(f"å¤‡ä»½æ¢å¤å¤±è´¥: {restore_error}")

    def run_genetic_algorithm(self, evaluate_func, param_ranges=None) -> Dict[str, Any]:
        """
        é—ä¼ ç®—æ³•å‚æ•°ä¼˜åŒ–ï¼ˆé«˜ç²¾åº¦ç‰ˆæœ¬ï¼‰
        
        ä¸“ä¸ºé«˜å‡†ç¡®åº¦è®¾è®¡ï¼Œä¸è€ƒè™‘æ‰§è¡Œæ—¶é—´é™åˆ¶
        
        å‚æ•°:
        evaluate_func: è¯„ä¼°å‡½æ•°ï¼Œæ¥æ”¶å‚æ•°å­—å…¸ï¼Œè¿”å›è¯„åˆ†
        param_ranges: å‚æ•°èŒƒå›´å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶
        
        è¿”å›:
        dict: æœ€ä¼˜å‚æ•°å­—å…¸
        """
        from datetime import datetime
        
        print(f"        ğŸ§¬ åˆå§‹åŒ–é—ä¼ ç®—æ³• [{datetime.now().strftime('%H:%M:%S')}]")
        self.logger.info("ğŸ§¬ å¯åŠ¨é—ä¼ ç®—æ³•ä¼˜åŒ–ï¼ˆé«˜ç²¾åº¦æ¨¡å¼ï¼‰")
        start_time = time.time()
        
        try:
            # è·å–é—ä¼ ç®—æ³•é…ç½®ï¼ˆé’ˆå¯¹é«˜ç²¾åº¦è°ƒæ•´ï¼‰
            genetic_config = self.config.get('genetic_algorithm', {})
            
            # é«˜ç²¾åº¦é…ç½®ï¼šå¢åŠ ç§ç¾¤å’Œä»£æ•°
            population_size = genetic_config.get('population_size', 50)  # å¢åŠ åˆ°50
            generations = genetic_config.get('generations', 30)          # å¢åŠ åˆ°30
            crossover_rate = genetic_config.get('crossover_rate', 0.8)
            mutation_rate = genetic_config.get('mutation_rate', 0.15)    # ç¨å¾®æé«˜å˜å¼‚ç‡
            elite_ratio = genetic_config.get('elite_ratio', 0.1)         # ä¿ç•™10%ç²¾è‹±
            
            print(f"        ğŸ“Š é—ä¼ ç®—æ³•é…ç½®:")
            print(f"           ç§ç¾¤å¤§å°: {population_size} ä¸ªä½“")
            print(f"           è¿›åŒ–ä»£æ•°: {generations} ä»£")
            print(f"           äº¤å‰æ¦‚ç‡: {crossover_rate:.1%}")
            print(f"           å˜å¼‚æ¦‚ç‡: {mutation_rate:.1%}")
            print(f"           ç²¾è‹±æ¯”ä¾‹: {elite_ratio:.1%}")
            
            self.logger.info(f"é«˜ç²¾åº¦é—ä¼ ç®—æ³•é…ç½®: ç§ç¾¤{population_size}, ä»£æ•°{generations}")
            
            # è·å–æˆ–ç”Ÿæˆå‚æ•°èŒƒå›´
            if param_ranges is None:
                param_ranges = self._get_enhanced_parameter_ranges({})
            
            print(f"        ğŸ¯ ä¼˜åŒ–å‚æ•°æ•°é‡: {len(param_ranges)} ä¸ª")
            
            # åˆå§‹åŒ–ç§ç¾¤
            print(f"        ğŸŒ± ç”Ÿæˆåˆå§‹ç§ç¾¤... [{datetime.now().strftime('%H:%M:%S')}]")
            population = self._initialize_population(param_ranges, population_size)
            
            best_individual = None
            best_score = -float('inf')
            best_generation = 0
            stagnation_count = 0
            recent_generations = []
            
            print(f"        ğŸš€ å¼€å§‹è¿›åŒ–è¿‡ç¨‹ (æ€»è®¡ {population_size * generations} æ¬¡è¯„ä¼°)")
            total_evaluations = population_size * generations
            
            # è¿›åŒ–ä¸»å¾ªç¯
            for generation in range(generations):
                generation_start_time = time.time()
                current_time = datetime.now().strftime("%H:%M:%S")
                
                print(f"        ğŸ§¬ ç¬¬ {generation + 1}/{generations} ä»£è¿›åŒ– ({((generation + 1)/generations)*100:.1f}% å®Œæˆ) [{current_time}]")
                self.logger.info(f"\nğŸ§¬ ç¬¬ {generation + 1}/{generations} ä»£è¿›åŒ– "
                               f"({((generation + 1)/generations)*100:.1f}% å®Œæˆ)")
                self.logger.info("------------------------------------------------------------")
                
                # è¯„ä¼°å½“å‰ç§ç¾¤
                scores = []
                valid_evaluations = 0
                failed_evaluations = 0
                
                # æ¯10ä¸ªä¸ªä½“æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦ï¼Œé¿å…è¿‡å¤šè¾“å‡º
                for i, individual in enumerate(population):
                    if (i + 1) % 10 == 0 or i == len(population) - 1:
                        current_progress = ((generation * population_size + i + 1) / total_evaluations) * 100
                        print(f"        ğŸ” è¯„ä¼°è¿›åº¦: {i+1}/{population_size} ä¸ªä½“ | æ€»è¿›åº¦: {current_progress:.1f}% | ç¬¬{generation + 1}ä»£")
                        self.logger.info(f"ğŸ” è¯„ä¼°è¿›åº¦: {i+1}/{population_size} ä¸ªä½“ | "
                                       f"æ€»è¿›åº¦: {current_progress:.1f}% | ç¬¬{generation + 1}ä»£")
                    
                    try:
                        score = evaluate_func(individual)
                        if score is not None and score >= 0:
                            scores.append(score)
                            valid_evaluations += 1
                        else:
                            scores.append(0.0)
                            failed_evaluations += 1
                    except Exception as e:
                        self.logger.warning(f"ä¸ªä½“è¯„ä¼°å¤±è´¥: {e}")
                        scores.append(0.0)
                        failed_evaluations += 1
                
                # æ›´æ–°å…¨å±€æœ€ä¼˜
                generation_best_idx = np.argmax(scores)
                generation_best_score = scores[generation_best_idx]
                
                if generation_best_score > best_score:
                    best_score = generation_best_score
                    best_individual = population[generation_best_idx].copy()
                    best_generation = generation + 1
                    stagnation_count = 0
                    print(f"        ğŸ‰ å‘ç°æ–°æœ€ä½³è§£! å¾—åˆ†: {best_score:.6f}")
                    self.logger.info(f"ğŸ‰ å‘ç°æ–°æœ€ä½³è§£! å¾—åˆ†: {best_score:.6f}")
                else:
                    stagnation_count += 1
                
                # ç»Ÿè®¡ä¿¡æ¯
                if len(scores) > 0:
                    max_score = max(scores)
                    avg_score = sum(scores) / len(scores)
                    min_score = min(scores)
                    std_score = np.std(scores)
                    
                    generation_time = time.time() - generation_start_time
                    
                    # é¢„è®¡å‰©ä½™æ—¶é—´
                    remaining_generations = generations - generation - 1
                    if generation > 0:
                        avg_generation_time = (time.time() - start_time) / (generation + 1)
                        estimated_remaining = remaining_generations * avg_generation_time
                    else:
                        estimated_remaining = remaining_generations * generation_time
                    
                    print(f"        ğŸ“Š ç¬¬{generation + 1}ä»£ç»Ÿè®¡:")
                    print(f"           âœ… æœ‰æ•ˆä¸ªä½“: {valid_evaluations}/{population_size}")
                    print(f"           âŒ å¤±è´¥ä¸ªä½“: {failed_evaluations}")
                    print(f"           ğŸ“ˆ æœ€é«˜åˆ†: {max_score:.6f}")
                    print(f"           ğŸ“Š å¹³å‡åˆ†: {avg_score:.6f}")
                    print(f"           ğŸ“‰ æœ€ä½åˆ†: {min_score:.6f}")
                    print(f"           ğŸ“ æ ‡å‡†å·®: {std_score:.6f}")
                    print(f"           ğŸ† å†å²æœ€ä¼˜: {best_score:.6f}")
                    print(f"           â±ï¸ æœ¬ä»£è€—æ—¶: {generation_time:.2f}s")
                    print(f"           â³ é¢„è®¡å‰©ä½™æ—¶é—´: {estimated_remaining:.1f}s ({estimated_remaining/60:.1f}åˆ†é’Ÿ)")
                    
                    self.logger.info(f"ğŸ“Š ç¬¬{generation + 1}ä»£ç»Ÿè®¡:")
                    self.logger.info(f"   âœ… æœ‰æ•ˆä¸ªä½“: {valid_evaluations}/{population_size}")
                    self.logger.info(f"   âŒ å¤±è´¥ä¸ªä½“: {failed_evaluations}")
                    self.logger.info(f"   ğŸ“ˆ æœ€é«˜åˆ†: {max_score:.6f}")
                    self.logger.info(f"   ğŸ“Š å¹³å‡åˆ†: {avg_score:.6f}")
                    self.logger.info(f"   ğŸ“‰ æœ€ä½åˆ†: {min_score:.6f}")
                    self.logger.info(f"   ğŸ“ æ ‡å‡†å·®: {std_score:.6f}")
                    self.logger.info(f"   ğŸ† å†å²æœ€ä¼˜: {best_score:.6f}")
                    self.logger.info(f"   â±ï¸ æœ¬ä»£è€—æ—¶: {generation_time:.2f}s")
                    self.logger.info(f"   â³ é¢„è®¡å‰©ä½™æ—¶é—´: {estimated_remaining:.1f}s ({estimated_remaining/60:.1f}åˆ†é’Ÿ)")
                    
                    # ä¿å­˜æœ€è¿‘å‡ ä»£çš„ç»Ÿè®¡ä¿¡æ¯
                    recent_generations.append({
                        'generation': generation + 1,
                        'max_score': max_score,
                        'avg_score': avg_score,
                        'std_score': std_score,
                        'best_score': best_score
                    })
                
                # æ¯5ä»£åˆ†æä¸€æ¬¡æ”¶æ•›è¶‹åŠ¿
                if (generation + 1) % 5 == 0 and len(recent_generations) >= 5:
                    self._log_genetic_statistics(recent_generations[-5:])
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€ä»£ï¼Œè¿›è¡Œè¿›åŒ–æ“ä½œ
                if generation < generations - 1:
                    evolution_start = time.time()
                    print(f"        ğŸ”„ å¼€å§‹ç¬¬{generation + 1}ä»£è¿›åŒ–æ“ä½œ... [{datetime.now().strftime('%H:%M:%S')}]")
                    self.logger.info(f"ğŸ”„ å¼€å§‹ç¬¬{generation + 1}ä»£è¿›åŒ–æ“ä½œ...")
                    
                    # è¿›åŒ–ç§ç¾¤
                    population = self._evolve_population(
                        population, scores, param_ranges, population_size,
                        crossover_rate, mutation_rate, elite_ratio
                    )
                    
                    evolution_time = time.time() - evolution_start
                    print(f"        âœ… è¿›åŒ–æ“ä½œå®Œæˆ (è€—æ—¶: {evolution_time:.2f}s)")
                    self.logger.info(f"âœ… è¿›åŒ–æ“ä½œå®Œæˆ (è€—æ—¶: {evolution_time:.2f}s)")
                
                # æå‰åœæ­¢æ¡ä»¶ï¼šè¿ç»­å¤šä»£æ— æ”¹å–„
                if stagnation_count >= 10:
                    print(f"        ğŸ›‘ è¿ç»­{stagnation_count}ä»£æ— æ”¹å–„ï¼Œæå‰åœæ­¢")
                    self.logger.info(f"è¿ç»­{stagnation_count}ä»£æ— æ”¹å–„ï¼Œæå‰åœæ­¢")
                    break
                
                print(f"        {'='*60}")
                self.logger.info("------------------------------------------------------------")
            
            total_time = time.time() - start_time
            current_time = datetime.now().strftime('%H:%M:%S')
            
            print(f"        ğŸ‰ é—ä¼ ç®—æ³•ä¼˜åŒ–å®Œæˆ! [{current_time}]")
            print(f"        â±ï¸ æ€»è€—æ—¶: {total_time:.2f}s ({total_time/60:.1f}åˆ†é’Ÿ)")
            print(f"        ğŸ† æœ€ä¼˜å¾—åˆ†: {best_score:.6f}")
            print(f"        ğŸ“ æœ€ä½³ä»£æ•°: ç¬¬{best_generation}ä»£")
            
            if best_individual:
                print(f"        ğŸ”§ æœ€ä¼˜å‚æ•°:")
                for param_name, param_value in best_individual.items():
                    print(f"           {param_name}: {param_value}")
            
            self.logger.info("ğŸ‰ é—ä¼ ç®—æ³•ä¼˜åŒ–å®Œæˆ!")
            self.logger.info(f"æ€»è€—æ—¶: {total_time:.2f}s, æœ€ä¼˜å¾—åˆ†: {best_score:.6f}")
            self.logger.info(f"æœ€ä½³è§£åœ¨ç¬¬{best_generation}ä»£å‘ç°")
            
            return best_individual if best_individual else {}
            
        except Exception as e:
            current_time = datetime.now().strftime('%H:%M:%S')
            print(f"        âŒ é—ä¼ ç®—æ³•æ‰§è¡Œå¤±è´¥: {e} [{current_time}]")
            self.logger.error(f"é—ä¼ ç®—æ³•æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return {}
    
    def _get_enhanced_parameter_ranges(self, base_ranges: dict) -> dict:
        """
        è·å–å¢å¼ºçš„å‚æ•°èŒƒå›´ï¼ˆæ›´ç²¾ç»†çš„æœç´¢ï¼‰
        
        å‚æ•°:
        base_ranges: åŸºç¡€å‚æ•°èŒƒå›´
        
        è¿”å›:
        dict: å¢å¼ºçš„å‚æ•°èŒƒå›´
        """
        # ğŸš¨ é‡è¦ï¼šå›ºå®šå‚æ•°ï¼Œä¸å‚ä¸é—ä¼ ç®—æ³•ä¼˜åŒ–
        # rise_threshold: 0.04 å’Œ max_days: 20 æ˜¯ç”¨æˆ·é¢„è®¾çš„å›ºå®šå€¼
        
        enhanced_ranges = {
            # âŒ ç§»é™¤å›ºå®šå‚æ•°ï¼Œä¸å‚ä¸ä¼˜åŒ–
            # 'rise_threshold': ç”¨æˆ·æŒ‡å®šå›ºå®šä¸º0.04
            # 'max_days': ç”¨æˆ·æŒ‡å®šå›ºå®šä¸º20
            
            # RSIå‚æ•°ï¼ˆæ‰©å±•èŒƒå›´ï¼‰
            'rsi_oversold_threshold': {
                'min': 20, 'max': 40, 'type': 'int'
            },
            'rsi_low_threshold': {
                'min': 30, 'max': 50, 'type': 'int'
            },
            
            # ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé«˜ç²¾åº¦ï¼‰
            'final_threshold': {
                'min': 0.25, 'max': 0.85, 'type': 'float', 'precision': 4
            },
            
            # é«˜çº§æƒé‡å‚æ•°ï¼ˆæ–°å¢ï¼‰
            'dynamic_confidence_adjustment': {
                'min': 0.02, 'max': 0.30, 'type': 'float', 'precision': 4
            },
            'market_sentiment_weight': {
                'min': 0.05, 'max': 0.35, 'type': 'float', 'precision': 4
            },
            'trend_strength_weight': {
                'min': 0.03, 'max': 0.25, 'type': 'float', 'precision': 4
            },
            'volume_weight': {
                'min': 0.10, 'max': 0.45, 'type': 'float', 'precision': 4
            },
            'price_momentum_weight': {
                'min': 0.08, 'max': 0.35, 'type': 'float', 'precision': 4
            },
            
            # å¸ƒæ—å¸¦å‚æ•°
            'bb_near_threshold': {
                'min': 1.005, 'max': 1.05, 'type': 'float', 'precision': 5
            },
            
            # æˆäº¤é‡å‚æ•°
            'volume_panic_threshold': {
                'min': 1.2, 'max': 2.0, 'type': 'float', 'precision': 3
            },
            'volume_surge_threshold': {
                'min': 1.1, 'max': 1.5, 'type': 'float', 'precision': 3
            },
            'volume_shrink_threshold': {
                'min': 0.5, 'max': 0.9, 'type': 'float', 'precision': 3
            }
        }
        
        # åˆå¹¶ç”¨æˆ·é…ç½®çš„èŒƒå›´ï¼ˆä½†æ’é™¤å›ºå®šå‚æ•°ï¼‰
        for param_name, param_config in base_ranges.items():
            # ğŸš¨ è·³è¿‡å›ºå®šå‚æ•°ï¼Œä¸å…è®¸ä¼˜åŒ–
            if param_name in ['rise_threshold', 'max_days']:
                self.logger.info(f"âš ï¸ è·³è¿‡å›ºå®šå‚æ•° {param_name}ï¼Œæ­¤å‚æ•°ä¸å‚ä¸ä¼˜åŒ–")
                continue
                
            if param_name in enhanced_ranges:
                # æ›´æ–°ç°æœ‰å‚æ•°èŒƒå›´
                enhanced_ranges[param_name].update(param_config)
            else:
                # æ·»åŠ æ–°å‚æ•°
                enhanced_ranges[param_name] = param_config.copy()
                enhanced_ranges[param_name]['type'] = 'float'  # é»˜è®¤ä¸ºæµ®ç‚¹æ•°
                enhanced_ranges[param_name]['precision'] = 4
        
        self.logger.info(f"ğŸ¯ å¢å¼ºå‚æ•°æœç´¢ç©ºé—´: {len(enhanced_ranges)} ä¸ªå‚æ•°")
        self.logger.info(f"ğŸ”’ å›ºå®šå‚æ•°: rise_threshold=0.04, max_days=20 (ä¸å‚ä¸ä¼˜åŒ–)")
        return enhanced_ranges
    
    def _initialize_population(self, param_ranges: dict, population_size: int) -> List[Dict]:
        """
        åˆå§‹åŒ–ç§ç¾¤
        
        å‚æ•°:
        param_ranges: å‚æ•°èŒƒå›´
        population_size: ç§ç¾¤å¤§å°
        
        è¿”å›:
        List[Dict]: åˆå§‹ç§ç¾¤
        """
        if not param_ranges:
            raise ValueError("å‚æ•°èŒƒå›´ä¸èƒ½ä¸ºç©º")
        
        if population_size <= 0:
            raise ValueError(f"ç§ç¾¤å¤§å°å¿…é¡»å¤§äº0ï¼Œå½“å‰å€¼: {population_size}")
        
        population = []
        
        # éªŒè¯å‚æ•°èŒƒå›´çš„æœ‰æ•ˆæ€§
        for param_name, param_config in param_ranges.items():
            if 'min' not in param_config or 'max' not in param_config:
                raise ValueError(f"å‚æ•° {param_name} ç¼ºå°‘ min æˆ– max é…ç½®")
            
            min_val = param_config['min']
            max_val = param_config['max']
            
            if min_val >= max_val:
                raise ValueError(f"å‚æ•° {param_name} çš„æœ€å°å€¼({min_val})å¿…é¡»å°äºæœ€å¤§å€¼({max_val})")
        
        for _ in range(population_size):
            individual = {}
            for param_name, param_config in param_ranges.items():
                min_val = param_config['min']
                max_val = param_config['max']
                param_type = param_config.get('type', 'float')
                
                try:
                    if param_type == 'int':
                        # ç¡®ä¿æ•´æ•°èŒƒå›´æœ‰æ•ˆ
                        if max_val - min_val < 1:
                            individual[param_name] = min_val
                        else:
                            individual[param_name] = np.random.randint(min_val, max_val + 1)
                    else:  # float
                        individual[param_name] = np.random.uniform(min_val, max_val)
                        precision = param_config.get('precision', 4)
                        individual[param_name] = round(individual[param_name], precision)
                        
                except Exception as e:
                    self.logger.error(f"åˆå§‹åŒ–å‚æ•° {param_name} å¤±è´¥: {e}")
                    # ä½¿ç”¨ä¸­é—´å€¼ä½œä¸ºé»˜è®¤å€¼
                    if param_type == 'int':
                        individual[param_name] = int((min_val + max_val) / 2)
                    else:
                        individual[param_name] = round((min_val + max_val) / 2, 
                                                     param_config.get('precision', 4))
            
            population.append(individual)
        
        self.logger.info(f"âœ… åˆå§‹åŒ–ç§ç¾¤: {population_size} ä¸ªä¸ªä½“ï¼ŒåŒ…å« {len(param_ranges)} ä¸ªå‚æ•°")
        return population
    
    def _evolve_population(self, population: List[Dict], scores: List[float], 
                          param_ranges: dict, population_size: int,
                          crossover_rate: float, mutation_rate: float, 
                          elite_ratio: float) -> List[Dict]:
        """
        è¿›åŒ–ç§ç¾¤
        
        å‚æ•°:
        population: å½“å‰ç§ç¾¤
        scores: è¯„åˆ†åˆ—è¡¨
        param_ranges: å‚æ•°èŒƒå›´
        population_size: ç§ç¾¤å¤§å°
        crossover_rate: äº¤å‰æ¦‚ç‡
        mutation_rate: å˜å¼‚æ¦‚ç‡
        elite_ratio: ç²¾è‹±ä¿ç•™æ¯”ä¾‹
        
        è¿”å›:
        List[Dict]: æ–°ç§ç¾¤
        """
        # æ’åºä¸ªä½“ï¼ˆæŒ‰å¾—åˆ†é™åºï¼‰
        sorted_indices = np.argsort(scores)[::-1]
        sorted_population = [population[i] for i in sorted_indices]
        sorted_scores = [scores[i] for i in sorted_indices]
        
        # ç²¾è‹±ä¿ç•™ï¼ˆæ·±æ‹·è´ä»¥é¿å…å¼•ç”¨é—®é¢˜ï¼‰
        elite_count = int(population_size * elite_ratio)
        new_population = [individual.copy() for individual in sorted_population[:elite_count]]
        
        # ç”Ÿæˆå‰©ä½™ä¸ªä½“
        remaining_count = population_size - elite_count
        children_needed = remaining_count // 2 * 2  # ç¡®ä¿å¶æ•°ä¸ªå­ä»£
        
        for _ in range(children_needed // 2):
            # é€‰æ‹©çˆ¶æ¯ï¼ˆé”¦æ ‡èµ›é€‰æ‹©ï¼‰
            parent1 = self._tournament_selection(sorted_population, sorted_scores)
            parent2 = self._tournament_selection(sorted_population, sorted_scores)
            
            # äº¤å‰
            if np.random.random() < crossover_rate:
                child1, child2 = self._crossover(parent1, parent2, param_ranges)
            else:
                child1, child2 = parent1.copy(), parent2.copy()
            
            # å˜å¼‚ï¼ˆæ¯ä¸ªå­ä»£ç‹¬ç«‹å†³å®šæ˜¯å¦å˜å¼‚ï¼‰
            if np.random.random() < mutation_rate:
                child1 = self._mutate(child1, param_ranges)
            if np.random.random() < mutation_rate:
                child2 = self._mutate(child2, param_ranges)
            
            # æ·»åŠ åˆ°æ–°ç§ç¾¤
            new_population.extend([child1, child2])
        
        # å¦‚æœè¿˜éœ€è¦è¡¥å……ä¸ªä½“ï¼ˆå¥‡æ•°æƒ…å†µï¼‰
        while len(new_population) < population_size:
            parent = self._tournament_selection(sorted_population, sorted_scores)
            child = self._mutate(parent.copy(), param_ranges) if np.random.random() < mutation_rate else parent.copy()
            new_population.append(child)
        
        # ç¡®ä¿ç²¾ç¡®çš„ç§ç¾¤å¤§å°
        return new_population[:population_size]
    
    def _tournament_selection(self, population: List[Dict], scores: List[float], 
                             tournament_size: int = 5) -> Dict:
        """
        é”¦æ ‡èµ›é€‰æ‹©
        
        å‚æ•°:
        population: ç§ç¾¤
        scores: è¯„åˆ†
        tournament_size: é”¦æ ‡èµ›å¤§å°
        
        è¿”å›:
        Dict: é€‰ä¸­çš„ä¸ªä½“
        """
        if not population or not scores:
            raise ValueError("ç§ç¾¤æˆ–è¯„åˆ†åˆ—è¡¨ä¸ºç©º")
        
        if len(population) != len(scores):
            raise ValueError(f"ç§ç¾¤å¤§å°({len(population)})ä¸è¯„åˆ†æ•°é‡({len(scores)})ä¸åŒ¹é…")
        
        # è¿‡æ»¤æœ‰æ•ˆçš„ä¸ªä½“ï¼ˆè¯„åˆ†ä¸æ˜¯è´Ÿæ— ç©·æˆ–NaNï¼‰
        valid_indices = [i for i, score in enumerate(scores) 
                        if score != -float('inf') and not np.isnan(score)]
        
        if not valid_indices:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆä¸ªä½“ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª
            self.logger.warning("é”¦æ ‡èµ›é€‰æ‹©ï¼šæ²¡æœ‰æœ‰æ•ˆä¸ªä½“ï¼Œéšæœºé€‰æ‹©")
            return population[np.random.randint(len(population))].copy()
        
        # ä»æœ‰æ•ˆä¸ªä½“ä¸­è¿›è¡Œé”¦æ ‡èµ›é€‰æ‹©
        available_size = len(valid_indices)
        actual_tournament_size = min(tournament_size, available_size)
        
        tournament_indices = np.random.choice(valid_indices, 
                                            size=actual_tournament_size, 
                                            replace=False)
        
        # æ‰¾åˆ°æœ€ä½³ä¸ªä½“
        best_idx = max(tournament_indices, key=lambda i: scores[i])
        return population[best_idx].copy()
    
    def _crossover(self, parent1: Dict, parent2: Dict, param_ranges: dict) -> Tuple[Dict, Dict]:
        """
        äº¤å‰æ“ä½œï¼ˆç»Ÿä¸€äº¤å‰ + ç®—æœ¯äº¤å‰ï¼‰
        
        å‚æ•°:
        parent1: çˆ¶æ¯1
        parent2: çˆ¶æ¯2
        param_ranges: å‚æ•°èŒƒå›´
        
        è¿”å›:
        Tuple[Dict, Dict]: ä¸¤ä¸ªå­ä»£
        """
        # å‚æ•°ä¸€è‡´æ€§æ£€æŸ¥
        if set(parent1.keys()) != set(parent2.keys()):
            self.logger.warning("çˆ¶æ¯ä¸ªä½“å‚æ•°ä¸ä¸€è‡´ï¼Œä½¿ç”¨äº¤é›†")
            common_params = set(parent1.keys()) & set(parent2.keys())
        else:
            common_params = set(parent1.keys())
        
        child1, child2 = {}, {}
        
        for param_name in common_params:
            # ç¡®ä¿å‚æ•°åœ¨ä¸¤ä¸ªçˆ¶æ¯ä¸­éƒ½å­˜åœ¨
            if param_name not in parent2:
                child1[param_name] = parent1[param_name]
                child2[param_name] = parent1[param_name]
                continue
            
            if np.random.random() < 0.5:
                # äº¤æ¢åŸºå› 
                child1[param_name] = parent2[param_name]
                child2[param_name] = parent1[param_name]
            else:
                child1[param_name] = parent1[param_name]
                child2[param_name] = parent2[param_name]
            
            # ç®—æœ¯äº¤å‰ï¼ˆç”¨äºæ•°å€¼å‚æ•°ï¼‰
            if np.random.random() < 0.3:  # 30%æ¦‚ç‡è¿›è¡Œç®—æœ¯äº¤å‰
                alpha = np.random.random()
                val1 = parent1[param_name]
                val2 = parent2[param_name]
                
                new_val1 = alpha * val1 + (1 - alpha) * val2
                new_val2 = (1 - alpha) * val1 + alpha * val2
                
                # ç¡®ä¿åœ¨èŒƒå›´å†…
                param_config = param_ranges.get(param_name, {})
                min_val = param_config.get('min', 0)
                max_val = param_config.get('max', 1)
                param_type = param_config.get('type', 'float')
                
                new_val1 = np.clip(new_val1, min_val, max_val)
                new_val2 = np.clip(new_val2, min_val, max_val)
                
                if param_type == 'int':
                    new_val1 = int(round(new_val1))
                    new_val2 = int(round(new_val2))
                else:
                    precision = param_config.get('precision', 4)
                    new_val1 = round(new_val1, precision)
                    new_val2 = round(new_val2, precision)
                
                child1[param_name] = new_val1
                child2[param_name] = new_val2
        
        return child1, child2
    
    def _mutate(self, individual: Dict, param_ranges: dict, 
               mutation_strength: float = 0.1) -> Dict:
        """
        å˜å¼‚æ“ä½œ
        
        å‚æ•°:
        individual: ä¸ªä½“
        param_ranges: å‚æ•°èŒƒå›´
        mutation_strength: å˜å¼‚å¼ºåº¦
        
        è¿”å›:
        Dict: å˜å¼‚åçš„ä¸ªä½“
        """
        mutated = individual.copy()
        
        for param_name, param_value in individual.items():
            if np.random.random() < 0.3:  # æ¯ä¸ªåŸºå› 30%æ¦‚ç‡å˜å¼‚
                param_config = param_ranges.get(param_name, {})
                min_val = param_config.get('min', 0)
                max_val = param_config.get('max', 1)
                param_type = param_config.get('type', 'float')
                
                if param_type == 'int':
                    # æ•´æ•°å˜å¼‚ï¼šéšæœºé€‰æ‹©é‚»è¿‘å€¼
                    mutation_range = max(1, int((max_val - min_val) * mutation_strength))
                    delta = np.random.randint(-mutation_range, mutation_range + 1)
                    new_val = param_value + delta
                    new_val = np.clip(new_val, min_val, max_val)
                    mutated[param_name] = int(new_val)
                else:
                    # æµ®ç‚¹æ•°å˜å¼‚ï¼šé«˜æ–¯å˜å¼‚
                    mutation_range = (max_val - min_val) * mutation_strength
                    delta = np.random.normal(0, mutation_range)
                    new_val = param_value + delta
                    new_val = np.clip(new_val, min_val, max_val)
                    
                    precision = param_config.get('precision', 4)
                    mutated[param_name] = round(new_val, precision)
        
        return mutated
    
    def _validate_and_fix_parameters(self, params: Dict, param_ranges: dict) -> Dict:
        """
        éªŒè¯å¹¶ä¿®å¤å‚æ•°
        
        å‚æ•°:
        params: å‚æ•°å­—å…¸
        param_ranges: å‚æ•°èŒƒå›´
        
        è¿”å›:
        Dict: ä¿®å¤åçš„å‚æ•°
        """
        fixed_params = {}
        
        for param_name, param_value in params.items():
            if param_name in param_ranges:
                param_config = param_ranges[param_name]
                min_val = param_config.get('min', 0)
                max_val = param_config.get('max', 1)
                param_type = param_config.get('type', 'float')
                
                # ç¡®ä¿åœ¨èŒƒå›´å†…
                fixed_value = np.clip(param_value, min_val, max_val)
                
                if param_type == 'int':
                    fixed_value = int(round(fixed_value))
                else:
                    precision = param_config.get('precision', 4)
                    fixed_value = round(fixed_value, precision)
                
                fixed_params[param_name] = fixed_value
            else:
                fixed_params[param_name] = param_value
        
        return fixed_params
    
    def _log_genetic_statistics(self, recent_generations: List[Dict]):
        """
        è®°å½•é—ä¼ ç®—æ³•ç»Ÿè®¡ä¿¡æ¯
        
        å‚æ•°:
        recent_generations: æœ€è¿‘å‡ ä»£çš„ç»Ÿè®¡ä¿¡æ¯
        """
        if not recent_generations or len(recent_generations) == 0:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„ä»£æ•°ç»Ÿè®¡ä¿¡æ¯")
            return
        
        try:
            avg_scores = [gen.get('avg_score', 0) for gen in recent_generations if gen.get('avg_score') is not None and gen.get('avg_score') != -1.0]
            max_scores = [gen.get('max_score', 0) for gen in recent_generations if gen.get('max_score') is not None and gen.get('max_score') != -1.0]
            generation_times = [gen.get('generation_time', 0) for gen in recent_generations if gen.get('generation_time') is not None]
            
            if not avg_scores or not max_scores:
                self.logger.warning("ç»Ÿè®¡æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡ç»Ÿè®¡æŠ¥å‘Š")
                return
            
            self.logger.info(f"ğŸ“Š æœ€è¿‘ {len(recent_generations)} ä»£æ€§èƒ½åˆ†æ:")
            self.logger.info(f"   ğŸ“ˆ å¹³å‡åˆ†è¶‹åŠ¿: {avg_scores[0]:.4f} â†’ {avg_scores[-1]:.4f} "
                           f"(å˜åŒ–: {avg_scores[-1] - avg_scores[0]:+.4f})")
            self.logger.info(f"   ğŸ¯ æœ€é«˜åˆ†è¶‹åŠ¿: {max_scores[0]:.4f} â†’ {max_scores[-1]:.4f} "
                           f"(æ”¹å–„: {max_scores[-1] - max_scores[0]:+.4f})")
            
            if generation_times:
                avg_time = np.mean(generation_times)
                self.logger.info(f"   â±ï¸ å¹³å‡ä»£è€—æ—¶: {avg_time:.2f}s")
            
            # æ”¶æ•›æ€§åˆ†æ
            if len(max_scores) >= 3:
                recent_improvement = max_scores[-1] - max_scores[-3]
                if abs(recent_improvement) < 0.001:
                    self.logger.info(f"   ğŸ¯ æ”¶æ•›çŠ¶æ€: ç¨³å®š (è¿‘æœŸæ”¹å–„: {recent_improvement:+.6f})")
                else:
                    self.logger.info(f"   ğŸš€ æ”¶æ•›çŠ¶æ€: ä¼˜åŒ–ä¸­ (è¿‘æœŸæ”¹å–„: {recent_improvement:+.6f})")
            
        except Exception as e:
            self.logger.warning(f"ç»Ÿè®¡ä¿¡æ¯ç”Ÿæˆå¤±è´¥: {e}")