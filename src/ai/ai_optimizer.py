#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
AIä¼˜åŒ–æ¨¡å—
ä½¿ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•ä¼˜åŒ–ç­–ç•¥å‚æ•°å’Œé¢„æµ‹ç›¸å¯¹ä½ç‚¹
"""

import os
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Any, List, Tuple, Optional
import pickle
import json
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from strategy.strategy_module import StrategyModule

# æœºå™¨å­¦ä¹ ç›¸å…³
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

class AIOptimizer:
    """AIä¼˜åŒ–å™¨ç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–AIä¼˜åŒ–å™¨
        
        å‚æ•°:
        config: é…ç½®å­—å…¸
        """
        self.logger = logging.getLogger('AIOptimizer')
        self.config = config
        
        # AIé…ç½®
        ai_config = config.get('ai', {})
        self.model_type = ai_config.get('model_type', 'machine_learning')
        self.optimization_interval = ai_config.get('optimization_interval', 30)
        
        # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
        self.models_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'models')
        if not os.path.exists(self.models_dir):
            os.makedirs(self.models_dir)
            
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = None
        self.scaler = None
        self.feature_names = None
        
        self.logger.info("AIä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹ç±»å‹: %s", self.model_type)
        
    def optimize_strategy_parameters(self, strategy_module, data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä¼˜åŒ–ç­–ç•¥å‚æ•°
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–åçš„å‚æ•°
        """
        self.logger.info("å¼€å§‹ä¼˜åŒ–ç­–ç•¥å‚æ•°")
        
        try:
            # 1. è·å–åŸºå‡†ç­–ç•¥çš„è¯†åˆ«ç»“æœä½œä¸ºå›ºå®šæ ‡ç­¾
            baseline_backtest = strategy_module.backtest(data)
            fixed_labels = baseline_backtest['is_low_point'].astype(int).values
            self.logger.info(f"åŸºå‡†ç­–ç•¥è¯†åˆ«ç‚¹æ•°: {np.sum(fixed_labels)}")
            
            # 2. ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°æœç´¢èŒƒå›´
            optimization_config = self.config.get('optimization', {})
            param_ranges = optimization_config.get('param_ranges', {})
            
            # è·å–å„ä¸ªå‚æ•°çš„æœç´¢èŒƒå›´
            rise_threshold_range = param_ranges.get('rise_threshold', {})
            max_days_range = param_ranges.get('max_days', {})
            rsi_oversold_range = param_ranges.get('rsi_oversold_threshold', {})
            rsi_low_range = param_ranges.get('rsi_low_threshold', {})
            final_threshold_range = param_ranges.get('final_threshold', {})
            
            # å®šä¹‰å‚æ•°æœç´¢ç©ºé—´
            param_grid = {
                'rise_threshold': np.arange(
                    rise_threshold_range.get('min', 0.03),
                    rise_threshold_range.get('max', 0.08) + rise_threshold_range.get('step', 0.005),
                    rise_threshold_range.get('step', 0.005)
                ),
                'max_days': np.arange(
                    max_days_range.get('min', 10),
                    max_days_range.get('max', 30) + max_days_range.get('step', 1),
                    max_days_range.get('step', 1)
                ),
                'rsi_oversold_threshold': np.arange(
                    rsi_oversold_range.get('min', 25),
                    rsi_oversold_range.get('max', 35) + rsi_oversold_range.get('step', 1),
                    rsi_oversold_range.get('step', 1)
                ),
                'rsi_low_threshold': np.arange(
                    rsi_low_range.get('min', 35),
                    rsi_low_range.get('max', 45) + rsi_low_range.get('step', 1),
                    rsi_low_range.get('step', 1)
                ),
                'final_threshold': np.arange(
                    final_threshold_range.get('min', 0.3),
                    final_threshold_range.get('max', 0.7) + final_threshold_range.get('step', 0.05),
                    final_threshold_range.get('step', 0.05)
                )
            }
            
            self.logger.info(f"å‚æ•°æœç´¢èŒƒå›´:")
            for param, values in param_grid.items():
                self.logger.info(f"  {param}: {values[0]} - {values[-1]}, æ­¥é•¿: {values[1]-values[0] if len(values)>1 else 'N/A'}")
            
            best_score = -1
            best_params = None
            total_combinations = 1
            for values in param_grid.values():
                total_combinations *= len(values)
            
            self.logger.info(f"æ€»æœç´¢ç»„åˆæ•°: {total_combinations}")
            
            # 3. åŸºäºå›ºå®šæ ‡ç­¾ä¼˜åŒ–ç­–ç•¥å‚æ•°
            # ä¸ºäº†å‡å°‘è®¡ç®—é‡ï¼Œæˆ‘ä»¬ä½¿ç”¨éšæœºé‡‡æ ·è€Œä¸æ˜¯å…¨ç½‘æ ¼æœç´¢
            max_iterations = min(100, total_combinations)  # æœ€å¤š100æ¬¡è¿­ä»£
            self.logger.info(f"ä½¿ç”¨éšæœºé‡‡æ ·ï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
            
            for iteration in range(max_iterations):
                # éšæœºé€‰æ‹©å‚æ•°ç»„åˆ
                params = {
                    'rise_threshold': np.random.choice(param_grid['rise_threshold']),
                    'max_days': int(np.random.choice(param_grid['max_days'])),
                    'rsi_oversold_threshold': int(np.random.choice(param_grid['rsi_oversold_threshold'])),
                    'rsi_low_threshold': int(np.random.choice(param_grid['rsi_low_threshold'])),
                    'final_threshold': np.random.choice(param_grid['final_threshold'])
                }
                
                # ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°å‚æ•°
                score = self._evaluate_params_with_fixed_labels_advanced(
                    data, fixed_labels, params
                )
                
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
                    self.logger.info(f"å‘ç°æ›´å¥½çš„å‚æ•°ç»„åˆ (è¿­ä»£ {iteration+1}): {best_params}, å¾—åˆ†: {best_score:.4f}")
                        
            self.logger.info("å‚æ•°ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³å‚æ•°: %s, å¾—åˆ†: %.4f", best_params, best_score)
            return best_params
            
        except Exception as e:
            self.logger.error("ä¼˜åŒ–ç­–ç•¥å‚æ•°å¤±è´¥: %s", str(e))
            # è¿”å›é»˜è®¤å‚æ•°
            return {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.05),
                'max_days': self.config.get('strategy', {}).get('max_days', 20),
                'rsi_oversold_threshold': self.config.get('strategy', {}).get('confidence_weights', {}).get('rsi_oversold_threshold', 30),
                'rsi_low_threshold': self.config.get('strategy', {}).get('confidence_weights', {}).get('rsi_low_threshold', 40),
                'final_threshold': self.config.get('strategy', {}).get('confidence_weights', {}).get('final_threshold', 0.5)
            }
    
    def _evaluate_params_with_fixed_labels(self, data: pd.DataFrame, fixed_labels: np.ndarray, 
                                         rise_threshold: float, max_days: int) -> float:
        """
        ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°ç­–ç•¥å‚æ•°
        
        å‚æ•°:
        data: å†å²æ•°æ®
        fixed_labels: å›ºå®šçš„æ ‡ç­¾ï¼ˆç›¸å¯¹ä½ç‚¹æ ‡è¯†ï¼‰
        rise_threshold: æ¶¨å¹…é˜ˆå€¼
        max_days: æœ€å¤§å¤©æ•°
        
        è¿”å›:
        float: ç­–ç•¥å¾—åˆ†
        """
        try:
            # 1. è®¡ç®—æ¯ä¸ªè¯†åˆ«ç‚¹çš„æœªæ¥è¡¨ç°
            scores = []
            low_point_indices = np.where(fixed_labels == 1)[0]
            
            for idx in low_point_indices:
                if idx >= len(data) - max_days:
                    continue
                    
                current_price = data.iloc[idx]['close']
                max_rise = 0.0
                days_to_rise = 0
                
                # è®¡ç®—æœªæ¥max_dayså†…çš„æœ€å¤§æ¶¨å¹…
                for j in range(1, max_days + 1):
                    if idx + j >= len(data):
                        break
                    future_price = data.iloc[idx + j]['close']
                    rise_rate = (future_price - current_price) / current_price
                    
                    if rise_rate > max_rise:
                        max_rise = rise_rate
                        
                    if rise_rate >= rise_threshold and days_to_rise == 0:
                        days_to_rise = j
                
                # è®¡ç®—å•ä¸ªç‚¹çš„å¾—åˆ†
                success = max_rise >= rise_threshold
                point_score = self._calculate_point_score(success, max_rise, days_to_rise, max_days)
                scores.append(point_score)
            
            # 2. è®¡ç®—æ€»ä½“å¾—åˆ†
            if len(scores) == 0:
                return 0.0
                
            return np.mean(scores)
            
        except Exception as e:
            self.logger.error("è¯„ä¼°å‚æ•°å¤±è´¥: %s", str(e))
            return 0.0
    
    def _calculate_point_score(self, success: bool, max_rise: float, days_to_rise: int, max_days: int) -> float:
        """
        è®¡ç®—å•ä¸ªè¯†åˆ«ç‚¹çš„å¾—åˆ†
        
        å‚æ•°:
        success: æ˜¯å¦æˆåŠŸè¾¾åˆ°ç›®æ ‡æ¶¨å¹…
        max_rise: æœ€å¤§æ¶¨å¹…
        days_to_rise: è¾¾åˆ°ç›®æ ‡æ¶¨å¹…çš„å¤©æ•°
        max_days: æœ€å¤§è§‚å¯Ÿå¤©æ•°
        
        è¿”å›:
        float: å•ä¸ªç‚¹å¾—åˆ†
        """
        # ä»é…ç½®æ–‡ä»¶è·å–è¯„åˆ†å‚æ•°
        ai_config = self.config.get('ai', {})
        scoring_config = ai_config.get('scoring', {})
        
        # æˆåŠŸç‡æƒé‡ï¼š40%
        success_weight = scoring_config.get('success_weight', 0.4)
        success_score = 1.0 if success else 0.0
        
        # æ¶¨å¹…æƒé‡ï¼š30%ï¼ˆç›¸å¯¹äºåŸºå‡†æ¶¨å¹…ï¼‰
        rise_weight = scoring_config.get('rise_weight', 0.3)
        rise_benchmark = scoring_config.get('rise_benchmark', 0.1)  # 10%åŸºå‡†
        rise_score = min(max_rise / rise_benchmark, 1.0)
        
        # é€Ÿåº¦æƒé‡ï¼š20%ï¼ˆå¤©æ•°è¶Šå°‘è¶Šå¥½ï¼‰
        speed_weight = scoring_config.get('speed_weight', 0.2)
        if days_to_rise > 0:
            speed_score = min(max_days / days_to_rise, 1.0)
        else:
            speed_score = 0.0
        
        # é£é™©è°ƒæ•´ï¼š10%ï¼ˆé¿å…è¿‡åº¦å†’é™©ï¼‰
        risk_weight = scoring_config.get('risk_weight', 0.1)
        risk_benchmark = scoring_config.get('risk_benchmark', 0.2)  # 20%é£é™©é˜ˆå€¼
        risk_score = min(max_rise / risk_benchmark, 1.0)  # è¶…è¿‡é£é™©é˜ˆå€¼çš„æ¶¨å¹…ç»™äºˆé£é™©æƒ©ç½š
        
        # ç»¼åˆå¾—åˆ†
        total_score = (
            success_score * success_weight +
            rise_score * rise_weight +
            speed_score * speed_weight +
            risk_score * risk_weight
        )
        
        return total_score
        
    def prepare_features(self, data: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        å‡†å¤‡æœºå™¨å­¦ä¹ ç‰¹å¾
        
        å‚æ•°:
        data: å†å²æ•°æ®
        
        è¿”å›:
        tuple: (ç‰¹å¾çŸ©é˜µ, ç‰¹å¾åç§°åˆ—è¡¨)
        """
        self.logger.info("å‡†å¤‡æœºå™¨å­¦ä¹ ç‰¹å¾")
        
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_columns = [
            'ma5', 'ma10', 'ma20', 'ma60',
            'rsi', 'macd', 'signal', 'hist',
            'bb_upper', 'bb_lower',
            'dist_ma5', 'dist_ma10', 'dist_ma20',
            'volume_change', 'volatility',
            'price_change', 'price_change_5d', 'price_change_10d'
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„åˆ—
        available_columns = [col for col in feature_columns if col in data.columns]
        
        if len(available_columns) == 0:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾åˆ—")
            return np.array([]), []
            
        # æå–ç‰¹å¾
        features = data[available_columns].fillna(0).values
        
        self.logger.info("ç‰¹å¾å‡†å¤‡å®Œæˆï¼Œç‰¹å¾æ•°é‡: %d, æ ·æœ¬æ•°é‡: %d", 
                        len(available_columns), len(features))
        
        return features, available_columns
        
    def prepare_labels(self, data: pd.DataFrame, strategy_module) -> np.ndarray:
        """
        å‡†å¤‡æœºå™¨å­¦ä¹ æ ‡ç­¾
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        
        è¿”å›:
        numpy.ndarray: æ ‡ç­¾æ•°ç»„
        """
        self.logger.info("å‡†å¤‡æœºå™¨å­¦ä¹ æ ‡ç­¾")
        
        # è¿è¡Œå›æµ‹è·å–çœŸå®çš„ç›¸å¯¹ä½ç‚¹æ ‡ç­¾
        backtest_results = strategy_module.backtest(data)
        labels = backtest_results['is_low_point'].astype(int).values
        
        positive_count = np.sum(labels)
        total_count = len(labels)
        
        self.logger.info("æ ‡ç­¾å‡†å¤‡å®Œæˆï¼Œæ­£æ ·æœ¬: %d, æ€»æ ·æœ¬: %d, æ­£æ ·æœ¬æ¯”ä¾‹: %.2f%%", 
                        positive_count, total_count, positive_count / total_count * 100)
        
        return labels
        
    def train_model(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        åªè´Ÿè´£è®­ç»ƒæ¨¡å‹å¹¶ä¿å­˜ï¼Œä¸åšè¯„ä¼°ã€‚
        """
        self.logger.info("å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼ˆä¸åšéªŒè¯è¯„ä¼°ï¼‰")
        try:
            features, feature_names = self.prepare_features(data)
            labels = self.prepare_labels(data, strategy_module)
            if len(features) == 0 or len(labels) == 0:
                self.logger.error("ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
                return {'success': False, 'error': 'ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©º'}
            min_length = min(len(features), len(labels))
            features = features[:min_length]
            labels = labels[:min_length]
            aligned_data = data.iloc[:min_length].copy()
            split_ratio = self.config.get("ai", {}).get("train_test_split_ratio", 0.8)
            split_index = int(len(features) * split_ratio)
            X_train = features[:split_index]
            y_train = labels[:split_index]
            train_dates = aligned_data["date"].iloc[:split_index]
            sample_weights = self._calculate_sample_weights(train_dates)
            if self.model_type == 'machine_learning':
                model = Pipeline([
                    ('scaler', StandardScaler()),
                    ('classifier', RandomForestClassifier(
                        n_estimators=100,
                        max_depth=10,
                        min_samples_split=5,
                        min_samples_leaf=2,
                        random_state=42,
                        class_weight='balanced'
                    ))
                ])
            else:
                model = Pipeline([
                    ('scaler', StandardScaler()),
                    ('classifier', RandomForestClassifier(
                        n_estimators=100,
                        random_state=42,
                        class_weight='balanced'
                    ))
                ])
            self.logger.info(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, sample_weights shape: {sample_weights.shape}")
            model.fit(X_train, y_train, classifier__sample_weight=sample_weights)
            self.model = model
            self.feature_names = feature_names
            self._save_model()
            self.logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")
            return {'success': True, 'train_samples': len(X_train), 'feature_count': len(feature_names)}
        except Exception as e:
            self.logger.error("è®­ç»ƒæ¨¡å‹å¤±è´¥: %s", str(e))
            return {'success': False, 'error': str(e)}

    def validate_model(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        åªè´Ÿè´£è¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°ã€‚
        """
        self.logger.info("å¼€å§‹éªŒè¯æ¨¡å‹ï¼ˆåªåšè¯„ä¼°ï¼Œä¸è®­ç»ƒï¼‰")
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    return {'success': False, 'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'}
            features, feature_names = self.prepare_features(data)
            labels = self.prepare_labels(data, strategy_module)
            if len(features) == 0 or len(labels) == 0:
                self.logger.error("ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œæ— æ³•éªŒè¯æ¨¡å‹")
                return {'success': False, 'error': 'ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©º'}
            min_length = min(len(features), len(labels))
            features = features[:min_length]
            labels = labels[:min_length]
            split_ratio = self.config.get("ai", {}).get("train_test_split_ratio", 0.8)
            split_index = int(len(features) * split_ratio)
            X_test = features[split_index:]
            y_test = labels[split_index:]
            if len(X_test) == 0 or len(y_test) == 0:
                self.logger.warning("éªŒè¯é›†ä¸ºç©ºï¼Œæ— æ³•è¯„ä¼°æ¨¡å‹")
                return {'success': False, 'error': 'éªŒè¯é›†ä¸ºç©º'}
            y_pred = self.model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, zero_division=0)
            recall = recall_score(y_test, y_pred, zero_division=0)
            f1 = f1_score(y_test, y_pred, zero_division=0)
            positive_count_test = np.sum(y_test)
            self.logger.info("æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°å®Œæˆï¼Œå‡†ç¡®ç‡: %.4f, ç²¾ç¡®ç‡: %.4f, å¬å›ç‡: %.4f, F1: %.4f", accuracy, precision, recall, f1)
            return {
                'success': True,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'test_samples': len(X_test),
                'positive_samples_test': positive_count_test
            }
        except Exception as e:
            self.logger.error("éªŒè¯æ¨¡å‹å¤±è´¥: %s", str(e))
            return {'success': False, 'error': str(e)}

    def predict_low_point(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        é¢„æµ‹ç›¸å¯¹ä½ç‚¹
        
        å‚æ•°:
        data: å¸‚åœºæ•°æ®
        
        è¿”å›:
        dict: é¢„æµ‹ç»“æœ
        """
        self.logger.info("é¢„æµ‹ç›¸å¯¹ä½ç‚¹")
        
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    return {
                        'is_low_point': False,
                        'confidence': 0.0,
                        'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'
                    }
                    
            if len(data) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'error': 'æ•°æ®ä¸ºç©º'
                }
                
            # å‡†å¤‡ç‰¹å¾
            features, _ = self.prepare_features(data)
            
            if len(features) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'error': 'æ— æ³•æå–ç‰¹å¾'
                }
                
            # ä½¿ç”¨æœ€æ–°æ•°æ®è¿›è¡Œé¢„æµ‹
            latest_features = features[-1:].reshape(1, -1)
            
            # é¢„æµ‹
            prediction = self.model.predict(latest_features)[0]
            prediction_proba = self.model.predict_proba(latest_features)[0]
            
            # è·å–ç½®ä¿¡åº¦
            confidence = prediction_proba[1] if len(prediction_proba) > 1 else 0.0
            
            result = {
                'is_low_point': bool(prediction),
                'confidence': float(confidence),
                'prediction_proba': prediction_proba.tolist()
            }
            
            self.logger.info("----------------------------------------------------");
            self.logger.info("AIé¢„æµ‹ç»“æœ: \033[1m%s\033[0m, ç½®ä¿¡åº¦: \033[1m%.4f\033[0m", 
                           "ç›¸å¯¹ä½ç‚¹" if prediction else "éç›¸å¯¹ä½ç‚¹", confidence)
            self.logger.info("----------------------------------------------------");
            return result
            
        except Exception as e:
            self.logger.error("é¢„æµ‹ç›¸å¯¹ä½ç‚¹å¤±è´¥: %s", str(e))
            return {
                'is_low_point': False,
                'confidence': 0.0,
                'error': str(e)
            }
            
    def get_feature_importance(self) -> Optional[Dict[str, float]]:
        """
        è·å–ç‰¹å¾é‡è¦æ€§
        
        è¿”å›:
        dict: ç‰¹å¾é‡è¦æ€§ï¼Œå¦‚æœæ¨¡å‹æœªè®­ç»ƒè¿”å›None
        """
        if self.model is None or self.feature_names is None:
            return None
            
        try:
            # è·å–åˆ†ç±»å™¨
            classifier = self.model.named_steps['classifier']
            
            if hasattr(classifier, 'feature_importances_'):
                importances = classifier.feature_importances_
                feature_importance = dict(zip(self.feature_names, importances))
                
                # æŒ‰é‡è¦æ€§æ’åº
                sorted_importance = dict(sorted(feature_importance.items(), 
                                              key=lambda x: x[1], reverse=True))
                
                self.logger.info("ç‰¹å¾é‡è¦æ€§è·å–æˆåŠŸ")
                return sorted_importance
            else:
                self.logger.warning("æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§")
                return None
                
        except Exception as e:
            self.logger.error("è·å–ç‰¹å¾é‡è¦æ€§å¤±è´¥: %s", str(e))
            return None
            
    def _save_model(self) -> bool:
        """
        ä¿å­˜æ¨¡å‹
        
        è¿”å›:
        bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ä¿å­˜æ¨¡å‹
            model_path = os.path.join(self.models_dir, f'model_{timestamp}.pkl')
            with open(model_path, 'wb') as f:
                pickle.dump(self.model, f)
                
            # ä¿å­˜ç‰¹å¾åç§°
            features_path = os.path.join(self.models_dir, f'features_{timestamp}.json')
            with open(features_path, 'w') as f:
                json.dump(self.feature_names, f)
                
            # ä¿å­˜æœ€æ–°æ¨¡å‹çš„è·¯å¾„
            latest_path = os.path.join(self.models_dir, 'latest_model.txt')
            with open(latest_path, 'w') as f:
                f.write(f'{model_path}\n{features_path}')
                
            self.logger.info("æ¨¡å‹ä¿å­˜æˆåŠŸ: %s", model_path)
            return True
            
        except Exception as e:
            self.logger.error("ä¿å­˜æ¨¡å‹å¤±è´¥: %s", str(e))
            return False
            
    def _load_model(self) -> bool:
        """
        åŠ è½½æ¨¡å‹
        
        è¿”å›:
        bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            latest_path = os.path.join(self.models_dir, 'latest_model.txt')
            
            if not os.path.exists(latest_path):
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„æ¨¡å‹")
                return False
                
            # è¯»å–æœ€æ–°æ¨¡å‹è·¯å¾„
            with open(latest_path, 'r') as f:
                lines = f.read().strip().split('\n')
                if len(lines) < 2:
                    self.logger.error("æ¨¡å‹è·¯å¾„æ–‡ä»¶æ ¼å¼é”™è¯¯")
                    return False
                    
                model_path = lines[0]
                features_path = lines[1]
                
            # åŠ è½½æ¨¡å‹
            with open(model_path, 'rb') as f:
                self.model = pickle.load(f)
                
            # åŠ è½½ç‰¹å¾åç§°
            with open(features_path, 'r') as f:
                self.feature_names = json.load(f)
                
            self.logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ: %s", model_path)
            return True
            
        except Exception as e:
            self.logger.error("åŠ è½½æ¨¡å‹å¤±è´¥: %s", str(e))
            return False
            
    def run_genetic_algorithm(self, evaluate_func, population_size: int = 20, 
                            generations: int = 10) -> Dict[str, Any]:
        """
        è¿è¡Œé—ä¼ ç®—æ³•ä¼˜åŒ–
        
        å‚æ•°:
        evaluate_func: è¯„ä¼°å‡½æ•°
        population_size: ç§ç¾¤å¤§å°
        generations: è¿­ä»£ä»£æ•°
        
        è¿”å›:
        dict: æœ€ä¼˜å‚æ•°
        """
        self.logger.info("è¿è¡Œé—ä¼ ç®—æ³•ä¼˜åŒ–ï¼Œç§ç¾¤å¤§å°: %d, è¿­ä»£ä»£æ•°: %d", 
                        population_size, generations)
        
        try:
            # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°èŒƒå›´
            optimization_config = self.config.get('optimization', {})
            param_ranges = optimization_config.get('param_ranges', {})
            rise_threshold_range = param_ranges.get('rise_threshold', {})
            max_days_range = param_ranges.get('max_days', {})
            
            # è·å–rise_thresholdçš„èŒƒå›´
            min_threshold = rise_threshold_range.get('min', 0.03)
            max_threshold = rise_threshold_range.get('max', 0.08)
            
            # è·å–max_daysçš„èŒƒå›´
            min_days = max_days_range.get('min', 10)
            max_days = max_days_range.get('max', 30)
            
            # åˆå§‹åŒ–ç§ç¾¤
            population = []
            for _ in range(population_size):
                individual = {
                    'rise_threshold': np.random.uniform(min_threshold, max_threshold),
                    'max_days': np.random.randint(min_days, max_days + 1)
                }
                population.append(individual)
                
            best_individual = None
            best_score = -1
            
            for generation in range(generations):
                # è¯„ä¼°ç§ç¾¤
                scores = []
                for individual in population:
                    score = evaluate_func(individual)
                    scores.append(score)
                    
                    if score > best_score:
                        best_score = score
                        best_individual = individual.copy()
                        
                # é€‰æ‹©ã€äº¤å‰ã€å˜å¼‚
                population = self._genetic_operations(population, scores)
                
                self.logger.info("ç¬¬ %d ä»£å®Œæˆï¼Œæœ€ä½³å¾—åˆ†: %.4f", generation + 1, best_score)
                
            self.logger.info("é—ä¼ ç®—æ³•ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³å‚æ•°: %s, å¾—åˆ†: %.4f", 
                           best_individual, best_score)
            
            return best_individual
            
        except Exception as e:
            self.logger.error("é—ä¼ ç®—æ³•ä¼˜åŒ–å¤±è´¥: %s", str(e))
            return {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.05), 
                'max_days': self.config.get('strategy', {}).get('max_days', 20)
            }
            
    def _genetic_operations(self, population: List[Dict], scores: List[float]) -> List[Dict]:
        """
        é—ä¼ ç®—æ³•æ“ä½œï¼ˆé€‰æ‹©ã€äº¤å‰ã€å˜å¼‚ï¼‰
        
        å‚æ•°:
        population: å½“å‰ç§ç¾¤
        scores: é€‚åº”åº¦å¾—åˆ†
        
        è¿”å›:
        list: æ–°ç§ç¾¤
        """
        # é€‰æ‹©ï¼ˆè½®ç›˜èµŒé€‰æ‹©ï¼‰
        total_score = sum(scores)
        if total_score <= 0:
            # å¦‚æœæ‰€æœ‰å¾—åˆ†éƒ½æ˜¯è´Ÿæ•°æˆ–é›¶ï¼Œéšæœºé€‰æ‹©
            selected = np.random.choice(len(population), size=len(population), replace=True)
        else:
            probabilities = [score / total_score for score in scores]
            selected = np.random.choice(len(population), size=len(population), 
                                      replace=True, p=probabilities)
            
        new_population = []
        
        for i in range(0, len(population), 2):
            parent1 = population[selected[i]]
            parent2 = population[selected[min(i + 1, len(population) - 1)]]
            
            # äº¤å‰
            child1, child2 = self._crossover(parent1, parent2)
            
            # å˜å¼‚
            child1 = self._mutate(child1)
            child2 = self._mutate(child2)
            
            new_population.extend([child1, child2])
            
        return new_population[:len(population)]
        
    def _crossover(self, parent1: Dict, parent2: Dict) -> Tuple[Dict, Dict]:
        """
        äº¤å‰æ“ä½œ
        
        å‚æ•°:
        parent1: çˆ¶ä»£1
        parent2: çˆ¶ä»£2
        
        è¿”å›:
        tuple: (å­ä»£1, å­ä»£2)
        """
        child1 = {
            'rise_threshold': parent1['rise_threshold'],
            'max_days': parent2['max_days']
        }
        
        child2 = {
            'rise_threshold': parent2['rise_threshold'],
            'max_days': parent1['max_days']
        }
        
        return child1, child2
        
    def _mutate(self, individual: Dict, mutation_rate: float = 0.1) -> Dict:
        """
        å˜å¼‚æ“ä½œ
        
        å‚æ•°:
        individual: ä¸ªä½“
        mutation_rate: å˜å¼‚ç‡
        
        è¿”å›:
        dict: å˜å¼‚åçš„ä¸ªä½“
        """
        mutated = individual.copy()
        
        # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°èŒƒå›´
        optimization_config = self.config.get('optimization', {})
        param_ranges = optimization_config.get('param_ranges', {})
        rise_threshold_range = param_ranges.get('rise_threshold', {})
        max_days_range = param_ranges.get('max_days', {})
        
        # è·å–rise_thresholdçš„èŒƒå›´
        min_threshold = rise_threshold_range.get('min', 0.03)
        max_threshold = rise_threshold_range.get('max', 0.08)
        
        # è·å–max_daysçš„èŒƒå›´
        min_days = max_days_range.get('min', 10)
        max_days = max_days_range.get('max', 30)
        
        if np.random.random() < mutation_rate:
            mutated['rise_threshold'] = np.clip(
                mutated['rise_threshold'] + np.random.normal(0, 0.005),
                min_threshold, max_threshold
            )
            
        if np.random.random() < mutation_rate:
            mutated['max_days'] = np.clip(
                int(mutated['max_days'] + np.random.randint(-2, 3)),
                min_days, max_days
            )
            
        return mutated

    def _calculate_sample_weights(self, dates: pd.Series) -> np.ndarray:
        """
        æ ¹æ®æ•°æ®æ—¥æœŸè®¡ç®—æ ·æœ¬æƒé‡ï¼Œè¶Šè¿‘çš„æ•°æ®æƒé‡è¶Šé«˜ã€‚
        æƒé‡è¡°å‡æ¨¡å‹ï¼šV(t) = Vâ‚€ Ã— e^(-Î»t)
        å…¶ä¸­Î»æ˜¯è¡°å‡ç³»æ•°ï¼Œæ ¹æ®åˆ†ææŠ¥å‘Šï¼ŒÎ»çº¦ä¸º0.3-0.5ã€‚
        è¿™é‡Œæˆ‘ä»¬å–Î»=0.4ï¼Œå¹¶æ ¹æ®æ—¶é—´å·®è®¡ç®—æƒé‡ã€‚
        
        å‚æ•°:
        dates: è®­ç»ƒé›†æ•°æ®çš„æ—¥æœŸåºåˆ—
        
        è¿”å›:
        numpy.ndarray: æ ·æœ¬æƒé‡æ•°ç»„
        """
        self.logger.info("è®¡ç®—æ ·æœ¬æƒé‡")
        
        weights = np.ones(len(dates))
        if len(dates) == 0: # Handle empty dates series
            return weights

        latest_date = dates.max()
        
        for i, date in enumerate(dates):
            time_diff = (latest_date - date).days / 365.25  # å¹´ä¸ºå•ä½
            # è¡°å‡ç³»æ•°Î»ï¼Œå¯ä»¥æ ¹æ®configé…ç½®
            decay_rate = self.config.get("ai", {}).get("data_decay_rate", 0.4)
            weight = np.exp(-decay_rate * time_diff)
            weights[i] = weight
            
        # å½’ä¸€åŒ–æƒé‡ï¼Œä½¿å…¶å’Œä¸º1ï¼Œæˆ–è€…ä¿æŒåŸå§‹æ¯”ä¾‹
        # è¿™é‡Œé€‰æ‹©ä¿æŒåŸå§‹æ¯”ä¾‹ï¼Œå› ä¸ºRandomForestClassifierçš„sample_weightå‚æ•°æ˜¯ä¹˜æ³•å…³ç³»
        # ä¹Ÿå¯ä»¥é€‰æ‹©å½’ä¸€åŒ–åˆ°æŸä¸ªèŒƒå›´ï¼Œä¾‹å¦‚0-1
        
        self.logger.info("æ ·æœ¬æƒé‡è®¡ç®—å®Œæˆï¼Œæœ€å¤§æƒé‡: %.4f, æœ€å°æƒé‡: %.4f", 
                        np.max(weights), np.min(weights))
        
        return weights

    def optimize_strategy_parameters_advanced(self, strategy_module, data: pd.DataFrame) -> Dict[str, Any]:
        """
        é«˜çº§ç­–ç•¥å‚æ•°ä¼˜åŒ– - ä½¿ç”¨å¤šç›®æ ‡ä¼˜åŒ–
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–åçš„å‚æ•°
        """
        self.logger.info("å¼€å§‹é«˜çº§ç­–ç•¥å‚æ•°ä¼˜åŒ–")
        
        try:
            from scipy.optimize import minimize
            
            def objective(params):
                rise_threshold = params[0]
                
                # ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°
                baseline_strategy = StrategyModule(self.config)
                baseline_backtest = baseline_strategy.backtest(data)
                fixed_labels = baseline_backtest['is_low_point'].astype(int).values
                
                # ä»configè¯»å–max_daysï¼Œä¸å‚ä¸ä¼˜åŒ–
                max_days = self.config.get('strategy', {}).get('max_days', 20)
                
                score = self._evaluate_params_with_fixed_labels(
                    data, fixed_labels, rise_threshold, max_days
                )
                
                return -score  # æœ€å°åŒ–è´Ÿå¾—åˆ† = æœ€å¤§åŒ–å¾—åˆ†
            
            # çº¦æŸæ¡ä»¶ï¼ˆåªä¼˜åŒ–rise_thresholdï¼‰
            # ä»é…ç½®æ–‡ä»¶è·å–rise_thresholdçš„èŒƒå›´
            optimization_config = self.config.get('optimization', {})
            param_ranges = optimization_config.get('param_ranges', {})
            rise_threshold_range = param_ranges.get('rise_threshold', {})
            
            min_threshold = rise_threshold_range.get('min', 0.03)
            max_threshold = rise_threshold_range.get('max', 0.08)
            
            bounds = [(min_threshold, max_threshold)]
            
            # åˆå§‹å€¼
            x0 = [self.config.get('strategy', {}).get('rise_threshold', 0.05)]
            
            # ä¼˜åŒ–
            result = minimize(objective, x0, bounds=bounds, method='L-BFGS-B')
            
            if result.success:
                # ä»configè¯»å–max_days
                max_days = self.config.get('strategy', {}).get('max_days', 20)
                
                best_params = {
                    'rise_threshold': result.x[0],
                    'max_days': max_days
                }
                best_score = -result.fun
                
                self.logger.info("é«˜çº§ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³å‚æ•°: %s, å¾—åˆ†: %.4f", best_params, best_score)
                return best_params
            else:
                self.logger.warning("é«˜çº§ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç½‘æ ¼æœç´¢")
                return self.optimize_strategy_parameters(strategy_module, data)
                
        except ImportError:
            self.logger.warning("scipyæœªå®‰è£…ï¼Œä½¿ç”¨ç½‘æ ¼æœç´¢")
            return self.optimize_strategy_parameters(strategy_module, data)
        except Exception as e:
            self.logger.error("é«˜çº§ä¼˜åŒ–å¤±è´¥: %s", str(e))
            return self.optimize_strategy_parameters(strategy_module, data)
    
    def time_series_cv_evaluation(self, data: pd.DataFrame, strategy_module) -> float:
        """
        æ—¶é—´åºåˆ—äº¤å‰éªŒè¯è¯„ä¼°
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        
        è¿”å›:
        float: å¹³å‡å¾—åˆ†
        """
        self.logger.info("ğŸ”„ å¼€å§‹æ—¶é—´åºåˆ—äº¤å‰éªŒè¯è¯„ä¼°")
        
        try:
            total_score = 0
            cv_folds = 5
            fold_scores = []
            
            self.logger.info(f"ğŸ“Š å°†æ•°æ®åˆ†ä¸º {cv_folds} æŠ˜è¿›è¡ŒéªŒè¯...")
            
            for i in range(cv_folds):
                # æŒ‰æ—¶é—´åˆ†å‰²æ•°æ®
                split_point = int(len(data) * (i + 1) / cv_folds)
                train_data = data.iloc[:split_point]
                test_data = data.iloc[split_point:min(split_point + 100, len(data))]  # æµ‹è¯•çª—å£
                
                if len(test_data) < 20:  # æµ‹è¯•æ•°æ®å¤ªå°‘ï¼Œè·³è¿‡
                    self.logger.info(f"   â­ï¸ ç¬¬{i+1}æŠ˜ï¼šæµ‹è¯•æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                    continue
                
                self.logger.info(f"   ğŸ”„ ç¬¬{i+1}æŠ˜ï¼šè®­ç»ƒæ•°æ® {len(train_data)} æ¡ï¼Œæµ‹è¯•æ•°æ® {len(test_data)} æ¡")
                
                # åœ¨è®­ç»ƒæ•°æ®ä¸Šä¼˜åŒ–ç­–ç•¥å‚æ•°
                temp_strategy = StrategyModule(self.config)
                optimized_params = self.optimize_strategy_parameters(temp_strategy, train_data)
                temp_strategy.update_params(optimized_params)
                
                # åœ¨æµ‹è¯•æ•°æ®ä¸Šè¯„ä¼°
                backtest_results = temp_strategy.backtest(test_data)
                evaluation = temp_strategy.evaluate_strategy(backtest_results)
                score = evaluation['score']
                
                fold_scores.append(score)
                total_score += score
                
                self.logger.info(f"   âœ… ç¬¬{i+1}æŠ˜å¾—åˆ†: {score:.4f}")
            
            if len(fold_scores) == 0:
                self.logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„äº¤å‰éªŒè¯ç»“æœ")
                return 0.0
                
            avg_score = total_score / len(fold_scores)
            self.logger.info(f"ğŸ“Š äº¤å‰éªŒè¯å®Œæˆï¼Œå¹³å‡å¾—åˆ†: {avg_score:.4f} (å…±{len(fold_scores)}æŠ˜)")
            
            return avg_score
            
        except Exception as e:
            self.logger.error("âŒ æ—¶é—´åºåˆ—äº¤å‰éªŒè¯å¤±è´¥: %s", str(e))
            return 0.0
    
    def hierarchical_optimization(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        åˆ†å±‚ä¼˜åŒ–ç­–ç•¥
        
        å‚æ•°:
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–ç»“æœ
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸ—ï¸ å¼€å§‹åˆ†å±‚ä¼˜åŒ–ç­–ç•¥")
        self.logger.info("=" * 60)
        
        try:
            # ç¬¬ä¸€å±‚ï¼šç­–ç•¥å‚æ•°ä¼˜åŒ–
            self.logger.info("ğŸ“Š ç¬¬ä¸€å±‚ï¼šç­–ç•¥å‚æ•°ä¼˜åŒ–...")
            strategy_module = StrategyModule(self.config)
            strategy_params = self.optimize_strategy_parameters(strategy_module, data)
            self.logger.info("âœ… ç­–ç•¥å‚æ•°ä¼˜åŒ–å®Œæˆ")
            self.logger.info(f"   - æ¶¨å¹…é˜ˆå€¼: {strategy_params['rise_threshold']:.3f}")
            self.logger.info(f"   - æœ€å¤§è§‚å¯Ÿå¤©æ•°: {strategy_params['max_days']}")
            
            # ç¬¬äºŒå±‚ï¼šåŸºäºä¼˜åŒ–åçš„ç­–ç•¥è®­ç»ƒAIæ¨¡å‹
            self.logger.info("ğŸ¤– ç¬¬äºŒå±‚ï¼šæ›´æ–°ç­–ç•¥å‚æ•°å¹¶å‡†å¤‡AIè®­ç»ƒ...")
            strategy_module.update_params(strategy_params)
            self.logger.info("âœ… ç­–ç•¥å‚æ•°æ›´æ–°å®Œæˆ")
            
            # ç¬¬ä¸‰å±‚ï¼šæ—¶é—´åºåˆ—äº¤å‰éªŒè¯
            self.logger.info("ğŸ”„ ç¬¬ä¸‰å±‚ï¼šæ—¶é—´åºåˆ—äº¤å‰éªŒè¯...")
            cv_score = self.time_series_cv_evaluation(data, strategy_module)
            self.logger.info(f"âœ… äº¤å‰éªŒè¯å®Œæˆï¼Œå¹³å‡å¾—åˆ†: {cv_score:.4f}")
            
            # ç¬¬å››å±‚ï¼šé«˜çº§ä¼˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            self.logger.info("ğŸš€ ç¬¬å››å±‚ï¼šé«˜çº§ä¼˜åŒ–...")
            try:
                advanced_params = self.optimize_strategy_parameters_advanced(strategy_module, data)
                advanced_score = self._evaluate_params_with_fixed_labels(
                    data, 
                    strategy_module.backtest(data)['is_low_point'].astype(int).values,
                    advanced_params['rise_threshold'],
                    advanced_params['max_days']
                )
                
                self.logger.info(f"   - é«˜çº§ä¼˜åŒ–å¾—åˆ†: {advanced_score:.4f}")
                self.logger.info(f"   - äº¤å‰éªŒè¯å¾—åˆ†: {cv_score:.4f}")
                
                # é€‰æ‹©æ›´å¥½çš„å‚æ•°
                if advanced_score > cv_score:
                    final_params = advanced_params
                    final_score = advanced_score
                    self.logger.info("âœ… é€‰æ‹©é«˜çº§ä¼˜åŒ–å‚æ•°ï¼ˆå¾—åˆ†æ›´é«˜ï¼‰")
                else:
                    final_params = strategy_params
                    final_score = cv_score
                    self.logger.info("âœ… é€‰æ‹©äº¤å‰éªŒè¯å‚æ•°ï¼ˆå¾—åˆ†æ›´é«˜ï¼‰")
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ é«˜çº§ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ä¼˜åŒ–ç»“æœ: {str(e)}")
                final_params = strategy_params
                final_score = cv_score
                self.logger.info("âœ… ä½¿ç”¨åŸºç¡€ä¼˜åŒ–å‚æ•°")
            
            result = {
                'strategy_params': final_params,
                'cv_score': cv_score,
                'final_score': final_score,
                'optimization_method': 'hierarchical'
            }
            
            self.logger.info("=" * 60)
            self.logger.info("ğŸ‰ åˆ†å±‚ä¼˜åŒ–å®Œæˆ")
            self.logger.info("=" * 60)
            self.logger.info(f"ğŸ“ˆ æœ€ç»ˆå‚æ•°:")
            self.logger.info(f"   - æ¶¨å¹…é˜ˆå€¼: {final_params['rise_threshold']:.3f}")
            self.logger.info(f"   - æœ€å¤§è§‚å¯Ÿå¤©æ•°: {final_params['max_days']}")
            self.logger.info(f"   - RSIè¶…å–é˜ˆå€¼: {final_params.get('rsi_oversold_threshold', 'N/A')}")
            self.logger.info(f"   - RSIåä½é˜ˆå€¼: {final_params.get('rsi_low_threshold', 'N/A')}")
            self.logger.info(f"   - ç½®ä¿¡åº¦é˜ˆå€¼: {final_params.get('final_threshold', 'N/A')}")
            self.logger.info(f"ğŸ“Š æœ€ç»ˆå¾—åˆ†: {final_score:.4f}")
            self.logger.info(f"ğŸ”§ ä¼˜åŒ–æ–¹æ³•: {result['optimization_method']}")
            self.logger.info("=" * 60)
            
            return result
            
        except Exception as e:
            self.logger.error("âŒ åˆ†å±‚ä¼˜åŒ–å¤±è´¥: %s", str(e))
            self.logger.info("ğŸ”„ ä½¿ç”¨é»˜è®¤å‚æ•°ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
            return {
                'strategy_params': {
                    'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.05), 
                    'max_days': self.config.get('strategy', {}).get('max_days', 20)
                },
                'cv_score': 0.0,
                'final_score': 0.0,
                'optimization_method': 'fallback'
            }

    def _evaluate_params_with_fixed_labels_advanced(self, data: pd.DataFrame, fixed_labels: np.ndarray, 
                                                  params: Dict[str, Any]) -> float:
        """
        ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°å¤šå‚æ•°ç­–ç•¥
        
        å‚æ•°:
        data: å†å²æ•°æ®
        fixed_labels: å›ºå®šçš„æ ‡ç­¾ï¼ˆç›¸å¯¹ä½ç‚¹æ ‡è¯†ï¼‰
        params: å‚æ•°å­—å…¸ï¼ŒåŒ…å«rise_threshold, max_days, rsi_oversold_threshold, rsi_low_threshold, final_threshold
        
        è¿”å›:
        float: ç­–ç•¥å¾—åˆ†
        """
        try:
            # 1. è®¡ç®—æ¯ä¸ªè¯†åˆ«ç‚¹çš„æœªæ¥è¡¨ç°
            scores = []
            low_point_indices = np.where(fixed_labels == 1)[0]
            
            rise_threshold = params['rise_threshold']
            max_days = params['max_days']
            
            for idx in low_point_indices:
                if idx >= len(data) - max_days:
                    continue
                    
                current_price = data.iloc[idx]['close']
                max_rise = 0.0
                days_to_rise = 0
                
                # è®¡ç®—æœªæ¥max_dayså†…çš„æœ€å¤§æ¶¨å¹…
                for j in range(1, max_days + 1):
                    if idx + j >= len(data):
                        break
                    future_price = data.iloc[idx + j]['close']
                    rise_rate = (future_price - current_price) / current_price
                    
                    if rise_rate > max_rise:
                        max_rise = rise_rate
                        
                    if rise_rate >= rise_threshold and days_to_rise == 0:
                        days_to_rise = j
                
                # è®¡ç®—å•ä¸ªç‚¹çš„å¾—åˆ†
                success = max_rise >= rise_threshold
                point_score = self._calculate_point_score(success, max_rise, days_to_rise, max_days)
                scores.append(point_score)
            
            # 2. è®¡ç®—æ€»ä½“å¾—åˆ†
            if len(scores) == 0:
                return 0.0
                
            return np.mean(scores)
            
        except Exception as e:
            self.logger.error("è¯„ä¼°å¤šå‚æ•°å¤±è´¥: %s", str(e))
            return 0.0


