#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
AIä¼˜åŒ–å™¨æ¨¡å—
è´Ÿè´£ä½¿ç”¨AIæŠ€æœ¯ä¼˜åŒ–ç­–ç•¥å‚æ•°
"""

import logging
import os
import json
import pickle
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, Any, List, Tuple, Optional
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# è´å¶æ–¯ä¼˜åŒ–ç›¸å…³å¯¼å…¥
try:
    from skopt import gp_minimize
    from skopt.space import Real, Integer
    from skopt.utils import use_named_args
    BAYESIAN_AVAILABLE = True
except ImportError:
    BAYESIAN_AVAILABLE = False

# å¯¼å…¥ç­–ç•¥æ¨¡å—
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'strategy'))
from strategy_module import StrategyModule


class AIOptimizer:
    """AIä¼˜åŒ–å™¨ç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–AIä¼˜åŒ–å™¨
        
        å‚æ•°:
        config: é…ç½®ä¿¡æ¯
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # è®¾ç½®æ¨¡å‹ç›®å½•
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        self.models_dir = os.path.join(project_root, 'models')
        
        # ç¡®ä¿æ¨¡å‹ç›®å½•å­˜åœ¨
        if not os.path.exists(self.models_dir):
            os.makedirs(self.models_dir)
            
        # è®¾ç½®å‚æ•°å†å²è®°å½•æ–‡ä»¶è·¯å¾„
        cache_dir = os.path.join(project_root, 'cache')
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
        self.parameter_history_file = os.path.join(cache_dir, 'parameter_history.json')
        self.best_parameters_file = os.path.join(cache_dir, 'best_parameters.json')
        
        # åˆå§‹åŒ–æ¨¡å‹ç›¸å…³å±æ€§
        self.model = None
        self.feature_names = None
        
        # ä»é…ç½®è·å–æ¨¡å‹ç±»å‹
        ai_config = config.get('ai', {})
        self.model_type = ai_config.get('model_type', 'machine_learning')
        
        self.logger.info("AIä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹ç±»å‹: %s", self.model_type)

    def strict_data_split(self, data: pd.DataFrame, preserve_test_set: bool = True) -> Dict[str, pd.DataFrame]:
        """
        ä¸¥æ ¼çš„æ•°æ®åˆ†å‰²ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
        
        å‚æ•°:
        data: è¾“å…¥æ•°æ®
        preserve_test_set: æ˜¯å¦ä¿æŠ¤æµ‹è¯•é›†
        
        è¿”å›:
        dict: åŒ…å«è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„å­—å…¸
        """
        self.logger.info("ğŸ”’ å¼€å§‹ä¸¥æ ¼æ•°æ®åˆ†å‰²...")
        
        try:
            # ä»é…ç½®è·å–åˆ†å‰²æ¯”ä¾‹
            ai_config = self.config.get('ai', {})
            validation_config = ai_config.get('validation', {})
            
            train_ratio = validation_config.get('train_ratio', 0.65)
            validation_ratio = validation_config.get('validation_ratio', 0.20)
            test_ratio = validation_config.get('test_ratio', 0.15)
            
            # ç¡®ä¿æ¯”ä¾‹å’Œä¸º1
            total_ratio = train_ratio + validation_ratio + test_ratio
            if abs(total_ratio - 1.0) > 0.001:
                self.logger.warning(f"åˆ†å‰²æ¯”ä¾‹æ€»å’Œä¸ä¸º1: {total_ratio:.3f}ï¼Œè¿›è¡Œå½’ä¸€åŒ–")
                train_ratio /= total_ratio
                validation_ratio /= total_ratio
                test_ratio /= total_ratio
            
            # è®¡ç®—åˆ†å‰²ç‚¹
            n = len(data)
            train_end = int(n * train_ratio)
            validation_end = int(n * (train_ratio + validation_ratio))
            
            # æ—¶é—´åºåˆ—åˆ†å‰²ï¼ˆä¿æŒæ—¶é—´é¡ºåºï¼‰
            train_data = data.iloc[:train_end].copy()
            validation_data = data.iloc[train_end:validation_end].copy()
            test_data = data.iloc[validation_end:].copy()
            
            # æ£€æµ‹æ•°æ®æ³„éœ²
            train_dates = set(pd.to_datetime(train_data['date']).dt.date)
            test_dates = set(pd.to_datetime(test_data['date']).dt.date)
            overlap = train_dates.intersection(test_dates)
            
            if overlap:
                self.logger.warning(f"âŒ æ£€æµ‹åˆ°æ•°æ®æ³„éœ²ï¼š{len(overlap)}ä¸ªé‡å¤æ—¥æœŸ")
                for date in list(overlap)[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    self.logger.warning(f"   é‡å¤æ—¥æœŸ: {date}")
            else:
                self.logger.info("âœ… æ•°æ®æ³„éœ²æ£€æµ‹é€šè¿‡ï¼Œæ— é‡å¤æ—¥æœŸ")
            
            self.logger.info("ğŸ“Š æ•°æ®åˆ†å‰²å®Œæˆ:")
            self.logger.info(f"   - è®­ç»ƒé›†: {len(train_data)} æ¡ ({len(train_data)/n:.1%})")
            self.logger.info(f"   - éªŒè¯é›†: {len(validation_data)} æ¡ ({len(validation_data)/n:.1%})")
            self.logger.info(f"   - æµ‹è¯•é›†: {len(test_data)} æ¡ ({len(test_data)/n:.1%})")
            
            return {
                'train': train_data,
                'validation': validation_data,
                'test': test_data
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ä¸¥æ ¼æ•°æ®åˆ†å‰²å¤±è´¥: {str(e)}")
            raise

    def walk_forward_validation(self, data: pd.DataFrame, strategy_module, 
                              window_size: int = 252, step_size: int = 63) -> Dict[str, Any]:
        """
        èµ°å‰éªŒè¯ï¼Œæ¨¡æ‹ŸçœŸå®äº¤æ˜“ç¯å¢ƒ
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—
        window_size: è®­ç»ƒçª—å£å¤§å°ï¼ˆäº¤æ˜“æ—¥æ•°ï¼‰
        step_size: æ­¥è¿›å¤§å°ï¼ˆäº¤æ˜“æ—¥æ•°ï¼‰
        
        è¿”å›:
        dict: éªŒè¯ç»“æœ
        """
        self.logger.info("ğŸš¶ å¼€å§‹èµ°å‰éªŒè¯...")
        
        try:
            scores = []
            windows = []
            
            # è®¡ç®—æ€»çª—å£æ•°
            total_windows = max(1, (len(data) - window_size) // step_size)
            self.logger.info(f"æ€»éªŒè¯çª—å£æ•°: {total_windows}")
            
            for i in range(total_windows):
                start_idx = i * step_size
                train_end_idx = start_idx + window_size
                test_start_idx = train_end_idx
                test_end_idx = min(test_start_idx + step_size, len(data))
                
                if test_end_idx <= test_start_idx:
                    continue
                
                # åˆ†å‰²æ•°æ®
                train_window = data.iloc[start_idx:train_end_idx].copy()
                test_window = data.iloc[test_start_idx:test_end_idx].copy()
                
                self.logger.info(f"çª—å£ {i+1}/{total_windows}: è®­ç»ƒ {len(train_window)} æ¡, æµ‹è¯• {len(test_window)} æ¡")
                
                # åœ¨è®­ç»ƒçª—å£ä¸Šä¼˜åŒ–å‚æ•°
                optimized_params = self.optimize_strategy_parameters_on_train_only(strategy_module, train_window)
                
                # æ›´æ–°ç­–ç•¥å‚æ•°
                temp_strategy = StrategyModule(self.config)
                temp_strategy.update_params(optimized_params)
                
                # åœ¨æµ‹è¯•çª—å£ä¸Šè¯„ä¼°
                test_results = temp_strategy.backtest(test_window)
                evaluation = temp_strategy.evaluate_strategy(test_results)
                
                score = evaluation['score']
                scores.append(score)
                windows.append({
                    'window': i + 1,
                    'train_start': train_window.iloc[0]['date'],
                    'train_end': train_window.iloc[-1]['date'],
                    'test_start': test_window.iloc[0]['date'],
                    'test_end': test_window.iloc[-1]['date'],
                    'score': score
                })
                
                self.logger.info(f"çª—å£ {i+1} å¾—åˆ†: {score:.4f}")
            
            if not scores:
                self.logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„éªŒè¯çª—å£")
                return {'success': False, 'error': 'æ²¡æœ‰æœ‰æ•ˆçš„éªŒè¯çª—å£'}
            
            avg_score = np.mean(scores)
            std_score = np.std(scores)
            
            self.logger.info("âœ… èµ°å‰éªŒè¯å®Œæˆ")
            self.logger.info(f"å¹³å‡å¾—åˆ†: {avg_score:.4f} Â± {std_score:.4f}")
            
            return {
                'success': True,
                'avg_score': avg_score,
                'std_score': std_score,
                'all_scores': scores,
                'windows': windows
            }
            
        except Exception as e:
            self.logger.error(f"âŒ èµ°å‰éªŒè¯å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}

    def optimize_strategy_parameters_on_train_only(self, strategy_module, train_data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä»…åœ¨è®­ç»ƒé›†ä¸Šä¼˜åŒ–ç­–ç•¥å‚æ•°
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—
        train_data: è®­ç»ƒæ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–åçš„å‚æ•°
        """
        self.logger.info("ğŸ¯ å¼€å§‹è®­ç»ƒé›†ç­–ç•¥å‚æ•°ä¼˜åŒ–...")
        
        try:
            # å›ºå®šæ ¸å¿ƒå‚æ•°
            fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
            fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
            
            # è·å–åŸºå‡†ç­–ç•¥è¯†åˆ«ç»“æœ
            baseline_backtest = strategy_module.backtest(train_data)
            fixed_labels = baseline_backtest['is_low_point'].astype(int).values
            
            # å‚æ•°æœç´¢èŒƒå›´
            param_ranges = {
                'rsi_oversold_threshold': np.arange(25, 36, 1),
                'rsi_low_threshold': np.arange(35, 46, 1),
                'final_threshold': np.arange(0.3, 0.71, 0.05)
            }
            
            best_score = -1
            best_params = None
            
            # ç®€åŒ–æœç´¢ï¼ˆä»…é’ˆå¯¹è®­ç»ƒé›†ï¼‰
            max_iterations = 50
            
            for i in range(max_iterations):
                params = {
                    'rise_threshold': fixed_rise_threshold,
                    'max_days': fixed_max_days,
                    'rsi_oversold_threshold': int(np.random.choice(param_ranges['rsi_oversold_threshold'])),
                    'rsi_low_threshold': int(np.random.choice(param_ranges['rsi_low_threshold'])),
                    'final_threshold': np.random.choice(param_ranges['final_threshold'])
                }
                
                score = self._evaluate_params_with_fixed_labels(
                    train_data, fixed_labels, 
                    params['rise_threshold'], params['max_days']
                )
                
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
            
            self.logger.info(f"âœ… è®­ç»ƒé›†ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³å¾—åˆ†: {best_score:.4f}")
            
            return best_params if best_params else {
                'rise_threshold': fixed_rise_threshold,
                'max_days': fixed_max_days,
                'rsi_oversold_threshold': 30,
                'rsi_low_threshold': 40,
                'final_threshold': 0.5
            }
            
        except Exception as e:
            self.logger.error(f"âŒ è®­ç»ƒé›†ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04),
                'max_days': self.config.get('strategy', {}).get('max_days', 20),
                'rsi_oversold_threshold': 30,
                'rsi_low_threshold': 40,
                'final_threshold': 0.5
            }

    def _evaluate_params_with_fixed_labels(self, data: pd.DataFrame, fixed_labels: np.ndarray, 
                                         rise_threshold: float, max_days: int) -> float:
        """
        ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°ç­–ç•¥å‚æ•°
        
        å‚æ•°:
        data: å†å²æ•°æ®
        fixed_labels: å›ºå®šçš„æ ‡ç­¾ï¼ˆç›¸å¯¹ä½ç‚¹æ ‡è¯†ï¼‰
        rise_threshold: æ¶¨å¹…é˜ˆå€¼
        max_days: æœ€å¤§å¤©æ•°
        
        è¿”å›:
        float: ç­–ç•¥å¾—åˆ†
        """
        try:
            scores = []
            low_point_indices = np.where(fixed_labels == 1)[0]
            
            for idx in low_point_indices:
                if idx >= len(data) - max_days:
                    continue
                    
                current_price = data.iloc[idx]['close']
                max_rise = 0.0
                days_to_rise = 0
                
                # è®¡ç®—æœªæ¥max_dayså†…çš„æœ€å¤§æ¶¨å¹…
                for j in range(1, max_days + 1):
                    if idx + j >= len(data):
                        break
                    future_price = data.iloc[idx + j]['close']
                    rise_rate = (future_price - current_price) / current_price
                    
                    if rise_rate > max_rise:
                        max_rise = rise_rate
                        
                    if rise_rate >= rise_threshold and days_to_rise == 0:
                        days_to_rise = j
                
                # è®¡ç®—å•ä¸ªç‚¹çš„å¾—åˆ†
                success = max_rise >= rise_threshold
                point_score = self._calculate_point_score(success, max_rise, days_to_rise, max_days)
                scores.append(point_score)
            
            return np.mean(scores) if scores else 0.0
            
        except Exception as e:
            self.logger.error("è¯„ä¼°å‚æ•°å¤±è´¥: %s", str(e))
            return 0.0

    def _calculate_point_score(self, success: bool, max_rise: float, days_to_rise: int, max_days: int) -> float:
        """
        è®¡ç®—å•ä¸ªè¯†åˆ«ç‚¹çš„å¾—åˆ†
        
        å‚æ•°:
        success: æ˜¯å¦æˆåŠŸè¾¾åˆ°ç›®æ ‡æ¶¨å¹…
        max_rise: æœ€å¤§æ¶¨å¹…
        days_to_rise: è¾¾åˆ°ç›®æ ‡æ¶¨å¹…çš„å¤©æ•°
        max_days: æœ€å¤§è§‚å¯Ÿå¤©æ•°
        
        è¿”å›:
        float: å•ä¸ªç‚¹å¾—åˆ†
        """
        # æˆåŠŸç‡æƒé‡ï¼š60%
        success_score = 1.0 if success else 0.0
        
        # æ¶¨å¹…æƒé‡ï¼š30%
        rise_score = min(max_rise / 0.1, 1.0)  # ä»¥10%ä¸ºåŸºå‡†
        
        # é€Ÿåº¦æƒé‡ï¼š10%
        if days_to_rise > 0:
            speed_score = min(max_days / days_to_rise, 1.0)
        else:
            speed_score = 0.0
        
        total_score = success_score * 0.6 + rise_score * 0.3 + speed_score * 0.1
        return total_score

    def bayesian_optimize_parameters(self, strategy_module, data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–è¿›è¡Œå‚æ•°æœç´¢
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–ç»“æœ
        """
        self.logger.info("ğŸ” å¼€å§‹è´å¶æ–¯ä¼˜åŒ–å‚æ•°æœç´¢...")
        
        if not BAYESIAN_AVAILABLE:
            self.logger.error("âŒ scikit-optimizeæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–")
            return {'success': False, 'error': 'scikit-optimizeæœªå®‰è£…'}
        
        try:
            # è·å–è´å¶æ–¯ä¼˜åŒ–é…ç½®
            ai_config = self.config.get('ai', {})
            bayesian_config = ai_config.get('bayesian_optimization', {})
            
            if not bayesian_config.get('enabled', True):
                self.logger.info("è´å¶æ–¯ä¼˜åŒ–å·²ç¦ç”¨ï¼Œè·³è¿‡")
                return {'success': False, 'error': 'è´å¶æ–¯ä¼˜åŒ–å·²ç¦ç”¨'}
            
            # é…ç½®å‚æ•°
            n_calls = bayesian_config.get('n_calls', 100)
            n_initial_points = bayesian_config.get('n_initial_points', 20)
            acq_func = bayesian_config.get('acq_func', 'EI')
            xi = bayesian_config.get('xi', 0.01)
            kappa = bayesian_config.get('kappa', 1.96)
            n_jobs = bayesian_config.get('n_jobs', 1)
            random_state = bayesian_config.get('random_state', 42)
            
            self.logger.info(f"è´å¶æ–¯ä¼˜åŒ–é…ç½®:")
            self.logger.info(f"  - è°ƒç”¨æ¬¡æ•°: {n_calls}")
            self.logger.info(f"  - åˆå§‹ç‚¹æ•°: {n_initial_points}")
            self.logger.info(f"  - é‡‡é›†å‡½æ•°: {acq_func}")
            
            # è·å–å½“å‰ç­–ç•¥å‚æ•°ä½œä¸ºä¼˜åŒ–èµ·ç‚¹
            current_params = strategy_module.get_current_params()
            self.logger.info(f"ğŸ¯ å½“å‰å‚æ•°ä½œä¸ºè´å¶æ–¯ä¼˜åŒ–èµ·ç‚¹: {current_params}")
            
            # å®šä¹‰åŸºäºå½“å‰å‚æ•°çš„è‡ªé€‚åº”å‚æ•°ç©ºé—´
            optimization_ranges = ai_config.get('optimization_ranges', {})
            
            dimensions = []
            param_names = []
            
            # æ™ºèƒ½æœç´¢å› å­
            search_factor = bayesian_config.get('search_factor', 0.3)
            
            # ä»é…ç½®ä¸­è¯»å–å‚æ•°èŒƒå›´ï¼Œå¹¶åŸºäºå½“å‰å‚æ•°è°ƒæ•´
            for param_name, param_range in optimization_ranges.items():
                base_min = param_range.get('min', 0.0)
                base_max = param_range.get('max', 1.0)
                current_value = current_params.get(param_name, (base_min + base_max) / 2)
                
                # åŸºäºå½“å‰å€¼åŠ¨æ€è°ƒæ•´æœç´¢èŒƒå›´
                range_width = base_max - base_min
                adaptive_radius = range_width * search_factor
                
                adaptive_min = max(base_min, current_value - adaptive_radius)
                adaptive_max = min(base_max, current_value + adaptive_radius)
                
                dimensions.append(Real(adaptive_min, adaptive_max, name=param_name))
                param_names.append(param_name)
                
                self.logger.info(f"   - {param_name}: å½“å‰å€¼ {current_value:.3f}, æœç´¢èŒƒå›´ [{adaptive_min:.3f}, {adaptive_max:.3f}]")
            
            # RSIç›¸å…³å‚æ•°çš„è‡ªé€‚åº”èŒƒå›´
            base_rsi_oversold = current_params.get('rsi_oversold_threshold', 30)
            base_rsi_low = current_params.get('rsi_low_threshold', 40)
            base_final_threshold = current_params.get('final_threshold', 0.5)
            
            # RSIå‚æ•°æœç´¢åŠå¾„
            rsi_radius = 4  # RSIå‚æ•°çš„æœç´¢åŠå¾„
            threshold_radius = 0.15  # final_thresholdçš„æœç´¢åŠå¾„
            
            # è‡ªé€‚åº”RSI oversoldèŒƒå›´
            rsi_oversold_min = max(25, base_rsi_oversold - rsi_radius)
            rsi_oversold_max = min(35, base_rsi_oversold + rsi_radius)
            
            # è‡ªé€‚åº”RSI lowèŒƒå›´
            rsi_low_min = max(35, base_rsi_low - rsi_radius)
            rsi_low_max = min(45, base_rsi_low + rsi_radius)
            
            # è‡ªé€‚åº”final_thresholdèŒƒå›´
            final_threshold_min = max(0.3, base_final_threshold - threshold_radius)
            final_threshold_max = min(0.7, base_final_threshold + threshold_radius)
            
            # æ·»åŠ è‡ªé€‚åº”RSIç›¸å…³å‚æ•°
            dimensions.extend([
                Integer(rsi_oversold_min, rsi_oversold_max, name='rsi_oversold_threshold'),
                Integer(rsi_low_min, rsi_low_max, name='rsi_low_threshold'),
                Real(final_threshold_min, final_threshold_max, name='final_threshold')
            ])
            param_names.extend(['rsi_oversold_threshold', 'rsi_low_threshold', 'final_threshold'])
            
            self.logger.info(f"   - rsi_oversold_threshold: å½“å‰å€¼ {base_rsi_oversold}, æœç´¢èŒƒå›´ [{rsi_oversold_min}, {rsi_oversold_max}]")
            self.logger.info(f"   - rsi_low_threshold: å½“å‰å€¼ {base_rsi_low}, æœç´¢èŒƒå›´ [{rsi_low_min}, {rsi_low_max}]")
            self.logger.info(f"   - final_threshold: å½“å‰å€¼ {base_final_threshold:.3f}, æœç´¢èŒƒå›´ [{final_threshold_min:.3f}, {final_threshold_max:.3f}]")
            
            if len(dimensions) == 0:
                self.logger.error("âŒ æœªå®šä¹‰ä¼˜åŒ–å‚æ•°ç©ºé—´")
                return {'success': False, 'error': 'æœªå®šä¹‰ä¼˜åŒ–å‚æ•°ç©ºé—´'}
            
            self.logger.info(f"å‚æ•°ç©ºé—´ç»´åº¦: {len(dimensions)}")
            for i, dim in enumerate(dimensions):
                self.logger.info(f"  - {param_names[i]}: [{dim.low}, {dim.high}]")
            
            # å›ºå®šæ ¸å¿ƒå‚æ•°
            fixed_params = {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04),
                'max_days': self.config.get('strategy', {}).get('max_days', 20)
            }
            
            # è·å–åŸºå‡†ç­–ç•¥ç»“æœç”¨äºæ ‡ç­¾å›ºå®š
            baseline_backtest = strategy_module.backtest(data)
            fixed_labels = baseline_backtest['is_low_point'].astype(int).values
            
            # è®°å½•è¯„ä¼°å†å²
            evaluation_history = []
            
            @use_named_args(dimensions)
            def objective(**params):
                """ç›®æ ‡å‡½æ•°ï¼šæœ€å°åŒ–è´Ÿå¾—åˆ†ï¼ˆå› ä¸ºgp_minimizeæ˜¯æœ€å°åŒ–ï¼‰"""
                try:
                    # åˆå¹¶å›ºå®šå‚æ•°å’Œä¼˜åŒ–å‚æ•°
                    full_params = fixed_params.copy()
                    full_params.update(params)
                    
                    # è¯„ä¼°å‚æ•°
                    score = self._evaluate_params_with_fixed_labels(
                        data, fixed_labels, 
                        full_params['rise_threshold'], 
                        full_params['max_days']
                    )
                    
                    # è®°å½•è¯„ä¼°å†å²
                    evaluation_history.append({
                        'params': params.copy(),
                        'score': score,
                        'iteration': len(evaluation_history) + 1
                    })
                    
                    if len(evaluation_history) % 10 == 0:
                        self.logger.info(f"è´å¶æ–¯ä¼˜åŒ–è¿›åº¦: {len(evaluation_history)}/{n_calls}, å½“å‰å¾—åˆ†: {score:.4f}")
                    
                    # è¿”å›è´Ÿå¾—åˆ†ï¼ˆå› ä¸ºè¦æœ€å°åŒ–ï¼‰
                    return -score
                    
                except Exception as e:
                    self.logger.error(f"ç›®æ ‡å‡½æ•°è¯„ä¼°å¤±è´¥: {str(e)}")
                    return 1.0  # è¿”å›æœ€å·®å¾—åˆ†
            
            # è¿è¡Œè´å¶æ–¯ä¼˜åŒ–
            self.logger.info("ğŸš€ å¼€å§‹è´å¶æ–¯ä¼˜åŒ–...")
            
            # æ ¹æ®é‡‡é›†å‡½æ•°è®¾ç½®å‚æ•°
            gp_kwargs = {
                'func': objective,
                'dimensions': dimensions,
                'n_calls': n_calls,
                'n_initial_points': n_initial_points,
                'acq_func': acq_func,
                'random_state': random_state,
                'n_jobs': n_jobs,
                'verbose': False
            }
            
            # æ ¹æ®é‡‡é›†å‡½æ•°ç±»å‹æ·»åŠ ç‰¹å®šå‚æ•°
            if acq_func == 'EI':
                gp_kwargs['xi'] = xi
            elif acq_func == 'LCB':
                gp_kwargs['kappa'] = kappa
            
            result = gp_minimize(**gp_kwargs)
            
            # æå–æœ€ä¼˜å‚æ•°
            best_params = fixed_params.copy()
            for i, param_name in enumerate(param_names):
                best_params[param_name] = result.x[i]
            
            best_score = -result.fun  # è½¬æ¢å›æ­£å¾—åˆ†
            
            self.logger.info("âœ… è´å¶æ–¯ä¼˜åŒ–å®Œæˆ")
            self.logger.info(f"   - æœ€ä¼˜å¾—åˆ†: {best_score:.4f}")
            self.logger.info(f"   - æ€»è¯„ä¼°æ¬¡æ•°: {len(evaluation_history)}")
            self.logger.info(f"   - æœ€ä¼˜å‚æ•°:")
            for param, value in best_params.items():
                if param not in fixed_params:
                    self.logger.info(f"     - {param}: {value:.4f}")
            
            # åˆ†ææ”¶æ•›æƒ…å†µ
            scores = [eval_record['score'] for eval_record in evaluation_history]
            best_scores = np.maximum.accumulate(scores)
            improvement_rate = (best_scores[-1] - best_scores[n_initial_points]) / max(best_scores[n_initial_points], 0.001)
            
            self.logger.info(f"   - æ”¹è¿›ç‡: {improvement_rate:.2%}")
            self.logger.info(f"   - æœ€ç»ˆæ”¶æ•›å¾—åˆ†: {best_scores[-1]:.4f}")
            
            return {
                'success': True,
                'best_params': best_params,
                'best_score': best_score,
                'n_evaluations': len(evaluation_history),
                'improvement_rate': improvement_rate,
                'evaluation_history': evaluation_history,
                'convergence_scores': best_scores.tolist(),
                'optimization_result': result
            }
            
        except Exception as e:
            self.logger.error(f"âŒ è´å¶æ–¯ä¼˜åŒ–å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}

    def optimize_strategy_parameters(self, strategy_module, data: pd.DataFrame) -> Dict[str, Any]:
        """
        æ™ºèƒ½å‚æ•°ä¼˜åŒ–ï¼šæ ¹æ®é…ç½®é€‰æ‹©æœ€ä½³ä¼˜åŒ–ç­–ç•¥
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–åçš„å‚æ•°
        """
        self.logger.info("ğŸ¯ å¼€å§‹æ™ºèƒ½å‚æ•°ä¼˜åŒ–...")
        
        try:
            # è·å–ä¼˜åŒ–é…ç½®
            ai_config = self.config.get('ai', {})
            bayesian_config = ai_config.get('bayesian_optimization', {})
            advanced_config = ai_config.get('advanced_optimization', {})
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨è´å¶æ–¯ä¼˜åŒ–
            if bayesian_config.get('enabled', False) and BAYESIAN_AVAILABLE:
                self.logger.info("ğŸ” ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ç­–ç•¥")
                
                # ä½¿ç”¨ä¸¥æ ¼æ•°æ®åˆ†å‰²è¿›è¡Œè´å¶æ–¯ä¼˜åŒ–
                if advanced_config.get('use_hierarchical', True):
                    data_splits = self.strict_data_split(data, preserve_test_set=True)
                    train_data = data_splits['train']
                    
                    # åœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œè´å¶æ–¯ä¼˜åŒ–
                    bayesian_result = self.bayesian_optimize_parameters(strategy_module, train_data)
                    
                    if bayesian_result['success']:
                        return bayesian_result['best_params']
                    else:
                        self.logger.warning(f"è´å¶æ–¯ä¼˜åŒ–å¤±è´¥: {bayesian_result.get('error')}")
                        self.logger.info("å›é€€åˆ°ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•")
                        
                else:
                    # åœ¨å…¨éƒ¨æ•°æ®ä¸Šè¿›è¡Œè´å¶æ–¯ä¼˜åŒ–
                    bayesian_result = self.bayesian_optimize_parameters(strategy_module, data)
                    
                    if bayesian_result['success']:
                        return bayesian_result['best_params']
                    else:
                        self.logger.warning(f"è´å¶æ–¯ä¼˜åŒ–å¤±è´¥: {bayesian_result.get('error')}")
                        self.logger.info("å›é€€åˆ°ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•")
            
            # å›é€€åˆ°ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•
            self.logger.info("ğŸ”§ ä½¿ç”¨ä¼ ç»Ÿå‚æ•°ä¼˜åŒ–ç­–ç•¥")
            return self._traditional_parameter_optimization(strategy_module, data)
            
        except Exception as e:
            self.logger.error(f"âŒ æ™ºèƒ½å‚æ•°ä¼˜åŒ–å¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤å‚æ•°
            return {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04),
                'max_days': self.config.get('strategy', {}).get('max_days', 20),
                'rsi_oversold_threshold': 30,
                'rsi_low_threshold': 40,
                'final_threshold': 0.5
            }

    def _traditional_parameter_optimization(self, strategy_module, data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä¼ ç»Ÿå‚æ•°ä¼˜åŒ–æ–¹æ³•ï¼ˆåŸºäºå†å²ç»“æœçš„å¢é‡ä¼˜åŒ–ï¼‰
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–åçš„å‚æ•°
        """
        self.logger.info("ğŸ”§ æ‰§è¡Œå¢é‡å‚æ•°ä¼˜åŒ–...")
        
        try:
            # å›ºå®šæ ¸å¿ƒå‚æ•°
            fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
            fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
            
            # è·å–å½“å‰ç­–ç•¥å‚æ•°ä½œä¸ºä¼˜åŒ–èµ·ç‚¹
            current_params = strategy_module.get_current_params()
            self.logger.info(f"ğŸ¯ å½“å‰å‚æ•°ä½œä¸ºä¼˜åŒ–èµ·ç‚¹: {current_params}")
            
            # åŸºäºå½“å‰å‚æ•°åŠ¨æ€è°ƒæ•´æœç´¢èŒƒå›´
            base_rsi_oversold = current_params.get('rsi_oversold_threshold', 30)
            base_rsi_low = current_params.get('rsi_low_threshold', 40)
            base_final_threshold = current_params.get('final_threshold', 0.5)
            
            # æ™ºèƒ½æœç´¢èŒƒå›´ï¼šå›´ç»•å½“å‰æœ€ä¼˜å‚æ•°è¿›è¡Œå±€éƒ¨æœç´¢
            search_radius = self.config.get('ai', {}).get('optimization', {}).get('search_radius', 3)
            
            param_ranges = {
                'rsi_oversold_threshold': np.arange(
                    max(25, base_rsi_oversold - search_radius), 
                    min(36, base_rsi_oversold + search_radius + 1), 1
                ),
                'rsi_low_threshold': np.arange(
                    max(35, base_rsi_low - search_radius), 
                    min(46, base_rsi_low + search_radius + 1), 1
                ),
                'final_threshold': np.arange(
                    max(0.3, base_final_threshold - 0.1), 
                    min(0.71, base_final_threshold + 0.1), 0.05
                )
            }
            
            self.logger.info(f"ğŸ” æ™ºèƒ½æœç´¢èŒƒå›´:")
            self.logger.info(f"   - rsi_oversold_threshold: {param_ranges['rsi_oversold_threshold']}")
            self.logger.info(f"   - rsi_low_threshold: {param_ranges['rsi_low_threshold']}")
            self.logger.info(f"   - final_threshold: {param_ranges['final_threshold'][0]:.2f} - {param_ranges['final_threshold'][-1]:.2f}")
            
            # è·å–åŸºå‡†ç­–ç•¥è¯†åˆ«ç»“æœ
            baseline_backtest = strategy_module.backtest(data)
            fixed_labels = baseline_backtest['is_low_point'].astype(int).values
            
            # é¦–å…ˆè¯„ä¼°å½“å‰å‚æ•°ä½œä¸ºåŸºå‡†
            current_score = self._evaluate_params_with_fixed_labels(
                data, fixed_labels, fixed_rise_threshold, fixed_max_days
            )
            
            best_score = current_score
            best_params = {
                'rise_threshold': fixed_rise_threshold,
                'max_days': fixed_max_days,
                'rsi_oversold_threshold': base_rsi_oversold,
                'rsi_low_threshold': base_rsi_low,
                'final_threshold': base_final_threshold
            }
            
            self.logger.info(f"ğŸ“Š å½“å‰å‚æ•°åŸºå‡†å¾—åˆ†: {current_score:.4f}")
            
            # è·å–ä¼˜åŒ–é…ç½®
            ai_config = self.config.get('ai', {})
            optimization_config = ai_config.get('optimization', {})
            max_iterations = optimization_config.get('global_iterations', 100)  # å‡å°‘è¿­ä»£æ¬¡æ•°ï¼Œå› ä¸ºæœç´¢èŒƒå›´æ›´ç²¾ç¡®
            
            # å¢é‡ä¼˜åŒ–æœç´¢
            improvements = 0
            for i in range(max_iterations):
                # 80%æ¦‚ç‡è¿›è¡Œå±€éƒ¨æœç´¢ï¼Œ20%æ¦‚ç‡è¿›è¡Œå…¨å±€æ¢ç´¢
                if np.random.random() < 0.8:
                    # å±€éƒ¨æœç´¢ï¼šåœ¨ç¼©å°èŒƒå›´å†…æœç´¢
                    params = {
                        'rise_threshold': fixed_rise_threshold,
                        'max_days': fixed_max_days,
                        'rsi_oversold_threshold': int(np.random.choice(param_ranges['rsi_oversold_threshold'])),
                        'rsi_low_threshold': int(np.random.choice(param_ranges['rsi_low_threshold'])),
                        'final_threshold': np.random.choice(param_ranges['final_threshold'])
                    }
                else:
                    # å…¨å±€æ¢ç´¢ï¼šåœ¨æ›´å¤§èŒƒå›´å†…æœç´¢ï¼Œé¿å…å±€éƒ¨æœ€ä¼˜
                    global_ranges = {
                        'rsi_oversold_threshold': np.arange(25, 36, 1),
                        'rsi_low_threshold': np.arange(35, 46, 1),
                        'final_threshold': np.arange(0.3, 0.71, 0.05)
                    }
                    params = {
                        'rise_threshold': fixed_rise_threshold,
                        'max_days': fixed_max_days,
                        'rsi_oversold_threshold': int(np.random.choice(global_ranges['rsi_oversold_threshold'])),
                        'rsi_low_threshold': int(np.random.choice(global_ranges['rsi_low_threshold'])),
                        'final_threshold': np.random.choice(global_ranges['final_threshold'])
                    }
                
                score = self._evaluate_params_with_fixed_labels(
                    data, fixed_labels, 
                    params['rise_threshold'], params['max_days']
                )
                
                if score > best_score:
                    improvement = score - best_score
                    best_score = score
                    best_params = params.copy()
                    improvements += 1
                    self.logger.info(f"ğŸ‰ å‘ç°æ›´ä¼˜å‚æ•°! å¾—åˆ†: {score:.4f} (+{improvement:.4f})")
                    
                    # åŠ¨æ€è°ƒæ•´æœç´¢èŒƒå›´åˆ°æ–°çš„æœ€ä¼˜ç‚¹å‘¨å›´
                    base_rsi_oversold = best_params['rsi_oversold_threshold']
                    base_rsi_low = best_params['rsi_low_threshold']
                    base_final_threshold = best_params['final_threshold']
                    
                    param_ranges = {
                        'rsi_oversold_threshold': np.arange(
                            max(25, base_rsi_oversold - search_radius), 
                            min(36, base_rsi_oversold + search_radius + 1), 1
                        ),
                        'rsi_low_threshold': np.arange(
                            max(35, base_rsi_low - search_radius), 
                            min(46, base_rsi_low + search_radius + 1), 1
                        ),
                        'final_threshold': np.arange(
                            max(0.3, base_final_threshold - 0.1), 
                            min(0.71, base_final_threshold + 0.1), 0.05
                        )
                    }
                
                if (i + 1) % 25 == 0:
                    self.logger.info(f"å¢é‡ä¼˜åŒ–è¿›åº¦: {i + 1}/{max_iterations}, å½“å‰æœ€ä½³å¾—åˆ†: {best_score:.4f}, æ”¹è¿›æ¬¡æ•°: {improvements}")
            
            improvement_rate = (best_score - current_score) / current_score * 100 if current_score > 0 else 0
            self.logger.info(f"âœ… å¢é‡ä¼˜åŒ–å®Œæˆ")
            self.logger.info(f"   - æœ€ä½³å¾—åˆ†: {best_score:.4f}")
            self.logger.info(f"   - æ”¹è¿›å¹…åº¦: {improvement_rate:+.2f}%")
            self.logger.info(f"   - æ”¹è¿›æ¬¡æ•°: {improvements}")
            
            return best_params
            
        except Exception as e:
            self.logger.error(f"âŒ å¢é‡å‚æ•°ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04),
                'max_days': self.config.get('strategy', {}).get('max_days', 20),
                'rsi_oversold_threshold': 30,
                'rsi_low_threshold': 40,
                'final_threshold': 0.5
            }

    def evaluate_on_test_set_only(self, strategy_module, test_data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä»…åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ç­–ç•¥
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—
        test_data: æµ‹è¯•æ•°æ®
        
        è¿”å›:
        dict: è¯„ä¼°ç»“æœ
        """
        self.logger.info("ğŸ¯ å¼€å§‹æµ‹è¯•é›†è¯„ä¼°...")
        
        try:
            # åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œå›æµ‹
            test_backtest = strategy_module.backtest(test_data)
            test_evaluation = strategy_module.evaluate_strategy(test_backtest)
            
            test_score = test_evaluation['score']
            
            self.logger.info(f"âœ… æµ‹è¯•é›†è¯„ä¼°å®Œæˆ")
            self.logger.info(f"   - æµ‹è¯•é›†å¾—åˆ†: {test_score:.4f}")
            self.logger.info(f"   - è¯†åˆ«ç‚¹æ•°: {test_evaluation.get('total_points', 0)}")
            self.logger.info(f"   - æˆåŠŸç‡: {test_evaluation.get('success_rate', 0):.2%}")
            
            return {
                'success': True,
                'test_score': test_score,
                'test_evaluation': test_evaluation,
                'test_size': len(test_data)
            }
            
        except Exception as e:
            self.logger.error(f"âŒ æµ‹è¯•é›†è¯„ä¼°å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}

    def train_model(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        åªè´Ÿè´£è®­ç»ƒæ¨¡å‹å¹¶ä¿å­˜ï¼Œä¸åšè¯„ä¼°ã€‚
        """
        self.logger.info("å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼ˆä¸åšéªŒè¯è¯„ä¼°ï¼‰")
        try:
            features, feature_names = self.prepare_features(data)
            labels = self.prepare_labels(data, strategy_module)
            if len(features) == 0 or len(labels) == 0:
                self.logger.error("ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
                return {'success': False, 'error': 'ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©º'}
            min_length = min(len(features), len(labels))
            features = features[:min_length]
            labels = labels[:min_length]
            aligned_data = data.iloc[:min_length].copy()
            split_ratio = self.config.get("ai", {}).get("train_test_split_ratio", 0.8)
            split_index = int(len(features) * split_ratio)
            X_train = features[:split_index]
            y_train = labels[:split_index]
            train_dates = aligned_data["date"].iloc[:split_index]
            sample_weights = self._calculate_sample_weights(train_dates)
            if self.model_type == 'machine_learning':
                model = Pipeline([
                    ('scaler', StandardScaler()),
                    ('classifier', RandomForestClassifier(
                        n_estimators=100,
                        max_depth=10,
                        min_samples_split=5,
                        min_samples_leaf=2,
                        random_state=42,
                        class_weight='balanced'
                    ))
                ])
            else:
                model = Pipeline([
                    ('scaler', StandardScaler()),
                    ('classifier', RandomForestClassifier(
                        n_estimators=100,
                        random_state=42,
                        class_weight='balanced'
                    ))
                ])
            self.logger.info(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, sample_weights shape: {sample_weights.shape}")
            model.fit(X_train, y_train, classifier__sample_weight=sample_weights)
            self.model = model
            self.feature_names = feature_names
            self._save_model()
            self.logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")
            return {'success': True, 'train_samples': len(X_train), 'feature_count': len(feature_names)}
        except Exception as e:
            self.logger.error("è®­ç»ƒæ¨¡å‹å¤±è´¥: %s", str(e))
            return {'success': False, 'error': str(e)}

    def validate_model(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        åªè´Ÿè´£è¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°ã€‚
        """
        self.logger.info("å¼€å§‹éªŒè¯æ¨¡å‹ï¼ˆåªåšè¯„ä¼°ï¼Œä¸è®­ç»ƒï¼‰")
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    return {'success': False, 'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'}
            features, feature_names = self.prepare_features(data)
            labels = self.prepare_labels(data, strategy_module)
            if len(features) == 0 or len(labels) == 0:
                self.logger.error("ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œæ— æ³•éªŒè¯æ¨¡å‹")
                return {'success': False, 'error': 'ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©º'}
            min_length = min(len(features), len(labels))
            features = features[:min_length]
            labels = labels[:min_length]
            split_ratio = self.config.get("ai", {}).get("train_test_split_ratio", 0.8)
            split_index = int(len(features) * split_ratio)
            X_test = features[split_index:]
            y_test = labels[split_index:]
            if len(X_test) == 0 or len(y_test) == 0:
                self.logger.warning("éªŒè¯é›†ä¸ºç©ºï¼Œæ— æ³•è¯„ä¼°æ¨¡å‹")
                return {'success': False, 'error': 'éªŒè¯é›†ä¸ºç©º'}
            y_pred = self.model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, zero_division=0)
            recall = recall_score(y_test, y_pred, zero_division=0)
            f1 = f1_score(y_test, y_pred, zero_division=0)
            positive_count_test = np.sum(y_test)
            self.logger.info("æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°å®Œæˆï¼Œå‡†ç¡®ç‡: %.4f, ç²¾ç¡®ç‡: %.4f, å¬å›ç‡: %.4f, F1: %.4f", accuracy, precision, recall, f1)
            return {
                'success': True,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'test_samples': len(X_test),
                'positive_samples_test': positive_count_test
            }
        except Exception as e:
            self.logger.error("éªŒè¯æ¨¡å‹å¤±è´¥: %s", str(e))
            return {'success': False, 'error': str(e)}

    def predict_low_point(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        é¢„æµ‹ç›¸å¯¹ä½ç‚¹
        
        å‚æ•°:
        data: å¸‚åœºæ•°æ®
        
        è¿”å›:
        dict: é¢„æµ‹ç»“æœ
        """
        self.logger.info("é¢„æµ‹ç›¸å¯¹ä½ç‚¹")
        
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    return {
                        'is_low_point': False,
                        'confidence': 0.0,
                        'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'
                    }
                    
            if len(data) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'error': 'æ•°æ®ä¸ºç©º'
                }
                
            # å‡†å¤‡ç‰¹å¾
            features, _ = self.prepare_features(data)
            
            if len(features) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'error': 'æ— æ³•æå–ç‰¹å¾'
                }
                
            # ä½¿ç”¨æœ€æ–°æ•°æ®è¿›è¡Œé¢„æµ‹
            latest_features = features[-1:].reshape(1, -1)
            
            # é¢„æµ‹
            prediction = self.model.predict(latest_features)[0]
            prediction_proba = self.model.predict_proba(latest_features)[0]
            
            # è·å–ç½®ä¿¡åº¦
            confidence = prediction_proba[1] if len(prediction_proba) > 1 else 0.0
            
            result = {
                'is_low_point': bool(prediction),
                'confidence': float(confidence),
                'prediction_proba': prediction_proba.tolist()
            }
            
            self.logger.info("----------------------------------------------------");
            self.logger.info("AIé¢„æµ‹ç»“æœ: \033[1m%s\033[0m, ç½®ä¿¡åº¦: \033[1m%.4f\033[0m", 
                           "ç›¸å¯¹ä½ç‚¹" if prediction else "éç›¸å¯¹ä½ç‚¹", confidence)
            self.logger.info("----------------------------------------------------");
            return result
            
        except Exception as e:
            self.logger.error("é¢„æµ‹ç›¸å¯¹ä½ç‚¹å¤±è´¥: %s", str(e))
            return {
                'is_low_point': False,
                'confidence': 0.0,
                'error': str(e)
            }

    def prepare_features(self, data: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        å‡†å¤‡æœºå™¨å­¦ä¹ ç‰¹å¾
        
        å‚æ•°:
        data: å†å²æ•°æ®
        
        è¿”å›:
        tuple: (ç‰¹å¾çŸ©é˜µ, ç‰¹å¾åç§°åˆ—è¡¨)
        """
        self.logger.info("å‡†å¤‡æœºå™¨å­¦ä¹ ç‰¹å¾")
        
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_columns = [
            'ma5', 'ma10', 'ma20', 'ma60',
            'rsi', 'macd', 'signal', 'hist',
            'bb_upper', 'bb_lower',
            'dist_ma5', 'dist_ma10', 'dist_ma20',
            'volume_change', 'volatility',
            'price_change', 'price_change_5d', 'price_change_10d'
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„åˆ—
        available_columns = [col for col in feature_columns if col in data.columns]
        
        if len(available_columns) == 0:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾åˆ—")
            return np.array([]), []
            
        # æå–ç‰¹å¾
        features = data[available_columns].fillna(0).values
        
        self.logger.info("ç‰¹å¾å‡†å¤‡å®Œæˆï¼Œç‰¹å¾æ•°é‡: %d, æ ·æœ¬æ•°é‡: %d", 
                        len(available_columns), len(features))
        
        return features, available_columns
        
    def prepare_labels(self, data: pd.DataFrame, strategy_module) -> np.ndarray:
        """
        å‡†å¤‡æœºå™¨å­¦ä¹ æ ‡ç­¾
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        
        è¿”å›:
        numpy.ndarray: æ ‡ç­¾æ•°ç»„
        """
        self.logger.info("å‡†å¤‡æœºå™¨å­¦ä¹ æ ‡ç­¾")
        
        # è¿è¡Œå›æµ‹è·å–çœŸå®çš„ç›¸å¯¹ä½ç‚¹æ ‡ç­¾
        backtest_results = strategy_module.backtest(data)
        labels = backtest_results['is_low_point'].astype(int).values
        
        positive_count = np.sum(labels)
        total_count = len(labels)
        
        self.logger.info("æ ‡ç­¾å‡†å¤‡å®Œæˆï¼Œæ­£æ ·æœ¬: %d, æ€»æ ·æœ¬: %d, æ­£æ ·æœ¬æ¯”ä¾‹: %.2f%%", 
                        positive_count, total_count, positive_count / total_count * 100)
        
        return labels

    def _save_model(self) -> bool:
        """
        ä¿å­˜æ¨¡å‹
        
        è¿”å›:
        bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ä¿å­˜æ¨¡å‹
            model_path = os.path.join(self.models_dir, f'model_{timestamp}.pkl')
            with open(model_path, 'wb') as f:
                pickle.dump(self.model, f)
                
            # ä¿å­˜ç‰¹å¾åç§°
            features_path = os.path.join(self.models_dir, f'features_{timestamp}.json')
            with open(features_path, 'w') as f:
                json.dump(self.feature_names, f)
                
            # ä¿å­˜æœ€æ–°æ¨¡å‹çš„è·¯å¾„
            latest_path = os.path.join(self.models_dir, 'latest_model.txt')
            with open(latest_path, 'w') as f:
                f.write(f'{model_path}\n{features_path}')
                
            self.logger.info("æ¨¡å‹ä¿å­˜æˆåŠŸ: %s", model_path)
            return True
            
        except Exception as e:
            self.logger.error("ä¿å­˜æ¨¡å‹å¤±è´¥: %s", str(e))
            return False

    def _load_model(self) -> bool:
        """
        åŠ è½½æ¨¡å‹
        
        è¿”å›:
        bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            latest_path = os.path.join(self.models_dir, 'latest_model.txt')
            
            if not os.path.exists(latest_path):
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„æ¨¡å‹")
                return False
                
            # è¯»å–æœ€æ–°æ¨¡å‹è·¯å¾„
            with open(latest_path, 'r') as f:
                lines = f.read().strip().split('\n')
                if len(lines) < 2:
                    self.logger.error("æ¨¡å‹è·¯å¾„æ–‡ä»¶æ ¼å¼é”™è¯¯")
                    return False
                    
                model_path = lines[0]
                features_path = lines[1]
                
            # åŠ è½½æ¨¡å‹
            with open(model_path, 'rb') as f:
                self.model = pickle.load(f)
                
            # åŠ è½½ç‰¹å¾åç§°
            with open(features_path, 'r') as f:
                self.feature_names = json.load(f)
                
            self.logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ: %s", model_path)
            return True
            
        except Exception as e:
            self.logger.error("åŠ è½½æ¨¡å‹å¤±è´¥: %s", str(e))
            return False

    def _calculate_sample_weights(self, dates: pd.Series) -> np.ndarray:
        """
        æ ¹æ®æ•°æ®æ—¥æœŸè®¡ç®—æ ·æœ¬æƒé‡ï¼Œè¶Šè¿‘çš„æ•°æ®æƒé‡è¶Šé«˜ã€‚
        æƒé‡è¡°å‡æ¨¡å‹ï¼šV(t) = Vâ‚€ Ã— e^(-Î»t)
        å…¶ä¸­Î»æ˜¯è¡°å‡ç³»æ•°ï¼Œæ ¹æ®åˆ†ææŠ¥å‘Šï¼ŒÎ»çº¦ä¸º0.3-0.5ã€‚
        è¿™é‡Œæˆ‘ä»¬å–Î»=0.4ï¼Œå¹¶æ ¹æ®æ—¶é—´å·®è®¡ç®—æƒé‡ã€‚
        
        å‚æ•°:
        dates: è®­ç»ƒé›†æ•°æ®çš„æ—¥æœŸåºåˆ—
        
        è¿”å›:
        numpy.ndarray: æ ·æœ¬æƒé‡æ•°ç»„
        """
        self.logger.info("è®¡ç®—æ ·æœ¬æƒé‡")
        
        weights = np.ones(len(dates))
        if len(dates) == 0: # Handle empty dates series
            return weights

        latest_date = dates.max()
        
        for i, date in enumerate(dates):
            time_diff = (latest_date - date).days / 365.25  # å¹´ä¸ºå•ä½
            # è¡°å‡ç³»æ•°Î»ï¼Œå¯ä»¥æ ¹æ®configé…ç½®
            decay_rate = self.config.get("ai", {}).get("data_decay_rate", 0.4)
            weight = np.exp(-decay_rate * time_diff)
            weights[i] = weight
            
        # å½’ä¸€åŒ–æƒé‡ï¼Œä½¿å…¶å’Œä¸º1ï¼Œæˆ–è€…ä¿æŒåŸå§‹æ¯”ä¾‹
        # è¿™é‡Œé€‰æ‹©ä¿æŒåŸå§‹æ¯”ä¾‹ï¼Œå› ä¸ºRandomForestClassifierçš„sample_weightå‚æ•°æ˜¯ä¹˜æ³•å…³ç³»
        # ä¹Ÿå¯ä»¥é€‰æ‹©å½’ä¸€åŒ–åˆ°æŸä¸ªèŒƒå›´ï¼Œä¾‹å¦‚0-1
        
        self.logger.info("æ ·æœ¬æƒé‡è®¡ç®—å®Œæˆï¼Œæœ€å¤§æƒé‡: %.4f, æœ€å°æƒé‡: %.4f", 
                        np.max(weights), np.min(weights))
        
        return weights

    def get_feature_importance(self) -> Dict[str, float]:
        """
        è·å–æ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§
        
        è¿”å›:
        dict: ç‰¹å¾åç§°å’Œé‡è¦æ€§çš„å­—å…¸ï¼ŒæŒ‰é‡è¦æ€§é™åºæ’åˆ—
        """
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    self.logger.error("æ— æ³•è·å–ç‰¹å¾é‡è¦æ€§ï¼šæ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                    return {}
            
            if self.feature_names is None:
                self.logger.error("ç‰¹å¾åç§°æœªè®¾ç½®ï¼Œæ— æ³•è·å–ç‰¹å¾é‡è¦æ€§")
                return {}
            
            # ä»Pipelineä¸­è·å–RandomForestClassifier
            if hasattr(self.model, 'named_steps') and 'classifier' in self.model.named_steps:
                classifier = self.model.named_steps['classifier']
                if hasattr(classifier, 'feature_importances_'):
                    feature_importances = classifier.feature_importances_
                else:
                    self.logger.error("åˆ†ç±»å™¨æ²¡æœ‰feature_importances_å±æ€§")
                    return {}
            else:
                self.logger.error("æ¨¡å‹æ²¡æœ‰é¢„æœŸçš„Pipelineç»“æ„")
                return {}
            
            # åˆ›å»ºç‰¹å¾é‡è¦æ€§å­—å…¸
            importance_dict = {}
            for i, feature_name in enumerate(self.feature_names):
                if i < len(feature_importances):
                    importance_dict[feature_name] = float(feature_importances[i])
            
            # æŒ‰é‡è¦æ€§é™åºæ’åˆ—
            importance_dict = dict(sorted(importance_dict.items(), key=lambda x: x[1], reverse=True))
            
            self.logger.info("ç‰¹å¾é‡è¦æ€§è·å–æˆåŠŸï¼Œå…± %d ä¸ªç‰¹å¾", len(importance_dict))
            
            return importance_dict
            
        except Exception as e:
            self.logger.error("è·å–ç‰¹å¾é‡è¦æ€§å¤±è´¥: %s", str(e))
            return {}

    def run_genetic_algorithm(self, evaluate_func, population_size: int = 20, generations: int = 10) -> Dict[str, Any]:
        """
        è¿è¡Œé—ä¼ ç®—æ³•è¿›è¡Œå‚æ•°ä¼˜åŒ–
        
        å‚æ•°:
        evaluate_func: è¯„ä¼°å‡½æ•°
        population_size: ç§ç¾¤å¤§å°
        generations: è¿­ä»£ä»£æ•°
        
        è¿”å›:
        dict: æœ€ä¼˜å‚æ•°
        """
        self.logger.info("ğŸ§¬ å¼€å§‹é—ä¼ ç®—æ³•ä¼˜åŒ–...")
        
        try:
            # è·å–å‚æ•°èŒƒå›´
            param_ranges = {
                'rsi_oversold_threshold': (25, 35),
                'rsi_low_threshold': (35, 45),
                'final_threshold': (0.3, 0.7)
            }
            
            # å›ºå®šæ ¸å¿ƒå‚æ•°
            fixed_params = {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04),
                'max_days': self.config.get('strategy', {}).get('max_days', 20)
            }
            
            # ç®€åŒ–çš„é—ä¼ ç®—æ³•å®ç°
            best_score = -1
            best_params = None
            
            for generation in range(generations):
                # ç”Ÿæˆéšæœºç§ç¾¤
                population = []
                for _ in range(population_size):
                    individual = fixed_params.copy()
                    individual['rsi_oversold_threshold'] = np.random.randint(
                        param_ranges['rsi_oversold_threshold'][0],
                        param_ranges['rsi_oversold_threshold'][1] + 1
                    )
                    individual['rsi_low_threshold'] = np.random.randint(
                        param_ranges['rsi_low_threshold'][0],
                        param_ranges['rsi_low_threshold'][1] + 1
                    )
                    individual['final_threshold'] = np.random.uniform(
                        param_ranges['final_threshold'][0],
                        param_ranges['final_threshold'][1]
                    )
                    population.append(individual)
                
                # è¯„ä¼°ç§ç¾¤
                for individual in population:
                    score = evaluate_func(individual)
                    if score > best_score:
                        best_score = score
                        best_params = individual.copy()
                
                self.logger.info(f"é—ä¼ ç®—æ³•ç¬¬ {generation + 1}/{generations} ä»£, å½“å‰æœ€ä½³å¾—åˆ†: {best_score:.4f}")
            
            self.logger.info(f"âœ… é—ä¼ ç®—æ³•ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³å¾—åˆ†: {best_score:.4f}")
            
            return best_params if best_params else fixed_params
            
        except Exception as e:
            self.logger.error(f"âŒ é—ä¼ ç®—æ³•ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04),
                'max_days': self.config.get('strategy', {}).get('max_days', 20),
                'rsi_oversold_threshold': 30,
                'rsi_low_threshold': 40,
                'final_threshold': 0.5
            }


class EarlyStopping:
    """æ—©åœæœºåˆ¶ç±»"""
    
    def __init__(self, patience: int = 20, min_delta: float = 0.001):
        """
        åˆå§‹åŒ–æ—©åœæœºåˆ¶
        
        å‚æ•°:
        patience: è€å¿ƒå€¼ï¼Œè¿ç»­å¤šå°‘æ¬¡æ— æ”¹è¿›ååœæ­¢
        min_delta: æœ€å°æ”¹è¿›å¹…åº¦
        """
        self.patience = patience
        self.min_delta = min_delta
        self.best_score = -np.inf
        self.wait = 0
        
    def __call__(self, val_score: float) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ
        
        å‚æ•°:
        val_score: å½“å‰éªŒè¯å¾—åˆ†
        
        è¿”å›:
        bool: æ˜¯å¦åº”è¯¥åœæ­¢
        """
        if val_score > self.best_score + self.min_delta:
            self.best_score = val_score
            self.wait = 0
            return False
        else:
            self.wait += 1
            return self.wait >= self.patience 