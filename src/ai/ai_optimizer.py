#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
AIä¼˜åŒ–æ¨¡å—
ä½¿ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•ä¼˜åŒ–ç­–ç•¥å‚æ•°å’Œé¢„æµ‹ç›¸å¯¹ä½ç‚¹
"""

import os
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Any, List, Tuple, Optional
import pickle
import json
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from strategy.strategy_module import StrategyModule

# æœºå™¨å­¦ä¹ ç›¸å…³
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

class AIOptimizer:
    """AIä¼˜åŒ–å™¨ç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–AIä¼˜åŒ–å™¨
        
        å‚æ•°:
        config: é…ç½®å­—å…¸
        """
        self.logger = logging.getLogger('AIOptimizer')
        self.config = config
        
        # AIé…ç½®
        ai_config = config.get('ai', {})
        self.model_type = ai_config.get('model_type', 'machine_learning')
        self.optimization_interval = ai_config.get('optimization_interval', 30)
        
        # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
        self.models_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'models')
        if not os.path.exists(self.models_dir):
            os.makedirs(self.models_dir)
            
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = None
        self.scaler = None
        self.feature_names = None
        
        self.logger.info("AIä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹ç±»å‹: %s", self.model_type)
        
    def optimize_strategy_parameters(self, strategy_module, data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä¼˜åŒ–ç­–ç•¥å‚æ•°ï¼ˆrise_thresholdå’Œmax_daysä¿æŒå›ºå®šï¼‰
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–åçš„å‚æ•°
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸš€ å¼€å§‹AIç­–ç•¥å‚æ•°ä¼˜åŒ–")
        self.logger.info("=" * 60)
        
        try:
            # 1. è·å–åŸºå‡†ç­–ç•¥çš„è¯†åˆ«ç»“æœä½œä¸ºå›ºå®šæ ‡ç­¾
            self.logger.info("ğŸ“Š é˜¶æ®µ1: è·å–åŸºå‡†ç­–ç•¥è¯†åˆ«ç»“æœ...")
            baseline_backtest = strategy_module.backtest(data)
            fixed_labels = baseline_backtest['is_low_point'].astype(int).values
            self.logger.info(f"âœ… åŸºå‡†ç­–ç•¥è¯†åˆ«ç‚¹æ•°: {np.sum(fixed_labels)}")
            
            # 2. å›ºå®šæ ¸å¿ƒå‚æ•°ï¼Œä¸å…è®¸ä¼˜åŒ–
            self.logger.info("ğŸ”§ é˜¶æ®µ2: è®¾ç½®å›ºå®šå‚æ•°...")
            fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
            fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
            
            self.logger.info(f"âœ… å›ºå®šå‚æ•°è®¾ç½®å®Œæˆ:")
            self.logger.info(f"   - rise_threshold: {fixed_rise_threshold}")
            self.logger.info(f"   - max_days: {fixed_max_days}")
            
            # 3. ä»é…ç½®æ–‡ä»¶è·å–å¯ä¼˜åŒ–å‚æ•°çš„æœç´¢èŒƒå›´
            self.logger.info("ğŸ“‹ é˜¶æ®µ3: é…ç½®å‚æ•°æœç´¢èŒƒå›´...")
            ai_config = self.config.get('ai', {})
            optimization_ranges = ai_config.get('optimization_ranges', {})
            
            # è·å–åŸæœ‰å¯ä¼˜åŒ–å‚æ•°çš„æœç´¢èŒƒå›´
            rsi_oversold_range = optimization_ranges.get('rsi_oversold_threshold', {})
            rsi_low_range = optimization_ranges.get('rsi_low_threshold', {})
            final_threshold_range = optimization_ranges.get('final_threshold', {})
            
            # è·å–æ–°å¢AIä¼˜åŒ–å‚æ•°çš„æœç´¢èŒƒå›´
            dynamic_confidence_range = optimization_ranges.get('dynamic_confidence_adjustment', {})
            market_sentiment_range = optimization_ranges.get('market_sentiment_weight', {})
            trend_strength_range = optimization_ranges.get('trend_strength_weight', {})
            
            # å®šä¹‰å¯ä¼˜åŒ–å‚æ•°çš„æœç´¢ç©ºé—´
            param_grid = {
                'rsi_oversold_threshold': np.arange(
                    rsi_oversold_range.get('min', 25),
                    rsi_oversold_range.get('max', 35) + rsi_oversold_range.get('step', 1),
                    rsi_oversold_range.get('step', 1)
                ),
                'rsi_low_threshold': np.arange(
                    rsi_low_range.get('min', 35),
                    rsi_low_range.get('max', 45) + rsi_low_range.get('step', 1),
                    rsi_low_range.get('step', 1)
                ),
                'final_threshold': np.arange(
                    final_threshold_range.get('min', 0.3),
                    final_threshold_range.get('max', 0.7) + final_threshold_range.get('step', 0.05),
                    final_threshold_range.get('step', 0.05)
                ),
                # æ–°å¢AIä¼˜åŒ–å‚æ•°
                'dynamic_confidence_adjustment': np.arange(
                    dynamic_confidence_range.get('min', 0.05),
                    dynamic_confidence_range.get('max', 0.25) + dynamic_confidence_range.get('step', 0.02),
                    dynamic_confidence_range.get('step', 0.02)
                ),
                'market_sentiment_weight': np.arange(
                    market_sentiment_range.get('min', 0.08),
                    market_sentiment_range.get('max', 0.25) + market_sentiment_range.get('step', 0.02),
                    market_sentiment_range.get('step', 0.02)
                ),
                'trend_strength_weight': np.arange(
                    trend_strength_range.get('min', 0.06),
                    trend_strength_range.get('max', 0.20) + trend_strength_range.get('step', 0.02),
                    trend_strength_range.get('step', 0.02)
                )
            }
            
            self.logger.info("âœ… å¯ä¼˜åŒ–å‚æ•°æœç´¢èŒƒå›´:")
            for param, values in param_grid.items():
                self.logger.info(f"   - {param}: {values[0]} - {values[-1]}, æ­¥é•¿: {values[1]-values[0] if len(values)>1 else 'N/A'}")
            
            best_score = -1
            best_params = None
            total_combinations = 1
            for values in param_grid.values():
                total_combinations *= len(values)
            
            self.logger.info(f"ğŸ“ˆ æ€»æœç´¢ç»„åˆæ•°: {total_combinations:,}")
            
            # 4. åŸºäºå›ºå®šæ ‡ç­¾ä¼˜åŒ–å¯è°ƒå‚æ•°
            # ä¸ºäº†å‡å°‘è®¡ç®—é‡ï¼Œæˆ‘ä»¬ä½¿ç”¨éšæœºé‡‡æ ·è€Œä¸æ˜¯å…¨ç½‘æ ¼æœç´¢
            max_iterations = min(150, total_combinations)  # å¢åŠ è¿­ä»£æ¬¡æ•°ä»¥è¦†ç›–æ›´å¤šå‚æ•°ç»„åˆ
            self.logger.info(f"ğŸ¯ ä½¿ç”¨éšæœºé‡‡æ ·ï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
            
            # è®°å½•ä¼˜åŒ–å¼€å§‹æ—¶é—´
            import time
            start_time = time.time()
            
            self.logger.info("ğŸ”„ é˜¶æ®µ4: å¼€å§‹å‚æ•°ä¼˜åŒ–è¿­ä»£...")
            self.logger.info("-" * 50)
            
            # è®°å½•æ”¹è¿›æ¬¡æ•°
            improvement_count = 0
            
            for iteration in range(max_iterations):
                # è®¡ç®—è¿›åº¦
                progress = (iteration + 1) / max_iterations * 100
                
                # æ¯5æ¬¡è¿­ä»£æˆ–ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶æ‰“å°è¿›åº¦
                if iteration == 0 or (iteration + 1) % 5 == 0:
                    elapsed_time = time.time() - start_time
                    avg_time_per_iter = elapsed_time / (iteration + 1)
                    remaining_iter = max_iterations - (iteration + 1)
                    estimated_remaining_time = remaining_iter * avg_time_per_iter
                    
                    self.logger.info(f"ğŸ“Š è¿›åº¦: {progress:.1f}% ({iteration+1}/{max_iterations})")
                    self.logger.info(f"â±ï¸  å·²ç”¨æ—¶é—´: {elapsed_time:.1f}s, é¢„è®¡å‰©ä½™: {estimated_remaining_time:.1f}s")
                    self.logger.info(f"ğŸ† å½“å‰æœ€ä½³å¾—åˆ†: {best_score:.4f}")
                    if best_params:
                        self.logger.info(f"ğŸ¯ å½“å‰æœ€ä½³å‚æ•°: RSIè¶…å–={best_params['rsi_oversold_threshold']}, "
                                       f"RSIä½å€¼={best_params['rsi_low_threshold']}, "
                                       f"ç½®ä¿¡åº¦={best_params['final_threshold']:.3f}")
                    self.logger.info("-" * 30)
                
                # éšæœºé€‰æ‹©å¯ä¼˜åŒ–å‚æ•°ç»„åˆï¼Œå›ºå®šæ ¸å¿ƒå‚æ•°
                params = {
                    'rise_threshold': fixed_rise_threshold,  # å›ºå®šä¸å˜
                    'max_days': fixed_max_days,              # å›ºå®šä¸å˜
                    'rsi_oversold_threshold': int(np.random.choice(param_grid['rsi_oversold_threshold'])),
                    'rsi_low_threshold': int(np.random.choice(param_grid['rsi_low_threshold'])),
                    'final_threshold': np.random.choice(param_grid['final_threshold']),
                    # æ–°å¢AIä¼˜åŒ–å‚æ•°
                    'dynamic_confidence_adjustment': np.random.choice(param_grid['dynamic_confidence_adjustment']),
                    'market_sentiment_weight': np.random.choice(param_grid['market_sentiment_weight']),
                    'trend_strength_weight': np.random.choice(param_grid['trend_strength_weight'])
                }
                
                # ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°å‚æ•°
                score = self._evaluate_params_with_fixed_labels_advanced(
                    data, fixed_labels, params
                )
                
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
                    improvement_count += 1
                    
                    # è®¡ç®—æ”¹è¿›å¹…åº¦
                    improvement = score - best_score if best_score != -1 else 0
                    
                    self.logger.info(f"ğŸ‰ å‘ç°æ›´å¥½çš„å‚æ•°ç»„åˆ (ç¬¬{improvement_count}æ¬¡æ”¹è¿›, è¿­ä»£{iteration+1}):")
                    self.logger.info(f"   ğŸ“ˆ å¾—åˆ†æå‡: {improvement:.4f} â†’ {best_score:.4f}")
                    self.logger.info(f"   ğŸ”§ å‚æ•°è¯¦æƒ…:")
                    self.logger.info(f"      - RSIè¶…å–é˜ˆå€¼: {best_params['rsi_oversold_threshold']}")
                    self.logger.info(f"      - RSIä½å€¼é˜ˆå€¼: {best_params['rsi_low_threshold']}")
                    self.logger.info(f"      - æœ€ç»ˆç½®ä¿¡åº¦: {best_params['final_threshold']:.3f}")
                    self.logger.info(f"      - åŠ¨æ€è°ƒæ•´ç³»æ•°: {best_params['dynamic_confidence_adjustment']:.3f}")
                    self.logger.info(f"      - å¸‚åœºæƒ…ç»ªæƒé‡: {best_params['market_sentiment_weight']:.3f}")
                    self.logger.info(f"      - è¶‹åŠ¿å¼ºåº¦æƒé‡: {best_params['trend_strength_weight']:.3f}")
                    self.logger.info("-" * 50)
            
            # ä¼˜åŒ–å®Œæˆç»Ÿè®¡
            total_time = time.time() - start_time
            self.logger.info("=" * 60)
            self.logger.info("ğŸ¯ AIç­–ç•¥å‚æ•°ä¼˜åŒ–å®Œæˆ!")
            self.logger.info("=" * 60)
            self.logger.info(f"ğŸ“Š ä¼˜åŒ–ç»Ÿè®¡:")
            self.logger.info(f"   - æ€»è¿­ä»£æ¬¡æ•°: {max_iterations}")
            self.logger.info(f"   - æ€»è€—æ—¶: {total_time:.1f}ç§’")
            self.logger.info(f"   - å¹³å‡æ¯æ¬¡è¿­ä»£: {total_time/max_iterations:.3f}ç§’")
            self.logger.info(f"   - æ”¹è¿›æ¬¡æ•°: {improvement_count}")
            self.logger.info(f"   - æœ€ç»ˆæœ€ä½³å¾—åˆ†: {best_score:.4f}")
            self.logger.info("")
            self.logger.info(f"ğŸ† æœ€ç»ˆæœ€ä½³å‚æ•°:")
            for key, value in best_params.items():
                if isinstance(value, float):
                    self.logger.info(f"   - {key}: {value:.4f}")
                else:
                    self.logger.info(f"   - {key}: {value}")
            
            return best_params
            
        except Exception as e:
            self.logger.error("âŒ ä¼˜åŒ–ç­–ç•¥å‚æ•°å¤±è´¥: %s", str(e))
            # è¿”å›é»˜è®¤å‚æ•°ï¼Œä¿æŒæ ¸å¿ƒå‚æ•°å›ºå®š
            return {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04),  # å›ºå®š
                'max_days': self.config.get('strategy', {}).get('max_days', 20),                # å›ºå®š
                'rsi_oversold_threshold': self.config.get('strategy', {}).get('confidence_weights', {}).get('rsi_oversold_threshold', 30),
                'rsi_low_threshold': self.config.get('strategy', {}).get('confidence_weights', {}).get('rsi_low_threshold', 40),
                'final_threshold': self.config.get('strategy', {}).get('confidence_weights', {}).get('final_threshold', 0.5),
                # æ–°å¢AIä¼˜åŒ–å‚æ•°é»˜è®¤å€¼
                'dynamic_confidence_adjustment': self.config.get('strategy', {}).get('confidence_weights', {}).get('dynamic_confidence_adjustment', 0.1),
                'market_sentiment_weight': self.config.get('strategy', {}).get('confidence_weights', {}).get('market_sentiment_weight', 0.15),
                'trend_strength_weight': self.config.get('strategy', {}).get('confidence_weights', {}).get('trend_strength_weight', 0.12)
            }
    
    def _evaluate_params_with_fixed_labels(self, data: pd.DataFrame, fixed_labels: np.ndarray, 
                                         rise_threshold: float, max_days: int) -> float:
        """
        ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°ç­–ç•¥å‚æ•°
        
        å‚æ•°:
        data: å†å²æ•°æ®
        fixed_labels: å›ºå®šçš„æ ‡ç­¾ï¼ˆç›¸å¯¹ä½ç‚¹æ ‡è¯†ï¼‰
        rise_threshold: æ¶¨å¹…é˜ˆå€¼
        max_days: æœ€å¤§å¤©æ•°
        
        è¿”å›:
        float: ç­–ç•¥å¾—åˆ†
        """
        try:
            # 1. è®¡ç®—æ¯ä¸ªè¯†åˆ«ç‚¹çš„æœªæ¥è¡¨ç°
            scores = []
            low_point_indices = np.where(fixed_labels == 1)[0]
            
            for idx in low_point_indices:
                if idx >= len(data) - max_days:
                    continue
                    
                current_price = data.iloc[idx]['close']
                max_rise = 0.0
                days_to_rise = 0
                
                # è®¡ç®—æœªæ¥max_dayså†…çš„æœ€å¤§æ¶¨å¹…
                for j in range(1, max_days + 1):
                    if idx + j >= len(data):
                        break
                    future_price = data.iloc[idx + j]['close']
                    rise_rate = (future_price - current_price) / current_price
                    
                    if rise_rate > max_rise:
                        max_rise = rise_rate
                        
                    if rise_rate >= rise_threshold and days_to_rise == 0:
                        days_to_rise = j
                
                # è®¡ç®—å•ä¸ªç‚¹çš„å¾—åˆ†
                success = max_rise >= rise_threshold
                point_score = self._calculate_point_score(success, max_rise, days_to_rise, max_days)
                scores.append(point_score)
            
            # 2. è®¡ç®—æ€»ä½“å¾—åˆ†
            if len(scores) == 0:
                return 0.0
                
            return np.mean(scores)
            
        except Exception as e:
            self.logger.error("è¯„ä¼°å‚æ•°å¤±è´¥: %s", str(e))
            return 0.0
    
    def _calculate_point_score(self, success: bool, max_rise: float, days_to_rise: int, max_days: int) -> float:
        """
        è®¡ç®—å•ä¸ªè¯†åˆ«ç‚¹çš„å¾—åˆ†
        
        å‚æ•°:
        success: æ˜¯å¦æˆåŠŸè¾¾åˆ°ç›®æ ‡æ¶¨å¹…
        max_rise: æœ€å¤§æ¶¨å¹…
        days_to_rise: è¾¾åˆ°ç›®æ ‡æ¶¨å¹…çš„å¤©æ•°
        max_days: æœ€å¤§è§‚å¯Ÿå¤©æ•°
        
        è¿”å›:
        float: å•ä¸ªç‚¹å¾—åˆ†
        """
        # ä»é…ç½®æ–‡ä»¶è·å–è¯„åˆ†å‚æ•°
        ai_config = self.config.get('ai', {})
        scoring_config = ai_config.get('scoring', {})
        
        # æˆåŠŸç‡æƒé‡ï¼š40%
        success_weight = scoring_config.get('success_weight', 0.4)
        success_score = 1.0 if success else 0.0
        
        # æ¶¨å¹…æƒé‡ï¼š30%ï¼ˆç›¸å¯¹äºåŸºå‡†æ¶¨å¹…ï¼‰
        rise_weight = scoring_config.get('rise_weight', 0.3)
        rise_benchmark = scoring_config.get('rise_benchmark', 0.1)  # 10%åŸºå‡†
        rise_score = min(max_rise / rise_benchmark, 1.0)
        
        # é€Ÿåº¦æƒé‡ï¼š20%ï¼ˆå¤©æ•°è¶Šå°‘è¶Šå¥½ï¼‰
        speed_weight = scoring_config.get('speed_weight', 0.2)
        if days_to_rise > 0:
            speed_score = min(max_days / days_to_rise, 1.0)
        else:
            speed_score = 0.0
        
        # é£é™©è°ƒæ•´ï¼š10%ï¼ˆé¿å…è¿‡åº¦å†’é™©ï¼‰
        risk_weight = scoring_config.get('risk_weight', 0.1)
        risk_benchmark = scoring_config.get('risk_benchmark', 0.2)  # 20%é£é™©é˜ˆå€¼
        risk_score = min(max_rise / risk_benchmark, 1.0)  # è¶…è¿‡é£é™©é˜ˆå€¼çš„æ¶¨å¹…ç»™äºˆé£é™©æƒ©ç½š
        
        # ç»¼åˆå¾—åˆ†
        total_score = (
            success_score * success_weight +
            rise_score * rise_weight +
            speed_score * speed_weight +
            risk_score * risk_weight
        )
        
        return total_score
        
    def prepare_features(self, data: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        å‡†å¤‡æœºå™¨å­¦ä¹ ç‰¹å¾
        
        å‚æ•°:
        data: å†å²æ•°æ®
        
        è¿”å›:
        tuple: (ç‰¹å¾çŸ©é˜µ, ç‰¹å¾åç§°åˆ—è¡¨)
        """
        self.logger.info("å‡†å¤‡æœºå™¨å­¦ä¹ ç‰¹å¾")
        
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_columns = [
            'ma5', 'ma10', 'ma20', 'ma60',
            'rsi', 'macd', 'signal', 'hist',
            'bb_upper', 'bb_lower',
            'dist_ma5', 'dist_ma10', 'dist_ma20',
            'volume_change', 'volatility',
            'price_change', 'price_change_5d', 'price_change_10d'
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„åˆ—
        available_columns = [col for col in feature_columns if col in data.columns]
        
        if len(available_columns) == 0:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾åˆ—")
            return np.array([]), []
            
        # æå–ç‰¹å¾
        features = data[available_columns].fillna(0).values
        
        self.logger.info("ç‰¹å¾å‡†å¤‡å®Œæˆï¼Œç‰¹å¾æ•°é‡: %d, æ ·æœ¬æ•°é‡: %d", 
                        len(available_columns), len(features))
        
        return features, available_columns
        
    def prepare_labels(self, data: pd.DataFrame, strategy_module) -> np.ndarray:
        """
        å‡†å¤‡æœºå™¨å­¦ä¹ æ ‡ç­¾
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        
        è¿”å›:
        numpy.ndarray: æ ‡ç­¾æ•°ç»„
        """
        self.logger.info("å‡†å¤‡æœºå™¨å­¦ä¹ æ ‡ç­¾")
        
        # è¿è¡Œå›æµ‹è·å–çœŸå®çš„ç›¸å¯¹ä½ç‚¹æ ‡ç­¾
        backtest_results = strategy_module.backtest(data)
        labels = backtest_results['is_low_point'].astype(int).values
        
        positive_count = np.sum(labels)
        total_count = len(labels)
        
        self.logger.info("æ ‡ç­¾å‡†å¤‡å®Œæˆï¼Œæ­£æ ·æœ¬: %d, æ€»æ ·æœ¬: %d, æ­£æ ·æœ¬æ¯”ä¾‹: %.2f%%", 
                        positive_count, total_count, positive_count / total_count * 100)
        
        return labels
        
    def train_model(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        åªè´Ÿè´£è®­ç»ƒæ¨¡å‹å¹¶ä¿å­˜ï¼Œä¸åšè¯„ä¼°ã€‚
        """
        self.logger.info("å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼ˆä¸åšéªŒè¯è¯„ä¼°ï¼‰")
        try:
            features, feature_names = self.prepare_features(data)
            labels = self.prepare_labels(data, strategy_module)
            if len(features) == 0 or len(labels) == 0:
                self.logger.error("ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
                return {'success': False, 'error': 'ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©º'}
            min_length = min(len(features), len(labels))
            features = features[:min_length]
            labels = labels[:min_length]
            aligned_data = data.iloc[:min_length].copy()
            split_ratio = self.config.get("ai", {}).get("train_test_split_ratio", 0.8)
            split_index = int(len(features) * split_ratio)
            X_train = features[:split_index]
            y_train = labels[:split_index]
            train_dates = aligned_data["date"].iloc[:split_index]
            sample_weights = self._calculate_sample_weights(train_dates)
            if self.model_type == 'machine_learning':
                model = Pipeline([
                    ('scaler', StandardScaler()),
                    ('classifier', RandomForestClassifier(
                        n_estimators=100,
                        max_depth=10,
                        min_samples_split=5,
                        min_samples_leaf=2,
                        random_state=42,
                        class_weight='balanced'
                    ))
                ])
            else:
                model = Pipeline([
                    ('scaler', StandardScaler()),
                    ('classifier', RandomForestClassifier(
                        n_estimators=100,
                        random_state=42,
                        class_weight='balanced'
                    ))
                ])
            self.logger.info(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, sample_weights shape: {sample_weights.shape}")
            model.fit(X_train, y_train, classifier__sample_weight=sample_weights)
            self.model = model
            self.feature_names = feature_names
            self._save_model()
            self.logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")
            return {'success': True, 'train_samples': len(X_train), 'feature_count': len(feature_names)}
        except Exception as e:
            self.logger.error("è®­ç»ƒæ¨¡å‹å¤±è´¥: %s", str(e))
            return {'success': False, 'error': str(e)}

    def validate_model(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        åªè´Ÿè´£è¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°ã€‚
        """
        self.logger.info("å¼€å§‹éªŒè¯æ¨¡å‹ï¼ˆåªåšè¯„ä¼°ï¼Œä¸è®­ç»ƒï¼‰")
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    return {'success': False, 'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'}
            features, feature_names = self.prepare_features(data)
            labels = self.prepare_labels(data, strategy_module)
            if len(features) == 0 or len(labels) == 0:
                self.logger.error("ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œæ— æ³•éªŒè¯æ¨¡å‹")
                return {'success': False, 'error': 'ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©º'}
            min_length = min(len(features), len(labels))
            features = features[:min_length]
            labels = labels[:min_length]
            split_ratio = self.config.get("ai", {}).get("train_test_split_ratio", 0.8)
            split_index = int(len(features) * split_ratio)
            X_test = features[split_index:]
            y_test = labels[split_index:]
            if len(X_test) == 0 or len(y_test) == 0:
                self.logger.warning("éªŒè¯é›†ä¸ºç©ºï¼Œæ— æ³•è¯„ä¼°æ¨¡å‹")
                return {'success': False, 'error': 'éªŒè¯é›†ä¸ºç©º'}
            y_pred = self.model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, zero_division=0)
            recall = recall_score(y_test, y_pred, zero_division=0)
            f1 = f1_score(y_test, y_pred, zero_division=0)
            positive_count_test = np.sum(y_test)
            self.logger.info("æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°å®Œæˆï¼Œå‡†ç¡®ç‡: %.4f, ç²¾ç¡®ç‡: %.4f, å¬å›ç‡: %.4f, F1: %.4f", accuracy, precision, recall, f1)
            return {
                'success': True,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'test_samples': len(X_test),
                'positive_samples_test': positive_count_test
            }
        except Exception as e:
            self.logger.error("éªŒè¯æ¨¡å‹å¤±è´¥: %s", str(e))
            return {'success': False, 'error': str(e)}

    def predict_low_point(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        é¢„æµ‹ç›¸å¯¹ä½ç‚¹
        
        å‚æ•°:
        data: å¸‚åœºæ•°æ®
        
        è¿”å›:
        dict: é¢„æµ‹ç»“æœ
        """
        self.logger.info("é¢„æµ‹ç›¸å¯¹ä½ç‚¹")
        
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    return {
                        'is_low_point': False,
                        'confidence': 0.0,
                        'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'
                    }
                    
            if len(data) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'error': 'æ•°æ®ä¸ºç©º'
                }
                
            # å‡†å¤‡ç‰¹å¾
            features, _ = self.prepare_features(data)
            
            if len(features) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'error': 'æ— æ³•æå–ç‰¹å¾'
                }
                
            # ä½¿ç”¨æœ€æ–°æ•°æ®è¿›è¡Œé¢„æµ‹
            latest_features = features[-1:].reshape(1, -1)
            
            # é¢„æµ‹
            prediction = self.model.predict(latest_features)[0]
            prediction_proba = self.model.predict_proba(latest_features)[0]
            
            # è·å–ç½®ä¿¡åº¦
            confidence = prediction_proba[1] if len(prediction_proba) > 1 else 0.0
            
            result = {
                'is_low_point': bool(prediction),
                'confidence': float(confidence),
                'prediction_proba': prediction_proba.tolist()
            }
            
            self.logger.info("----------------------------------------------------");
            self.logger.info("AIé¢„æµ‹ç»“æœ: \033[1m%s\033[0m, ç½®ä¿¡åº¦: \033[1m%.4f\033[0m", 
                           "ç›¸å¯¹ä½ç‚¹" if prediction else "éç›¸å¯¹ä½ç‚¹", confidence)
            self.logger.info("----------------------------------------------------");
            return result
            
        except Exception as e:
            self.logger.error("é¢„æµ‹ç›¸å¯¹ä½ç‚¹å¤±è´¥: %s", str(e))
            return {
                'is_low_point': False,
                'confidence': 0.0,
                'error': str(e)
            }
            
    def get_feature_importance(self) -> Optional[Dict[str, float]]:
        """
        è·å–ç‰¹å¾é‡è¦æ€§
        
        è¿”å›:
        dict: ç‰¹å¾é‡è¦æ€§ï¼Œå¦‚æœæ¨¡å‹æœªè®­ç»ƒè¿”å›None
        """
        if self.model is None or self.feature_names is None:
            return None
            
        try:
            # è·å–åˆ†ç±»å™¨
            classifier = self.model.named_steps['classifier']
            
            if hasattr(classifier, 'feature_importances_'):
                importances = classifier.feature_importances_
                feature_importance = dict(zip(self.feature_names, importances))
                
                # æŒ‰é‡è¦æ€§æ’åº
                sorted_importance = dict(sorted(feature_importance.items(), 
                                              key=lambda x: x[1], reverse=True))
                
                self.logger.info("ç‰¹å¾é‡è¦æ€§è·å–æˆåŠŸ")
                return sorted_importance
            else:
                self.logger.warning("æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§")
                return None
                
        except Exception as e:
            self.logger.error("è·å–ç‰¹å¾é‡è¦æ€§å¤±è´¥: %s", str(e))
            return None
            
    def _save_model(self) -> bool:
        """
        ä¿å­˜æ¨¡å‹
        
        è¿”å›:
        bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ä¿å­˜æ¨¡å‹
            model_path = os.path.join(self.models_dir, f'model_{timestamp}.pkl')
            with open(model_path, 'wb') as f:
                pickle.dump(self.model, f)
                
            # ä¿å­˜ç‰¹å¾åç§°
            features_path = os.path.join(self.models_dir, f'features_{timestamp}.json')
            with open(features_path, 'w') as f:
                json.dump(self.feature_names, f)
                
            # ä¿å­˜æœ€æ–°æ¨¡å‹çš„è·¯å¾„
            latest_path = os.path.join(self.models_dir, 'latest_model.txt')
            with open(latest_path, 'w') as f:
                f.write(f'{model_path}\n{features_path}')
                
            self.logger.info("æ¨¡å‹ä¿å­˜æˆåŠŸ: %s", model_path)
            return True
            
        except Exception as e:
            self.logger.error("ä¿å­˜æ¨¡å‹å¤±è´¥: %s", str(e))
            return False
            
    def _load_model(self) -> bool:
        """
        åŠ è½½æ¨¡å‹
        
        è¿”å›:
        bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            latest_path = os.path.join(self.models_dir, 'latest_model.txt')
            
            if not os.path.exists(latest_path):
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„æ¨¡å‹")
                return False
                
            # è¯»å–æœ€æ–°æ¨¡å‹è·¯å¾„
            with open(latest_path, 'r') as f:
                lines = f.read().strip().split('\n')
                if len(lines) < 2:
                    self.logger.error("æ¨¡å‹è·¯å¾„æ–‡ä»¶æ ¼å¼é”™è¯¯")
                    return False
                    
                model_path = lines[0]
                features_path = lines[1]
                
            # åŠ è½½æ¨¡å‹
            with open(model_path, 'rb') as f:
                self.model = pickle.load(f)
                
            # åŠ è½½ç‰¹å¾åç§°
            with open(features_path, 'r') as f:
                self.feature_names = json.load(f)
                
            self.logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ: %s", model_path)
            return True
            
        except Exception as e:
            self.logger.error("åŠ è½½æ¨¡å‹å¤±è´¥: %s", str(e))
            return False
            
    def run_genetic_algorithm(self, evaluate_func, population_size: int = 20, 
                            generations: int = 10) -> Dict[str, Any]:
        """
        è¿è¡Œé—ä¼ ç®—æ³•ä¼˜åŒ–ï¼ˆrise_thresholdå’Œmax_daysä¿æŒå›ºå®šï¼‰
        
        å‚æ•°:
        evaluate_func: è¯„ä¼°å‡½æ•°
        population_size: ç§ç¾¤å¤§å°
        generations: è¿­ä»£ä»£æ•°
        
        è¿”å›:
        dict: æœ€ä¼˜å‚æ•°
        """
        self.logger.info("è¿è¡Œé—ä¼ ç®—æ³•ä¼˜åŒ–ï¼ˆrise_thresholdå’Œmax_daysä¿æŒå›ºå®šï¼‰ï¼Œç§ç¾¤å¤§å°: %d, è¿­ä»£ä»£æ•°: %d", 
                        population_size, generations)
        
        try:
            # å›ºå®šæ ¸å¿ƒå‚æ•°ï¼Œä¸å…è®¸ä¼˜åŒ–
            fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
            fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
            
            self.logger.info(f"å›ºå®šå‚æ•° - rise_threshold: {fixed_rise_threshold}, max_days: {fixed_max_days}")
            
            # ç”±äºæ ¸å¿ƒå‚æ•°å·²å›ºå®šï¼Œé—ä¼ ç®—æ³•ä¸éœ€è¦è¿›è¡Œ
            # ç›´æ¥è¿”å›å›ºå®šå‚æ•°
            self.logger.info("æ ¸å¿ƒå‚æ•°å·²å›ºå®šï¼Œè·³è¿‡é—ä¼ ç®—æ³•ä¼˜åŒ–")
            
            return {
                'rise_threshold': fixed_rise_threshold,
                'max_days': fixed_max_days
            }
            
        except Exception as e:
            self.logger.error("é—ä¼ ç®—æ³•ä¼˜åŒ–å¤±è´¥: %s", str(e))
            return {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04), 
                'max_days': self.config.get('strategy', {}).get('max_days', 20)
            }
            
    def _genetic_operations(self, population: List[Dict], scores: List[float]) -> List[Dict]:
        """
        é—ä¼ ç®—æ³•æ“ä½œï¼ˆé€‰æ‹©ã€äº¤å‰ã€å˜å¼‚ï¼‰
        
        å‚æ•°:
        population: å½“å‰ç§ç¾¤
        scores: é€‚åº”åº¦å¾—åˆ†
        
        è¿”å›:
        list: æ–°ç§ç¾¤
        """
        # é€‰æ‹©ï¼ˆè½®ç›˜èµŒé€‰æ‹©ï¼‰
        total_score = sum(scores)
        if total_score <= 0:
            # å¦‚æœæ‰€æœ‰å¾—åˆ†éƒ½æ˜¯è´Ÿæ•°æˆ–é›¶ï¼Œéšæœºé€‰æ‹©
            selected = np.random.choice(len(population), size=len(population), replace=True)
        else:
            probabilities = [score / total_score for score in scores]
            selected = np.random.choice(len(population), size=len(population), 
                                      replace=True, p=probabilities)
            
        new_population = []
        
        for i in range(0, len(population), 2):
            parent1 = population[selected[i]]
            parent2 = population[selected[min(i + 1, len(population) - 1)]]
            
            # äº¤å‰
            child1, child2 = self._crossover(parent1, parent2)
            
            # å˜å¼‚
            child1 = self._mutate(child1)
            child2 = self._mutate(child2)
            
            new_population.extend([child1, child2])
            
        return new_population[:len(population)]
        
    def _crossover(self, parent1: Dict, parent2: Dict) -> Tuple[Dict, Dict]:
        """
        äº¤å‰æ“ä½œï¼ˆrise_thresholdå’Œmax_daysä¿æŒå›ºå®šï¼‰
        
        å‚æ•°:
        parent1: çˆ¶ä»£1
        parent2: çˆ¶ä»£2
        
        è¿”å›:
        tuple: (å­ä»£1, å­ä»£2)
        """
        # å›ºå®šæ ¸å¿ƒå‚æ•°
        fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
        fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
        
        child1 = {
            'rise_threshold': fixed_rise_threshold,  # å›ºå®šä¸å˜
            'max_days': fixed_max_days              # å›ºå®šä¸å˜
        }
        
        child2 = {
            'rise_threshold': fixed_rise_threshold,  # å›ºå®šä¸å˜
            'max_days': fixed_max_days              # å›ºå®šä¸å˜
        }
        
        return child1, child2
        
    def _mutate(self, individual: Dict, mutation_rate: float = 0.1) -> Dict:
        """
        å˜å¼‚æ“ä½œï¼ˆrise_thresholdå’Œmax_daysä¿æŒå›ºå®šï¼‰
        
        å‚æ•°:
        individual: ä¸ªä½“
        mutation_rate: å˜å¼‚ç‡
        
        è¿”å›:
        dict: å˜å¼‚åçš„ä¸ªä½“
        """
        mutated = individual.copy()
        
        # å›ºå®šæ ¸å¿ƒå‚æ•°ï¼Œä¸å…è®¸å˜å¼‚
        fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
        fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
        
        # ç¡®ä¿æ ¸å¿ƒå‚æ•°ä¿æŒå›ºå®š
        mutated['rise_threshold'] = fixed_rise_threshold
        mutated['max_days'] = fixed_max_days
            
        return mutated

    def _calculate_sample_weights(self, dates: pd.Series) -> np.ndarray:
        """
        æ ¹æ®æ•°æ®æ—¥æœŸè®¡ç®—æ ·æœ¬æƒé‡ï¼Œè¶Šè¿‘çš„æ•°æ®æƒé‡è¶Šé«˜ã€‚
        æƒé‡è¡°å‡æ¨¡å‹ï¼šV(t) = Vâ‚€ Ã— e^(-Î»t)
        å…¶ä¸­Î»æ˜¯è¡°å‡ç³»æ•°ï¼Œæ ¹æ®åˆ†ææŠ¥å‘Šï¼ŒÎ»çº¦ä¸º0.3-0.5ã€‚
        è¿™é‡Œæˆ‘ä»¬å–Î»=0.4ï¼Œå¹¶æ ¹æ®æ—¶é—´å·®è®¡ç®—æƒé‡ã€‚
        
        å‚æ•°:
        dates: è®­ç»ƒé›†æ•°æ®çš„æ—¥æœŸåºåˆ—
        
        è¿”å›:
        numpy.ndarray: æ ·æœ¬æƒé‡æ•°ç»„
        """
        self.logger.info("è®¡ç®—æ ·æœ¬æƒé‡")
        
        weights = np.ones(len(dates))
        if len(dates) == 0: # Handle empty dates series
            return weights

        latest_date = dates.max()
        
        for i, date in enumerate(dates):
            time_diff = (latest_date - date).days / 365.25  # å¹´ä¸ºå•ä½
            # è¡°å‡ç³»æ•°Î»ï¼Œå¯ä»¥æ ¹æ®configé…ç½®
            decay_rate = self.config.get("ai", {}).get("data_decay_rate", 0.4)
            weight = np.exp(-decay_rate * time_diff)
            weights[i] = weight
            
        # å½’ä¸€åŒ–æƒé‡ï¼Œä½¿å…¶å’Œä¸º1ï¼Œæˆ–è€…ä¿æŒåŸå§‹æ¯”ä¾‹
        # è¿™é‡Œé€‰æ‹©ä¿æŒåŸå§‹æ¯”ä¾‹ï¼Œå› ä¸ºRandomForestClassifierçš„sample_weightå‚æ•°æ˜¯ä¹˜æ³•å…³ç³»
        # ä¹Ÿå¯ä»¥é€‰æ‹©å½’ä¸€åŒ–åˆ°æŸä¸ªèŒƒå›´ï¼Œä¾‹å¦‚0-1
        
        self.logger.info("æ ·æœ¬æƒé‡è®¡ç®—å®Œæˆï¼Œæœ€å¤§æƒé‡: %.4f, æœ€å°æƒé‡: %.4f", 
                        np.max(weights), np.min(weights))
        
        return weights

    def optimize_strategy_parameters_advanced(self, strategy_module, data: pd.DataFrame) -> Dict[str, Any]:
        """
        é«˜çº§ç­–ç•¥å‚æ•°ä¼˜åŒ– - ä½¿ç”¨å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆrise_thresholdä¿æŒå›ºå®šï¼‰
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–åçš„å‚æ•°
        """
        self.logger.info("å¼€å§‹é«˜çº§ç­–ç•¥å‚æ•°ä¼˜åŒ–ï¼ˆrise_thresholdä¿æŒå›ºå®šï¼‰")
        
        try:
            # å›ºå®šæ ¸å¿ƒå‚æ•°ï¼Œä¸å…è®¸ä¼˜åŒ–
            fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
            fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
            
            self.logger.info(f"å›ºå®šå‚æ•° - rise_threshold: {fixed_rise_threshold}, max_days: {fixed_max_days}")
            
            # ç”±äºrise_thresholdå’Œmax_dayséƒ½æ˜¯å›ºå®šçš„ï¼Œé«˜çº§ä¼˜åŒ–å®é™…ä¸Šä¸éœ€è¦è¿›è¡Œ
            # ç›´æ¥è¿”å›å›ºå®šå‚æ•°ï¼Œåªä¼˜åŒ–å…¶ä»–å‚æ•°
            self.logger.info("æ ¸å¿ƒå‚æ•°å·²å›ºå®šï¼Œè·³è¿‡é«˜çº§ä¼˜åŒ–ï¼Œä½¿ç”¨åŸºç¡€ä¼˜åŒ–æ–¹æ³•")
            return self.optimize_strategy_parameters(strategy_module, data)
                
        except Exception as e:
            self.logger.error("é«˜çº§ä¼˜åŒ–å¤±è´¥: %s", str(e))
            return self.optimize_strategy_parameters(strategy_module, data)
    
    def time_series_cv_evaluation(self, data: pd.DataFrame, strategy_module) -> float:
        """
        æ—¶é—´åºåˆ—äº¤å‰éªŒè¯è¯„ä¼°
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        
        è¿”å›:
        float: å¹³å‡å¾—åˆ†
        """
        self.logger.info("ğŸ”„ å¼€å§‹æ—¶é—´åºåˆ—äº¤å‰éªŒè¯è¯„ä¼°")
        
        try:
            total_score = 0
            cv_folds = 5
            fold_scores = []
            
            self.logger.info(f"ğŸ“Š å°†æ•°æ®åˆ†ä¸º {cv_folds} æŠ˜è¿›è¡ŒéªŒè¯...")
            
            # è®°å½•å¼€å§‹æ—¶é—´
            import time
            cv_start_time = time.time()
            
            for i in range(cv_folds):
                fold_start_time = time.time()
                fold_progress = (i + 1) / cv_folds * 100
                
                self.logger.info(f"ğŸ”„ ç¬¬{i+1}/{cv_folds}æŠ˜ ({fold_progress:.1f}%) - å¼€å§‹å¤„ç†...")
                
                # æŒ‰æ—¶é—´åˆ†å‰²æ•°æ®
                split_point = int(len(data) * (i + 1) / cv_folds)
                train_data = data.iloc[:split_point]
                test_data = data.iloc[split_point:min(split_point + 100, len(data))]  # æµ‹è¯•çª—å£
                
                if len(test_data) < 20:  # æµ‹è¯•æ•°æ®å¤ªå°‘ï¼Œè·³è¿‡
                    self.logger.info(f"   â­ï¸ ç¬¬{i+1}æŠ˜ï¼šæµ‹è¯•æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                    continue
                
                self.logger.info(f"   ğŸ“‹ æ•°æ®åˆ†å‰²å®Œæˆï¼šè®­ç»ƒæ•°æ® {len(train_data)} æ¡ï¼Œæµ‹è¯•æ•°æ® {len(test_data)} æ¡")
                
                # åœ¨è®­ç»ƒæ•°æ®ä¸Šä¼˜åŒ–ç­–ç•¥å‚æ•°
                self.logger.info(f"   ğŸ”§ ç¬¬{i+1}æŠ˜ï¼šå¼€å§‹å‚æ•°ä¼˜åŒ–...")
                temp_strategy = StrategyModule(self.config)
                optimized_params = self.optimize_strategy_parameters(temp_strategy, train_data)
                temp_strategy.update_params(optimized_params)
                self.logger.info(f"   âœ… ç¬¬{i+1}æŠ˜ï¼šå‚æ•°ä¼˜åŒ–å®Œæˆ")
                
                # åœ¨æµ‹è¯•æ•°æ®ä¸Šè¯„ä¼°
                self.logger.info(f"   ğŸ“Š ç¬¬{i+1}æŠ˜ï¼šå¼€å§‹å›æµ‹è¯„ä¼°...")
                backtest_results = temp_strategy.backtest(test_data)
                evaluation = temp_strategy.evaluate_strategy(backtest_results)
                score = evaluation['score']
                
                fold_scores.append(score)
                total_score += score
                
                fold_time = time.time() - fold_start_time
                self.logger.info(f"   âœ… ç¬¬{i+1}æŠ˜å®Œæˆï¼šå¾—åˆ† {score:.4f}ï¼Œè€—æ—¶ {fold_time:.1f}ç§’")
                
                # æ˜¾ç¤ºæ•´ä½“è¿›åº¦
                elapsed_time = time.time() - cv_start_time
                avg_time_per_fold = elapsed_time / (i + 1)
                remaining_folds = cv_folds - (i + 1)
                estimated_remaining_time = remaining_folds * avg_time_per_fold
                
                self.logger.info(f"   ğŸ“ˆ æ•´ä½“è¿›åº¦ï¼š{fold_progress:.1f}%ï¼Œå·²ç”¨æ—¶é—´ï¼š{elapsed_time:.1f}ç§’ï¼Œé¢„è®¡å‰©ä½™ï¼š{estimated_remaining_time:.1f}ç§’")
                self.logger.info("-" * 40)
            
            if len(fold_scores) == 0:
                self.logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„äº¤å‰éªŒè¯ç»“æœ")
                return 0.0
                
            avg_score = total_score / len(fold_scores)
            total_cv_time = time.time() - cv_start_time
            self.logger.info(f"ğŸ“Š äº¤å‰éªŒè¯å®Œæˆï¼Œå¹³å‡å¾—åˆ†: {avg_score:.4f} (å…±{len(fold_scores)}æŠ˜)")
            self.logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_cv_time:.1f}ç§’ï¼Œå¹³å‡æ¯æŠ˜: {total_cv_time/len(fold_scores):.1f}ç§’")
            
            return avg_score
            
        except Exception as e:
            self.logger.error("âŒ æ—¶é—´åºåˆ—äº¤å‰éªŒè¯å¤±è´¥: %s", str(e))
            return 0.0
    
    def hierarchical_optimization(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        åˆ†å±‚ä¼˜åŒ–ç­–ç•¥
        
        å‚æ•°:
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–ç»“æœ
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸ—ï¸ å¼€å§‹åˆ†å±‚ä¼˜åŒ–ç­–ç•¥")
        self.logger.info("=" * 60)
        
        try:
            # è®°å½•å¼€å§‹æ—¶é—´
            import time
            start_time = time.time()
            
            # ç¬¬ä¸€å±‚ï¼šç­–ç•¥å‚æ•°ä¼˜åŒ–
            self.logger.info("ğŸ“Š ç¬¬ä¸€å±‚ï¼šç­–ç•¥å‚æ•°ä¼˜åŒ–...")
            self.logger.info("   ğŸ”§ åˆ›å»ºç­–ç•¥æ¨¡å—å®ä¾‹...")
            layer1_start = time.time()
            strategy_module = StrategyModule(self.config)
            self.logger.info("   âœ… ç­–ç•¥æ¨¡å—åˆ›å»ºå®Œæˆ")
            
            self.logger.info("   ğŸ¯ å¼€å§‹å‚æ•°ä¼˜åŒ–...")
            strategy_params = self.optimize_strategy_parameters(strategy_module, data)
            layer1_time = time.time() - layer1_start
            self.logger.info("âœ… ç­–ç•¥å‚æ•°ä¼˜åŒ–å®Œæˆ")
            self.logger.info(f"   - æ¶¨å¹…é˜ˆå€¼: {strategy_params['rise_threshold']:.3f}")
            self.logger.info(f"   - æœ€å¤§è§‚å¯Ÿå¤©æ•°: {strategy_params['max_days']}")
            self.logger.info(f"   - è€—æ—¶: {layer1_time:.1f}ç§’")
            
            # ç¬¬äºŒå±‚ï¼šåŸºäºä¼˜åŒ–åçš„ç­–ç•¥è®­ç»ƒAIæ¨¡å‹
            self.logger.info("ğŸ¤– ç¬¬äºŒå±‚ï¼šæ›´æ–°ç­–ç•¥å‚æ•°å¹¶å‡†å¤‡AIè®­ç»ƒ...")
            layer2_start = time.time()
            
            self.logger.info("   ğŸ”„ æ›´æ–°ç­–ç•¥å‚æ•°...")
            strategy_module.update_params(strategy_params)
            self.logger.info("âœ… ç­–ç•¥å‚æ•°æ›´æ–°å®Œæˆ")
            
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            self.logger.info("ğŸ“‹ å‡†å¤‡AIè®­ç»ƒæ•°æ®...")
            self.logger.info("   ğŸ“Š æå–ç‰¹å¾...")
            features, feature_names = self.prepare_features(data)
            self.logger.info("   ğŸ·ï¸ å‡†å¤‡æ ‡ç­¾...")
            labels = self.prepare_labels(data, strategy_module)
            self.logger.info(f"   - ç‰¹å¾æ•°é‡: {len(feature_names)}")
            self.logger.info(f"   - æ ·æœ¬æ•°é‡: {len(features)}")
            self.logger.info(f"   - æ­£æ ·æœ¬æ¯”ä¾‹: {np.mean(labels):.2%}")
            
            # è®­ç»ƒAIæ¨¡å‹
            self.logger.info("ğŸ¯ å¼€å§‹è®­ç»ƒAIæ¨¡å‹...")
            training_result = self.train_model(data, strategy_module)
            layer2_time = time.time() - layer2_start
            self.logger.info("âœ… AIæ¨¡å‹è®­ç»ƒå®Œæˆ")
            self.logger.info(f"   - è®­ç»ƒå‡†ç¡®ç‡: {training_result.get('accuracy', 0):.4f}")
            self.logger.info(f"   - è€—æ—¶: {layer2_time:.1f}ç§’")
            
            # ç¬¬ä¸‰å±‚ï¼šæ—¶é—´åºåˆ—äº¤å‰éªŒè¯
            self.logger.info("ğŸ”„ ç¬¬ä¸‰å±‚ï¼šæ—¶é—´åºåˆ—äº¤å‰éªŒè¯...")
            layer3_start = time.time()
            cv_score = self.time_series_cv_evaluation(data, strategy_module)
            layer3_time = time.time() - layer3_start
            self.logger.info(f"âœ… äº¤å‰éªŒè¯å®Œæˆï¼Œå¹³å‡å¾—åˆ†: {cv_score:.4f}")
            self.logger.info(f"   - è€—æ—¶: {layer3_time:.1f}ç§’")
            
            # ç¬¬å››å±‚ï¼šé«˜çº§ä¼˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            self.logger.info("ğŸš€ ç¬¬å››å±‚ï¼šé«˜çº§ä¼˜åŒ–...")
            layer4_start = time.time()
            try:
                self.logger.info("   ğŸ”§ å¼€å§‹é«˜çº§å‚æ•°ä¼˜åŒ–...")
                advanced_params = self.optimize_strategy_parameters_advanced(strategy_module, data)
                self.logger.info("   ğŸ“Š è¯„ä¼°é«˜çº§ä¼˜åŒ–ç»“æœ...")
                advanced_score = self._evaluate_params_with_fixed_labels(
                    data, 
                    strategy_module.backtest(data)['is_low_point'].astype(int).values,
                    advanced_params['rise_threshold'],
                    advanced_params['max_days']
                )
                layer4_time = time.time() - layer4_start
                self.logger.info("âœ… é«˜çº§ä¼˜åŒ–å®Œæˆ")
                self.logger.info(f"   - é«˜çº§ä¼˜åŒ–å¾—åˆ†: {advanced_score:.4f}")
                self.logger.info(f"   - è€—æ—¶: {layer4_time:.1f}ç§’")
            except Exception as e:
                self.logger.warning(f"âš ï¸ é«˜çº§ä¼˜åŒ–å¤±è´¥: {str(e)}")
                advanced_params = strategy_params
                advanced_score = cv_score
                layer4_time = time.time() - layer4_start
            
            # æœ€ç»ˆç»“æœç»Ÿè®¡
            total_time = time.time() - start_time
            self.logger.info("=" * 60)
            self.logger.info("ğŸ¯ åˆ†å±‚ä¼˜åŒ–å®Œæˆ!")
            self.logger.info("=" * 60)
            self.logger.info(f"ğŸ“Š ä¼˜åŒ–ç»Ÿè®¡:")
            self.logger.info(f"   - æ€»è€—æ—¶: {total_time:.1f}ç§’")
            self.logger.info(f"   - ç¬¬ä¸€å±‚è€—æ—¶: {layer1_time:.1f}ç§’ ({layer1_time/total_time*100:.1f}%)")
            self.logger.info(f"   - ç¬¬äºŒå±‚è€—æ—¶: {layer2_time:.1f}ç§’ ({layer2_time/total_time*100:.1f}%)")
            self.logger.info(f"   - ç¬¬ä¸‰å±‚è€—æ—¶: {layer3_time:.1f}ç§’ ({layer3_time/total_time*100:.1f}%)")
            self.logger.info(f"   - ç¬¬å››å±‚è€—æ—¶: {layer4_time:.1f}ç§’ ({layer4_time/total_time*100:.1f}%)")
            self.logger.info("")
            self.logger.info(f"ğŸ† æœ€ç»ˆç»“æœ:")
            self.logger.info(f"   - äº¤å‰éªŒè¯å¾—åˆ†: {cv_score:.4f}")
            self.logger.info(f"   - é«˜çº§ä¼˜åŒ–å¾—åˆ†: {advanced_score:.4f}")
            self.logger.info(f"   - æœ€ä½³å¾—åˆ†: {max(cv_score, advanced_score):.4f}")
            
            # è¿”å›æœ€ä½³ç»“æœ
            if advanced_score > cv_score:
                final_params = advanced_params
                self.logger.info("   - é€‰æ‹©é«˜çº§ä¼˜åŒ–ç»“æœ")
            else:
                final_params = strategy_params
                self.logger.info("   - é€‰æ‹©åŸºç¡€ä¼˜åŒ–ç»“æœ")
            
            return {
                'params': final_params,
                'cv_score': cv_score,
                'advanced_score': advanced_score,
                'best_score': max(cv_score, advanced_score),
                'total_time': total_time,
                'layer_times': {
                    'layer1': layer1_time,
                    'layer2': layer2_time,
                    'layer3': layer3_time,
                    'layer4': layer4_time
                }
            }
            
        except Exception as e:
            self.logger.error("âŒ åˆ†å±‚ä¼˜åŒ–å¤±è´¥: %s", str(e))
            return {
                'params': self.config.get('strategy', {}),
                'cv_score': 0.0,
                'advanced_score': 0.0,
                'best_score': 0.0,
                'error': str(e)
            }

    def _evaluate_params_with_fixed_labels_advanced(self, data: pd.DataFrame, fixed_labels: np.ndarray, 
                                                  params: Dict[str, Any]) -> float:
        """
        ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°å¤šå‚æ•°ç­–ç•¥
        
        å‚æ•°:
        data: å†å²æ•°æ®
        fixed_labels: å›ºå®šçš„æ ‡ç­¾ï¼ˆç›¸å¯¹ä½ç‚¹æ ‡è¯†ï¼‰
        params: å‚æ•°å­—å…¸ï¼ŒåŒ…å«rise_threshold, max_days, rsi_oversold_threshold, rsi_low_threshold, final_threshold
        
        è¿”å›:
        float: ç­–ç•¥å¾—åˆ†
        """
        try:
            # 1. è®¡ç®—æ¯ä¸ªè¯†åˆ«ç‚¹çš„æœªæ¥è¡¨ç°
            scores = []
            low_point_indices = np.where(fixed_labels == 1)[0]
            
            rise_threshold = params['rise_threshold']
            max_days = params['max_days']
            
            for idx in low_point_indices:
                if idx >= len(data) - max_days:
                    continue
                    
                current_price = data.iloc[idx]['close']
                max_rise = 0.0
                days_to_rise = 0
                
                # è®¡ç®—æœªæ¥max_dayså†…çš„æœ€å¤§æ¶¨å¹…
                for j in range(1, max_days + 1):
                    if idx + j >= len(data):
                        break
                    future_price = data.iloc[idx + j]['close']
                    rise_rate = (future_price - current_price) / current_price
                    
                    if rise_rate > max_rise:
                        max_rise = rise_rate
                        
                    if rise_rate >= rise_threshold and days_to_rise == 0:
                        days_to_rise = j
                
                # è®¡ç®—å•ä¸ªç‚¹çš„å¾—åˆ†
                success = max_rise >= rise_threshold
                point_score = self._calculate_point_score(success, max_rise, days_to_rise, max_days)
                scores.append(point_score)
            
            # 2. è®¡ç®—æ€»ä½“å¾—åˆ†
            if len(scores) == 0:
                return 0.0
                
            return np.mean(scores)
            
        except Exception as e:
            self.logger.error("è¯„ä¼°å¤šå‚æ•°å¤±è´¥: %s", str(e))
            return 0.0


