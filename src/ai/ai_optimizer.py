#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
AIä¼˜åŒ–æ¨¡å—
ä½¿ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•ä¼˜åŒ–ç­–ç•¥å‚æ•°å’Œé¢„æµ‹ç›¸å¯¹ä½ç‚¹
"""

import os
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Any, List, Tuple, Optional
import pickle
import json
import sys
import time
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from strategy.strategy_module import StrategyModule

# æœºå™¨å­¦ä¹ ç›¸å…³
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

class AIOptimizer:
    """AIä¼˜åŒ–å™¨ç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–AIä¼˜åŒ–å™¨
        
        å‚æ•°:
        config: é…ç½®å­—å…¸
        """
        self.logger = logging.getLogger('AIOptimizer')
        self.config = config
        
        # AIé…ç½®
        ai_config = config.get('ai', {})
        self.model_type = ai_config.get('model_type', 'machine_learning')
        self.optimization_interval = ai_config.get('optimization_interval', 30)
        
        # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
        self.models_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'models')
        if not os.path.exists(self.models_dir):
            os.makedirs(self.models_dir)
            
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = None
        self.scaler = None
        self.feature_names = None
        
        # å‚æ•°å†å²è®°å½•
        self.parameter_history_file = os.path.join(self.models_dir, 'parameter_history.json')
        self.best_parameters_file = os.path.join(self.models_dir, 'best_parameters.json')
        
        # æ–°å¢ï¼šä¸¥æ ¼æ•°æ®åˆ†å‰²é…ç½®
        validation_config = ai_config.get('validation', {})
        self.train_ratio = validation_config.get('train_ratio', 0.6)
        self.validation_ratio = validation_config.get('validation_ratio', 0.2)
        self.test_ratio = validation_config.get('test_ratio', 0.2)
        
        # ç¡®ä¿æ¯”ä¾‹æ€»å’Œä¸º1
        total_ratio = self.train_ratio + self.validation_ratio + self.test_ratio
        if abs(total_ratio - 1.0) > 1e-6:
            self.logger.warning(f"æ•°æ®åˆ†å‰²æ¯”ä¾‹æ€»å’Œ {total_ratio:.3f} ä¸ç­‰äº1.0ï¼Œè‡ªåŠ¨è°ƒæ•´")
            self.train_ratio = self.train_ratio / total_ratio
            self.validation_ratio = self.validation_ratio / total_ratio
            self.test_ratio = self.test_ratio / total_ratio
        
        # æ•°æ®æ³„éœ²ä¿æŠ¤
        self._test_set_locked = False
        self._test_set_indices = None
        
        self.logger.info("AIä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹ç±»å‹: %s", self.model_type)
        self.logger.info(f"æ•°æ®åˆ†å‰²æ¯”ä¾‹ - è®­ç»ƒ: {self.train_ratio:.1%}, éªŒè¯: {self.validation_ratio:.1%}, æµ‹è¯•: {self.test_ratio:.1%}")
        
    def strict_data_split(self, data: pd.DataFrame, preserve_test_set: bool = True) -> Dict[str, pd.DataFrame]:
        """
        ä¸¥æ ¼çš„æ—¶é—´åºåˆ—æ•°æ®åˆ†å‰²ï¼Œé˜²æ­¢æ•°æ®æ³„éœ²
        
        å‚æ•°:
        data: åŸå§‹æ•°æ®
        preserve_test_set: æ˜¯å¦ä¿æŠ¤æµ‹è¯•é›†ï¼ˆä¸€æ—¦åˆ†å‰²ï¼Œæµ‹è¯•é›†æ°¸è¿œä¸å‚ä¸ä¼˜åŒ–ï¼‰
        
        è¿”å›:
        dict: åŒ…å« 'train', 'validation', 'test' é”®çš„æ•°æ®å­—å…¸
        """
        self.logger.info("ğŸ”’ å¼€å§‹ä¸¥æ ¼æ•°æ®åˆ†å‰²...")
        
        # æŒ‰æ—¶é—´åºåˆ—åˆ†å‰²æ•°æ®
        n = len(data)
        train_end = int(n * self.train_ratio)
        val_end = int(n * (self.train_ratio + self.validation_ratio))
        
        # åˆ†å‰²æ•°æ®
        train_data = data.iloc[:train_end].copy()
        validation_data = data.iloc[train_end:val_end].copy()
        test_data = data.iloc[val_end:].copy()
        
        # ä¿æŠ¤æµ‹è¯•é›†
        if preserve_test_set:
            if self._test_set_locked and self._test_set_indices is not None:
                # æ£€æŸ¥æµ‹è¯•é›†æ˜¯å¦è¢«ç¯¡æ”¹
                current_test_indices = test_data.index.tolist()
                if current_test_indices != self._test_set_indices:
                    self.logger.error("âŒ æ£€æµ‹åˆ°æµ‹è¯•é›†æ•°æ®æ³„éœ²é£é™©ï¼")
                    raise ValueError("æµ‹è¯•é›†æ•°æ®å·²è¢«ç¯¡æ”¹ï¼Œå­˜åœ¨æ•°æ®æ³„éœ²é£é™©")
                self.logger.info("ğŸ”’ æµ‹è¯•é›†å®Œæ•´æ€§éªŒè¯é€šè¿‡")
            else:
                # é¦–æ¬¡é”å®šæµ‹è¯•é›†
                self._test_set_indices = test_data.index.tolist()
                self._test_set_locked = True
                self.logger.info("ğŸ”’ æµ‹è¯•é›†å·²é”å®šï¼Œé˜²æ­¢æ•°æ®æ³„éœ²")
        
        self.logger.info(f"âœ… æ•°æ®åˆ†å‰²å®Œæˆ:")
        self.logger.info(f"   - è®­ç»ƒé›†: {len(train_data)} æ¡ ({len(train_data)/n:.1%})")
        self.logger.info(f"   - éªŒè¯é›†: {len(validation_data)} æ¡ ({len(validation_data)/n:.1%})")
        self.logger.info(f"   - æµ‹è¯•é›†: {len(test_data)} æ¡ ({len(test_data)/n:.1%})")
        self.logger.info(f"   - æ—¶é—´èŒƒå›´:")
        self.logger.info(f"     è®­ç»ƒ: {train_data.iloc[0]['date']} ~ {train_data.iloc[-1]['date']}")
        self.logger.info(f"     éªŒè¯: {validation_data.iloc[0]['date']} ~ {validation_data.iloc[-1]['date']}")
        self.logger.info(f"     æµ‹è¯•: {test_data.iloc[0]['date']} ~ {test_data.iloc[-1]['date']}")
        
        return {
            'train': train_data,
            'validation': validation_data,
            'test': test_data
        }
    
    def walk_forward_validation(self, data: pd.DataFrame, strategy_module, 
                              window_size: int = 252, step_size: int = 63) -> Dict[str, Any]:
        """
        èµ°å‰éªŒè¯ï¼šæ¨¡æ‹ŸçœŸå®äº¤æ˜“ç¯å¢ƒçš„ä¸¥æ ¼éªŒè¯æ–¹æ³•
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        window_size: è®­ç»ƒçª—å£å¤§å°ï¼ˆäº¤æ˜“æ—¥ï¼‰
        step_size: æ­¥è¿›å¤§å°ï¼ˆäº¤æ˜“æ—¥ï¼‰
        
        è¿”å›:
        dict: éªŒè¯ç»“æœ
        """
        self.logger.info("ğŸš¶ å¼€å§‹èµ°å‰éªŒè¯...")
        self.logger.info(f"   - è®­ç»ƒçª—å£: {window_size} å¤©")
        self.logger.info(f"   - æ­¥è¿›å¤§å°: {step_size} å¤©")
        
        scores = []
        fold_results = []
        start_time = time.time()
        
        # è®¡ç®—æ€»çš„éªŒè¯æŠ˜æ•°
        total_folds = max(0, (len(data) - window_size) // step_size)
        if total_folds == 0:
            self.logger.error("âŒ æ•°æ®ä¸è¶³ä»¥è¿›è¡Œèµ°å‰éªŒè¯")
            return {'success': False, 'error': 'æ•°æ®ä¸è¶³'}
        
        self.logger.info(f"ğŸ“Š æ€»éªŒè¯æŠ˜æ•°: {total_folds}")
        
        for fold in range(total_folds):
            fold_start_time = time.time()
            
            # è®¡ç®—æ•°æ®çª—å£
            start_idx = fold * step_size
            train_end_idx = start_idx + window_size
            test_start_idx = train_end_idx
            test_end_idx = min(test_start_idx + step_size, len(data))
            
            # æ£€æŸ¥æµ‹è¯•çª—å£æ˜¯å¦è¶³å¤Ÿ
            if test_end_idx - test_start_idx < 20:
                self.logger.info(f"   â­ï¸ ç¬¬{fold+1}æŠ˜ï¼šæµ‹è¯•çª—å£ä¸è¶³ï¼Œè·³è¿‡")
                continue
            
            # è·å–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
            train_data = data.iloc[start_idx:train_end_idx].copy()
            test_data = data.iloc[test_start_idx:test_end_idx].copy()
            
            self.logger.info(f"ğŸ”„ ç¬¬{fold+1}/{total_folds}æŠ˜:")
            self.logger.info(f"   - è®­ç»ƒæ•°æ®: {len(train_data)} æ¡")
            self.logger.info(f"   - æµ‹è¯•æ•°æ®: {len(test_data)} æ¡")
            self.logger.info(f"   - è®­ç»ƒæœŸé—´: {train_data.iloc[0]['date']} ~ {train_data.iloc[-1]['date']}")
            self.logger.info(f"   - æµ‹è¯•æœŸé—´: {test_data.iloc[0]['date']} ~ {test_data.iloc[-1]['date']}")
            
            try:
                # åœ¨è®­ç»ƒæ•°æ®ä¸Šä¼˜åŒ–å‚æ•°ï¼ˆä¸¥æ ¼éš”ç¦»ï¼‰
                temp_strategy = StrategyModule(self.config)
                optimized_params = self.optimize_strategy_parameters_on_train_only(
                    temp_strategy, train_data
                )
                temp_strategy.update_params(optimized_params)
                
                # åœ¨æµ‹è¯•æ•°æ®ä¸Šè¯„ä¼°ï¼ˆç»å¯¹ä¸å‚ä¸ä¼˜åŒ–ï¼‰
                backtest_results = temp_strategy.backtest(test_data)
                evaluation = temp_strategy.evaluate_strategy(backtest_results)
                score = evaluation['score']
                
                scores.append(score)
                fold_results.append({
                    'fold': fold + 1,
                    'score': score,
                    'train_period': f"{train_data.iloc[0]['date']} ~ {train_data.iloc[-1]['date']}",
                    'test_period': f"{test_data.iloc[0]['date']} ~ {test_data.iloc[-1]['date']}",
                    'optimized_params': optimized_params,
                    'evaluation': evaluation
                })
                
                fold_time = time.time() - fold_start_time
                self.logger.info(f"   âœ… å¾—åˆ†: {score:.4f}ï¼Œè€—æ—¶: {fold_time:.1f}ç§’")
                
            except Exception as e:
                self.logger.error(f"   âŒ ç¬¬{fold+1}æŠ˜å¤±è´¥: {str(e)}")
                continue
        
        if len(scores) == 0:
            self.logger.error("âŒ èµ°å‰éªŒè¯å¤±è´¥ï¼Œæ²¡æœ‰æœ‰æ•ˆç»“æœ")
            return {'success': False, 'error': 'æ²¡æœ‰æœ‰æ•ˆçš„éªŒè¯ç»“æœ'}
        
        # ç»Ÿè®¡ç»“æœ
        avg_score = np.mean(scores)
        std_score = np.std(scores)
        min_score = np.min(scores)
        max_score = np.max(scores)
        total_time = time.time() - start_time
        
        self.logger.info("âœ… èµ°å‰éªŒè¯å®Œæˆ!")
        self.logger.info(f"ğŸ“Š éªŒè¯ç»Ÿè®¡:")
        self.logger.info(f"   - æœ‰æ•ˆæŠ˜æ•°: {len(scores)}/{total_folds}")
        self.logger.info(f"   - å¹³å‡å¾—åˆ†: {avg_score:.4f} Â± {std_score:.4f}")
        self.logger.info(f"   - å¾—åˆ†èŒƒå›´: [{min_score:.4f}, {max_score:.4f}]")
        self.logger.info(f"   - æ€»è€—æ—¶: {total_time:.1f}ç§’")
        
        return {
            'success': True,
            'avg_score': avg_score,
            'std_score': std_score,
            'min_score': min_score,
            'max_score': max_score,
            'valid_folds': len(scores),
            'total_folds': total_folds,
            'fold_results': fold_results,
            'total_time': total_time
        }
    
    def optimize_strategy_parameters_on_train_only(self, strategy_module, train_data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä»…åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿›è¡Œå‚æ•°ä¼˜åŒ–ï¼Œç»å¯¹ä¸ä½¿ç”¨éªŒè¯/æµ‹è¯•æ•°æ®
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        train_data: ä¸¥æ ¼çš„è®­ç»ƒæ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–åçš„å‚æ•°
        """
        self.logger.info("ğŸ”§ å¼€å§‹è®­ç»ƒé›†å‚æ•°ä¼˜åŒ–ï¼ˆæ•°æ®æ³„éœ²ä¿æŠ¤ï¼‰...")
        
        try:
            # 1. éªŒè¯è¿™æ˜¯çº¯è®­ç»ƒæ•°æ®
            if self._test_set_locked and self._test_set_indices:
                train_indices = train_data.index.tolist()
                test_indices_set = set(self._test_set_indices)
                if any(idx in test_indices_set for idx in train_indices):
                    raise ValueError("âŒ æ£€æµ‹åˆ°æ•°æ®æ³„éœ²ï¼šè®­ç»ƒæ•°æ®åŒ…å«æµ‹è¯•é›†æ•°æ®ï¼")
            
            # 2. è·å–åŸºå‡†ç­–ç•¥çš„è¯†åˆ«ç»“æœä½œä¸ºå›ºå®šæ ‡ç­¾
            baseline_backtest = strategy_module.backtest(train_data)
            fixed_labels = baseline_backtest['is_low_point'].astype(int).values
            
            # 3. å›ºå®šæ ¸å¿ƒå‚æ•°
            fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
            fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
            
            # 4. è·å–æœç´¢èŒƒå›´
            ai_config = self.config.get('ai', {})
            optimization_ranges = ai_config.get('optimization_ranges', {})
            
            # ç›´æ¥æ„å»ºå‚æ•°ç½‘æ ¼ï¼ˆé¿å…æ–¹æ³•é¡ºåºä¾èµ–é—®é¢˜ï¼‰
            param_grid = {}
            param_configs = {
                'rsi_oversold_threshold': {'type': 'int', 'default_min': 25, 'default_max': 35, 'default_step': 1},
                'rsi_low_threshold': {'type': 'int', 'default_min': 35, 'default_max': 45, 'default_step': 1},
                'final_threshold': {'type': 'float', 'default_min': 0.3, 'default_max': 0.7, 'default_step': 0.05},
                'dynamic_confidence_adjustment': {'type': 'float', 'default_min': 0.05, 'default_max': 0.25, 'default_step': 0.02},
                'market_sentiment_weight': {'type': 'float', 'default_min': 0.08, 'default_max': 0.25, 'default_step': 0.02},
                'trend_strength_weight': {'type': 'float', 'default_min': 0.06, 'default_max': 0.20, 'default_step': 0.02},
                'volume_weight': {'type': 'float', 'default_min': 0.15, 'default_max': 0.35, 'default_step': 0.02},
                'price_momentum_weight': {'type': 'float', 'default_min': 0.12, 'default_max': 0.30, 'default_step': 0.02}
            }
            
            for param_name, config in param_configs.items():
                param_range = optimization_ranges.get(param_name, {})
                min_val = param_range.get('min', config['default_min'])
                max_val = param_range.get('max', config['default_max'])
                step = param_range.get('step', config['default_step'])
                
                if config['type'] == 'int':
                    param_grid[param_name] = np.arange(min_val, max_val + 1, step)
                else:
                    param_grid[param_name] = np.arange(min_val, max_val + step, step)
            
            # 5. æ—©åœæœºåˆ¶
            early_stopping = EarlyStopping(
                patience=ai_config.get('early_stopping', {}).get('patience', 50),
                min_delta=ai_config.get('early_stopping', {}).get('min_delta', 0.001)
            )
            
            # 6. å‚æ•°ä¼˜åŒ–ï¼ˆä»…ä½¿ç”¨è®­ç»ƒæ•°æ®ï¼‰
            best_score = -1
            best_params = None
            max_iterations = 200  # å‡å°‘è¿­ä»£æ¬¡æ•°ä»¥æé«˜æ•ˆç‡
            
            for iteration in range(max_iterations):
                # éšæœºç”Ÿæˆå‚æ•°ç»„åˆ
                params = {
                    'rise_threshold': fixed_rise_threshold,
                    'max_days': fixed_max_days,
                    'rsi_oversold_threshold': int(np.random.choice(param_grid['rsi_oversold_threshold'])),
                    'rsi_low_threshold': int(np.random.choice(param_grid['rsi_low_threshold'])),
                    'final_threshold': np.random.choice(param_grid['final_threshold']),
                    'dynamic_confidence_adjustment': np.random.choice(param_grid['dynamic_confidence_adjustment']),
                    'market_sentiment_weight': np.random.choice(param_grid['market_sentiment_weight']),
                    'trend_strength_weight': np.random.choice(param_grid['trend_strength_weight']),
                    'volume_weight': np.random.choice(param_grid['volume_weight']),
                    'price_momentum_weight': np.random.choice(param_grid['price_momentum_weight'])
                }
                
                # è¯„ä¼°å‚æ•°ï¼ˆä»…ä½¿ç”¨è®­ç»ƒæ•°æ®ï¼‰
                # ç›´æ¥å®ç°è¯„ä¼°é€»è¾‘é¿å…æ–¹æ³•é¡ºåºä¾èµ–
                try:
                    scores = []
                    low_point_indices = np.where(fixed_labels == 1)[0]
                    
                    rise_threshold = params['rise_threshold']
                    max_days = params['max_days']
                    
                    for idx in low_point_indices:
                        if idx >= len(train_data) - max_days:
                            continue
                            
                        current_price = train_data.iloc[idx]['close']
                        max_rise = 0.0
                        days_to_rise = 0
                        
                        # è®¡ç®—æœªæ¥max_dayså†…çš„æœ€å¤§æ¶¨å¹…
                        for j in range(1, max_days + 1):
                            if idx + j >= len(train_data):
                                break
                            future_price = train_data.iloc[idx + j]['close']
                            rise_rate = (future_price - current_price) / current_price
                            
                            if rise_rate > max_rise:
                                max_rise = rise_rate
                                
                            if rise_rate >= rise_threshold and days_to_rise == 0:
                                days_to_rise = j
                        
                        # è®¡ç®—å•ä¸ªç‚¹çš„å¾—åˆ†
                        success = max_rise >= rise_threshold
                        
                        # ç®€åŒ–çš„å¾—åˆ†è®¡ç®—
                        if success:
                            speed_factor = max_days / max(days_to_rise, 1) if days_to_rise > 0 else 0
                            point_score = 0.6 + 0.3 * min(max_rise / 0.1, 1.0) + 0.1 * min(speed_factor, 1.0)
                        else:
                            point_score = 0.1 * min(max_rise / 0.05, 1.0)  # éƒ¨åˆ†åˆ†æ•°
                        
                        scores.append(point_score)
                    
                    score = np.mean(scores) if len(scores) > 0 else 0.0
                    
                except Exception as eval_error:
                    self.logger.warning(f"å‚æ•°è¯„ä¼°å¤±è´¥: {str(eval_error)}")
                    score = 0.0
                
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
                
                # æ—©åœæ£€æŸ¥
                if early_stopping(score):
                    self.logger.info(f"ğŸ›‘ æ—©åœè§¦å‘ï¼Œåœæ­¢ä¼˜åŒ– (è¿­ä»£: {iteration+1})")
                    break
            
            self.logger.info(f"âœ… è®­ç»ƒé›†ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³å¾—åˆ†: {best_score:.4f}")
            return best_params
            
        except Exception as e:
            self.logger.error(f"âŒ è®­ç»ƒé›†å‚æ•°ä¼˜åŒ–å¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤å‚æ•°
            return {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04),
                'max_days': self.config.get('strategy', {}).get('max_days', 20),
                'rsi_oversold_threshold': 30,
                'rsi_low_threshold': 40,
                'final_threshold': 0.5,
                'dynamic_confidence_adjustment': 0.15,
                'market_sentiment_weight': 0.15,
                'trend_strength_weight': 0.12,
                'volume_weight': 0.25,
                'price_momentum_weight': 0.20
            }
    
    def evaluate_on_test_set_only(self, strategy_module, test_data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä»…åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼°ï¼Œç»å¯¹ä¸å½±å“ä¼˜åŒ–è¿‡ç¨‹
        
        å‚æ•°:
        strategy_module: å·²ä¼˜åŒ–çš„ç­–ç•¥æ¨¡å—
        test_data: ä¸¥æ ¼ä¿æŠ¤çš„æµ‹è¯•æ•°æ®
        
        è¿”å›:
        dict: æµ‹è¯•é›†è¯„ä¼°ç»“æœ
        """
        self.logger.info("ğŸ¯ å¼€å§‹æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼°...")
        
        try:
            # éªŒè¯æµ‹è¯•é›†å®Œæ•´æ€§
            if self._test_set_locked and self._test_set_indices:
                test_indices = test_data.index.tolist()
                if test_indices != self._test_set_indices:
                    raise ValueError("âŒ æµ‹è¯•é›†æ•°æ®ä¸å®Œæ•´æˆ–è¢«ç¯¡æ”¹ï¼")
            
            # åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œå›æµ‹
            self.logger.info("ğŸ“Š åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œå›æµ‹...")
            backtest_results = strategy_module.backtest(test_data)
            evaluation = strategy_module.evaluate_strategy(backtest_results)
            
            # è¯¦ç»†ç»Ÿè®¡
            test_score = evaluation['score']
            success_rate = evaluation['success_rate']
            total_points = evaluation['total_points']
            avg_rise = evaluation['avg_rise']
            
            self.logger.info("âœ… æµ‹è¯•é›†è¯„ä¼°å®Œæˆ!")
            self.logger.info(f"ğŸ“Š æµ‹è¯•é›†æ€§èƒ½:")
            self.logger.info(f"   - ç»¼åˆå¾—åˆ†: {test_score:.4f}")
            self.logger.info(f"   - æˆåŠŸç‡: {success_rate:.2%}")
            self.logger.info(f"   - è¯†åˆ«ç‚¹æ•°: {total_points}")
            self.logger.info(f"   - å¹³å‡æ¶¨å¹…: {avg_rise:.2%}")
            self.logger.info(f"   - æµ‹è¯•æœŸé—´: {test_data.iloc[0]['date']} ~ {test_data.iloc[-1]['date']}")
            
            return {
                'success': True,
                'test_score': test_score,
                'success_rate': success_rate,
                'total_points': total_points,
                'avg_rise': avg_rise,
                'test_period': f"{test_data.iloc[0]['date']} ~ {test_data.iloc[-1]['date']}",
                'backtest_results': backtest_results,
                'evaluation': evaluation
            }
            
        except Exception as e:
            self.logger.error(f"âŒ æµ‹è¯•é›†è¯„ä¼°å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}


class EarlyStopping:
    """æ—©åœæœºåˆ¶ç±»"""
    
    def __init__(self, patience: int = 20, min_delta: float = 0.001):
        """
        åˆå§‹åŒ–æ—©åœæœºåˆ¶
        
        å‚æ•°:
        patience: è€å¿ƒå€¼ï¼Œè¿ç»­å¤šå°‘æ¬¡æ— æ”¹è¿›ååœæ­¢
        min_delta: æœ€å°æ”¹è¿›å¹…åº¦
        """
        self.patience = patience
        self.min_delta = min_delta
        self.best_score = -np.inf
        self.wait = 0
        
    def __call__(self, val_score: float) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ
        
        å‚æ•°:
        val_score: å½“å‰éªŒè¯å¾—åˆ†
        
        è¿”å›:
        bool: æ˜¯å¦åº”è¯¥åœæ­¢
        """
        if val_score > self.best_score + self.min_delta:
            self.best_score = val_score
            self.wait = 0
            return False
        else:
            self.wait += 1
            return self.wait >= self.patience

    def optimize_strategy_parameters(self, strategy_module, data: pd.DataFrame) -> Dict[str, Any]:
        """
        ä¼˜åŒ–ç­–ç•¥å‚æ•°ï¼ˆrise_thresholdå’Œmax_daysä¿æŒå›ºå®šï¼‰
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–åçš„å‚æ•°
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸš€ å¼€å§‹AIç­–ç•¥å‚æ•°ä¼˜åŒ–")
        self.logger.info("=" * 60)
        
        try:
            # 1. è·å–åŸºå‡†ç­–ç•¥çš„è¯†åˆ«ç»“æœä½œä¸ºå›ºå®šæ ‡ç­¾
            self.logger.info("ğŸ“Š é˜¶æ®µ1: è·å–åŸºå‡†ç­–ç•¥è¯†åˆ«ç»“æœ...")
            baseline_backtest = strategy_module.backtest(data)
            fixed_labels = baseline_backtest['is_low_point'].astype(int).values
            self.logger.info(f"âœ… åŸºå‡†ç­–ç•¥è¯†åˆ«ç‚¹æ•°: {np.sum(fixed_labels)}")
            
            # 2. å›ºå®šæ ¸å¿ƒå‚æ•°ï¼Œä¸å…è®¸ä¼˜åŒ–
            self.logger.info("ğŸ”§ é˜¶æ®µ2: è®¾ç½®å›ºå®šå‚æ•°...")
            fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
            fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
            
            self.logger.info(f"âœ… å›ºå®šå‚æ•°è®¾ç½®å®Œæˆ:")
            self.logger.info(f"   - rise_threshold: {fixed_rise_threshold}")
            self.logger.info(f"   - max_days: {fixed_max_days}")
            
            # 3. åŠ è½½å†å²æœ€ä¼˜å‚æ•°ï¼Œå†³å®šæ˜¯å¦è¿›è¡Œå¢é‡ä¼˜åŒ–
            self.logger.info("ğŸ“‹ é˜¶æ®µ3: æ£€æŸ¥å†å²å‚æ•°...")
            historical_best_params = self._load_best_parameters()
            
            if historical_best_params:
                self.logger.info("ğŸ”„ å‘ç°å†å²æœ€ä¼˜å‚æ•°ï¼Œå¯ç”¨å¢é‡ä¼˜åŒ–æ¨¡å¼")
                use_incremental = True
                base_params = historical_best_params
            else:
                self.logger.info("ğŸ†• æ²¡æœ‰å†å²å‚æ•°ï¼Œä½¿ç”¨å…¨å±€æœç´¢æ¨¡å¼")
                use_incremental = False
                base_params = None
            
            # 4. ä»é…ç½®æ–‡ä»¶è·å–å¯ä¼˜åŒ–å‚æ•°çš„æœç´¢èŒƒå›´
            self.logger.info("ğŸ“‹ é˜¶æ®µ4: é…ç½®å‚æ•°æœç´¢èŒƒå›´...")
            ai_config = self.config.get('ai', {})
            optimization_ranges = ai_config.get('optimization_ranges', {})
            
            # éªŒè¯é…ç½®
            if not self._validate_optimization_config(optimization_ranges):
                self.logger.error("âŒ ä¼˜åŒ–é…ç½®éªŒè¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                optimization_ranges = {}
            
            # æ ¹æ®æ˜¯å¦å¢é‡ä¼˜åŒ–é€‰æ‹©æœç´¢èŒƒå›´
            if use_incremental:
                self.logger.info("ğŸ¯ ä½¿ç”¨å¢é‡æœç´¢èŒƒå›´ï¼ˆåŸºäºå†å²æœ€ä¼˜å‚æ•°ï¼‰:")
                param_grid = self._get_incremental_search_ranges(base_params, optimization_ranges)
            else:
                self.logger.info("ğŸŒ ä½¿ç”¨å…¨å±€æœç´¢èŒƒå›´:")
                param_grid = self._build_parameter_grid(optimization_ranges)
            
            self.logger.info("âœ… å¯ä¼˜åŒ–å‚æ•°æœç´¢èŒƒå›´:")
            for param, values in param_grid.items():
                self.logger.info(f"   - {param}: {values[0]} - {values[-1]}, æ­¥é•¿: {values[1]-values[0] if len(values)>1 else 'N/A'}")
            
            # 5. è®¾ç½®åˆå§‹æœ€ä½³å‚æ•°å’Œå¾—åˆ†
            if use_incremental and base_params:
                # å¢é‡ä¼˜åŒ–ï¼šä»¥å†å²æœ€ä¼˜å‚æ•°ä¸ºèµ·ç‚¹
                best_score = self._evaluate_params_with_fixed_labels_advanced(data, fixed_labels, base_params)
                best_params = base_params.copy()
                self.logger.info(f"ğŸ¯ å†å²æœ€ä¼˜å‚æ•°ä½œä¸ºèµ·ç‚¹ï¼Œå¾—åˆ†: {best_score:.4f}")
            else:
                # å…¨å±€ä¼˜åŒ–ï¼šä»é›¶å¼€å§‹
                best_score = -1
                best_params = None
            
            total_combinations = 1
            for values in param_grid.values():
                total_combinations *= len(values)
            
            self.logger.info(f"ğŸ“ˆ æ€»æœç´¢ç»„åˆæ•°: {total_combinations:,}")
            
            # 6. åŸºäºå›ºå®šæ ‡ç­¾ä¼˜åŒ–å¯è°ƒå‚æ•°
            # ä»é…ç½®æ–‡ä»¶è·å–è¿­ä»£æ¬¡æ•°é…ç½®
            optimization_config = ai_config.get('optimization', {})
            global_iterations = optimization_config.get('global_iterations', 150)
            incremental_iterations = optimization_config.get('incremental_iterations', 100)
            enable_incremental = optimization_config.get('enable_incremental', True)
            
            # æ ¹æ®æ˜¯å¦å¢é‡ä¼˜åŒ–è°ƒæ•´è¿­ä»£æ¬¡æ•°
            if use_incremental and enable_incremental:
                max_iterations = min(incremental_iterations, total_combinations)  # å¢é‡ä¼˜åŒ–ä½¿ç”¨è¾ƒå°‘è¿­ä»£
                self.logger.info(f"ğŸ¯ å¢é‡ä¼˜åŒ–æ¨¡å¼ï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations} (é…ç½®å€¼: {incremental_iterations})")
            else:
                max_iterations = min(global_iterations, total_combinations)  # å…¨å±€ä¼˜åŒ–ä½¿ç”¨æ›´å¤šè¿­ä»£
                self.logger.info(f"ğŸŒ å…¨å±€ä¼˜åŒ–æ¨¡å¼ï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations} (é…ç½®å€¼: {global_iterations})")
            
            # é¢„ç”Ÿæˆå‚æ•°ç»„åˆä»¥æé«˜æ•ˆç‡
            self.logger.info("âš¡ é¢„ç”Ÿæˆå‚æ•°ç»„åˆ...")
            param_combinations = []
            for _ in range(max_iterations):
                params = {
                    'rise_threshold': fixed_rise_threshold,  # å›ºå®šä¸å˜
                    'max_days': fixed_max_days,              # å›ºå®šä¸å˜
                    'rsi_oversold_threshold': int(np.random.choice(param_grid['rsi_oversold_threshold'])),
                    'rsi_low_threshold': int(np.random.choice(param_grid['rsi_low_threshold'])),
                    'final_threshold': np.random.choice(param_grid['final_threshold']),
                    # æ–°å¢AIä¼˜åŒ–å‚æ•°
                    'dynamic_confidence_adjustment': np.random.choice(param_grid['dynamic_confidence_adjustment']),
                    'market_sentiment_weight': np.random.choice(param_grid['market_sentiment_weight']),
                    'trend_strength_weight': np.random.choice(param_grid['trend_strength_weight']),
                    # æ–°å¢2ä¸ªé«˜é‡è¦åº¦å‚æ•°
                    'volume_weight': np.random.choice(param_grid['volume_weight']),
                    'price_momentum_weight': np.random.choice(param_grid['price_momentum_weight'])
                }
                param_combinations.append(params)
            
            # è®°å½•ä¼˜åŒ–å¼€å§‹æ—¶é—´
            import time
            start_time = time.time()
            
            self.logger.info("ğŸ”„ é˜¶æ®µ5: å¼€å§‹å‚æ•°ä¼˜åŒ–è¿­ä»£...")
            self.logger.info("-" * 50)
            
            # è®°å½•æ”¹è¿›æ¬¡æ•°
            improvement_count = 0
            
            for iteration in range(max_iterations):
                # è®¡ç®—è¿›åº¦
                progress = (iteration + 1) / max_iterations * 100
                
                # æ¯5æ¬¡è¿­ä»£æˆ–ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶æ‰“å°è¿›åº¦
                if iteration == 0 or (iteration + 1) % 5 == 0:
                    elapsed_time = time.time() - start_time
                    avg_time_per_iter = elapsed_time / (iteration + 1)
                    remaining_iter = max_iterations - (iteration + 1)
                    estimated_remaining_time = remaining_iter * avg_time_per_iter
                    
                    self.logger.info(f"ğŸ“Š è¿›åº¦: {progress:.1f}% ({iteration+1}/{max_iterations})")
                    self.logger.info(f"â±ï¸  å·²ç”¨æ—¶é—´: {elapsed_time:.1f}s, é¢„è®¡å‰©ä½™: {estimated_remaining_time:.1f}s")
                    self.logger.info(f"ğŸ† å½“å‰æœ€ä½³å¾—åˆ†: {best_score:.4f}")
                    if best_params:
                        self.logger.info(f"ğŸ¯ å½“å‰æœ€ä½³å‚æ•°:")
                        self.logger.info(f"   - RSIè¶…å–é˜ˆå€¼: {best_params['rsi_oversold_threshold']}")
                        self.logger.info(f"   - RSIä½å€¼é˜ˆå€¼: {best_params['rsi_low_threshold']}")
                        self.logger.info(f"   - æœ€ç»ˆç½®ä¿¡åº¦: {best_params['final_threshold']:.3f}")
                        self.logger.info(f"   - åŠ¨æ€è°ƒæ•´ç³»æ•°: {best_params['dynamic_confidence_adjustment']:.3f}")
                        self.logger.info(f"   - å¸‚åœºæƒ…ç»ªæƒé‡: {best_params['market_sentiment_weight']:.3f}")
                        self.logger.info(f"   - è¶‹åŠ¿å¼ºåº¦æƒé‡: {best_params['trend_strength_weight']:.3f}")
                        self.logger.info(f"   - æˆäº¤é‡æƒé‡: {best_params['volume_weight']:.3f}")
                        self.logger.info(f"   - ä»·æ ¼åŠ¨é‡æƒé‡: {best_params['price_momentum_weight']:.3f}")
                    self.logger.info("-" * 30)
                
                # ä½¿ç”¨é¢„ç”Ÿæˆçš„å‚æ•°ç»„åˆ
                params = param_combinations[iteration]
                
                # ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°å‚æ•°
                score = self._evaluate_params_with_fixed_labels_advanced(
                    data, fixed_labels, params
                )
                
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
                    improvement_count += 1
                    
                    # è®¡ç®—æ”¹è¿›å¹…åº¦
                    improvement = score - best_score if best_score != -1 else 0
                    
                    self.logger.info(f"ğŸ‰ å‘ç°æ›´å¥½çš„å‚æ•°ç»„åˆ (ç¬¬{improvement_count}æ¬¡æ”¹è¿›, è¿­ä»£{iteration+1}):")
                    self.logger.info(f"   ğŸ“ˆ å¾—åˆ†æå‡: {improvement:.4f} â†’ {best_score:.4f}")
                    self.logger.info(f"   ğŸ”§ å‚æ•°è¯¦æƒ…:")
                    self.logger.info(f"      - RSIè¶…å–é˜ˆå€¼: {best_params['rsi_oversold_threshold']}")
                    self.logger.info(f"      - RSIä½å€¼é˜ˆå€¼: {best_params['rsi_low_threshold']}")
                    self.logger.info(f"      - æœ€ç»ˆç½®ä¿¡åº¦: {best_params['final_threshold']:.3f}")
                    self.logger.info(f"      - åŠ¨æ€è°ƒæ•´ç³»æ•°: {best_params['dynamic_confidence_adjustment']:.3f}")
                    self.logger.info(f"      - å¸‚åœºæƒ…ç»ªæƒé‡: {best_params['market_sentiment_weight']:.3f}")
                    self.logger.info(f"      - è¶‹åŠ¿å¼ºåº¦æƒé‡: {best_params['trend_strength_weight']:.3f}")
                    self.logger.info(f"      - æˆäº¤é‡æƒé‡: {best_params['volume_weight']:.3f}")
                    self.logger.info(f"      - ä»·æ ¼åŠ¨é‡æƒé‡: {best_params['price_momentum_weight']:.3f}")
                    self.logger.info("-" * 50)
            
            # ä¼˜åŒ–å®Œæˆç»Ÿè®¡
            total_time = time.time() - start_time
            self.logger.info("=" * 60)
            self.logger.info("ğŸ¯ AIç­–ç•¥å‚æ•°ä¼˜åŒ–å®Œæˆ!")
            self.logger.info("=" * 60)
            self.logger.info(f"ğŸ“Š ä¼˜åŒ–ç»Ÿè®¡:")
            self.logger.info(f"   - ä¼˜åŒ–æ¨¡å¼: {'å¢é‡ä¼˜åŒ–' if use_incremental else 'å…¨å±€ä¼˜åŒ–'}")
            self.logger.info(f"   - æ€»è¿­ä»£æ¬¡æ•°: {max_iterations}")
            self.logger.info(f"   - æ€»è€—æ—¶: {total_time:.1f}ç§’")
            self.logger.info(f"   - å¹³å‡æ¯æ¬¡è¿­ä»£: {total_time/max_iterations:.3f}ç§’")
            self.logger.info(f"   - æ”¹è¿›æ¬¡æ•°: {improvement_count}")
            self.logger.info(f"   - æœ€ç»ˆæœ€ä½³å¾—åˆ†: {best_score:.4f}")
            self.logger.info("")
            self.logger.info(f"ğŸ† æœ€ç»ˆæœ€ä½³å‚æ•°:")
            for key, value in best_params.items():
                if isinstance(value, float):
                    self.logger.info(f"   - {key}: {value:.4f}")
                else:
                    self.logger.info(f"   - {key}: {value}")
            
            # ä¿å­˜ä¼˜åŒ–ç»“æœåˆ°å†å²è®°å½•
            self.logger.info("ğŸ’¾ ä¿å­˜ä¼˜åŒ–ç»“æœ...")
            self._save_parameter_history(best_params, best_score)
            self._save_best_parameters(best_params, best_score)
            
            return best_params
            
        except Exception as e:
            self.logger.error("AIç­–ç•¥å‚æ•°ä¼˜åŒ–å¤±è´¥: %s", str(e))
            self.logger.error("é”™è¯¯è¯¦æƒ…:", exc_info=True)
            
            # å°è¯•è¿”å›é»˜è®¤å‚æ•°
            try:
                default_params = {
                    'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04),
                    'max_days': self.config.get('strategy', {}).get('max_days', 20),
                    'rsi_oversold_threshold': 30,
                    'rsi_low_threshold': 40,
                    'final_threshold': 0.5,
                    'dynamic_confidence_adjustment': 0.15,
                    'market_sentiment_weight': 0.15,
                    'trend_strength_weight': 0.12,
                    'volume_weight': 0.25,
                    'price_momentum_weight': 0.20
                }
                self.logger.warning("è¿”å›é»˜è®¤å‚æ•°ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
                return default_params
            except Exception as fallback_error:
                self.logger.error("å¤‡é€‰æ–¹æ¡ˆä¹Ÿå¤±è´¥: %s", str(fallback_error))
                return {}
    
    def _evaluate_params_with_fixed_labels(self, data: pd.DataFrame, fixed_labels: np.ndarray, 
                                         rise_threshold: float, max_days: int) -> float:
        """
        ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°ç­–ç•¥å‚æ•°
        
        å‚æ•°:
        data: å†å²æ•°æ®
        fixed_labels: å›ºå®šçš„æ ‡ç­¾ï¼ˆç›¸å¯¹ä½ç‚¹æ ‡è¯†ï¼‰
        rise_threshold: æ¶¨å¹…é˜ˆå€¼
        max_days: æœ€å¤§å¤©æ•°
        
        è¿”å›:
        float: ç­–ç•¥å¾—åˆ†
        """
        try:
            # 1. è®¡ç®—æ¯ä¸ªè¯†åˆ«ç‚¹çš„æœªæ¥è¡¨ç°
            scores = []
            low_point_indices = np.where(fixed_labels == 1)[0]
            
            for idx in low_point_indices:
                if idx >= len(data) - max_days:
                    continue
                    
                current_price = data.iloc[idx]['close']
                max_rise = 0.0
                days_to_rise = 0
                
                # è®¡ç®—æœªæ¥max_dayså†…çš„æœ€å¤§æ¶¨å¹…
                for j in range(1, max_days + 1):
                    if idx + j >= len(data):
                        break
                    future_price = data.iloc[idx + j]['close']
                    rise_rate = (future_price - current_price) / current_price
                    
                    if rise_rate > max_rise:
                        max_rise = rise_rate
                        
                    if rise_rate >= rise_threshold and days_to_rise == 0:
                        days_to_rise = j
                
                # è®¡ç®—å•ä¸ªç‚¹çš„å¾—åˆ†
                success = max_rise >= rise_threshold
                point_score = self._calculate_point_score(success, max_rise, days_to_rise, max_days)
                scores.append(point_score)
            
            # 2. è®¡ç®—æ€»ä½“å¾—åˆ†
            if len(scores) == 0:
                return 0.0
                
            return np.mean(scores)
            
        except Exception as e:
            self.logger.error("è¯„ä¼°å‚æ•°å¤±è´¥: %s", str(e))
            return 0.0
    
    def _calculate_point_score(self, success: bool, max_rise: float, days_to_rise: int, max_days: int) -> float:
        """
        è®¡ç®—å•ä¸ªè¯†åˆ«ç‚¹çš„å¾—åˆ†
        
        å‚æ•°:
        success: æ˜¯å¦æˆåŠŸè¾¾åˆ°ç›®æ ‡æ¶¨å¹…
        max_rise: æœ€å¤§æ¶¨å¹…
        days_to_rise: è¾¾åˆ°ç›®æ ‡æ¶¨å¹…çš„å¤©æ•°
        max_days: æœ€å¤§è§‚å¯Ÿå¤©æ•°
        
        è¿”å›:
        float: å•ä¸ªç‚¹å¾—åˆ†
        """
        # ä»é…ç½®æ–‡ä»¶è·å–è¯„åˆ†å‚æ•°
        ai_config = self.config.get('ai', {})
        scoring_config = ai_config.get('scoring', {})
        
        # æˆåŠŸç‡æƒé‡ï¼š40%
        success_weight = scoring_config.get('success_weight', 0.4)
        success_score = 1.0 if success else 0.0
        
        # æ¶¨å¹…æƒé‡ï¼š30%ï¼ˆç›¸å¯¹äºåŸºå‡†æ¶¨å¹…ï¼‰
        rise_weight = scoring_config.get('rise_weight', 0.3)
        rise_benchmark = scoring_config.get('rise_benchmark', 0.1)  # 10%åŸºå‡†
        rise_score = min(max_rise / rise_benchmark, 1.0)
        
        # é€Ÿåº¦æƒé‡ï¼š20%ï¼ˆå¤©æ•°è¶Šå°‘è¶Šå¥½ï¼‰
        speed_weight = scoring_config.get('speed_weight', 0.2)
        if days_to_rise > 0:
            speed_score = min(max_days / days_to_rise, 1.0)
        else:
            speed_score = 0.0
        
        # é£é™©è°ƒæ•´ï¼š10%ï¼ˆé¿å…è¿‡åº¦å†’é™©ï¼‰
        risk_weight = scoring_config.get('risk_weight', 0.1)
        risk_benchmark = scoring_config.get('risk_benchmark', 0.2)  # 20%é£é™©é˜ˆå€¼
        risk_score = min(max_rise / risk_benchmark, 1.0)  # è¶…è¿‡é£é™©é˜ˆå€¼çš„æ¶¨å¹…ç»™äºˆé£é™©æƒ©ç½š
        
        # ç»¼åˆå¾—åˆ†
        total_score = (
            success_score * success_weight +
            rise_score * rise_weight +
            speed_score * speed_weight +
            risk_score * risk_weight
        )
        
        return total_score
        
    def prepare_features(self, data: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """
        å‡†å¤‡æœºå™¨å­¦ä¹ ç‰¹å¾
        
        å‚æ•°:
        data: å†å²æ•°æ®
        
        è¿”å›:
        tuple: (ç‰¹å¾çŸ©é˜µ, ç‰¹å¾åç§°åˆ—è¡¨)
        """
        self.logger.info("å‡†å¤‡æœºå™¨å­¦ä¹ ç‰¹å¾")
        
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_columns = [
            'ma5', 'ma10', 'ma20', 'ma60',
            'rsi', 'macd', 'signal', 'hist',
            'bb_upper', 'bb_lower',
            'dist_ma5', 'dist_ma10', 'dist_ma20',
            'volume_change', 'volatility',
            'price_change', 'price_change_5d', 'price_change_10d'
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„åˆ—
        available_columns = [col for col in feature_columns if col in data.columns]
        
        if len(available_columns) == 0:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾åˆ—")
            return np.array([]), []
            
        # æå–ç‰¹å¾
        features = data[available_columns].fillna(0).values
        
        self.logger.info("ç‰¹å¾å‡†å¤‡å®Œæˆï¼Œç‰¹å¾æ•°é‡: %d, æ ·æœ¬æ•°é‡: %d", 
                        len(available_columns), len(features))
        
        return features, available_columns
        
    def prepare_labels(self, data: pd.DataFrame, strategy_module) -> np.ndarray:
        """
        å‡†å¤‡æœºå™¨å­¦ä¹ æ ‡ç­¾
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        
        è¿”å›:
        numpy.ndarray: æ ‡ç­¾æ•°ç»„
        """
        self.logger.info("å‡†å¤‡æœºå™¨å­¦ä¹ æ ‡ç­¾")
        
        # è¿è¡Œå›æµ‹è·å–çœŸå®çš„ç›¸å¯¹ä½ç‚¹æ ‡ç­¾
        backtest_results = strategy_module.backtest(data)
        labels = backtest_results['is_low_point'].astype(int).values
        
        positive_count = np.sum(labels)
        total_count = len(labels)
        
        self.logger.info("æ ‡ç­¾å‡†å¤‡å®Œæˆï¼Œæ­£æ ·æœ¬: %d, æ€»æ ·æœ¬: %d, æ­£æ ·æœ¬æ¯”ä¾‹: %.2f%%", 
                        positive_count, total_count, positive_count / total_count * 100)
        
        return labels
        
    def train_model(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        åªè´Ÿè´£è®­ç»ƒæ¨¡å‹å¹¶ä¿å­˜ï¼Œä¸åšè¯„ä¼°ã€‚
        """
        self.logger.info("å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼ˆä¸åšéªŒè¯è¯„ä¼°ï¼‰")
        try:
            features, feature_names = self.prepare_features(data)
            labels = self.prepare_labels(data, strategy_module)
            if len(features) == 0 or len(labels) == 0:
                self.logger.error("ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
                return {'success': False, 'error': 'ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©º'}
            min_length = min(len(features), len(labels))
            features = features[:min_length]
            labels = labels[:min_length]
            aligned_data = data.iloc[:min_length].copy()
            split_ratio = self.config.get("ai", {}).get("train_test_split_ratio", 0.8)
            split_index = int(len(features) * split_ratio)
            X_train = features[:split_index]
            y_train = labels[:split_index]
            train_dates = aligned_data["date"].iloc[:split_index]
            sample_weights = self._calculate_sample_weights(train_dates)
            if self.model_type == 'machine_learning':
                model = Pipeline([
                    ('scaler', StandardScaler()),
                    ('classifier', RandomForestClassifier(
                        n_estimators=100,
                        max_depth=10,
                        min_samples_split=5,
                        min_samples_leaf=2,
                        random_state=42,
                        class_weight='balanced'
                    ))
                ])
            else:
                model = Pipeline([
                    ('scaler', StandardScaler()),
                    ('classifier', RandomForestClassifier(
                        n_estimators=100,
                        random_state=42,
                        class_weight='balanced'
                    ))
                ])
            self.logger.info(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, sample_weights shape: {sample_weights.shape}")
            model.fit(X_train, y_train, classifier__sample_weight=sample_weights)
            self.model = model
            self.feature_names = feature_names
            self._save_model()
            self.logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")
            return {'success': True, 'train_samples': len(X_train), 'feature_count': len(feature_names)}
        except Exception as e:
            self.logger.error("è®­ç»ƒæ¨¡å‹å¤±è´¥: %s", str(e))
            return {'success': False, 'error': str(e)}

    def validate_model(self, data: pd.DataFrame, strategy_module) -> Dict[str, Any]:
        """
        åªè´Ÿè´£è¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°ã€‚
        """
        self.logger.info("å¼€å§‹éªŒè¯æ¨¡å‹ï¼ˆåªåšè¯„ä¼°ï¼Œä¸è®­ç»ƒï¼‰")
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    return {'success': False, 'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'}
            features, feature_names = self.prepare_features(data)
            labels = self.prepare_labels(data, strategy_module)
            if len(features) == 0 or len(labels) == 0:
                self.logger.error("ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œæ— æ³•éªŒè¯æ¨¡å‹")
                return {'success': False, 'error': 'ç‰¹å¾æˆ–æ ‡ç­¾ä¸ºç©º'}
            min_length = min(len(features), len(labels))
            features = features[:min_length]
            labels = labels[:min_length]
            split_ratio = self.config.get("ai", {}).get("train_test_split_ratio", 0.8)
            split_index = int(len(features) * split_ratio)
            X_test = features[split_index:]
            y_test = labels[split_index:]
            if len(X_test) == 0 or len(y_test) == 0:
                self.logger.warning("éªŒè¯é›†ä¸ºç©ºï¼Œæ— æ³•è¯„ä¼°æ¨¡å‹")
                return {'success': False, 'error': 'éªŒè¯é›†ä¸ºç©º'}
            y_pred = self.model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, zero_division=0)
            recall = recall_score(y_test, y_pred, zero_division=0)
            f1 = f1_score(y_test, y_pred, zero_division=0)
            positive_count_test = np.sum(y_test)
            self.logger.info("æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°å®Œæˆï¼Œå‡†ç¡®ç‡: %.4f, ç²¾ç¡®ç‡: %.4f, å¬å›ç‡: %.4f, F1: %.4f", accuracy, precision, recall, f1)
            return {
                'success': True,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'test_samples': len(X_test),
                'positive_samples_test': positive_count_test
            }
        except Exception as e:
            self.logger.error("éªŒè¯æ¨¡å‹å¤±è´¥: %s", str(e))
            return {'success': False, 'error': str(e)}

    def predict_low_point(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        é¢„æµ‹ç›¸å¯¹ä½ç‚¹
        
        å‚æ•°:
        data: å¸‚åœºæ•°æ®
        
        è¿”å›:
        dict: é¢„æµ‹ç»“æœ
        """
        self.logger.info("é¢„æµ‹ç›¸å¯¹ä½ç‚¹")
        
        try:
            if self.model is None:
                self.logger.warning("æ¨¡å‹æœªè®­ç»ƒï¼Œå°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹")
                if not self._load_model():
                    return {
                        'is_low_point': False,
                        'confidence': 0.0,
                        'error': 'æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹'
                    }
                    
            if len(data) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'error': 'æ•°æ®ä¸ºç©º'
                }
                
            # å‡†å¤‡ç‰¹å¾
            features, _ = self.prepare_features(data)
            
            if len(features) == 0:
                return {
                    'is_low_point': False,
                    'confidence': 0.0,
                    'error': 'æ— æ³•æå–ç‰¹å¾'
                }
                
            # ä½¿ç”¨æœ€æ–°æ•°æ®è¿›è¡Œé¢„æµ‹
            latest_features = features[-1:].reshape(1, -1)
            
            # é¢„æµ‹
            prediction = self.model.predict(latest_features)[0]
            prediction_proba = self.model.predict_proba(latest_features)[0]
            
            # è·å–ç½®ä¿¡åº¦
            confidence = prediction_proba[1] if len(prediction_proba) > 1 else 0.0
            
            result = {
                'is_low_point': bool(prediction),
                'confidence': float(confidence),
                'prediction_proba': prediction_proba.tolist()
            }
            
            self.logger.info("----------------------------------------------------");
            self.logger.info("AIé¢„æµ‹ç»“æœ: \033[1m%s\033[0m, ç½®ä¿¡åº¦: \033[1m%.4f\033[0m", 
                           "ç›¸å¯¹ä½ç‚¹" if prediction else "éç›¸å¯¹ä½ç‚¹", confidence)
            self.logger.info("----------------------------------------------------");
            return result
            
        except Exception as e:
            self.logger.error("é¢„æµ‹ç›¸å¯¹ä½ç‚¹å¤±è´¥: %s", str(e))
            return {
                'is_low_point': False,
                'confidence': 0.0,
                'error': str(e)
            }
            
    def get_feature_importance(self) -> Optional[Dict[str, float]]:
        """
        è·å–ç‰¹å¾é‡è¦æ€§
        
        è¿”å›:
        dict: ç‰¹å¾é‡è¦æ€§ï¼Œå¦‚æœæ¨¡å‹æœªè®­ç»ƒè¿”å›None
        """
        if self.model is None or self.feature_names is None:
            return None
            
        try:
            # è·å–åˆ†ç±»å™¨
            classifier = self.model.named_steps['classifier']
            
            if hasattr(classifier, 'feature_importances_'):
                importances = classifier.feature_importances_
                feature_importance = dict(zip(self.feature_names, importances))
                
                # æŒ‰é‡è¦æ€§æ’åº
                sorted_importance = dict(sorted(feature_importance.items(), 
                                              key=lambda x: x[1], reverse=True))
                
                self.logger.info("ç‰¹å¾é‡è¦æ€§è·å–æˆåŠŸ")
                return sorted_importance
            else:
                self.logger.warning("æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§")
                return None
                
        except Exception as e:
            self.logger.error("è·å–ç‰¹å¾é‡è¦æ€§å¤±è´¥: %s", str(e))
            return None
            
    def _save_model(self) -> bool:
        """
        ä¿å­˜æ¨¡å‹
        
        è¿”å›:
        bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ä¿å­˜æ¨¡å‹
            model_path = os.path.join(self.models_dir, f'model_{timestamp}.pkl')
            with open(model_path, 'wb') as f:
                pickle.dump(self.model, f)
                
            # ä¿å­˜ç‰¹å¾åç§°
            features_path = os.path.join(self.models_dir, f'features_{timestamp}.json')
            with open(features_path, 'w') as f:
                json.dump(self.feature_names, f)
                
            # ä¿å­˜æœ€æ–°æ¨¡å‹çš„è·¯å¾„
            latest_path = os.path.join(self.models_dir, 'latest_model.txt')
            with open(latest_path, 'w') as f:
                f.write(f'{model_path}\n{features_path}')
                
            self.logger.info("æ¨¡å‹ä¿å­˜æˆåŠŸ: %s", model_path)
            return True
            
        except Exception as e:
            self.logger.error("ä¿å­˜æ¨¡å‹å¤±è´¥: %s", str(e))
            return False
            
    def _load_model(self) -> bool:
        """
        åŠ è½½æ¨¡å‹
        
        è¿”å›:
        bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            latest_path = os.path.join(self.models_dir, 'latest_model.txt')
            
            if not os.path.exists(latest_path):
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„æ¨¡å‹")
                return False
                
            # è¯»å–æœ€æ–°æ¨¡å‹è·¯å¾„
            with open(latest_path, 'r') as f:
                lines = f.read().strip().split('\n')
                if len(lines) < 2:
                    self.logger.error("æ¨¡å‹è·¯å¾„æ–‡ä»¶æ ¼å¼é”™è¯¯")
                    return False
                    
                model_path = lines[0]
                features_path = lines[1]
                
            # åŠ è½½æ¨¡å‹
            with open(model_path, 'rb') as f:
                self.model = pickle.load(f)
                
            # åŠ è½½ç‰¹å¾åç§°
            with open(features_path, 'r') as f:
                self.feature_names = json.load(f)
                
            self.logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ: %s", model_path)
            return True
            
        except Exception as e:
            self.logger.error("åŠ è½½æ¨¡å‹å¤±è´¥: %s", str(e))
            return False
            
    def run_genetic_algorithm(self, evaluate_func, population_size: int = 20, 
                            generations: int = 10) -> Dict[str, Any]:
        """
        è¿è¡Œé—ä¼ ç®—æ³•ä¼˜åŒ–ï¼ˆrise_thresholdå’Œmax_daysä¿æŒå›ºå®šï¼‰
        
        å‚æ•°:
        evaluate_func: è¯„ä¼°å‡½æ•°
        population_size: ç§ç¾¤å¤§å°
        generations: è¿­ä»£ä»£æ•°
        
        è¿”å›:
        dict: æœ€ä¼˜å‚æ•°
        """
        self.logger.info("è¿è¡Œé—ä¼ ç®—æ³•ä¼˜åŒ–ï¼ˆrise_thresholdå’Œmax_daysä¿æŒå›ºå®šï¼‰ï¼Œç§ç¾¤å¤§å°: %d, è¿­ä»£ä»£æ•°: %d", 
                        population_size, generations)
        
        try:
            # å›ºå®šæ ¸å¿ƒå‚æ•°ï¼Œä¸å…è®¸ä¼˜åŒ–
            fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
            fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
            
            self.logger.info(f"å›ºå®šå‚æ•° - rise_threshold: {fixed_rise_threshold}, max_days: {fixed_max_days}")
            
            # ç”±äºæ ¸å¿ƒå‚æ•°å·²å›ºå®šï¼Œé—ä¼ ç®—æ³•ä¸éœ€è¦è¿›è¡Œ
            # ç›´æ¥è¿”å›å›ºå®šå‚æ•°
            self.logger.info("æ ¸å¿ƒå‚æ•°å·²å›ºå®šï¼Œè·³è¿‡é—ä¼ ç®—æ³•ä¼˜åŒ–")
            
            return {
                'rise_threshold': fixed_rise_threshold,
                'max_days': fixed_max_days
            }
            
        except Exception as e:
            self.logger.error("é—ä¼ ç®—æ³•ä¼˜åŒ–å¤±è´¥: %s", str(e))
            return {
                'rise_threshold': self.config.get('strategy', {}).get('rise_threshold', 0.04), 
                'max_days': self.config.get('strategy', {}).get('max_days', 20)
            }
            
    def _genetic_operations(self, population: List[Dict], scores: List[float]) -> List[Dict]:
        """
        é—ä¼ ç®—æ³•æ“ä½œï¼ˆé€‰æ‹©ã€äº¤å‰ã€å˜å¼‚ï¼‰
        
        å‚æ•°:
        population: å½“å‰ç§ç¾¤
        scores: é€‚åº”åº¦å¾—åˆ†
        
        è¿”å›:
        list: æ–°ç§ç¾¤
        """
        # é€‰æ‹©ï¼ˆè½®ç›˜èµŒé€‰æ‹©ï¼‰
        total_score = sum(scores)
        if total_score <= 0:
            # å¦‚æœæ‰€æœ‰å¾—åˆ†éƒ½æ˜¯è´Ÿæ•°æˆ–é›¶ï¼Œéšæœºé€‰æ‹©
            selected = np.random.choice(len(population), size=len(population), replace=True)
        else:
            probabilities = [score / total_score for score in scores]
            selected = np.random.choice(len(population), size=len(population), 
                                      replace=True, p=probabilities)
            
        new_population = []
        
        for i in range(0, len(population), 2):
            parent1 = population[selected[i]]
            parent2 = population[selected[min(i + 1, len(population) - 1)]]
            
            # äº¤å‰
            child1, child2 = self._crossover(parent1, parent2)
            
            # å˜å¼‚
            child1 = self._mutate(child1)
            child2 = self._mutate(child2)
            
            new_population.extend([child1, child2])
            
        return new_population[:len(population)]
        
    def _crossover(self, parent1: Dict, parent2: Dict) -> Tuple[Dict, Dict]:
        """
        äº¤å‰æ“ä½œï¼ˆrise_thresholdå’Œmax_daysä¿æŒå›ºå®šï¼‰
        
        å‚æ•°:
        parent1: çˆ¶ä»£1
        parent2: çˆ¶ä»£2
        
        è¿”å›:
        tuple: (å­ä»£1, å­ä»£2)
        """
        # å›ºå®šæ ¸å¿ƒå‚æ•°
        fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
        fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
        
        child1 = {
            'rise_threshold': fixed_rise_threshold,  # å›ºå®šä¸å˜
            'max_days': fixed_max_days              # å›ºå®šä¸å˜
        }
        
        child2 = {
            'rise_threshold': fixed_rise_threshold,  # å›ºå®šä¸å˜
            'max_days': fixed_max_days              # å›ºå®šä¸å˜
        }
        
        return child1, child2
        
    def _mutate(self, individual: Dict, mutation_rate: float = 0.1) -> Dict:
        """
        å˜å¼‚æ“ä½œï¼ˆrise_thresholdå’Œmax_daysä¿æŒå›ºå®šï¼‰
        
        å‚æ•°:
        individual: ä¸ªä½“
        mutation_rate: å˜å¼‚ç‡
        
        è¿”å›:
        dict: å˜å¼‚åçš„ä¸ªä½“
        """
        mutated = individual.copy()
        
        # å›ºå®šæ ¸å¿ƒå‚æ•°ï¼Œä¸å…è®¸å˜å¼‚
        fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
        fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
        
        # ç¡®ä¿æ ¸å¿ƒå‚æ•°ä¿æŒå›ºå®š
        mutated['rise_threshold'] = fixed_rise_threshold
        mutated['max_days'] = fixed_max_days
            
        return mutated

    def _calculate_sample_weights(self, dates: pd.Series) -> np.ndarray:
        """
        æ ¹æ®æ•°æ®æ—¥æœŸè®¡ç®—æ ·æœ¬æƒé‡ï¼Œè¶Šè¿‘çš„æ•°æ®æƒé‡è¶Šé«˜ã€‚
        æƒé‡è¡°å‡æ¨¡å‹ï¼šV(t) = Vâ‚€ Ã— e^(-Î»t)
        å…¶ä¸­Î»æ˜¯è¡°å‡ç³»æ•°ï¼Œæ ¹æ®åˆ†ææŠ¥å‘Šï¼ŒÎ»çº¦ä¸º0.3-0.5ã€‚
        è¿™é‡Œæˆ‘ä»¬å–Î»=0.4ï¼Œå¹¶æ ¹æ®æ—¶é—´å·®è®¡ç®—æƒé‡ã€‚
        
        å‚æ•°:
        dates: è®­ç»ƒé›†æ•°æ®çš„æ—¥æœŸåºåˆ—
        
        è¿”å›:
        numpy.ndarray: æ ·æœ¬æƒé‡æ•°ç»„
        """
        self.logger.info("è®¡ç®—æ ·æœ¬æƒé‡")
        
        weights = np.ones(len(dates))
        if len(dates) == 0: # Handle empty dates series
            return weights

        latest_date = dates.max()
        
        for i, date in enumerate(dates):
            time_diff = (latest_date - date).days / 365.25  # å¹´ä¸ºå•ä½
            # è¡°å‡ç³»æ•°Î»ï¼Œå¯ä»¥æ ¹æ®configé…ç½®
            decay_rate = self.config.get("ai", {}).get("data_decay_rate", 0.4)
            weight = np.exp(-decay_rate * time_diff)
            weights[i] = weight
            
        # å½’ä¸€åŒ–æƒé‡ï¼Œä½¿å…¶å’Œä¸º1ï¼Œæˆ–è€…ä¿æŒåŸå§‹æ¯”ä¾‹
        # è¿™é‡Œé€‰æ‹©ä¿æŒåŸå§‹æ¯”ä¾‹ï¼Œå› ä¸ºRandomForestClassifierçš„sample_weightå‚æ•°æ˜¯ä¹˜æ³•å…³ç³»
        # ä¹Ÿå¯ä»¥é€‰æ‹©å½’ä¸€åŒ–åˆ°æŸä¸ªèŒƒå›´ï¼Œä¾‹å¦‚0-1
        
        self.logger.info("æ ·æœ¬æƒé‡è®¡ç®—å®Œæˆï¼Œæœ€å¤§æƒé‡: %.4f, æœ€å°æƒé‡: %.4f", 
                        np.max(weights), np.min(weights))
        
        return weights

    def optimize_strategy_parameters_advanced(self, strategy_module, data: pd.DataFrame) -> Dict[str, Any]:
        """
        é«˜çº§ç­–ç•¥å‚æ•°ä¼˜åŒ– - ä½¿ç”¨å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆrise_thresholdä¿æŒå›ºå®šï¼‰
        
        å‚æ•°:
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–åçš„å‚æ•°
        """
        self.logger.info("å¼€å§‹é«˜çº§ç­–ç•¥å‚æ•°ä¼˜åŒ–ï¼ˆrise_thresholdä¿æŒå›ºå®šï¼‰")
        
        try:
            # å›ºå®šæ ¸å¿ƒå‚æ•°ï¼Œä¸å…è®¸ä¼˜åŒ–
            fixed_rise_threshold = self.config.get('strategy', {}).get('rise_threshold', 0.04)
            fixed_max_days = self.config.get('strategy', {}).get('max_days', 20)
            
            self.logger.info(f"å›ºå®šå‚æ•° - rise_threshold: {fixed_rise_threshold}, max_days: {fixed_max_days}")
            
            # ç”±äºrise_thresholdå’Œmax_dayséƒ½æ˜¯å›ºå®šçš„ï¼Œé«˜çº§ä¼˜åŒ–å®é™…ä¸Šä¸éœ€è¦è¿›è¡Œ
            # ç›´æ¥è¿”å›å›ºå®šå‚æ•°ï¼Œåªä¼˜åŒ–å…¶ä»–å‚æ•°
            self.logger.info("æ ¸å¿ƒå‚æ•°å·²å›ºå®šï¼Œè·³è¿‡é«˜çº§ä¼˜åŒ–ï¼Œä½¿ç”¨åŸºç¡€ä¼˜åŒ–æ–¹æ³•")
            return self.optimize_strategy_parameters(strategy_module, data)
                
        except Exception as e:
            self.logger.error("é«˜çº§ä¼˜åŒ–å¤±è´¥: %s", str(e))
            return self.optimize_strategy_parameters(strategy_module, data)
    
    def time_series_cv_evaluation(self, data: pd.DataFrame, strategy_module) -> float:
        """
        æ—¶é—´åºåˆ—äº¤å‰éªŒè¯è¯„ä¼°
        
        å‚æ•°:
        data: å†å²æ•°æ®
        strategy_module: ç­–ç•¥æ¨¡å—å®ä¾‹
        
        è¿”å›:
        float: å¹³å‡å¾—åˆ†
        """
        self.logger.info("ğŸ”„ å¼€å§‹æ—¶é—´åºåˆ—äº¤å‰éªŒè¯è¯„ä¼°")
        
        try:
            total_score = 0
            cv_folds = 5
            fold_scores = []
            
            self.logger.info(f"ğŸ“Š å°†æ•°æ®åˆ†ä¸º {cv_folds} æŠ˜è¿›è¡ŒéªŒè¯...")
            
            # è®°å½•å¼€å§‹æ—¶é—´
            import time
            cv_start_time = time.time()
            
            for i in range(cv_folds):
                fold_start_time = time.time()
                fold_progress = (i + 1) / cv_folds * 100
                
                self.logger.info(f"ğŸ”„ ç¬¬{i+1}/{cv_folds}æŠ˜ ({fold_progress:.1f}%) - å¼€å§‹å¤„ç†...")
                
                # æŒ‰æ—¶é—´åˆ†å‰²æ•°æ®
                split_point = int(len(data) * (i + 1) / cv_folds)
                train_data = data.iloc[:split_point]
                test_data = data.iloc[split_point:min(split_point + 100, len(data))]  # æµ‹è¯•çª—å£
                
                if len(test_data) < 20:  # æµ‹è¯•æ•°æ®å¤ªå°‘ï¼Œè·³è¿‡
                    self.logger.info(f"   â­ï¸ ç¬¬{i+1}æŠ˜ï¼šæµ‹è¯•æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                    continue
                
                self.logger.info(f"   ğŸ“‹ æ•°æ®åˆ†å‰²å®Œæˆï¼šè®­ç»ƒæ•°æ® {len(train_data)} æ¡ï¼Œæµ‹è¯•æ•°æ® {len(test_data)} æ¡")
                
                # åœ¨è®­ç»ƒæ•°æ®ä¸Šä¼˜åŒ–ç­–ç•¥å‚æ•°
                self.logger.info(f"   ğŸ”§ ç¬¬{i+1}æŠ˜ï¼šå¼€å§‹å‚æ•°ä¼˜åŒ–...")
                temp_strategy = StrategyModule(self.config)
                optimized_params = self.optimize_strategy_parameters(temp_strategy, train_data)
                temp_strategy.update_params(optimized_params)
                self.logger.info(f"   âœ… ç¬¬{i+1}æŠ˜ï¼šå‚æ•°ä¼˜åŒ–å®Œæˆ")
                
                # åœ¨æµ‹è¯•æ•°æ®ä¸Šè¯„ä¼°
                self.logger.info(f"   ğŸ“Š ç¬¬{i+1}æŠ˜ï¼šå¼€å§‹å›æµ‹è¯„ä¼°...")
                backtest_results = temp_strategy.backtest(test_data)
                evaluation = temp_strategy.evaluate_strategy(backtest_results)
                score = evaluation['score']
                
                fold_scores.append(score)
                total_score += score
                
                fold_time = time.time() - fold_start_time
                self.logger.info(f"   âœ… ç¬¬{i+1}æŠ˜å®Œæˆï¼šå¾—åˆ† {score:.4f}ï¼Œè€—æ—¶ {fold_time:.1f}ç§’")
                
                # æ˜¾ç¤ºæ•´ä½“è¿›åº¦
                elapsed_time = time.time() - cv_start_time
                avg_time_per_fold = elapsed_time / (i + 1)
                remaining_folds = cv_folds - (i + 1)
                estimated_remaining_time = remaining_folds * avg_time_per_fold
                
                self.logger.info(f"   ğŸ“ˆ æ•´ä½“è¿›åº¦ï¼š{fold_progress:.1f}%ï¼Œå·²ç”¨æ—¶é—´ï¼š{elapsed_time:.1f}ç§’ï¼Œé¢„è®¡å‰©ä½™ï¼š{estimated_remaining_time:.1f}ç§’")
                self.logger.info("-" * 40)
            
            if len(fold_scores) == 0:
                self.logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„äº¤å‰éªŒè¯ç»“æœ")
                return 0.0
                
            avg_score = total_score / len(fold_scores)
            total_cv_time = time.time() - cv_start_time
            self.logger.info(f"ğŸ“Š äº¤å‰éªŒè¯å®Œæˆï¼Œå¹³å‡å¾—åˆ†: {avg_score:.4f} (å…±{len(fold_scores)}æŠ˜)")
            self.logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_cv_time:.1f}ç§’ï¼Œå¹³å‡æ¯æŠ˜: {total_cv_time/len(fold_scores):.1f}ç§’")
            
            return avg_score
            
        except Exception as e:
            self.logger.error("âŒ æ—¶é—´åºåˆ—äº¤å‰éªŒè¯å¤±è´¥: %s", str(e))
            return 0.0
    
    def hierarchical_optimization(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        åˆ†å±‚ä¼˜åŒ–ç­–ç•¥ï¼ˆä½¿ç”¨ä¸¥æ ¼æ•°æ®åˆ†å‰²é˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
        
        å‚æ•°:
        data: å†å²æ•°æ®
        
        è¿”å›:
        dict: ä¼˜åŒ–ç»“æœ
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸ—ï¸ å¼€å§‹åˆ†å±‚ä¼˜åŒ–ç­–ç•¥ï¼ˆä¸¥æ ¼æ•°æ®åˆ†å‰²ç‰ˆæœ¬ï¼‰")
        self.logger.info("=" * 60)
        
        try:
            start_time = time.time()
            
            # æ­¥éª¤1ï¼šä¸¥æ ¼æ•°æ®åˆ†å‰²
            self.logger.info("ğŸ”’ ç¬¬ä¸€æ­¥ï¼šä¸¥æ ¼æ•°æ®åˆ†å‰²...")
            data_splits = self.strict_data_split(data, preserve_test_set=True)
            train_data = data_splits['train']
            validation_data = data_splits['validation']
            test_data = data_splits['test']
            
            # ç¬¬ä¸€å±‚ï¼šä»…åœ¨è®­ç»ƒé›†ä¸Šä¼˜åŒ–ç­–ç•¥å‚æ•°
            self.logger.info("ğŸ“Š ç¬¬ä¸€å±‚ï¼šè®­ç»ƒé›†ç­–ç•¥å‚æ•°ä¼˜åŒ–...")
            layer1_start = time.time()
            strategy_module = StrategyModule(self.config)
            
            strategy_params = self.optimize_strategy_parameters_on_train_only(
                strategy_module, train_data
            )
            strategy_module.update_params(strategy_params)
            layer1_time = time.time() - layer1_start
            
            self.logger.info("âœ… ç¬¬ä¸€å±‚å®Œæˆ")
            self.logger.info(f"   - ä¼˜åŒ–å‚æ•°: {strategy_params}")
            self.logger.info(f"   - è€—æ—¶: {layer1_time:.1f}ç§’")
            
            # ç¬¬äºŒå±‚ï¼šåœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒAIæ¨¡å‹ï¼Œåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
            self.logger.info("ğŸ¤– ç¬¬äºŒå±‚ï¼šAIæ¨¡å‹è®­ç»ƒï¼ˆè®­ç»ƒé›†ï¼‰+ è¯„ä¼°ï¼ˆéªŒè¯é›†ï¼‰...")
            layer2_start = time.time()
            
            # ä½¿ç”¨è®­ç»ƒé›†è®­ç»ƒAIæ¨¡å‹
            training_result = self.train_model(train_data, strategy_module)
            
            # ä½¿ç”¨éªŒè¯é›†è¯„ä¼°AIæ¨¡å‹
            validation_result = self.validate_model(validation_data, strategy_module)
            
            layer2_time = time.time() - layer2_start
            self.logger.info("âœ… ç¬¬äºŒå±‚å®Œæˆ")
            self.logger.info(f"   - è®­ç»ƒå‡†ç¡®ç‡: {training_result.get('accuracy', 0):.4f}")
            self.logger.info(f"   - éªŒè¯å‡†ç¡®ç‡: {validation_result.get('accuracy', 0):.4f}")
            self.logger.info(f"   - è€—æ—¶: {layer2_time:.1f}ç§’")
            
            # ç¬¬ä¸‰å±‚ï¼šèµ°å‰éªŒè¯ï¼ˆä½¿ç”¨è®­ç»ƒ+éªŒè¯æ•°æ®ï¼‰
            self.logger.info("ğŸš¶ ç¬¬ä¸‰å±‚ï¼šèµ°å‰éªŒè¯...")
            layer3_start = time.time()
            
            # åˆå¹¶è®­ç»ƒå’ŒéªŒè¯æ•°æ®ç”¨äºèµ°å‰éªŒè¯
            train_val_data = pd.concat([train_data, validation_data]).reset_index(drop=True)
            
            # è·å–èµ°å‰éªŒè¯é…ç½®
            ai_config = self.config.get('ai', {})
            validation_config = ai_config.get('validation', {})
            walk_forward_config = validation_config.get('walk_forward', {})
            
            if walk_forward_config.get('enabled', True):
                wf_result = self.walk_forward_validation(
                    train_val_data, 
                    strategy_module,
                    window_size=walk_forward_config.get('window_size', 252),
                    step_size=walk_forward_config.get('step_size', 63)
                )
                cv_score = wf_result.get('avg_score', 0.0) if wf_result['success'] else 0.0
            else:
                # å¦‚æœç¦ç”¨èµ°å‰éªŒè¯ï¼Œä½¿ç”¨ç®€å•éªŒè¯é›†è¯„ä¼°
                val_backtest = strategy_module.backtest(validation_data)
                val_evaluation = strategy_module.evaluate_strategy(val_backtest)
                cv_score = val_evaluation['score']
            
            layer3_time = time.time() - layer3_start
            self.logger.info("âœ… ç¬¬ä¸‰å±‚å®Œæˆ")
            self.logger.info(f"   - éªŒè¯å¾—åˆ†: {cv_score:.4f}")
            self.logger.info(f"   - è€—æ—¶: {layer3_time:.1f}ç§’")
            
            # ç¬¬å››å±‚ï¼šæœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°ï¼ˆä¸¥æ ¼ä¿æŠ¤ï¼‰
            self.logger.info("ğŸ¯ ç¬¬å››å±‚ï¼šæµ‹è¯•é›†æœ€ç»ˆè¯„ä¼°...")
            layer4_start = time.time()
            
            test_result = self.evaluate_on_test_set_only(strategy_module, test_data)
            test_score = test_result.get('test_score', 0.0) if test_result['success'] else 0.0
            
            layer4_time = time.time() - layer4_start
            self.logger.info("âœ… ç¬¬å››å±‚å®Œæˆ")
            self.logger.info(f"   - æµ‹è¯•é›†å¾—åˆ†: {test_score:.4f}")
            self.logger.info(f"   - è€—æ—¶: {layer4_time:.1f}ç§’")
            
            # æœ€ç»ˆç»“æœç»Ÿè®¡
            total_time = time.time() - start_time
            self.logger.info("=" * 60)
            self.logger.info("ğŸ¯ åˆ†å±‚ä¼˜åŒ–å®Œæˆï¼ï¼ˆä¸¥æ ¼æ•°æ®åˆ†å‰²ç‰ˆæœ¬ï¼‰")
            self.logger.info("=" * 60)
            self.logger.info(f"ğŸ“Š ä¼˜åŒ–ç»Ÿè®¡:")
            self.logger.info(f"   - æ€»è€—æ—¶: {total_time:.1f}ç§’")
            self.logger.info(f"   - ç¬¬ä¸€å±‚ï¼ˆè®­ç»ƒé›†ä¼˜åŒ–ï¼‰: {layer1_time:.1f}ç§’ ({layer1_time/total_time*100:.1f}%)")
            self.logger.info(f"   - ç¬¬äºŒå±‚ï¼ˆAIè®­ç»ƒï¼‰: {layer2_time:.1f}ç§’ ({layer2_time/total_time*100:.1f}%)")
            self.logger.info(f"   - ç¬¬ä¸‰å±‚ï¼ˆèµ°å‰éªŒè¯ï¼‰: {layer3_time:.1f}ç§’ ({layer3_time/total_time*100:.1f}%)")
            self.logger.info(f"   - ç¬¬å››å±‚ï¼ˆæµ‹è¯•è¯„ä¼°ï¼‰: {layer4_time:.1f}ç§’ ({layer4_time/total_time*100:.1f}%)")
            self.logger.info("")
            self.logger.info(f"ğŸ† æœ€ç»ˆç»“æœ:")
            self.logger.info(f"   - éªŒè¯é›†å¾—åˆ†: {cv_score:.4f}")
            self.logger.info(f"   - æµ‹è¯•é›†å¾—åˆ†: {test_score:.4f}")
            self.logger.info(f"   - è¿‡æ‹Ÿåˆæ£€æµ‹: {'é€šè¿‡' if test_score >= cv_score * 0.8 else 'è­¦å‘Š'}")
            
            # è®¡ç®—è¿‡æ‹Ÿåˆç¨‹åº¦
            if cv_score > 0:
                overfitting_ratio = (cv_score - test_score) / cv_score
                if overfitting_ratio > 0.2:
                    self.logger.warning(f"âš ï¸ æ£€æµ‹åˆ°å¯èƒ½çš„è¿‡æ‹Ÿåˆï¼ŒéªŒè¯-æµ‹è¯•å¾—åˆ†å·®å¼‚: {overfitting_ratio:.1%}")
                else:
                    self.logger.info(f"âœ… è¿‡æ‹Ÿåˆé£é™©è¾ƒä½ï¼ŒéªŒè¯-æµ‹è¯•å¾—åˆ†å·®å¼‚: {overfitting_ratio:.1%}")
            
            return {
                'params': strategy_params,
                'cv_score': cv_score,
                'test_score': test_score,
                'best_score': cv_score,  # ä½¿ç”¨éªŒè¯é›†å¾—åˆ†ä½œä¸ºæœ€ä½³å¾—åˆ†
                'total_time': total_time,
                'layer_times': {
                    'layer1': layer1_time,
                    'layer2': layer2_time,
                    'layer3': layer3_time,
                    'layer4': layer4_time
                },
                'data_splits': {
                    'train_size': len(train_data),
                    'validation_size': len(validation_data),
                    'test_size': len(test_data)
                },
                'overfitting_check': {
                    'passed': test_score >= cv_score * 0.8,
                    'validation_score': cv_score,
                    'test_score': test_score,
                    'difference_ratio': (cv_score - test_score) / cv_score if cv_score > 0 else 0
                }
            }
            
        except Exception as e:
            self.logger.error("âŒ åˆ†å±‚ä¼˜åŒ–å¤±è´¥: %s", str(e))
            return {
                'params': self.config.get('strategy', {}),
                'cv_score': 0.0,
                'test_score': 0.0,
                'best_score': 0.0,
                'error': str(e)
            }

    def _evaluate_params_with_fixed_labels_advanced(self, data: pd.DataFrame, fixed_labels: np.ndarray, 
                                                  params: Dict[str, Any]) -> float:
        """
        ä½¿ç”¨å›ºå®šæ ‡ç­¾è¯„ä¼°å¤šå‚æ•°ç­–ç•¥
        
        å‚æ•°:
        data: å†å²æ•°æ®
        fixed_labels: å›ºå®šçš„æ ‡ç­¾ï¼ˆç›¸å¯¹ä½ç‚¹æ ‡è¯†ï¼‰
        params: å‚æ•°å­—å…¸ï¼ŒåŒ…å«rise_threshold, max_days, rsi_oversold_threshold, rsi_low_threshold, final_threshold
        
        è¿”å›:
        float: ç­–ç•¥å¾—åˆ†
        """
        try:
            # 1. è®¡ç®—æ¯ä¸ªè¯†åˆ«ç‚¹çš„æœªæ¥è¡¨ç°
            scores = []
            low_point_indices = np.where(fixed_labels == 1)[0]
            
            rise_threshold = params['rise_threshold']
            max_days = params['max_days']
            
            for idx in low_point_indices:
                if idx >= len(data) - max_days:
                    continue
                    
                current_price = data.iloc[idx]['close']
                max_rise = 0.0
                days_to_rise = 0
                
                # è®¡ç®—æœªæ¥max_dayså†…çš„æœ€å¤§æ¶¨å¹…
                for j in range(1, max_days + 1):
                    if idx + j >= len(data):
                        break
                    future_price = data.iloc[idx + j]['close']
                    rise_rate = (future_price - current_price) / current_price
                    
                    if rise_rate > max_rise:
                        max_rise = rise_rate
                        
                    if rise_rate >= rise_threshold and days_to_rise == 0:
                        days_to_rise = j
                
                # è®¡ç®—å•ä¸ªç‚¹çš„å¾—åˆ†
                success = max_rise >= rise_threshold
                point_score = self._calculate_point_score(success, max_rise, days_to_rise, max_days)
                scores.append(point_score)
            
            # 2. è®¡ç®—æ€»ä½“å¾—åˆ†
            if len(scores) == 0:
                return 0.0
                
            return np.mean(scores)
            
        except Exception as e:
            self.logger.error("è¯„ä¼°å¤šå‚æ•°å¤±è´¥: %s", str(e))
            return 0.0

    def _save_parameter_history(self, params: Dict[str, Any], score: float) -> bool:
        """
        ä¿å­˜å‚æ•°å†å²è®°å½•
        
        å‚æ•°:
        params: å‚æ•°å­—å…¸
        score: å¯¹åº”çš„å¾—åˆ†
        
        è¿”å›:
        bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # è¯»å–ç°æœ‰å†å²è®°å½•
            history = []
            if os.path.exists(self.parameter_history_file):
                with open(self.parameter_history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            
            # æ·»åŠ æ–°è®°å½•
            record = {
                'timestamp': datetime.now().isoformat(),
                'parameters': params,
                'score': score
            }
            history.append(record)
            
            # ä»é…ç½®æ–‡ä»¶è·å–æœ€å¤§è®°å½•æ•°
            ai_config = self.config.get('ai', {})
            optimization_config = ai_config.get('optimization', {})
            max_history_records = optimization_config.get('max_history_records', 100)
            enable_history = optimization_config.get('enable_history', True)
            
            # åªä¿ç•™æœ€è¿‘Næ¡è®°å½•
            if len(history) > max_history_records:
                history = history[-max_history_records:]
            
            # ä¿å­˜å†å²è®°å½•
            if enable_history:
                with open(self.parameter_history_file, 'w', encoding='utf-8') as f:
                    json.dump(history, f, indent=2, ensure_ascii=False)
                
                self.logger.info(f"å‚æ•°å†å²è®°å½•ä¿å­˜æˆåŠŸ (å…±{len(history)}æ¡è®°å½•)")
            else:
                self.logger.info("å‚æ•°å†å²è®°å½•åŠŸèƒ½å·²ç¦ç”¨")
            
            return True
            
        except Exception as e:
            self.logger.error("ä¿å­˜å‚æ•°å†å²è®°å½•å¤±è´¥: %s", str(e))
            return False
    
    def _load_best_parameters(self) -> Optional[Dict[str, Any]]:
        """
        åŠ è½½å†å²æœ€ä¼˜å‚æ•°
        
        è¿”å›:
        dict: å†å²æœ€ä¼˜å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        try:
            if not os.path.exists(self.best_parameters_file):
                self.logger.info("æ²¡æœ‰æ‰¾åˆ°å†å²æœ€ä¼˜å‚æ•°æ–‡ä»¶")
                return None
            
            with open(self.best_parameters_file, 'r', encoding='utf-8') as f:
                best_record = json.load(f)
            
            self.logger.info("åŠ è½½å†å²æœ€ä¼˜å‚æ•°æˆåŠŸ")
            self.logger.info(f"   - å†å²æœ€ä¼˜å¾—åˆ†: {best_record.get('score', 0):.4f}")
            self.logger.info(f"   - å†å²æœ€ä¼˜å‚æ•°: {best_record.get('parameters', {})}")
            
            return best_record.get('parameters')
            
        except Exception as e:
            self.logger.error("åŠ è½½å†å²æœ€ä¼˜å‚æ•°å¤±è´¥: %s", str(e))
            return None
    
    def _save_best_parameters(self, params: Dict[str, Any], score: float) -> bool:
        """
        ä¿å­˜å½“å‰æœ€ä¼˜å‚æ•°
        
        å‚æ•°:
        params: å‚æ•°å­—å…¸
        score: å¯¹åº”çš„å¾—åˆ†
        
        è¿”å›:
        bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            record = {
                'timestamp': datetime.now().isoformat(),
                'parameters': params,
                'score': score
            }
            
            with open(self.best_parameters_file, 'w', encoding='utf-8') as f:
                json.dump(record, f, indent=2, ensure_ascii=False)
            
            self.logger.info("å½“å‰æœ€ä¼˜å‚æ•°ä¿å­˜æˆåŠŸ")
            return True
            
        except Exception as e:
            self.logger.error("ä¿å­˜å½“å‰æœ€ä¼˜å‚æ•°å¤±è´¥: %s", str(e))
            return False
    
    def _get_incremental_search_ranges(self, base_params: Dict[str, Any], 
                                     optimization_ranges: Dict[str, Any]) -> Dict[str, np.ndarray]:
        """
        åŸºäºå†å²æœ€ä¼˜å‚æ•°ç”Ÿæˆå¢é‡æœç´¢èŒƒå›´
        
        å‚æ•°:
        base_params: åŸºç¡€å‚æ•°ï¼ˆå†å²æœ€ä¼˜å‚æ•°ï¼‰
        optimization_ranges: å®Œæ•´æœç´¢èŒƒå›´é…ç½®
        
        è¿”å›:
        dict: å¢é‡æœç´¢èŒƒå›´
        """
        try:
            incremental_ranges = {}
            
            # ä»é…ç½®æ–‡ä»¶è·å–æ”¶ç¼©æ¯”ä¾‹
            ai_config = self.config.get('ai', {})
            optimization_config = ai_config.get('optimization', {})
            contraction_factor = optimization_config.get('incremental_contraction_factor', 0.3)
            
            self.logger.info(f"ğŸ“Š å¢é‡æœç´¢æ”¶ç¼©æ¯”ä¾‹: {contraction_factor}")
            
            # å®šä¹‰æ‰€æœ‰å¿…éœ€çš„å‚æ•°åŠå…¶é»˜è®¤å€¼
            required_params = {
                'rsi_oversold_threshold': {'type': 'int', 'default': 30},
                'rsi_low_threshold': {'type': 'int', 'default': 40},
                'final_threshold': {'type': 'float', 'default': 0.5},
                'dynamic_confidence_adjustment': {'type': 'float', 'default': 0.15},
                'market_sentiment_weight': {'type': 'float', 'default': 0.15},
                'trend_strength_weight': {'type': 'float', 'default': 0.12},
                'volume_weight': {'type': 'float', 'default': 0.25},
                'price_momentum_weight': {'type': 'float', 'default': 0.20}
            }
            
            for param_name, param_info in required_params.items():
                # è·³è¿‡æ ¸å¿ƒå‚æ•°
                if param_name in ['rise_threshold', 'max_days']:
                    continue
                
                # è·å–åŸºç¡€å€¼ï¼ˆä»å†å²å‚æ•°æˆ–é»˜è®¤å€¼ï¼‰
                base_value = base_params.get(param_name, param_info['default'])
                
                # è·å–å‚æ•°èŒƒå›´é…ç½®
                param_range = optimization_ranges.get(param_name, {})
                
                # è®¾ç½®é»˜è®¤èŒƒå›´
                if param_name == 'rsi_oversold_threshold':
                    min_val = param_range.get('min', 25)
                    max_val = param_range.get('max', 35)
                    step = param_range.get('step', 1)
                elif param_name == 'rsi_low_threshold':
                    min_val = param_range.get('min', 35)
                    max_val = param_range.get('max', 45)
                    step = param_range.get('step', 1)
                elif param_name == 'final_threshold':
                    min_val = param_range.get('min', 0.3)
                    max_val = param_range.get('max', 0.7)
                    step = param_range.get('step', 0.05)
                elif param_name == 'dynamic_confidence_adjustment':
                    min_val = param_range.get('min', 0.05)
                    max_val = param_range.get('max', 0.25)
                    step = param_range.get('step', 0.02)
                elif param_name == 'market_sentiment_weight':
                    min_val = param_range.get('min', 0.08)
                    max_val = param_range.get('max', 0.25)
                    step = param_range.get('step', 0.02)
                elif param_name == 'trend_strength_weight':
                    min_val = param_range.get('min', 0.06)
                    max_val = param_range.get('max', 0.20)
                    step = param_range.get('step', 0.02)
                elif param_name == 'volume_weight':
                    min_val = param_range.get('min', 0.15)
                    max_val = param_range.get('max', 0.35)
                    step = param_range.get('step', 0.02)
                elif param_name == 'price_momentum_weight':
                    min_val = param_range.get('min', 0.12)
                    max_val = param_range.get('max', 0.30)
                    step = param_range.get('step', 0.02)
                else:
                    # ä½¿ç”¨é€šç”¨é»˜è®¤å€¼
                    min_val = param_range.get('min', 0)
                    max_val = param_range.get('max', 1)
                    step = param_range.get('step', 0.01)
                
                # è®¡ç®—å¢é‡æœç´¢èŒƒå›´
                range_width = max_val - min_val
                incremental_width = range_width * contraction_factor
                
                # ä»¥åŸºç¡€å€¼ä¸ºä¸­å¿ƒï¼Œå‘ä¸¤è¾¹æ‰©å±•
                new_min = max(min_val, base_value - incremental_width / 2)
                new_max = min(max_val, base_value + incremental_width / 2)
                
                # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªå€¼
                if new_min >= new_max:
                    new_min = max(min_val, base_value - step)
                    new_max = min(max_val, base_value + step)
                
                # ç”Ÿæˆæœç´¢æ•°ç»„
                if param_info['type'] == 'int':
                    # æ•´æ•°å‚æ•°
                    incremental_ranges[param_name] = np.arange(
                        int(new_min), int(new_max) + 1, max(1, int(step))
                    )
                else:
                    # æµ®ç‚¹æ•°å‚æ•°
                    incremental_ranges[param_name] = np.arange(
                        new_min, new_max + step, step
                    )
                
                # ç¡®ä¿æ•°ç»„ä¸ä¸ºç©º
                if len(incremental_ranges[param_name]) == 0:
                    incremental_ranges[param_name] = np.array([base_value])
                
                self.logger.info(f"   - {param_name}: {new_min:.4f} - {new_max:.4f} (åŸºäº {base_value:.4f})")
            
            return incremental_ranges
            
        except Exception as e:
            self.logger.error("ç”Ÿæˆå¢é‡æœç´¢èŒƒå›´å¤±è´¥: %s", str(e))
            # è¿”å›é»˜è®¤å‚æ•°ç½‘æ ¼ä½œä¸ºå¤‡é€‰
            return self._build_parameter_grid(optimization_ranges)

    def _build_parameter_grid(self, optimization_ranges: Dict[str, Any]) -> Dict[str, np.ndarray]:
        """
        æ„å»ºå‚æ•°æœç´¢ç½‘æ ¼
        
        å‚æ•°:
        optimization_ranges: å‚æ•°æœç´¢èŒƒå›´é…ç½®
        
        è¿”å›:
        dict: å‚æ•°æœç´¢ç½‘æ ¼
        """
        param_grid = {}
        
        # å®šä¹‰å‚æ•°é…ç½®
        param_configs = {
            'rsi_oversold_threshold': {'type': 'int', 'default_min': 25, 'default_max': 35, 'default_step': 1},
            'rsi_low_threshold': {'type': 'int', 'default_min': 35, 'default_max': 45, 'default_step': 1},
            'final_threshold': {'type': 'float', 'default_min': 0.3, 'default_max': 0.7, 'default_step': 0.05},
            'dynamic_confidence_adjustment': {'type': 'float', 'default_min': 0.05, 'default_max': 0.25, 'default_step': 0.02},
            'market_sentiment_weight': {'type': 'float', 'default_min': 0.08, 'default_max': 0.25, 'default_step': 0.02},
            'trend_strength_weight': {'type': 'float', 'default_min': 0.06, 'default_max': 0.20, 'default_step': 0.02},
            'volume_weight': {'type': 'float', 'default_min': 0.15, 'default_max': 0.35, 'default_step': 0.02},
            'price_momentum_weight': {'type': 'float', 'default_min': 0.12, 'default_max': 0.30, 'default_step': 0.02}
        }
        
        for param_name, config in param_configs.items():
            param_range = optimization_ranges.get(param_name, {})
            min_val = param_range.get('min', config['default_min'])
            max_val = param_range.get('max', config['default_max'])
            step = param_range.get('step', config['default_step'])
            
            if config['type'] == 'int':
                param_grid[param_name] = np.arange(min_val, max_val + 1, step)
            else:
                param_grid[param_name] = np.arange(min_val, max_val + step, step)
        
        return param_grid

    def _validate_optimization_config(self, optimization_ranges: Dict[str, Any]) -> bool:
        """
        éªŒè¯ä¼˜åŒ–é…ç½®çš„åˆç†æ€§
        
        å‚æ•°:
        optimization_ranges: å‚æ•°æœç´¢èŒƒå›´é…ç½®
        
        è¿”å›:
        bool: é…ç½®æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            required_params = [
                'rsi_oversold_threshold', 'rsi_low_threshold', 'final_threshold',
                'dynamic_confidence_adjustment', 'market_sentiment_weight', 'trend_strength_weight',
                'volume_weight', 'price_momentum_weight'
            ]
            
            for param in required_params:
                if param not in optimization_ranges:
                    self.logger.warning(f"å‚æ•° {param} æœªåœ¨é…ç½®ä¸­å®šä¹‰ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")
                    continue
                
                param_range = optimization_ranges[param]
                min_val = param_range.get('min')
                max_val = param_range.get('max')
                step = param_range.get('step')
                
                if min_val is None or max_val is None or step is None:
                    self.logger.error(f"å‚æ•° {param} é…ç½®ä¸å®Œæ•´ï¼Œç¼ºå°‘ min/max/step")
                    return False
                
                if min_val >= max_val:
                    self.logger.error(f"å‚æ•° {param} èŒƒå›´é…ç½®é”™è¯¯: min({min_val}) >= max({max_val})")
                    return False
                
                if step <= 0:
                    self.logger.error(f"å‚æ•° {param} æ­¥é•¿é…ç½®é”™è¯¯: step({step}) <= 0")
                    return False
            
            self.logger.info("âœ… ä¼˜åŒ–é…ç½®éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            self.logger.error(f"é…ç½®éªŒè¯å¤±è´¥: {str(e)}")
            return False


