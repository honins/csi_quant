#!/usr/bin/env python3
"""
åˆ†æé”™åˆ¤æ ·æœ¬è„šæœ¬
ä½¿ç”¨failure_analysisæ¨¡å—åˆ†ææœ€æ–°å›æµ‹ä¸­çš„é”™åˆ¤æ ·æœ¬ï¼Œè¾“å‡ºæ”¹è¿›å»ºè®®
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
import json

# æ·»åŠ srcè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from ai.failure_analysis import FailureAnalyzer
from strategy.strategy_module import StrategyModule
from data.data_module import DataModule

def load_latest_backtest_results():
    """åŠ è½½æœ€æ–°çš„å›æµ‹ç»“æœ"""
    csv_dir = "results/csv"
    if not os.path.exists(csv_dir):
        print(f"âŒ CSVç›®å½•ä¸å­˜åœ¨: {csv_dir}")
        return None
    
    # æ‰¾åˆ°æœ€æ–°çš„CSVæ–‡ä»¶
    csv_files = [f for f in os.listdir(csv_dir) if f.startswith("daily_details_rolling_backtest_") and f.endswith(".csv")]
    if not csv_files:
        print("âŒ æœªæ‰¾åˆ°å›æµ‹CSVæ–‡ä»¶")
        return None
    
    latest_csv = sorted(csv_files)[-1]
    csv_path = os.path.join(csv_dir, latest_csv)
    
    print(f"ğŸ“„ åŠ è½½æœ€æ–°å›æµ‹ç»“æœ: {csv_path}")
    
    try:
        df = pd.read_csv(csv_path)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è®°å½•")
        return df
    except Exception as e:
        print(f"âŒ åŠ è½½CSVæ–‡ä»¶å¤±è´¥: {e}")
        return None

def analyze_failed_predictions(backtest_df, data_df, config):
    """åˆ†æé”™åˆ¤æ ·æœ¬"""
    print("\nğŸ” å¼€å§‹åˆ†æé”™åˆ¤æ ·æœ¬...")
    
    # åˆå§‹åŒ–å¤±è´¥åˆ†æå™¨
    failure_analyzer = FailureAnalyzer(config)
    
    # å‡†å¤‡å›æµ‹ç»“æœæ ¼å¼
    backtest_results = []
    for _, row in backtest_df.iterrows():
        result = {
            'date': row['æ—¥æœŸ'],
            'is_low_point': row['é¢„æµ‹ä½ç‚¹'] == 'True',  # ä½¿ç”¨'True'å­—ç¬¦ä¸²æ¯”è¾ƒ
            'prediction': row['é¢„æµ‹ä½ç‚¹'] == 'True',
            'confidence': row['ç½®ä¿¡åº¦'],
            'strategy_confidence': row['ç­–ç•¥ç½®ä¿¡åº¦'],
            'actual_return': 0,  # CSVä¸­æ²¡æœ‰è¿™ä¸ªå­—æ®µï¼Œè®¾ä¸º0
            'future_max_rise': row['æœªæ¥æœ€å¤§æ¶¨å¹…'],
            'is_correct': row['é¢„æµ‹æ­£ç¡®'] == 'True',  # ä½¿ç”¨'True'å­—ç¬¦ä¸²æ¯”è¾ƒ
            'exit_date': '',  # CSVä¸­æ²¡æœ‰è¿™ä¸ªå­—æ®µ
            'exit_price': 0,  # CSVä¸­æ²¡æœ‰è¿™ä¸ªå­—æ®µ
            'trade_return': 0,  # CSVä¸­æ²¡æœ‰è¿™ä¸ªå­—æ®µ
            'price': row['é¢„æµ‹ä»·æ ¼'],  # ä½¿ç”¨é¢„æµ‹ä»·æ ¼ä½œä¸ºä¿¡å·ä»·æ ¼
            'close': row['é¢„æµ‹ä»·æ ¼']  # åŒæ—¶æä¾›closeå­—æ®µ
        }
        backtest_results.append(result)
    
    # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°æ ·æœ¬ç»Ÿè®¡
    df_results = pd.DataFrame(backtest_results)
    total_predictions = len(df_results)
    low_point_predictions = df_results['is_low_point'].sum()
    correct_predictions = df_results['is_correct'].sum()
    incorrect_predictions = total_predictions - correct_predictions
    
    print(f"   æ€»é¢„æµ‹æ•°: {total_predictions}")
    print(f"   é¢„æµ‹ä¸ºä½ç‚¹æ•°: {low_point_predictions}")
    print(f"   é¢„æµ‹æ­£ç¡®æ•°: {correct_predictions}")
    print(f"   é¢„æµ‹é”™è¯¯æ•°: {incorrect_predictions}")
    
    # æ£€æŸ¥rise_threshold
    rise_threshold = config.get('strategy', {}).get('rise_threshold', 0.04)
    print(f"   æ¶¨å¹…é˜ˆå€¼: {rise_threshold}")
    
    # æ”¹è¿›çš„å¤±è´¥æ¡ˆä¾‹æ£€æµ‹é€»è¾‘ï¼š
    # 1. é¢„æµ‹ä¸ºä½ç‚¹ä½†æœªæ¥æ¶¨å¹…æœªè¾¾åˆ°é˜ˆå€¼ï¼ˆä¼ ç»Ÿå®šä¹‰ï¼‰
    # 2. é¢„æµ‹é”™è¯¯çš„æ¡ˆä¾‹ï¼ˆæ›´å¹¿æ³›çš„å¤±è´¥å®šä¹‰ï¼‰
    traditional_failed_cases = df_results[
        (df_results['is_low_point'] == True) & 
        (df_results['future_max_rise'] < rise_threshold)
    ]
    
    # é¢„æµ‹é”™è¯¯çš„æ¡ˆä¾‹ï¼ˆåŒ…æ‹¬é¢„æµ‹ä¸ºä½ç‚¹ä½†å®é™…ä¸æ˜¯ï¼Œä»¥åŠé¢„æµ‹ä¸æ˜¯ä½ç‚¹ä½†å®é™…æ˜¯ï¼‰
    prediction_failed_cases = df_results[df_results['is_correct'] == False]
    
    print(f"   ä¼ ç»Ÿå¤±è´¥æ¡ˆä¾‹æ•°ï¼ˆé¢„æµ‹ä½ç‚¹ä½†æ¶¨å¹…ä¸è¶³ï¼‰: {len(traditional_failed_cases)}")
    print(f"   é¢„æµ‹é”™è¯¯æ¡ˆä¾‹æ•°: {len(prediction_failed_cases)}")
    
    # é€‰æ‹©åˆ†æçš„å¤±è´¥æ¡ˆä¾‹
    if len(traditional_failed_cases) > 0:
        # å¦‚æœæœ‰ä¼ ç»Ÿå¤±è´¥æ¡ˆä¾‹ï¼Œä¼˜å…ˆåˆ†æè¿™äº›
        failed_cases_to_analyze = traditional_failed_cases
        print(f"   âœ… ä½¿ç”¨ä¼ ç»Ÿå¤±è´¥æ¡ˆä¾‹è¿›è¡Œåˆ†æ: {len(failed_cases_to_analyze)} ä¸ª")
    elif len(prediction_failed_cases) > 0:
        # å¦åˆ™åˆ†æé¢„æµ‹é”™è¯¯çš„æ¡ˆä¾‹
        failed_cases_to_analyze = prediction_failed_cases.head(10)  # é™åˆ¶æ•°é‡é¿å…è¿‡å¤š
        print(f"   âœ… ä½¿ç”¨é¢„æµ‹é”™è¯¯æ¡ˆä¾‹è¿›è¡Œåˆ†æ: {len(failed_cases_to_analyze)} ä¸ª")
        
        # ä¸ºè¿™äº›æ¡ˆä¾‹æ·»åŠ å¤±è´¥æ ‡è®°ï¼Œä¾¿äºfailure_analyzerå¤„ç†
        for idx in failed_cases_to_analyze.index:
            backtest_results[idx]['analysis_type'] = 'prediction_error'
            # å¦‚æœæœªæ¥æ¶¨å¹…è¾¾åˆ°é˜ˆå€¼ä½†é¢„æµ‹é”™è¯¯ï¼Œå¯èƒ½æ˜¯å…¶ä»–ç±»å‹çš„é”™è¯¯
            if backtest_results[idx]['future_max_rise'] >= rise_threshold:
                backtest_results[idx]['analysis_type'] = 'false_negative'  # æ¼åˆ¤
            else:
                backtest_results[idx]['analysis_type'] = 'false_positive'  # è¯¯åˆ¤
    else:
        print("   âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•å¤±è´¥æ¡ˆä¾‹")
        return {
            'total_failures': 0,
            'failure_rate': 0.0,
            'failure_types': {},
            'detailed_analysis': [],
            'recommendations': []
        }
    
    # æ‰§è¡Œå¤±è´¥åˆ†æ
    failure_analysis = failure_analyzer.analyze_failures(backtest_results, data_df)
    
    return failure_analysis

def print_failure_analysis(failure_analysis):
    """æ‰“å°å¤±è´¥åˆ†æç»“æœ"""
    print("\n" + "="*60)
    print("ğŸ“Š é”™åˆ¤æ ·æœ¬åˆ†ææŠ¥å‘Š")
    print("="*60)
    
    # åŸºæœ¬ç»Ÿè®¡
    total_failures = failure_analysis.get('total_failures', 0)
    failure_rate = failure_analysis.get('failure_rate', 0)
    
    print(f"\nğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
    print(f"   æ€»é”™åˆ¤æ•°: {total_failures}")
    print(f"   é”™åˆ¤ç‡: {failure_rate:.2%}")
    
    # å¤±è´¥ç±»å‹åˆ†å¸ƒ
    failure_types = failure_analysis.get('failure_types', {})
    if failure_types:
        print(f"\nğŸ·ï¸ å¤±è´¥ç±»å‹åˆ†å¸ƒ:")
        for failure_type, info in failure_types.items():
            count = info.get('count', 0)
            percentage = info.get('percentage', 0)
            print(f"   {failure_type}: {count}æ¬¡ ({percentage:.1%})")
    
    # è¯¦ç»†åˆ†æ
    detailed_analysis = failure_analysis.get('detailed_analysis', [])
    if detailed_analysis:
        print(f"\nğŸ” è¯¦ç»†å¤±è´¥æ¡ˆä¾‹åˆ†æ (å‰5ä¸ª):")
        for i, analysis in enumerate(detailed_analysis[:5]):
            print(f"\n   æ¡ˆä¾‹ {i+1}:")
            print(f"     æ—¥æœŸ: {analysis.get('date', 'N/A')}")
            print(f"     å¤±è´¥ç±»å‹: {analysis.get('failure_type', 'N/A')}")
            print(f"     ç½®ä¿¡åº¦: {analysis.get('confidence', 0):.3f}")
            print(f"     ç­–ç•¥ç½®ä¿¡åº¦: {analysis.get('strategy_confidence', 0):.3f}")
            print(f"     å®é™…æ¶¨å¹…: {analysis.get('actual_rise', 0):.2%}")
            print(f"     åˆ†æåŸå› : {analysis.get('analysis', 'N/A')}")
    
    # æ”¹è¿›å»ºè®®
    recommendations = failure_analysis.get('recommendations', [])
    if recommendations:
        print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. {rec}")
    
    # é¢„æœŸæ”¹è¿›æ•ˆæœ
    expected_improvements = failure_analysis.get('expected_improvements', {})
    if expected_improvements:
        print(f"\nğŸ“ˆ é¢„æœŸæ”¹è¿›æ•ˆæœ:")
        for metric, improvement in expected_improvements.items():
            if isinstance(improvement, (int, float)):
                print(f"   {metric}: +{improvement:.2%}")
            else:
                print(f"   {metric}: {improvement}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨é”™åˆ¤æ ·æœ¬åˆ†æ...")
    
    # åŠ è½½é…ç½®
    try:
        from utils.config_loader import load_config
        config = load_config()
        print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return
    
    # åŠ è½½æœ€æ–°å›æµ‹ç»“æœ
    backtest_df = load_latest_backtest_results()
    if backtest_df is None:
        return
    
    # åŠ è½½å†å²æ•°æ®
    try:
        data_module = DataModule(config)
        # è·å–å›æµ‹æ—¥æœŸèŒƒå›´
        start_date = backtest_df['æ—¥æœŸ'].min()
        end_date = backtest_df['æ—¥æœŸ'].max()
        print(f"ğŸ“… å›æµ‹æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date}")
        
        # åŠ è½½æ›´å¤§èŒƒå›´çš„æ•°æ®ä»¥ä¾¿åˆ†æ
        from datetime import datetime, timedelta
        start_dt = datetime.strptime(start_date, '%Y-%m-%d') - timedelta(days=100)
        extended_start = start_dt.strftime('%Y-%m-%d')
        
        data_df = data_module.get_history_data(extended_start, end_date)
        print(f"âœ… æˆåŠŸåŠ è½½å†å²æ•°æ® {len(data_df)} æ¡è®°å½•")
    except Exception as e:
        print(f"âŒ å†å²æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # åˆ†æé”™åˆ¤æ ·æœ¬
    try:
        failure_analysis = analyze_failed_predictions(backtest_df, data_df, config)
        
        # æ‰“å°åˆ†æç»“æœ
        print_failure_analysis(failure_analysis)
        
        # ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"results/failure_analysis_{timestamp}.json"
        
        os.makedirs("results", exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(failure_analysis, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
    except Exception as e:
        print(f"âŒ é”™åˆ¤åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()